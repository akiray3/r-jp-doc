x
These unary and binary operators perform arithmetic on numeric orcomplex vectors (or objects which can be coerced to them).
Operators for the "Date" class.
Description of the classes "POSIXlt" and "POSIXct"representing calendar dates and times.
Generate regular sequences.
Accessing exported and internal variables, i.e. R objects(including lazy loaded data sets) in a namespace.
Accessing exported and internal variables, i.e. R objects(including lazy loaded data sets) in a namespace.
These operators act on raw, logical and number-like vectors.
Convert or print integers in hexadecimal format, with as many digitsas are needed to display the largest, using leading zeroes asnecessary.
Convert or print integers in octal format, with as many digits as areneeded to display the largest, using leading zeroes as necessary.
Binary operators which allow the comparison of values in atomic vectors.
Open parenthesis, (, and open brace, {, are.Primitive functions in R.
Operators acting on vectors, matrices, arrays and lists to extract orreplace parts.
Change the class of an object to indicate that it should be treated‘as is’.
Extract or replace subsets of data frames.
Description of the class "Date" representing calendar dates.
Time intervals creation, printing, and some arithmetic.  Theprint() method calls these “time differences”.
Operators acting on vectors, matrices, arrays and lists to extract orreplace parts.
This function provides a way to get a list of all the DLLs (seedyn.load) that are currently loaded in the R session.
Extract or replace subsets of factors.
Convert or print integers in hexadecimal format, with as many digitsas are needed to display the largest, using leading zeroes asnecessary.
Operators acting on vectors, matrices, arrays and lists to extract orreplace parts.
Print character strings without quotes.
A simple S3 class for representing numeric versionsincluding package versions, and associated methods.
Convert or print integers in octal format, with as many digits as areneeded to display the largest, using leading zeroes as necessary.
Description of the classes "POSIXlt" and "POSIXct"representing calendar dates and times.
Description of the classes "POSIXlt" and "POSIXct"representing calendar dates and times.
Operators acting on vectors, matrices, arrays and lists to extract orreplace parts.
table uses the cross-classifying factors to build a contingencytable of the counts at each combination of factor levels.
warnings and its print method print thevariable last.warning in a pleasing form.
Operators acting on vectors, matrices, arrays and lists to extract orreplace parts.
Extract or replace subsets of data frames.
Description of the class "Date" representing calendar dates.
Extract or replace subsets of factors.
A simple S3 class for representing numeric versionsincluding package versions, and associated methods.
Description of the classes "POSIXlt" and "POSIXct"representing calendar dates and times.
Description of the classes "POSIXlt" and "POSIXct"representing calendar dates and times.
Operators acting on vectors, matrices, arrays and lists to extract orreplace parts.
Extract or replace subsets of data frames.
Extract or replace subsets of factors.
A simple S3 class for representing numeric versionsincluding package versions, and associated methods.
Description of the classes "POSIXlt" and "POSIXct"representing calendar dates and times.
Operators acting on vectors, matrices, arrays and lists to extract orreplace parts.
Extract or replace subsets of data frames.
Description of the class "Date" representing calendar dates.
Time intervals creation, printing, and some arithmetic.  Theprint() method calls these “time differences”.
Extract or replace subsets of factors.
A simple S3 class for representing numeric versionsincluding package versions, and associated methods.
Description of the classes "POSIXlt" and "POSIXct"representing calendar dates and times.
Description of the classes "POSIXlt" and "POSIXct"representing calendar dates and times.
Open parenthesis, (, and open brace, {, are.Primitive functions in R.
Extract or replace the contents of a slot in a object with aformal (S4) class structure.
Extract or replace the contents of a slot in a object with aformal (S4) class structure.
These unary and binary operators perform arithmetic on numeric orcomplex vectors (or objects which can be coerced to them).
Time intervals creation, printing, and some arithmetic.  Theprint() method calls these “time differences”.
These unary and binary operators perform arithmetic on numeric orcomplex vectors (or objects which can be coerced to them).
Time intervals creation, printing, and some arithmetic.  Theprint() method calls these “time differences”.
These operators act on raw, logical and number-like vectors.
Convert or print integers in hexadecimal format, with as many digitsas are needed to display the largest, using leading zeroes asnecessary.
Convert or print integers in octal format, with as many digits as areneeded to display the largest, using leading zeroes as necessary.
These operators act on raw, logical and number-like vectors.
Multiplies two matrices, if they are conformable.  If one argument isa vector, it will be promoted to either a row or column matrix to makethe two arguments conformable.  If both are vectors of the samelength, it will return the inner product (as a matrix).
These unary and binary operators perform arithmetic on numeric orcomplex vectors (or objects which can be coerced to them).
These unary and binary operators perform arithmetic on numeric orcomplex vectors (or objects which can be coerced to them).
match returns a vector of the positions of (first) matches ofits first argument in its second.
The outer product of the arrays X and Y is the arrayA with dimension c(dim(X), dim(Y)) where elementA[c(arrayindex.x, arrayindex.y)]    = FUN(X[arrayindex.x], Y[arrayindex.y], ...).
Computes the generalised kronecker product of two arrays,X and Y.
These unary and binary operators perform arithmetic on numeric orcomplex vectors (or objects which can be coerced to them).
These unary and binary operators perform arithmetic on numeric orcomplex vectors (or objects which can be coerced to them).
Operators for the "Date" class.
Description of the classes "POSIXlt" and "POSIXct"representing calendar dates and times.
Binary operators which allow the comparison of values in atomic vectors.
Assign a value to a name.
Assign a value to a name.
Binary operators which allow the comparison of values in atomic vectors.
Assign a value to a name.
Binary operators which allow the comparison of values in atomic vectors.
Binary operators which allow the comparison of values in atomic vectors.
Binary operators which allow the comparison of values in atomic vectors.
These operators act on raw, logical and number-like vectors.
Convert or print integers in hexadecimal format, with as many digitsas are needed to display the largest, using leading zeroes asnecessary.
Convert or print integers in octal format, with as many digits as areneeded to display the largest, using leading zeroes as necessary.
These operators act on raw, logical and number-like vectors.
Tilde is used to separate the left- and right-hand sides in a model formula.
Operators acting on vectors, matrices, arrays and lists to extract orreplace parts.
This function provides a way to get a list of all the DLLs (seedyn.load) that are currently loaded in the R session.
A simple S3 class for representing numeric versionsincluding package versions, and associated methods.
Operators acting on vectors, matrices, arrays and lists to extract orreplace parts.
Extract or replace subsets of data frames.
Abbreviate strings to at least minlength characters,such that they remain unique (if they were),unless strict = TRUE.
abs(x) computes the absolute value of x, sqrt(x) computes the(principal) square root of x, √{x}.
These functions give the obvious trigonometric functions.  Theyrespectively compute the cosine, sine, tangent, arc-cosine, arc-sine,arc-tangent, and the two-argument arc-tangent.
These functions give the obvious hyperbolic functions.  Theyrespectively compute the hyperbolic cosine, sine, tangent, and theirinverses, arc-cosine, arc-sine, arc-tangent (or ‘area cosine’,etc).
These functions represent an interface for adjustmentsto environments and bindings within environments.  They allow forlocking environments as well as individual bindings, and for linkinga variable to a function.
The function factor is used to encode a vector as a factor (theterms ‘category’ and ‘enumerated type’ are also used forfactors).  If argument ordered is TRUE, the factorlevels are assumed to be ordered.  For compatibility with S there isalso a function ordered.
addTaskCallback registers an R functionthat is to be called each time a top-level taskis completed.
Searches for approximate matches to pattern (the first argument)within each element of the string x (the second argument) usingthe generalized Levenshtein edit distance (the minimal possiblyweighted number of insertions, deletions and substitutions needed totransform one string into another).
Searches for approximate matches to pattern (the first argument)within each element of the string x (the second argument) usingthe generalized Levenshtein edit distance (the minimal possiblyweighted number of insertions, deletions and substitutions needed totransform one string into another).
Functions to construct, coerce and check for both kinds of R lists.
Given a set of logical vectors, are all of the values true?
all.equal(x, y) is a utility to compare R objects xand y testing ‘near equality’.  If they are different,comparison is still made to some extent, and a report of thedifferences is returned.    Do not use all.equal directly inif expressions—either use isTRUE(all.equal(....)) oridentical if appropriate.
all.equal(x, y) is a utility to compare R objects xand y testing ‘near equality’.  If they are different,comparison is still made to some extent, and a report of thedifferences is returned.    Do not use all.equal directly inif expressions—either use isTRUE(all.equal(....)) oridentical if appropriate.
all.equal(x, y) is a utility to compare R objects xand y testing ‘near equality’.  If they are different,comparison is still made to some extent, and a report of thedifferences is returned.    Do not use all.equal directly inif expressions—either use isTRUE(all.equal(....)) oridentical if appropriate.
all.equal(x, y) is a utility to compare R objects xand y testing ‘near equality’.  If they are different,comparison is still made to some extent, and a report of thedifferences is returned.    Do not use all.equal directly inif expressions—either use isTRUE(all.equal(....)) oridentical if appropriate.
all.equal(x, y) is a utility to compare R objects xand y testing ‘near equality’.  If they are different,comparison is still made to some extent, and a report of thedifferences is returned.    Do not use all.equal directly inif expressions—either use isTRUE(all.equal(....)) oridentical if appropriate.
all.equal(x, y) is a utility to compare R objects xand y testing ‘near equality’.  If they are different,comparison is still made to some extent, and a report of thedifferences is returned.    Do not use all.equal directly inif expressions—either use isTRUE(all.equal(....)) oridentical if appropriate.
all.equal(x, y) is a utility to compare R objects xand y testing ‘near equality’.  If they are different,comparison is still made to some extent, and a report of thedifferences is returned.    Do not use all.equal directly inif expressions—either use isTRUE(all.equal(....)) oridentical if appropriate.
all.equal(x, y) is a utility to compare R objects xand y testing ‘near equality’.  If they are different,comparison is still made to some extent, and a report of thedifferences is returned.    Do not use all.equal directly inif expressions—either use isTRUE(all.equal(....)) oridentical if appropriate.
all.equal(x, y) is a utility to compare R objects xand y testing ‘near equality’.  If they are different,comparison is still made to some extent, and a report of thedifferences is returned.    Do not use all.equal directly inif expressions—either use isTRUE(all.equal(....)) oridentical if appropriate.
all.equal(x, y) is a utility to compare R objects xand y testing ‘near equality’.  If they are different,comparison is still made to some extent, and a report of thedifferences is returned.    Do not use all.equal directly inif expressions—either use isTRUE(all.equal(....)) oridentical if appropriate.
all.equal(x, y) is a utility to compare R objects xand y testing ‘near equality’.  If they are different,comparison is still made to some extent, and a report of thedifferences is returned.    Do not use all.equal directly inif expressions—either use isTRUE(all.equal(....)) oridentical if appropriate.
all.equal(x, y) is a utility to compare R objects xand y testing ‘near equality’.  If they are different,comparison is still made to some extent, and a report of thedifferences is returned.    Do not use all.equal directly inif expressions—either use isTRUE(all.equal(....)) oridentical if appropriate.
all.equal(x, y) is a utility to compare R objects xand y testing ‘near equality’.  If they are different,comparison is still made to some extent, and a report of thedifferences is returned.    Do not use all.equal directly inif expressions—either use isTRUE(all.equal(....)) oridentical if appropriate.
Return a character vector containing all the names which occur in anexpression or call.
Return a character vector containing all the names which occur in anexpression or call.
These functions provide a mechanism for handling unusual conditions,including errors and warnings.
Given a set of logical vectors, is at least one of the values true?
duplicated() determines which elements of a vector or dataframe are duplicatesof elements with smaller subscripts, and returns a logical vectorindicating which elements (rows) are duplicates.
duplicated() determines which elements of a vector or dataframe are duplicatesof elements with smaller subscripts, and returns a logical vectorindicating which elements (rows) are duplicates.
duplicated() determines which elements of a vector or dataframe are duplicatesof elements with smaller subscripts, and returns a logical vectorindicating which elements (rows) are duplicates.
duplicated() determines which elements of a vector or dataframe are duplicatesof elements with smaller subscripts, and returns a logical vectorindicating which elements (rows) are duplicates.
duplicated() determines which elements of a vector or dataframe are duplicatesof elements with smaller subscripts, and returns a logical vectorindicating which elements (rows) are duplicates.
NA is a logical constant of length 1 which contains a missingvalue indicator.  NA can be coerced to any other vectortype except raw.  There are also constants NA_integer_,NA_real_, NA_complex_ and NA_character_ of theother atomic vector types which support missing values: all of theseare reserved words in the R language.
NA is a logical constant of length 1 which contains a missingvalue indicator.  NA can be coerced to any other vectortype except raw.  There are also constants NA_integer_,NA_real_, NA_complex_ and NA_character_ of theother atomic vector types which support missing values: all of theseare reserved words in the R language.
A simple S3 class for representing numeric versionsincluding package versions, and associated methods.
Description of the classes "POSIXlt" and "POSIXct"representing calendar dates and times.
Transpose an array by permuting its dimensions and optionally resizingit.
Transpose an array by permuting its dimensions and optionally resizingit.
Transpose an array by permuting its dimensions and optionally resizingit.
Add elements to a vector.
Returns a vector or array or list of values obtained by applying afunction to margins of an array or matrix.
Basic functions which support complex arithmetic in R, in addition tothe arithmetic operators +, -, *, /, and ^.
Displays the argument names and corresponding default values of afunction or primitive.
Creates or tests for arrays.
Give the TRUE indices of a logical object, allowing for arrayindices.
Creates or tests for arrays.
Creates or tests for arrays.
Create or test for objects of mode "call" (or"(", see Details).
Create or test for objects of type "character".
These functions provide a mechanism for handling unusual conditions,including errors and warnings.
Functions to convert between character representations and objects ofclass "Date" representing calendar dates.
Create or test for objects of type "character".
These functions provide a mechanism for handling unusual conditions,including errors and warnings.
Create or test for objects of type "character".
Convert or print integers in hexadecimal format, with as many digitsas are needed to display the largest, using leading zeroes asnecessary.
A simple S3 class for representing numeric versionsincluding package versions, and associated methods.
Convert or print integers in octal format, with as many digits as areneeded to display the largest, using leading zeroes as necessary.
Functions to convert between character representations and objects ofclasses "POSIXlt" and "POSIXct" representing calendardates and times.
These functions are for working with source files and more generallywith “source references” ("srcref"), i.e., references tosource code.  The resulting data is used for printing and source leveldebugging, and is typically available in interactive R sessions,namely when options(keep.source = TRUE).
Basic functions which support complex arithmetic in R, in addition tothe arithmetic operators +, -, *, /, and ^.
Functions to check if an object is a data frame, or coerce it if possible.
Functions to check if an object is a data frame, or coerce it if possible.
Functions to check if an object is a data frame, or coerce it if possible.
Functions to check if an object is a data frame, or coerce it if possible.
Functions to check if an object is a data frame, or coerce it if possible.
Functions to check if an object is a data frame, or coerce it if possible.
Description of the class "Date" representing calendar dates.
Functions to check if an object is a data frame, or coerce it if possible.
Functions to check if an object is a data frame, or coerce it if possible.
Functions to check if an object is a data frame, or coerce it if possible.
Functions to check if an object is a data frame, or coerce it if possible.
Functions to check if an object is a data frame, or coerce it if possible.
Functions to check if an object is a data frame, or coerce it if possible.
Functions to check if an object is a data frame, or coerce it if possible.
Functions to check if an object is a data frame, or coerce it if possible.
Functions to check if an object is a data frame, or coerce it if possible.
Functions to check if an object is a data frame, or coerce it if possible.
A simple S3 class for representing numeric versionsincluding package versions, and associated methods.
Functions to check if an object is a data frame, or coerce it if possible.
Description of the classes "POSIXlt" and "POSIXct"representing calendar dates and times.
Description of the classes "POSIXlt" and "POSIXct"representing calendar dates and times.
Functions to check if an object is a data frame, or coerce it if possible.
table uses the cross-classifying factors to build a contingencytable of the counts at each combination of factor levels.
Functions to check if an object is a data frame, or coerce it if possible.
Functions to check if an object is a data frame, or coerce it if possible.
Functions to convert between character representations and objects ofclass "Date" representing calendar dates.
Functions to convert between character representations and objects ofclass "Date" representing calendar dates.
Functions to convert between character representations and objects ofclass "Date" representing calendar dates.
Functions to convert between character representations and objects ofclass "Date" representing calendar dates.
Functions to convert between character representations and objects ofclass "Date" representing calendar dates.
Functions to convert between character representations and objects ofclass "Date" representing calendar dates.
Functions to convert between character representations and objects ofclass "Date" representing calendar dates.
Time intervals creation, printing, and some arithmetic.  Theprint() method calls these “time differences”.
Create, coerce to or test for a double-precision vector.
Time intervals creation, printing, and some arithmetic.  Theprint() method calls these “time differences”.
Functions to manipulate objects of classes "POSIXlt" and"POSIXct" representing calendar dates and times.
A generic function coercing an R object to anenvironment.  A number or a character string isconverted to the corresponding environment on the search path.
Creates or tests for objects of mode "expression".
Creates or tests for objects of mode "expression".
The function factor is used to encode a vector as a factor (theterms ‘category’ and ‘enumerated type’ are also used forfactors).  If argument ordered is TRUE, the factorlevels are assumed to be ordered.  For compatibility with S there isalso a function ordered.
as.function is a generic function which is used to convertobjects to functions.
as.function is a generic function which is used to convertobjects to functions.
Convert or print integers in hexadecimal format, with as many digitsas are needed to display the largest, using leading zeroes asnecessary.
Creates or tests for objects of type "integer".
Functions to construct, coerce and check for both kinds of R lists.
Functions to construct, coerce and check for both kinds of R lists.
Description of the class "Date" representing calendar dates.
Functions to construct, coerce and check for both kinds of R lists.
Time intervals creation, printing, and some arithmetic.  Theprint() method calls these “time differences”.
Functions to construct, coerce and check for both kinds of R lists.
Functions to construct, coerce and check for both kinds of R lists.
Functions to construct, coerce and check for both kinds of R lists.
A simple S3 class for representing numeric versionsincluding package versions, and associated methods.
Description of the classes "POSIXlt" and "POSIXct"representing calendar dates and times.
Description of the classes "POSIXlt" and "POSIXct"representing calendar dates and times.
Create or test for objects of type "logical", and the basiclogical constants.
Create or test for objects of type "logical", and the basiclogical constants.
matrix creates a matrix from the given set of values.
matrix creates a matrix from the given set of values.
matrix creates a matrix from the given set of values.
Print character strings without quotes.
Description of the classes "POSIXlt" and "POSIXct"representing calendar dates and times.
A ‘name’ (also known as a ‘symbol’) is a way to refer toR objects by name (rather than the value of the object, if any, boundto that name).
NULL represents the null object in R: it is a reservedword.  NULL is often returned by expressions and functionswhose value is undefined.
NULL represents the null object in R: it is a reservedword.  NULL is often returned by expressions and functionswhose value is undefined.
Creates or coerces objects of type "numeric".is.numeric is a more general test of an object beinginterpretable as numbers.
A simple S3 class for representing numeric versionsincluding package versions, and associated methods.
Convert or print integers in octal format, with as many digits as areneeded to display the largest, using leading zeroes as necessary.
The function factor is used to encode a vector as a factor (theterms ‘category’ and ‘enumerated type’ are also used forfactors).  If argument ordered is TRUE, the factorlevels are assumed to be ordered.  For compatibility with S there isalso a function ordered.
A simple S3 class for representing numeric versionsincluding package versions, and associated methods.
Functions to construct, coerce and check for both kinds of R lists.
Functions to manipulate objects of classes "POSIXlt" and"POSIXct" representing calendar dates and times.
Functions to manipulate objects of classes "POSIXlt" and"POSIXct" representing calendar dates and times.
Functions to manipulate objects of classes "POSIXlt" and"POSIXct" representing calendar dates and times.
Functions to manipulate objects of classes "POSIXlt" and"POSIXct" representing calendar dates and times.
Functions to manipulate objects of classes "POSIXlt" and"POSIXct" representing calendar dates and times.
Functions to manipulate objects of classes "POSIXlt" and"POSIXct" representing calendar dates and times.
Functions to manipulate objects of classes "POSIXlt" and"POSIXct" representing calendar dates and times.
Functions to manipulate objects of classes "POSIXlt" and"POSIXct" representing calendar dates and times.
Functions to manipulate objects of classes "POSIXlt" and"POSIXct" representing calendar dates and times.
Functions to manipulate objects of classes "POSIXlt" and"POSIXct" representing calendar dates and times.
Functions to manipulate objects of classes "POSIXlt" and"POSIXct" representing calendar dates and times.
Functions to manipulate objects of classes "POSIXlt" and"POSIXct" representing calendar dates and times.
qr computes the QR decomposition of a matrix.
Creates or tests for objects of type "raw".
Create, coerce to or test for a double-precision vector.
Create, coerce to or test for a double-precision vector.
A ‘name’ (also known as a ‘symbol’) is a way to refer toR objects by name (rather than the value of the object, if any, boundto that name).
table uses the cross-classifying factors to build a contingencytable of the counts at each combination of factor levels.
table uses the cross-classifying factors to build a contingencytable of the counts at each combination of factor levels.
vector produces a vector of the given length and mode.
vector produces a vector of the given length and mode.
These functions give the obvious trigonometric functions.  Theyrespectively compute the cosine, sine, tangent, arc-cosine, arc-sine,arc-tangent, and the two-argument arc-tangent.
These functions give the obvious hyperbolic functions.  Theyrespectively compute the hyperbolic cosine, sine, tangent, and theirinverses, arc-cosine, arc-sine, arc-tangent (or ‘area cosine’,etc).
Internal namespace support functions.  Not intended to be calleddirectly, and only visible because of the special nature of thebase namespace.
Split an array or matrix by its margins.
Tests whether the object is an instance of an S4 class.
Tests whether the object is an instance of an S4 class.
Assign a value to a name in an environment.
These functions give the obvious trigonometric functions.  Theyrespectively compute the cosine, sine, tangent, arc-cosine, arc-sine,arc-tangent, and the two-argument arc-tangent.
These functions give the obvious trigonometric functions.  Theyrespectively compute the cosine, sine, tangent, arc-cosine, arc-sine,arc-tangent, and the two-argument arc-tangent.
These functions give the obvious hyperbolic functions.  Theyrespectively compute the hyperbolic cosine, sine, tangent, and theirinverses, arc-cosine, arc-sine, arc-tangent (or ‘area cosine’,etc).
The database is attached to the R search path.  This means that thedatabase is searched by R when evaluating a variable, so objects inthe database can be accessed by simply giving their names.
Functions to load and unload name spaces.
Get or set specific attributes of an object.
all.equal(x, y) is a utility to compare R objects xand y testing ‘near equality’.  If they are different,comparison is still made to some extent, and a report of thedifferences is returned.    Do not use all.equal directly inif expressions—either use isTRUE(all.equal(....)) oridentical if appropriate.
Get or set specific attributes of an object.
These functions access an object's attributes.The first form below returns the object's attribute list.The replacement forms uses the list on the right-handside of the assignment as the object's attributes (if appropriate).
These functions access an object's attributes.The first form below returns the object's attribute list.The replacement forms uses the list on the right-handside of the assignment as the object's attributes (if appropriate).
autoload creates a promise-to-evaluate autoloader andstores it with name name in .AutoloadEnv environment.When R attempts to evaluate name, autoloader is run,the package is loaded and name is re-evaluated in the newpackage's environment.  The result is that R behaves as ifpackage was loaded but it does not occupy memory.
autoload creates a promise-to-evaluate autoloader andstores it with name name in .AutoloadEnv environment.When R attempts to evaluate name, autoloader is run,the package is loaded and name is re-evaluated in the newpackage's environment.  The result is that R behaves as ifpackage was loaded but it does not occupy memory.
Solves a triangular system of linear equations.
Get, set, test for and create environments.
basename removes all of the path up to and including the lastpath separator (if any).
Bessel Functions of integer and fractional order, of firstand second kind, J(nu) and Y(nu), andModified Bessel functions (of first and third kind),I(nu) and K(nu).
Bessel Functions of integer and fractional order, of firstand second kind, J(nu) and Y(nu), andModified Bessel functions (of first and third kind),I(nu) and K(nu).
Bessel Functions of integer and fractional order, of firstand second kind, J(nu) and Y(nu), andModified Bessel functions (of first and third kind),I(nu) and K(nu).
Bessel Functions of integer and fractional order, of firstand second kind, J(nu) and Y(nu), andModified Bessel functions (of first and third kind),I(nu) and K(nu).
Special mathematical functions related to the beta and gammafunctions.
These functions represent an interface for adjustmentsto environments and bindings within environments.  They allow forlocking environments as well as individual bindings, and for linkinga variable to a function.
These functions represent an interface for adjustmentsto environments and bindings within environments.  They allow forlocking environments as well as individual bindings, and for linkinga variable to a function.
If Native Language Support (NLS) was enabled in this build of R (seethe bindtextdomain() example), attempt totranslate character vectors or set where the translations are to be found.
Logical operations on integer vectors with elements viewed as sets of bits.
Logical operations on integer vectors with elements viewed as sets of bits.
Logical operations on integer vectors with elements viewed as sets of bits.
Logical operations on integer vectors with elements viewed as sets of bits.
Logical operations on integer vectors with elements viewed as sets of bits.
Logical operations on integer vectors with elements viewed as sets of bits.
Get or set the body of a function which is basically all ofthe function definition but its formal arguments (formals),see the ‘Details’.
Get or set the body of a function which is basically all ofthe function definition but its formal arguments (formals),see the ‘Details’.
An analogue of the LISP backquote macro.  bquote quotes itsargument except that terms wrapped in .() are evaluated in thespecified where environment. If splice = TRUE thenterms wrapped in ..() are evaluated and spliced into a call.
These are the basic control-flow constructs of the R language.  Theyfunction in much the same way as control statements in any Algol-likelanguage.  They are all reserved words.
Interrupt the execution of an expression and allow the inspection ofthe environment where browser was called from.
A call to browser can provide context by supplying either a textargument or a condition argument.  These functions can be used toretrieve either of these arguments.
A call to browser can provide context by supplying either a textargument or a condition argument.  These functions can be used toretrieve either of these arguments.
A call to browser can provide context by supplying either a textargument or a condition argument.  These functions can be used toretrieve either of these arguments.
Return the names of all the built-in objects.  These are fetcheddirectly from the symbol table of the R interpreter.
Function by is an object-oriented wrapper fortapply applied to data frames.
Function by is an object-oriented wrapper fortapply applied to data frames.
Function by is an object-oriented wrapper fortapply applied to data frames.
Functions to create, open and close connections, i.e.,“generalized files”, such as possibly compressed files, URLs,pipes, etc.
This is a generic function which combines its arguments.
Description of the class "Date" representing calendar dates.
Time intervals creation, printing, and some arithmetic.  Theprint() method calls these “time differences”.
The function factor is used to encode a vector as a factor (theterms ‘category’ and ‘enumerated type’ are also used forfactors).  If argument ordered is TRUE, the factorlevels are assumed to be ordered.  For compatibility with S there isalso a function ordered.
Print character strings without quotes.
A simple S3 class for representing numeric versionsincluding package versions, and associated methods.
Description of the classes "POSIXlt" and "POSIXct"representing calendar dates and times.
Description of the classes "POSIXlt" and "POSIXct"representing calendar dates and times.
warnings and its print method print thevariable last.warning in a pleasing form.
Create or test for objects of mode "call" (or"(", see Details).
A downward-only version of Scheme's call with current continuation.
Report on the optional features which have been compiled into thisbuild of R.
Translate characters in character vectors, in particular from upper tolower case or vice versa.
Outputs the objects, concatenating the representations.  catperforms much less conversion than print.
Take a sequence of vector, matrix or data-frame arguments and combineby columns or rows, respectively.  These are genericfunctions with methods for other R classes.
Take a sequence of vector, matrix or data-frame arguments and combineby columns or rows, respectively.  These are genericfunctions with methods for other R classes.
ceiling takes a single numeric argument x and returns anumeric vector containing the smallest integers not less than thecorresponding elements of x.
Seeks a unique match of its first argument among theelements of its second.  If successful, it returns this element;otherwise, it performs an action specified by the third argument.
Create or test for objects of type "character".
charmatch seeks matches for the elements of its first argumentamong those of its second.
Conversion to and from and manipulation of objects of type "raw",both used as bits or “packed” 8 bits.
Translate characters in character vectors, in particular from upper tolower case or vice versa.
Description of the classes "POSIXlt" and "POSIXct"representing calendar dates and times.
Warn about extraneous arguments in the ... of its caller.  Autility to be used e.g., in S3 methods which need a formal ...argument but do not make any use of it.  This helps catching usererrors in calling the function in question (which is the caller ofchkDots()).
Compute the Choleski factorization of a real symmetricpositive-definite square matrix.
Compute the Choleski factorization of a real symmetricpositive-definite square matrix.
Invert a symmetric, positive definite square matrix from its Choleskidecomposition.  Equivalently, compute (X'X)^(-1)from the (R part) of the QR decomposition of X.
Special mathematical functions related to the beta and gammafunctions.
R possesses a simple generic function mechanism which can be used foran object-oriented style of programming.  Method dispatch takes placebased on the class of the first argument to the generic function.
R possesses a simple generic function mechanism which can be used foran object-oriented style of programming.  Method dispatch takes placebased on the class of the first argument to the generic function.
Functions to push back text lines onto a connection, and to enquirehow many lines are currently pushed back.
Functions to create, open and close connections, i.e.,“generalized files”, such as possibly compressed files, URLs,pipes, etc.
Functions to create, open and close connections, i.e.,“generalized files”, such as possibly compressed files, URLs,pipes, etc.
These functions are for working with source files and more generallywith “source references” ("srcref"), i.e., references tosource code.  The resulting data is used for printing and source leveldebugging, and is typically available in interactive R sessions,namely when options(keep.source = TRUE).
These functions are for working with source files and more generallywith “source references” ("srcref"), i.e., references tosource code.  The resulting data is used for printing and source leveldebugging, and is typically available in interactive R sessions,namely when options(keep.source = TRUE).
Display aspects of connections.
Returns a matrix of integers indicating their column number in amatrix-like object, or a factor of column labels.
Form row and column sums and means for numeric arrays (or data frames).
Retrieve or set the row or column names of a matrix-like object.
Retrieve or set the row or column names of a matrix-like object.
Form row and column sums and means for numeric arrays (or data frames).
Provides access to a copy of the command line arguments supplied whenthis R session was invoked.
These functions set and query a commentattribute for any R objects.  This is typically useful fordata.frames or model fits.
These functions set and query a commentattribute for any R objects.  This is typically useful fordata.frames or model fits.
Basic functions which support complex arithmetic in R, in addition tothe arithmetic operators +, -, *, /, and ^.
These functions provide a mechanism for handling unusual conditions,including errors and warnings.
These functions provide a mechanism for handling unusual conditions,including errors and warnings.
These functions provide a mechanism for handling unusual conditions,including errors and warnings.
These functions provide a mechanism for handling unusual conditions,including errors and warnings.
These functions provide a mechanism for handling unusual conditions,including errors and warnings.
library and require load and attach add-on packages.
conflicts reports on objects that exist with the same name intwo or more places on the search path, usually becausean object in the user's workspace or a package is masking a systemobject of the same name.  This helps discover unintentional masking.
Basic functions which support complex arithmetic in R, in addition tothe arithmetic operators +, -, *, /, and ^.
The R Who-is-who, describing who made significant contributions tothe development of R.
These functions give the obvious trigonometric functions.  Theyrespectively compute the cosine, sine, tangent, arc-cosine, arc-sine,arc-tangent, and the two-argument arc-tangent.
These functions give the obvious hyperbolic functions.  Theyrespectively compute the hyperbolic cosine, sine, tangent, and theirinverses, arc-cosine, arc-sine, arc-tangent (or ‘area cosine’,etc).
These functions give the obvious trigonometric functions.  Theyrespectively compute the cosine, sine, tangent, arc-cosine, arc-sine,arc-tangent, and the two-argument arc-tangent.
Given matrices x and y as arguments, return a matrixcross-product.  This is formally equivalent to (but usually slightlyfaster than) the call t(x) %*% y (crossprod) orx %*% t(y) (tcrossprod).
Report information on the C stack size and usage (if available).
Returns a vector whose elements are the cumulative sums, products,minima or maxima of the elements of the argument.
Returns a vector whose elements are the cumulative sums, products,minima or maxima of the elements of the argument.
Returns a vector whose elements are the cumulative sums, products,minima or maxima of the elements of the argument.
Returns a vector whose elements are the cumulative sums, products,minima or maxima of the elements of the argument.
Retrieve the headers for a URL for a supported protocol such ashttp://, ftp://, https:// and ftps://.An optional function not supported on all platforms.
cut divides the range of x into intervalsand codes the values in x according to whichinterval they fall.  The leftmost interval corresponds to level one,the next leftmost to level two and so on.
Method for cut applied to date-time objects.
cut divides the range of x into intervalsand codes the values in x according to whichinterval they fall.  The leftmost interval corresponds to level one,the next leftmost to level two and so on.
Method for cut applied to date-time objects.
Determine the class of an arbitrary R object.
The function data.frame() creates data frames, tightly coupledcollections of variables which share many of the properties ofmatrices and of lists, used as the fundamental data structure by mostof R's modeling software.
Return the matrix obtained by converting all the variables in a dataframe to numeric mode and then binding them together as the columns ofa matrix.  Factors and ordered factors are replaced by their internalcodes.
Returns a character string of the current system date and time.
Set, unset or query the debugging flag on a function.The text and condition arguments are the same as thosethat can be supplied via a call to browser.  They can be retrievedby the user once the browser has been entered, and provide a mechanism toallow users to identify which breakpoint has been activated.
Set, unset or query the debugging flag on a function.The text and condition arguments are the same as thosethat can be supplied via a call to browser.  They can be retrievedby the user once the browser has been entered, and provide a mechanism toallow users to identify which breakpoint has been activated.
Set, unset or query the debugging flag on a function.The text and condition arguments are the same as thosethat can be supplied via a call to browser.  They can be retrievedby the user once the browser has been entered, and provide a mechanism toallow users to identify which breakpoint has been activated.
The function data.frame() creates data frames, tightly coupledcollections of variables which share many of the properties ofmatrices and of lists, used as the fundamental data structure by mostof R's modeling software.
delayedAssign creates a promise to evaluate the givenexpression if its value is requested.  This provides direct accessto the lazy evaluation mechanism used by R for the evaluationof (interpreted) functions.
Turn unevaluated expressions into character strings.
Turn unevaluated expressions into character strings.
det calculates the determinant of a matrix.  determinantis a generic function that returns separately the modulus of the determinant,optionally on the logarithm scale, and the sign of the determinant.
Detach a database, i.e., remove it from the search()path of available R objects.  Usually this is either adata.frame which has been attached or apackage which was attached by library.
det calculates the determinant of a matrix.  determinantis a generic function that returns separately the modulus of the determinant,optionally on the logarithm scale, and the sign of the determinant.
det calculates the determinant of a matrix.  determinantis a generic function that returns separately the modulus of the determinant,optionally on the logarithm scale, and the sign of the determinant.
Writes an ASCII text representation of an R object to a file, the Rconsole, or a connection, or uses one to recreate the object.
Extract or replace the diagonal of a matrix,or construct a diagonal matrix.
Extract or replace the diagonal of a matrix,or construct a diagonal matrix.
Returns suitably lagged and iterated differences.
Returns suitably lagged and iterated differences.
Returns suitably lagged and iterated differences.
Time intervals creation, printing, and some arithmetic.  Theprint() method calls these “time differences”.
Returns suitably lagged and iterated differences.
Time intervals creation, printing, and some arithmetic.  Theprint() method calls these “time differences”.
Special mathematical functions related to the beta and gammafunctions.
Retrieve or set the dimension of an object.
Retrieve or set the dimension of an object.
Retrieve or set the dimension of an object.
Retrieve or set the dimnames of an object.
Retrieve or set the dimnames of an object.
Retrieve or set the dimnames of an object.
Retrieve or set the dimnames of an object.
These functions produce a character vector of the names of files ordirectories in the named directory.
These functions provide a low-level interface to the computer'sfile system.
These functions provide a low-level interface to the computer'sfile system.
basename removes all of the path up to and including the lastpath separator (if any).
do.call constructs and executes a function call from a name ora function and a list of arguments to be passed to it.
The dontCheck function is the same as identity, but is interpreted by R CMD check code analysis as a directiveto suppress checking of x.  Currently this is only used bycheckFF(registration = TRUE)when checking the .NAME argument of foreign function calls.
Create, coerce to or test for a double-precision vector.
Writes an ASCII text representation of an R object to a file, the Rconsole, or a connection, or uses one to recreate the object.
Single or double quote text by combining with appropriate single ordouble left and right quotation marks.
Delete the dimensions of an array which have only one level.
The function droplevels is used to drop unused levels from afactor or, more commonly, from factors in a data frame.
The function droplevels is used to drop unused levels from afactor or, more commonly, from factors in a data frame.
The function droplevels is used to drop unused levels from afactor or, more commonly, from factors in a data frame.
This function takes a vector of names of R objects and producestext representations of the objects on a file or connection.A dump file can usually be sourced into anotherR session.
duplicated() determines which elements of a vector or dataframe are duplicatesof elements with smaller subscripts, and returns a logical vectorindicating which elements (rows) are duplicates.
duplicated() determines which elements of a vector or dataframe are duplicatesof elements with smaller subscripts, and returns a logical vectorindicating which elements (rows) are duplicates.
duplicated() determines which elements of a vector or dataframe are duplicatesof elements with smaller subscripts, and returns a logical vectorindicating which elements (rows) are duplicates.
duplicated() determines which elements of a vector or dataframe are duplicatesof elements with smaller subscripts, and returns a logical vectorindicating which elements (rows) are duplicates.
duplicated() determines which elements of a vector or dataframe are duplicatesof elements with smaller subscripts, and returns a logical vectorindicating which elements (rows) are duplicates.
A simple S3 class for representing numeric versionsincluding package versions, and associated methods.
Description of the classes "POSIXlt" and "POSIXct"representing calendar dates and times.
warnings and its print method print thevariable last.warning in a pleasing form.
Load or unload DLLs (also known as shared objects), and test whether aC function or Fortran subroutine is available.
Load or unload DLLs (also known as shared objects), and test whether aC function or Fortran subroutine is available.
Search by name for an object (get) or zero or more objects(mget).
eapply applies FUN to the named values from anenvironment and returns the results as a list.  The usercan request that all named objects are used (normally names that beginwith a dot are not).  The output is not sorted and no enclosingenvironments are searched.
Computes eigenvalues and eigenvectors of numeric (double, integer,logical) or complex matrices.
Get, set, test for and create environments.
Read or set the declared encodings for a character vector.
Read or set the declared encodings for a character vector.
encodeString escapes the strings in a character vector in thesame way print.default does, and optionally fits the encodedstrings within a field width.
Read or set the declared encodings for a character vector.
Read or set the declared encodings for a character vector.
Determines if entries of x start or end with string (entries of)prefix or suffix respectively, where strings arerecycled to common lengths.
substitute returns the parse tree for the (unevaluated)expression expr, substituting any variables bound inenv.
Get, set, test for and create environments.
Get, set, test for and create environments.
Get, set, test for and create environments.
These functions represent an interface for adjustmentsto environments and bindings within environments.  They allow forlocking environments as well as individual bindings, and for linkinga variable to a function.
Get, set, test for and create environments.
These functions provide a mechanism for handling unusual conditions,including errors and warnings.
Evaluate an R expression in a specified environment.
Evaluate an R expression in a specified environment.
Evaluate an R expression in a specified environment.
Look for an R object of the given name and possibly return it
log computes logarithms, by default natural logarithms,log10 computes common (i.e., base 10) logarithms, andlog2 computes binary (i.e., base 2) logarithms.The general form log(x, base) computes logarithms with basebase.
Create a data frame from all combinations of the supplied vectors orfactors.  See the description of the return value for precise details ofthe way this is done.
log computes logarithms, by default natural logarithms,log10 computes common (i.e., base 10) logarithms, andlog2 computes binary (i.e., base 2) logarithms.The general form log(x, base) computes logarithms with basebase.
Creates or tests for objects of mode "expression".
Report versions of (external) third-party software used.
Create or test for objects of type "logical", and the basiclogical constants.
The function factor is used to encode a vector as a factor (theterms ‘category’ and ‘enumerated type’ are also used forfactors).  If argument ordered is TRUE, the factorlevels are assumed to be ordered.  For compatibility with S there isalso a function ordered.
Special mathematical functions related to the beta and gammafunctions.
Functions to create, open and close connections, i.e.,“generalized files”, such as possibly compressed files, URLs,pipes, etc.
Functions to create, open and close connections, i.e.,“generalized files”, such as possibly compressed files, URLs,pipes, etc.
Utility function to access information about files on the user'sfile systems.
These functions provide a low-level interface to the computer'sfile system.
Choose a file interactively.
These functions provide a low-level interface to the computer'sfile system.
These functions provide a low-level interface to the computer'sfile system.
These functions provide a low-level interface to the computer'sfile system.
Utility function to extract information about files on the user'sfile systems.
These functions provide a low-level interface to the computer'sfile system.
Utility function to extract information about files on the user'sfile systems.
Utility function to extract information about files on the user'sfile systems.
Construct the path to a file from components in a platform-independentway.
These functions provide a low-level interface to the computer'sfile system.
These functions provide a low-level interface to the computer'sfile system.
Display one or more (plain) text files, in a platformspecific way, typically via a ‘pager’.
Utility function to extract information about files on the user'sfile systems.
These functions provide a low-level interface to the computer'sfile system.
Reduce uses a binary function to successively combine theelements of a given vector and a possibly given initial value.Filter extracts the elements of a vector for which a predicate(logical) function gives true.  Find and Position givethe first or last such element and its position in the vector,respectively.  Map applies a function to the correspondingelements of given vectors.  Negate creates the negation of agiven function.
Reduce uses a binary function to successively combine theelements of a given vector and a possibly given initial value.Filter extracts the elements of a vector for which a predicate(logical) function gives true.  Find and Position givethe first or last such element and its position in the vector,respectively.  Map applies a function to the correspondingelements of given vectors.  Negate creates the negation of agiven function.
Find the paths to one or more packages.
Given a vector of non-decreasing breakpoints in vec, find theinterval containing each element of x; i.e., ifi <- findInterval(x,v), for each index j in xv[i[j]] ≤ x[j] < v[i[j] + 1]where v[0] := - Inf,v[N+1] := + Inf, and N <- length(v).At the two boundaries, the returned index may differ by 1, dependingon the optional arguments rightmost.closed and all.inside.
Internal objects in the base package most of which are only user-visiblebecause of the special nature of the base namespace.
These functions provide a mechanism for handling unusual conditions,including errors and warnings.
ceiling takes a single numeric argument x and returns anumeric vector containing the smallest integers not less than thecorresponding elements of x.
Functions to create, open and close connections, i.e.,“generalized files”, such as possibly compressed files, URLs,pipes, etc.
Functions to create, open and close connections, i.e.,“generalized files”, such as possibly compressed files, URLs,pipes, etc.
These are the basic control-flow constructs of the R language.  Theyfunction in much the same way as control statements in any Algol-likelanguage.  They are all reserved words.
Forces the evaluation of a function argument.
Call a function with a specified number of leading arguments forcedbefore the call if the function is a closure.
Get or set the formal arguments of a function.
Get or set the formal arguments of a function.
Format an R object for pretty printing.
Format an R object for pretty printing.
Format an R object for pretty printing.
Functions to convert between character representations and objects ofclass "Date" representing calendar dates.
Format an R object for pretty printing.
Time intervals creation, printing, and some arithmetic.  Theprint() method calls these “time differences”.
Format an R object for pretty printing.
Convert or print integers in hexadecimal format, with as many digitsas are needed to display the largest, using leading zeroes asnecessary.
Information is returned on how format(x, digits, nsmall)would be formatted.
library and require load and attach add-on packages.
A simple S3 class for representing numeric versionsincluding package versions, and associated methods.
Convert or print integers in octal format, with as many digits as areneeded to display the largest, using leading zeroes as necessary.
library and require load and attach add-on packages.
Functions to convert between character representations and objects ofclasses "POSIXlt" and "POSIXct" representing calendardates and times.
Functions to convert between character representations and objects ofclasses "POSIXlt" and "POSIXct" representing calendardates and times.
format.pval is intended for formatting p-values.
summary is a generic function used to produce result summariesof the results of various model fitting functions.  The functioninvokes particular methods which depend on theclass of the first argument.
formatC() formats numbers individually and flexibly usingC style format specifications.
Format vectors of items and their descriptions as 2-columntables or LaTeX-style description lists.
Solves a triangular system of linear equations.
These functions provide the base mechanisms for definingnew functions in the R language.
Special mathematical functions related to the beta and gammafunctions.
A call of gc causes a garbage collection to take place.gcinfo sets a flag so thatautomatic collection is either silent (verbose = FALSE) orprints memory usage statistics (verbose = TRUE).
This function reports the time spent in garbage collection so far inthe R session while GC timing was enabled.
A call of gc causes a garbage collection to take place.gcinfo sets a flag so thatautomatic collection is either silent (verbose = FALSE) orprints memory usage statistics (verbose = TRUE).
Provokes garbage collection on (nearly) every memory allocation.Intended to ferret out memory protection bugs.  Also makes R runvery slowly, unfortunately.
Provokes garbage collection on (nearly) every memory allocation.Intended to ferret out memory protection bugs.  Also makes R runvery slowly, unfortunately.
Search by name for an object (get) or zero or more objects(mget).
Look for an R object of the given name and possibly return it
Display aspects of connections.
This is an internal function that is called from R's C code todetermine the enclosing namespace of a.C/.Call/.Fortran/.External call which hasno PACKAGE argument. If the call has been made from a functionwithin a namespace, then we can find the DLL associated with thatnamespace.  The purpose of this is to avoid having to use thePACKAGE argument in these native calls and so better supportversions of packages.
This is an internal function that is called from R's C code todetermine the enclosing namespace of a.C/.Call/.Fortran/.External call which hasno PACKAGE argument. If the call has been made from a functionwithin a namespace, then we can find the DLL associated with thatnamespace.  The purpose of this is to avoid having to use thePACKAGE argument in these native calls and so better supportversions of packages.
Display aspects of connections.
This function allows us to query the set of routinesin a DLL that are registered with R to enhancedynamic lookup, error handling when calling native routines,and potentially security in the future.This function provides a description of each of theregistered routines in the DLL for the different interfaces,i.e. .C, .Call, .Fortranand .External.
This function allows us to query the set of routinesin a DLL that are registered with R to enhancedynamic lookup, error handling when calling native routines,and potentially security in the future.This function provides a description of each of theregistered routines in the DLL for the different interfaces,i.e. .C, .Call, .Fortranand .External.
This function allows us to query the set of routinesin a DLL that are registered with R to enhancedynamic lookup, error handling when calling native routines,and potentially security in the future.This function provides a description of each of theregistered routines in the DLL for the different interfaces,i.e. .C, .Call, .Fortranand .External.
Operators acting on vectors, matrices, arrays and lists to extract orreplace parts.
stop stops execution of the current expression and executesan error action.
Internal functions to support reflection on namespace objects.
These functions allow users to set actions to be taken before packagesare attached/detached and namespaces are (un)loaded.
This function provides a way to get a list of all the DLLs (seedyn.load) that are currently loaded in the R session.
Internal functions to support reflection on namespace objects.
Internal functions to support reflection on namespace objects.
Internal functions to support reflection on namespace objects.
Internal namespace support functions.  Not intended to be calleddirectly, and only visible because of the special nature of thebase namespace.
Internal functions to support reflection on namespace objects.
Internal functions to support reflection on namespace objects.
Internal functions to support reflection on namespace objects.
This finds and returns a description of one or more dynamically loadedor ‘exported’ built-in native symbols.  For each name, itreturns information about the name of the symbol, the library in whichit is located and, if available, the number of arguments it expectsand by which interface it should be called (i.e .Call,.C, .Fortran, or.External). Additionally, it returns the address of thesymbol and this can be passed to other C routines.  Specifically, thisprovides a way to explicitly share symbols between differentdynamically loaded package libraries.  Also, it provides a way toquery where symbols were resolved, and aids diagnosing strangebehavior associated with dynamic resolution.
Allow the user to set and examine a variety of global optionswhich affect the way in which R computes and displays its results.
A simple S3 class for representing numeric versionsincluding package versions, and associated methods.
These functions are for working with source files and more generallywith “source references” ("srcref"), i.e., references tosource code.  The resulting data is used for printing and source leveldebugging, and is typically available in interactive R sessions,namely when options(keep.source = TRUE).
This provides a way to get the names (or identifiers)for the currently registered task callbacksthat are invoked at the conclusion of each top-level task.These identifiers can be used to remove a callback.
If Native Language Support (NLS) was enabled in this build of R (seethe bindtextdomain() example), attempt totranslate character vectors or set where the translations are to be found.
A wrapper for the C function sprintf, that returns a charactervector containing a formatted combination of text and variable values.
getwd returns an absolute filepath representing the currentworking directory of the R process; setwd(dir) is used to setthe working directory to dir.
Generate factors by specifying the pattern of their levels.
These functions provide a mechanism for handling unusual conditions,including errors and warnings.
Get, set, test for and create environments.
grep, grepl, regexpr, gregexpr, regexec and gregexec search for matches to argumentpattern within each element of a character vector: they differ inthe format of and amount of detail in the results.
grep, grepl, regexpr, gregexpr, regexec and gregexec search for matches to argumentpattern within each element of a character vector: they differ inthe format of and amount of detail in the results.
grep, grepl, regexpr, gregexpr, regexec and gregexec search for matches to argumentpattern within each element of a character vector: they differ inthe format of and amount of detail in the results.
grep, grepl, regexpr, gregexpr, regexec and gregexec search for matches to argumentpattern within each element of a character vector: they differ inthe format of and amount of detail in the results.
grepRaw searches for substring pattern matches within araw vector x.
grouping returns a permutation which rearranges its firstargument such that identical values are adjacent to each other.  Alsoreturned as attributes are the group-wise partitioning and the maximumgroup size.
grep, grepl, regexpr, gregexpr, regexec and gregexec search for matches to argumentpattern within each element of a character vector: they differ inthe format of and amount of detail in the results.
gzcon provides a modified connection that wraps an existingconnection, and decompresses reads or compresses writes through thatconnection.  Standard gzip headers are assumed.
Functions to create, open and close connections, i.e.,“generalized files”, such as possibly compressed files, URLs,pipes, etc.
Change the class of an object to indicate that it should be treated‘as is’.
This uses system facilities to convert a character vector betweenencodings: the ‘i’ stands for ‘internationalization’.
This uses system facilities to convert a character vector betweenencodings: the ‘i’ stands for ‘internationalization’.
Controls the way collation is done by ICU (an optional part of the Rbuild).
Controls the way collation is done by ICU (an optional part of the Rbuild).
The safe and reliable way to test two objects for beingexactly equal.  It returns TRUE in this case,FALSE in every other case.
A trivial identity function returning its argument.
These are the basic control-flow constructs of the R language.  Theyfunction in much the same way as control statements in any Algol-likelanguage.  They are all reserved words.
ifelse returns a value with the same shape astest which is filled with elements selectedfrom either yes or nodepending on whether the element of testis TRUE or FALSE.
Basic functions which support complex arithmetic in R, in addition tothe arithmetic operators +, -, *, /, and ^.
Internal namespace support functions.  Not intended to be calleddirectly, and only visible because of the special nature of thebase namespace.
Functions to write a single R object to a file, and to restore it.
R possesses a simple generic function mechanism which can be used foran object-oriented style of programming.  Method dispatch takes placebased on the class of the first argument to the generic function.
Creates or tests for objects of type "integer".
interaction computes a factor which represents the interactionof the given factors.  The result of interaction is always unordered.
Return TRUE when R is being used interactively andFALSE otherwise.
Performs set union, intersection, (asymmetric!) difference,equality and membership on two vectors.
Conversion to and from and manipulation of objects of type "raw",both used as bits or “packed” 8 bits.
Conversion of UTF-8 encoded character vectors to and from integervectors representing a UTF-32 encoding.
Compute the lengths and values of runs of equal values in a vector– or the reverse operation.
Return a (temporarily) invisible copy of an object.
These functions provide a mechanism for handling unusual conditions,including errors and warnings.
These functions provide a mechanism for handling unusual conditions,including errors and warnings.
Creates or tests for arrays.
is.atomic returns TRUE if x is of an atomic type(or NULL) and FALSE otherwise.
Create or test for objects of mode "call" (or"(", see Details).
Create or test for objects of type "character".
Basic functions which support complex arithmetic in R, in addition tothe arithmetic operators +, -, *, /, and ^.
Functions to check if an object is a data frame, or coerce it if possible.
Create, coerce to or test for a double-precision vector.
Performs set union, intersection, (asymmetric!) difference,equality and membership on two vectors.
Get, set, test for and create environments.
Creates or tests for objects of mode "expression".
The function factor is used to encode a vector as a factor (theterms ‘category’ and ‘enumerated type’ are also used forfactors).  If argument ordered is TRUE, the factorlevels are assumed to be ordered.  For compatibility with S there isalso a function ordered.
is.finite and is.infinite return a vector of the samelength as x, indicating which elements are finite (not infiniteand not missing) or infinite.
Checks whether its argument is a (primitive) function.
is.finite and is.infinite return a vector of the samelength as x, indicating which elements are finite (not infiniteand not missing) or infinite.
Creates or tests for objects of type "integer".
is.language returns TRUE if x is avariable name, a call, or anexpression.
Functions to construct, coerce and check for both kinds of R lists.
Load or unload DLLs (also known as shared objects), and test whether aC function or Fortran subroutine is available.
Create or test for objects of type "logical", and the basiclogical constants.
matrix creates a matrix from the given set of values.
NA is a logical constant of length 1 which contains a missingvalue indicator.  NA can be coerced to any other vectortype except raw.  There are also constants NA_integer_,NA_real_, NA_complex_ and NA_character_ of theother atomic vector types which support missing values: all of theseare reserved words in the R language.
NA is a logical constant of length 1 which contains a missingvalue indicator.  NA can be coerced to any other vectortype except raw.  There are also constants NA_integer_,NA_real_, NA_complex_ and NA_character_ of theother atomic vector types which support missing values: all of theseare reserved words in the R language.
A simple S3 class for representing numeric versionsincluding package versions, and associated methods.
Description of the classes "POSIXlt" and "POSIXct"representing calendar dates and times.
NA is a logical constant of length 1 which contains a missingvalue indicator.  NA can be coerced to any other vectortype except raw.  There are also constants NA_integer_,NA_real_, NA_complex_ and NA_character_ of theother atomic vector types which support missing values: all of theseare reserved words in the R language.
NA is a logical constant of length 1 which contains a missingvalue indicator.  NA can be coerced to any other vectortype except raw.  There are also constants NA_integer_,NA_real_, NA_complex_ and NA_character_ of theother atomic vector types which support missing values: all of theseare reserved words in the R language.
The function factor is used to encode a vector as a factor (theterms ‘category’ and ‘enumerated type’ are also used forfactors).  If argument ordered is TRUE, the factorlevels are assumed to be ordered.  For compatibility with S there isalso a function ordered.
A simple S3 class for representing numeric versionsincluding package versions, and associated methods.
A ‘name’ (also known as a ‘symbol’) is a way to refer toR objects by name (rather than the value of the object, if any, boundto that name).
is.finite and is.infinite return a vector of the samelength as x, indicating which elements are finite (not infiniteand not missing) or infinite.
NULL represents the null object in R: it is a reservedword.  NULL is often returned by expressions and functionswhose value is undefined.
Creates or coerces objects of type "numeric".is.numeric is a more general test of an object beinginterpretable as numbers.
A simple S3 class for representing numeric versionsincluding package versions, and associated methods.
Creates or coerces objects of type "numeric".is.numeric is a more general test of an object beinginterpretable as numbers.
Time intervals creation, printing, and some arithmetic.  Theprint() method calls these “time differences”.
Creates or coerces objects of type "numeric".is.numeric is a more general test of an object beinginterpretable as numbers.
A function rather for internal use.  It returns TRUE if theobject x has the R internal OBJECT bit set, andFALSE otherwise.  The OBJECT bit is set when a"class" attribute is added and removed when that attribute isremoved, so this is a very efficient way to check if an object has aclass attribute.  (S4 objects always should.)
The function factor is used to encode a vector as a factor (theterms ‘category’ and ‘enumerated type’ are also used forfactors).  If argument ordered is TRUE, the factorlevels are assumed to be ordered.  For compatibility with S there isalso a function ordered.
A simple S3 class for representing numeric versionsincluding package versions, and associated methods.
Functions to construct, coerce and check for both kinds of R lists.
Checks whether its argument is a (primitive) function.
qr computes the QR decomposition of a matrix.
Test if running under R.
Creates or tests for objects of type "raw".
is.atomic returns TRUE if x is of an atomic type(or NULL) and FALSE otherwise.
is.single reports an error.  There are no single precisionvalues in R.
A ‘name’ (also known as a ‘symbol’) is a way to refer toR objects by name (rather than the value of the object, if any, boundto that name).
table uses the cross-classifying factors to build a contingencytable of the counts at each combination of factor levels.
Test if an object is not sorted (in increasing order), without thecost of sorting it.
vector produces a vector of the given length and mode.
R possesses a simple generic function mechanism which can be used foran object-oriented style of programming.  Method dispatch takes placebased on the class of the first argument to the generic function.
Display aspects of connections.
Internal namespace support functions.  Not intended to be calleddirectly, and only visible because of the special nature of thebase namespace.
Set, unset or query the debugging flag on a function.The text and condition arguments are the same as thosethat can be supplied via a call to browser.  They can be retrievedby the user once the browser has been entered, and provide a mechanism toallow users to identify which breakpoint has been activated.
These operators act on raw, logical and number-like vectors.
Functions to create, open and close connections, i.e.,“generalized files”, such as possibly compressed files, URLs,pipes, etc.
Internal namespace support functions.  Not intended to be calleddirectly, and only visible because of the special nature of thebase namespace.
Functions to load and unload name spaces.
Convenience wrappers to create date-times from numeric representations.
Convenience wrappers to create date-times from numeric representations.
Functions to create, open and close connections, i.e.,“generalized files”, such as possibly compressed files, URLs,pipes, etc.
These functions provide a mechanism for handling unusual conditions,including errors and warnings.
Tests whether the object is an instance of an S4 class.
Functions to re-position connections.
Generic function to test if object is symmetric or not.Currently only a matrix method is implemented, where acomplex matrix Z must be “Hermitian” forisSymmetric(Z) to be true.
Generic function to test if object is symmetric or not.Currently only a matrix method is implemented, where acomplex matrix Z must be “Hermitian” forisSymmetric(Z) to be true.
These operators act on raw, logical and number-like vectors.
Add a small amount of noise to a numeric vector.
Extract the weekday, month or quarter, or the Julian time(days since some origin).  These are generic functions: the methodsfor the internal date-time classes are documented here.
Extract the weekday, month or quarter, or the Julian time(days since some origin).  These are generic functions: the methodsfor the internal date-time classes are documented here.
Extract the weekday, month or quarter, or the Julian time(days since some origin).  These are generic functions: the methodsfor the internal date-time classes are documented here.
The condition number of a regular (square) matrix is the product ofthe norm of the matrix and the norm of its inverse (orpseudo-inverse), and hence depends on the kind of matrix-norm.
The condition number of a regular (square) matrix is the product ofthe norm of the matrix and the norm of its inverse (orpseudo-inverse), and hence depends on the kind of matrix-norm.
The condition number of a regular (square) matrix is the product ofthe norm of the matrix and the norm of its inverse (orpseudo-inverse), and hence depends on the kind of matrix-norm.
The condition number of a regular (square) matrix is the product ofthe norm of the matrix and the norm of its inverse (orpseudo-inverse), and hence depends on the kind of matrix-norm.
Computes the generalised kronecker product of two arrays,X and Y.
Report on localization information.
Report the name of the shared object file with LAPACK implementationin use.
Report the version of LAPACK in use.
Compute the singular-value decomposition of a rectangular matrix.
Find a suitable set of labels from an object for use in printing orplotting, for example.  A generic function.
Find a suitable set of labels from an object for use in printing orplotting, for example.  A generic function.
lapply returns a list of the same length as X, eachelement of which is the result of applying FUN to thecorresponding element of X.
Internal functions to lazy load a database of R objects.
Internal functions to lazy load a database of R objects.
Internal objects in the base package most of which are only user-visiblebecause of the special nature of the base namespace.
Special mathematical functions related to the beta and gammafunctions.
Special mathematical functions related to the beta and gammafunctions.
Get or set the length of vectors (including lists) and factors, and ofany other R object for which a method has been defined.
Description of the classes "POSIXlt" and "POSIXct"representing calendar dates and times.
Get or set the length of vectors (including lists) and factors, and ofany other R object for which a method has been defined.
Description of the class "Date" representing calendar dates.
Time intervals creation, printing, and some arithmetic.  Theprint() method calls these “time differences”.
Get or set the length of vectors (including lists) and factors, and ofany other R object for which a method has been defined.
Description of the classes "POSIXlt" and "POSIXct"representing calendar dates and times.
Description of the classes "POSIXlt" and "POSIXct"representing calendar dates and times.
Get the length of each element of a list or atomicvector (is.atomic) as an integer or numeric vector.
Constants built into R.
Constants built into R.
levels provides access to the levels attribute of a variable.The first form returns the value of the levels of its argumentand the second sets the attribute.
levels provides access to the levels attribute of a variable.The first form returns the value of the levels of its argumentand the second sets the attribute.
levels provides access to the levels attribute of a variable.The first form returns the value of the levels of its argumentand the second sets the attribute.
levels provides access to the levels attribute of a variable.The first form returns the value of the levels of its argumentand the second sets the attribute.
Special mathematical functions related to the beta and gammafunctions.
Special mathematical functions related to the beta and gammafunctions.
Report version of libcurl in use.
library and require load and attach add-on packages.
Load the specified file of compiled code if it has not been loadedalready, or unloads it.
Load the specified file of compiled code if it has not been loadedalready, or unloads it.
The license terms under which R is distributed.
The license terms under which R is distributed.
Functions to construct, coerce and check for both kinds of R lists.
These functions produce a character vector of the names of files ordirectories in the named directory.
These functions produce a character vector of the names of files ordirectories in the named directory.
Create a data frame from a list of variables.
From a named list x, create anenvironment containing all list components as objects, or“multi-assign” from x into a pre-existing environment.
Reload datasets written with the function save.
Functions to load and unload name spaces.
Internal namespace support functions.  Not intended to be calleddirectly, and only visible because of the special nature of thebase namespace.
Functions to load and unload name spaces.
Evaluate an R expression in a specified environment.
These functions represent an interface for adjustmentsto environments and bindings within environments.  They allow forlocking environments as well as individual bindings, and for linkinga variable to a function.
These functions represent an interface for adjustmentsto environments and bindings within environments.  They allow forlocking environments as well as individual bindings, and for linkinga variable to a function.
log computes logarithms, by default natural logarithms,log10 computes common (i.e., base 10) logarithms, andlog2 computes binary (i.e., base 2) logarithms.The general form log(x, base) computes logarithms with basebase.
log computes logarithms, by default natural logarithms,log10 computes common (i.e., base 10) logarithms, andlog2 computes binary (i.e., base 2) logarithms.The general form log(x, base) computes logarithms with basebase.
log computes logarithms, by default natural logarithms,log10 computes common (i.e., base 10) logarithms, andlog2 computes binary (i.e., base 2) logarithms.The general form log(x, base) computes logarithms with basebase.
log computes logarithms, by default natural logarithms,log10 computes common (i.e., base 10) logarithms, andlog2 computes binary (i.e., base 2) logarithms.The general form log(x, base) computes logarithms with basebase.
log computes logarithms, by default natural logarithms,log10 computes common (i.e., base 10) logarithms, andlog2 computes binary (i.e., base 2) logarithms.The general form log(x, base) computes logarithms with basebase.
Create or test for objects of type "logical", and the basiclogical constants.
Returns a matrix of logicals the same size of a given matrix withentries TRUE in the lower or upper triangle.
ls and objects return a vector of character stringsgiving the names of the objects in the specified environment.  Wheninvoked with no argument at the top level prompt, ls shows whatdata sets and functions a user has defined.  When invoked with noargument inside a function, ls returns the names of thefunction's local variables: this is useful in conjunction withbrowser.
Make syntactically valid names out of character vectors.
Makes the elements of a character vector unique byappending sequence numbers to duplicates.
These functions represent an interface for adjustmentsto environments and bindings within environments.  They allow forlocking environments as well as individual bindings, and for linkinga variable to a function.
Reduce uses a binary function to successively combine theelements of a given vector and a possibly given initial value.Filter extracts the elements of a vector for which a predicate(logical) function gives true.  Find and Position givethe first or last such element and its position in the vector,respectively.  Map applies a function to the correspondingelements of given vectors.  Negate creates the negation of agiven function.
mapply is a multivariate version of sapply.mapply applies FUN to the first elements of each ...argument, the second elements, the third elements, and so on.Arguments are recycled if necessary.
For a contingency table in array form, compute the sum of tableentries for a given margin or set of margins.
For a contingency table in array form, compute the sum of tableentries for a given margin or set of margins.
mat.or.vec creates an nr by nc zero matrix ifnc is greater than 1, and a zero vector of length nr ifnc equals 1.
match returns a vector of the positions of (first) matches ofits first argument in its second.
match.arg matches arg against a table of candidatevalues as specified by choices, where NULL means to takethe first one.
match.call returns a call in which all of the specified arguments arespecified by their full names.
When called inside functions that take a function as argument, extractthe desired function object while avoiding undesired matching toobjects of other types.
Group generic methods can be defined for four pre-specified groups offunctions, Math, Ops, Summary and Complex.(There are no objects of these names in base R, but there are in themethods package.)
Description of the class "Date" representing calendar dates.
Time intervals creation, printing, and some arithmetic.  Theprint() method calls these “time differences”.
The function factor is used to encode a vector as a factor (theterms ‘category’ and ‘enumerated type’ are also used forfactors).  If argument ordered is TRUE, the factorlevels are assumed to be ordered.  For compatibility with S there isalso a function ordered.
Description of the classes "POSIXlt" and "POSIXct"representing calendar dates and times.
matrix creates a matrix from the given set of values.
Returns the (regular or parallel) maxima and minima of theinput values.
Find the maximum position for each row of a matrix, breaking ties at random.
Generic function for the (trimmed) arithmetic mean.
Description of the class "Date" representing calendar dates.
Generic function for the (trimmed) arithmetic mean.
Time intervals creation, printing, and some arithmetic.  Theprint() method calls these “time differences”.
Description of the classes "POSIXlt" and "POSIXct"representing calendar dates and times.
Description of the classes "POSIXlt" and "POSIXct"representing calendar dates and times.
Query and set the maximal size of the vector heap and the maximalnumber of heap nodes for the current R process.
Query and set the maximal size of the vector heap and the maximalnumber of heap nodes for the current R process.
In-memory compression or decompression for raw vectors.
In-memory compression or decompression for raw vectors.
Lists the usage of the cons cells by SEXPREC type.
Merge two data frames by common columns or row names, or do otherversions of database join operations.
Merge two data frames by common columns or row names, or do otherversions of database join operations.
Merge two data frames by common columns or row names, or do otherversions of database join operations.
Generate a diagnostic message from its arguments.
Search by name for an object (get) or zero or more objects(mget).
Returns the (regular or parallel) maxima and minima of theinput values.
missing can be used to test whether a value was specifiedas an argument to a function.
Basic functions which support complex arithmetic in R, in addition tothe arithmetic operators +, -, *, /, and ^.
Get or set the ‘mode’ (a kind of ‘type’), or the storagemode of an R object.
Get or set the ‘mode’ (a kind of ‘type’), or the storagemode of an R object.
Constants built into R.
Constants built into R.
Extract the weekday, month or quarter, or the Julian time(days since some origin).  These are generic functions: the methodsfor the internal date-time classes are documented here.
Extract the weekday, month or quarter, or the Julian time(days since some origin).  These are generic functions: the methodsfor the internal date-time classes are documented here.
Extract the weekday, month or quarter, or the Julian time(days since some origin).  These are generic functions: the methodsfor the internal date-time classes are documented here.
These functions access an object's attributes.The first form below returns the object's attribute list.The replacement forms uses the list on the right-handside of the assignment as the object's attributes (if appropriate).
Functions to get or set the names of an object.
Description of the classes "POSIXlt" and "POSIXct"representing calendar dates and times.
Functions to get or set the names of an object.
Description of the classes "POSIXlt" and "POSIXct"representing calendar dates and times.
Internal namespace support functions.  Not intended to be calleddirectly, and only visible because of the special nature of thebase namespace.
Internal namespace support functions.  Not intended to be calleddirectly, and only visible because of the special nature of thebase namespace.
Internal namespace support functions.  Not intended to be calleddirectly, and only visible because of the special nature of thebase namespace.
Internal namespace support functions.  Not intended to be calleddirectly, and only visible because of the special nature of thebase namespace.
Internal namespace support functions.  Not intended to be calleddirectly, and only visible because of the special nature of thebase namespace.
When used inside a function body, nargs returns the number ofarguments supplied to that function, including positionalarguments left blank.
nchar takes a character vector as an argument andreturns a vector whose elements contain the sizes ofthe corresponding elements of x. Internally, it is a generic,for which methods can be defined (see InternalMethods).
nrow and ncol return the number of rows or columnspresent in x.NCOL and NROW do the same treating a vector as1-column matrix, even a 0-length vector, compatibly withas.matrix() or cbind(), see the example.
nrow and ncol return the number of rows or columnspresent in x.NCOL and NROW do the same treating a vector as1-column matrix, even a 0-length vector, compatibly withas.matrix() or cbind(), see the example.
Reduce uses a binary function to successively combine theelements of a given vector and a possibly given initial value.Filter extracts the elements of a vector for which a predicate(logical) function gives true.  Find and Position givethe first or last such element and its position in the vector,respectively.  Map applies a function to the correspondingelements of given vectors.  Negate creates the negation of agiven function.
Get, set, test for and create environments.
These are the basic control-flow constructs of the R language.  Theyfunction in much the same way as control statements in any Algol-likelanguage.  They are all reserved words.
R possesses a simple generic function mechanism which can be used foran object-oriented style of programming.  Method dispatch takes placebased on the class(es) of the first argument to the generic function or ofthe object supplied as an argument to UseMethod or NextMethod.
If Native Language Support (NLS) was enabled in this build of R (seethe bindtextdomain() example), attempt totranslate character vectors or set where the translations are to be found.
Return the number of levels which its argument has.
Print character strings without quotes.
Computes a matrix norm of x using LAPACK.  The norm can bethe one ("O") norm, the infinity ("I") norm, theFrobenius ("F") norm, the maximum modulus ("M") amongelements of a matrix, or the “spectral” or "2"-norm, asdetermined by the value of type.
Convert file paths to canonical form for the platform, to display themin a user-understandable form and so that relative and absolute paths canbe compared.
nrow and ncol return the number of rows or columnspresent in x.NCOL and NROW do the same treating a vector as1-column matrix, even a 0-length vector, compatibly withas.matrix() or cbind(), see the example.
nrow and ncol return the number of rows or columnspresent in x.NCOL and NROW do the same treating a vector as1-column matrix, even a 0-length vector, compatibly withas.matrix() or cbind(), see the example.
Display aspects of connections.
Creates or coerces objects of type "numeric".is.numeric is a more general test of an object beinginterpretable as numbers.
A simple S3 class for representing numeric versionsincluding package versions, and associated methods.
Conversion to and from and manipulation of objects of type "raw",both used as bits or “packed” 8 bits.
Conversion to and from and manipulation of objects of type "raw",both used as bits or “packed” 8 bits.
nchar takes a character vector as an argument andreturns a vector whose elements contain the sizes ofthe corresponding elements of x. Internally, it is a generic,for which methods can be defined (see InternalMethods).
ls and objects return a vector of character stringsgiving the names of the objects in the specified environment.  Wheninvoked with no argument at the top level prompt, ls shows whatdata sets and functions a user has defined.  When invoked with noargument inside a function, ls returns the names of thefunction's local variables: this is useful in conjunction withbrowser.
R possesses a simple generic function mechanism which can be used foran object-oriented style of programming.  Method dispatch takes placebased on the class of the first argument to the generic function.
R possesses a simple generic function mechanism which can be used foran object-oriented style of programming.  Method dispatch takes placebased on the class of the first argument to the generic function.
Information about time zones in R.  Sys.timezone returnsthe name of the current time zone.
on.exit records the expression given as its argument as needingto be executed when the current function exits (either naturally or asthe result of an error).  This is useful for resetting graphicalparameters or performing other cleanup actions.
Functions to create, open and close connections, i.e.,“generalized files”, such as possibly compressed files, URLs,pipes, etc.
Functions to create, open and close connections, i.e.,“generalized files”, such as possibly compressed files, URLs,pipes, etc.
These functions are for working with source files and more generallywith “source references” ("srcref"), i.e., references tosource code.  The resulting data is used for printing and source leveldebugging, and is typically available in interactive R sessions,namely when options(keep.source = TRUE).
These functions are for working with source files and more generallywith “source references” ("srcref"), i.e., references tosource code.  The resulting data is used for printing and source leveldebugging, and is typically available in interactive R sessions,namely when options(keep.source = TRUE).
These functions are for working with source files and more generallywith “source references” ("srcref"), i.e., references tosource code.  The resulting data is used for printing and source leveldebugging, and is typically available in interactive R sessions,namely when options(keep.source = TRUE).
Group generic methods can be defined for four pre-specified groups offunctions, Math, Ops, Summary and Complex.(There are no objects of these names in base R, but there are in themethods package.)
Operators for the "Date" class.
Time intervals creation, printing, and some arithmetic.  Theprint() method calls these “time differences”.
The function factor is used to encode a vector as a factor (theterms ‘category’ and ‘enumerated type’ are also used forfactors).  If argument ordered is TRUE, the factorlevels are assumed to be ordered.  For compatibility with S there isalso a function ordered.
A simple S3 class for representing numeric versionsincluding package versions, and associated methods.
The function factor is used to encode a vector as a factor (theterms ‘category’ and ‘enumerated type’ are also used forfactors).  If argument ordered is TRUE, the factorlevels are assumed to be ordered.  For compatibility with S there isalso a function ordered.
Description of the classes "POSIXlt" and "POSIXct"representing calendar dates and times.
Allow the user to set and examine a variety of global optionswhich affect the way in which R computes and displays its results.
order returns a permutation which rearranges its firstargument into ascending or descending order, breaking ties by furtherarguments.  sort.list does the same, using only one argument.See the examples for how to use these functions to sort data frames,etc.
The function factor is used to encode a vector as a factor (theterms ‘category’ and ‘enumerated type’ are also used forfactors).  If argument ordered is TRUE, the factorlevels are assumed to be ordered.  For compatibility with S there isalso a function ordered.
The outer product of the arrays X and Y is the arrayA with dimension c(dim(X), dim(Y)) where elementA[c(arrayindex.x, arrayindex.y)]    = FUN(X[arrayindex.x], Y[arrayindex.y], ...).
A simple S3 class for representing numeric versionsincluding package versions, and associated methods.
These functions allow users to set actions to be taken before packagesare attached/detached and namespaces are (un)loaded.
Internal namespace support functions.  Not intended to be calleddirectly, and only visible because of the special nature of thebase namespace.
Find the paths to one or more packages.
Generate a diagnostic message from its arguments.
Conversion to and from and manipulation of objects of type "raw",both used as bits or “packed” 8 bits.
Functions to construct, coerce and check for both kinds of R lists.
Get, set, test for and create environments.
Get, set, test for and create environments.
These functions provide access to environments(‘frames’ in S terminology) associated with functions furtherup the calling stack.
parse() returns the parsed but unevaluated expressions in anexpression, a “list” of calls.
Internal namespace support functions.  Not intended to be calleddirectly, and only visible because of the special nature of thebase namespace.
Concatenate vectors after converting to character.
Concatenate vectors after converting to character.
Expand a path name, for example by replacing a leading tilde by theuser's home directory (if defined on that platform).
Find the paths to one or more packages.
Report some of the configuration options of the version of PCRE in usein this R session.
Constants built into R.
Functions to create, open and close connections, i.e.,“generalized files”, such as possibly compressed files, URLs,pipes, etc.
Generic function for plotting of R objects.
pmatch seeks matches for the elements of its first argumentamong those of its second.
Returns the (regular or parallel) maxima and minima of theinput values.
Returns the (regular or parallel) maxima and minima of theinput values.
Returns the (regular or parallel) maxima and minima of theinput values.
Returns the (regular or parallel) maxima and minima of theinput values.
Find zeros of a real or complex polynomial.
Returns the environment at a specified position in the search path.
Reduce uses a binary function to successively combine theelements of a given vector and a possibly given initial value.Filter extracts the elements of a vector for which a predicate(logical) function gives true.  Find and Position givethe first or last such element and its position in the vector,respectively.  Map applies a function to the correspondingelements of given vectors.  Negate creates the negation of agiven function.
Compute a  sequence of about n+1 equally spaced ‘round’values which cover the range of the values in x.The values are chosen so that they are 1, 2 or 5 times a power of 10.
Compute a  sequence of about n+1 equally spaced ‘round’values which cover the range of the values in x.The values are chosen so that they are 1, 2 or 5 times a power of 10.
formatC() formats numbers individually and flexibly usingC style format specifications.
print prints its argument and returns it invisibly (viainvisible(x)).  It is a generic function which means thatnew printing methods can be easily added for new classes.
Change the class of an object to indicate that it should be treated‘as is’.
Function by is an object-oriented wrapper fortapply applied to data frames.
These functions provide a mechanism for handling unusual conditions,including errors and warnings.
Functions to create, open and close connections, i.e.,“generalized files”, such as possibly compressed files, URLs,pipes, etc.
Print a data frame.
Description of the class "Date" representing calendar dates.
print.default is the default method of the genericprint function which prints its argument.
Time intervals creation, printing, and some arithmetic.  Theprint() method calls these “time differences”.
print prints its argument and returns it invisibly (viainvisible(x)).  It is a generic function which means thatnew printing methods can be easily added for new classes.
This function provides a way to get a list of all the DLLs (seedyn.load) that are currently loaded in the R session.
This function provides a way to get a list of all the DLLs (seedyn.load) that are currently loaded in the R session.
This function allows us to query the set of routinesin a DLL that are registered with R to enhancedynamic lookup, error handling when calling native routines,and potentially security in the future.This function provides a description of each of theregistered routines in the DLL for the different interfaces,i.e. .C, .Call, .Fortranand .External.
Computes eigenvalues and eigenvectors of numeric (double, integer,logical) or complex matrices.
print prints its argument and returns it invisibly (viainvisible(x)).  It is a generic function which means thatnew printing methods can be easily added for new classes.
print prints its argument and returns it invisibly (viainvisible(x)).  It is a generic function which means thatnew printing methods can be easily added for new classes.
Convert or print integers in hexadecimal format, with as many digitsas are needed to display the largest, using leading zeroes asnecessary.
library and require load and attach add-on packages.
print prints its argument and returns it invisibly (viainvisible(x)).  It is a generic function which means thatnew printing methods can be easily added for new classes.
This function allows us to query the set of routinesin a DLL that are registered with R to enhancedynamic lookup, error handling when calling native routines,and potentially security in the future.This function provides a description of each of theregistered routines in the DLL for the different interfaces,i.e. .C, .Call, .Fortranand .External.
Print character strings without quotes.
A simple S3 class for representing numeric versionsincluding package versions, and associated methods.
Convert or print integers in octal format, with as many digits as areneeded to display the largest, using leading zeroes as necessary.
library and require load and attach add-on packages.
Description of the classes "POSIXlt" and "POSIXct"representing calendar dates and times.
Description of the classes "POSIXlt" and "POSIXct"representing calendar dates and times.
proc.time determines how much real and CPU time (in seconds)the currently running R process has already taken.
These functions provide a mechanism for handling unusual conditions,including errors and warnings.
Compute the lengths and values of runs of equal values in a vector– or the reverse operation.
print prints its argument and returns it invisibly (viainvisible(x)).  It is a generic function which means thatnew printing methods can be easily added for new classes.
These functions are for working with source files and more generallywith “source references” ("srcref"), i.e., references tosource code.  The resulting data is used for printing and source leveldebugging, and is typically available in interactive R sessions,namely when options(keep.source = TRUE).
These functions are for working with source files and more generallywith “source references” ("srcref"), i.e., references tosource code.  The resulting data is used for printing and source leveldebugging, and is typically available in interactive R sessions,namely when options(keep.source = TRUE).
table uses the cross-classifying factors to build a contingencytable of the counts at each combination of factor levels.
warnings and its print method print thevariable last.warning in a pleasing form.
summary is a generic function used to produce result summariesof the results of various model fitting functions.  The functioninvokes particular methods which depend on theclass of the first argument.
print prints its argument and returns it invisibly (viainvisible(x)).  It is a generic function which means thatnew printing methods can be easily added for new classes.
warnings and its print method print thevariable last.warning in a pleasing form.
An earlier method for printing matrices, provided for S compatibility.
proc.time determines how much real and CPU time (in seconds)the currently running R process has already taken.
prod returns the product of all the valuespresent in its arguments.
Returns conditional proportions given margins, i.e. entries of x, divided by the appropriate marginal sums. 
Returns conditional proportions given margins, i.e. entries of x, divided by the appropriate marginal sums. 
Retrieve or set the dimnames of an object.
Special mathematical functions related to the beta and gammafunctions.
Functions to push back text lines onto a connection, and to enquirehow many lines are currently pushed back.
Functions to push back text lines onto a connection, and to enquirehow many lines are currently pushed back.
The function quit or its alias q terminate the currentR session.
qr computes the QR decomposition of a matrix.
qr computes the QR decomposition of a matrix.
qr computes the QR decomposition of a matrix.
qr computes the QR decomposition of a matrix.
Returns the original matrix from which the object was constructed orthe components of the decomposition.
qr computes the QR decomposition of a matrix.
qr computes the QR decomposition of a matrix.
Returns the original matrix from which the object was constructed orthe components of the decomposition.
qr computes the QR decomposition of a matrix.
qr computes the QR decomposition of a matrix.
Returns the original matrix from which the object was constructed orthe components of the decomposition.
Extract the weekday, month or quarter, or the Julian time(days since some origin).  These are generic functions: the methodsfor the internal date-time classes are documented here.
Extract the weekday, month or quarter, or the Julian time(days since some origin).  These are generic functions: the methodsfor the internal date-time classes are documented here.
Extract the weekday, month or quarter, or the Julian time(days since some origin).  These are generic functions: the methodsfor the internal date-time classes are documented here.
The function quit or its alias q terminate the currentR session.
substitute returns the parse tree for the (unevaluated)expression expr, substituting any variables bound inenv.
A simple S3 class for representing numeric versionsincluding package versions, and associated methods.
Return the R home directory, or the full path to a component of theR installation.
R.Version() provides detailed information about the version ofR running.
R.Version() provides detailed information about the version ofR running.
R.Version() provides detailed information about the version ofR running.
range returns a vector containing the minimum and maximum ofall the given arguments.
range returns a vector containing the minimum and maximum ofall the given arguments.
Returns the sample ranks of the values in a vector.  Ties (i.e., equalvalues) and missing values can be handled in several ways.
rapply is a recursive version of lapply withflexibility in how the result is structured (how = "..").
Creates or tests for objects of type "raw".
Input and output raw connections.
Input and output raw connections.
Conversion to and from and manipulation of objects of type "raw",both used as bits or “packed” 8 bits.
Conversion to and from and manipulation of objects of type "raw",both used as bits or “packed” 8 bits.
Conversion to and from and manipulation of objects of type "raw",both used as bits or “packed” 8 bits.
Take a sequence of vector, matrix or data-frame arguments and combineby columns or rows, respectively.  These are genericfunctions with methods for other R classes.
Take a sequence of vector, matrix or data-frame arguments and combineby columns or rows, respectively.  These are genericfunctions with methods for other R classes.
The condition number of a regular (square) matrix is the product ofthe norm of the matrix and the norm of its inverse (orpseudo-inverse), and hence depends on the kind of matrix-norm.
Basic functions which support complex arithmetic in R, in addition tothe arithmetic operators +, -, *, /, and ^.
Reads or writes an R object from/to a file in Debian Control Fileformat.
Read binary data from or write binary data to a connection or raw vector.
Transfer character strings to and from connections, without assumingthey are null-terminated on the connection.
readline reads a line from the terminal (in interactive use).
Read some or all text lines from a connection.
Functions to write a single R object to a file, and to restore it.
Read as file such as ‘.Renviron’ or ‘Renviron.site’ in theformat described in the help for Startup, and set environmentvariables as defined in the file.
Recall is used as a placeholder for the name of the functionin which it is called.  It allows the definition of recursivefunctions which still work after being renamed, see example below.
Reduce uses a binary function to successively combine theelements of a given vector and a possibly given initial value.Filter extracts the elements of a vector for which a predicate(logical) function gives true.  Find and Position givethe first or last such element and its position in the vector,respectively.  Map applies a function to the correspondingelements of given vectors.  Negate creates the negation of agiven function.
Registers an R function to be called upon garbage collection ofobject or (optionally) at the end of an R session.
grep, grepl, regexpr, gregexpr, regexec and gregexec search for matches to argumentpattern within each element of a character vector: they differ inthe format of and amount of detail in the results.
grep, grepl, regexpr, gregexpr, regexec and gregexec search for matches to argumentpattern within each element of a character vector: they differ inthe format of and amount of detail in the results.
Internal namespace support functions.  Not intended to be calleddirectly, and only visible because of the special nature of thebase namespace.
Internal namespace support functions.  Not intended to be calleddirectly, and only visible because of the special nature of thebase namespace.
Extract or replace matched substrings from match data obtained byregexpr, gregexpr,regexec or gregexec.
Extract or replace matched substrings from match data obtained byregexpr, gregexpr,regexec or gregexec.
remove and rm can be used to remove objects.  These canbe specified successively as character strings, or in the charactervector list, or through a combination of both.  All objectsthus specified will be removed.
addTaskCallback registers an R functionthat is to be called each time a top-level taskis completed.
rep replicates the values in x.  It is a genericfunction, and the (internal) default method is described here.
rep replicates the values in x.  It is a genericfunction, and the (internal) default method is described here.
rep replicates the values in x.  It is a genericfunction, and the (internal) default method is described here.
Time intervals creation, printing, and some arithmetic.  Theprint() method calls these “time differences”.
rep replicates the values in x.  It is a genericfunction, and the (internal) default method is described here.
rep replicates the values in x.  It is a genericfunction, and the (internal) default method is described here.
A simple S3 class for representing numeric versionsincluding package versions, and associated methods.
rep replicates the values in x.  It is a genericfunction, and the (internal) default method is described here.
rep replicates the values in x.  It is a genericfunction, and the (internal) default method is described here.
These are the basic control-flow constructs of the R language.  Theyfunction in much the same way as control statements in any Algol-likelanguage.  They are all reserved words.
replace replaces the values in xwith indices given in list by those given in values.If necessary, the values in values are recycled.
lapply returns a list of the same length as X, eachelement of which is the result of applying FUN to thecorresponding element of X.
library and require load and attach add-on packages.
Functions to load and unload name spaces.
These functions provide a mechanism for handling unusual conditions,including errors and warnings.
These functions provide a mechanism for handling unusual conditions,including errors and warnings.
This function marks an object so that a message is printed whenever theinternal code copies the object.  It is amajor cause of hard-to-predict memory use in R.
These functions provide the base mechanisms for definingnew functions in the R language.
A call to trace allows you to insert debugging code (e.g., acall to browser or recover) at chosenplaces in any function.  A call to untrace cancels the tracing.Specified methods can be traced the same way, without tracing allcalls to the generic function.  Trace code (tracer) can be anyR expression.  Tracing can be temporarily turned on or off globallyby calling tracingState.
rev provides a reversed version of its argument.  It is genericfunction with a default method for vectors and one fordendrograms.
rev provides a reversed version of its argument.  It is genericfunction with a default method for vectors and one fordendrograms.
Compute the lengths and values of runs of equal values in a vector– or the reverse operation.
remove and rm can be used to remove objects.  These canbe specified successively as character strings, or in the charactervector list, or through a combination of both.  All objectsthus specified will be removed.
.Random.seed is an integer vector, containing the random numbergenerator (RNG) state for random number generation in R.  Itcan be saved and restored, but should not be altered by the user.
.Random.seed is an integer vector, containing the random numbergenerator (RNG) state for random number generation in R.  Itcan be saved and restored, but should not be altered by the user.
ceiling takes a single numeric argument x and returns anumeric vector containing the smallest integers not less than thecorresponding elements of x.
Round or truncate date-time objects.
Round or truncate date-time objects.
Returns a matrix of integers indicating their row number in amatrix-like object, or a factor indicating the row labels.
All data frames have row names, a character vector oflength the number of rows with no duplicates nor missing values.
All data frames have row names, a character vector oflength the number of rows with no duplicates nor missing values.
All data frames have row names, a character vector oflength the number of rows with no duplicates nor missing values.
All data frames have row names, a character vector oflength the number of rows with no duplicates nor missing values.
All data frames have row names, a character vector oflength the number of rows with no duplicates nor missing values.
All data frames have row names, a character vector oflength the number of rows with no duplicates nor missing values.
Form row and column sums and means for numeric arrays (or data frames).
Retrieve or set the row or column names of a matrix-like object.
Retrieve or set the row or column names of a matrix-like object.
Compute column sums across rows of a numeric matrix-like object foreach level of a grouping variable.  rowsum is generic, with amethod for data frames and a default method for vectors and matrices.
Compute column sums across rows of a numeric matrix-like object foreach level of a grouping variable.  rowsum is generic, with amethod for data frames and a default method for vectors and matrices.
Compute column sums across rows of a numeric matrix-like object foreach level of a grouping variable.  rowsum is generic, with amethod for data frames and a default method for vectors and matrices.
Form row and column sums and means for numeric arrays (or data frames).
sample takes a sample of the specified size from the elementsof x using either with or without replacement.
sample takes a sample of the specified size from the elementsof x using either with or without replacement.
lapply returns a list of the same length as X, eachelement of which is the result of applying FUN to thecorresponding element of X.
save writes an external representation of R objects to thespecified file.  The objects can be read back from the file at a laterdate by using the function load or attach(or data in some cases).
save writes an external representation of R objects to thespecified file.  The objects can be read back from the file at a laterdate by using the function load or attach(or data in some cases).
Functions to write a single R object to a file, and to restore it.
scale is generic function whose default method centers and/orscales the columns of a numeric matrix.
scale is generic function whose default method centers and/orscales the columns of a numeric matrix.
Read data into a vector or list from the console or file.
Gives a list of attached packages(see library), and R objects, usuallydata.frames.
Gives a list of attached packages(see library), and R objects, usuallydata.frames.
Functions to re-position connections.
Functions to re-position connections.
Generate regular sequences.  seq is a standard generic with adefault method.  seq.int is a primitive which can bemuch faster but has a few restrictions.  seq_along andseq_len are very fast primitives for two common cases.
Generate regular sequences.  seq is a standard generic with adefault method.  seq.int is a primitive which can bemuch faster but has a few restrictions.  seq_along andseq_len are very fast primitives for two common cases.
Generate regular sequences.  seq is a standard generic with adefault method.  seq.int is a primitive which can bemuch faster but has a few restrictions.  seq_along andseq_len are very fast primitives for two common cases.
The method for seq for objects of class"Date" representing calendar dates.
Generate regular sequences.  seq is a standard generic with adefault method.  seq.int is a primitive which can bemuch faster but has a few restrictions.  seq_along andseq_len are very fast primitives for two common cases.
Generate regular sequences.  seq is a standard generic with adefault method.  seq.int is a primitive which can bemuch faster but has a few restrictions.  seq_along andseq_len are very fast primitives for two common cases.
The method for seq for date-time classes.
The default method for sequence generates the sequenceseq(from[i], by = by[i], length.out = nvec[i]) for eachelement i in the parallel (and recycled) vectors from,by and nvec. It then returns the result of concatenatingthose sequences.
The default method for sequence generates the sequenceseq(from[i], by = by[i], length.out = nvec[i]) for eachelement i in the parallel (and recycled) vectors from,by and nvec. It then returns the result of concatenatingthose sequences.
A simple low-level interface for serializing to connections.
Functions to create, open and close connections, i.e.,“generalized files”, such as possibly compressed files, URLs,pipes, etc.
.Random.seed is an integer vector, containing the random numbergenerator (RNG) state for random number generation in R.  Itcan be saved and restored, but should not be altered by the user.
Performs set union, intersection, (asymmetric!) difference,equality and membership on two vectors.
Performs set union, intersection, (asymmetric!) difference,equality and membership on two vectors.
These functions allow users to set actions to be taken before packagesare attached/detached and namespaces are (un)loaded.
Internal namespace support functions.  Not intended to be calleddirectly, and only visible because of the special nature of thebase namespace.
Functions to set CPU and/or elapsed time limits for top-levelcomputations or the current session.
Functions to set CPU and/or elapsed time limits for top-levelcomputations or the current session.
getwd returns an absolute filepath representing the currentworking directory of the R process; setwd(dir) is used to setthe working directory to dir.
Display aspects of connections.
Quote a string to be passed to an operating system shell.
sign returns a vector with the signs of the correspondingelements of x (the sign of a real number is 1, 0, or -1if the number is positive, zero, or negative, respectively).
These functions provide a mechanism for handling unusual conditions,including errors and warnings.
ceiling takes a single numeric argument x and returns anumeric vector containing the smallest integers not less than thecorresponding elements of x.
These functions provide a mechanism for handling unusual conditions,including errors and warnings.
These functions provide a mechanism for handling unusual conditions,including errors and warnings.
These functions provide a mechanism for handling unusual conditions,including errors and warnings.
These functions provide a mechanism for handling unusual conditions,including errors and warnings.
lapply returns a list of the same length as X, eachelement of which is the result of applying FUN to thecorresponding element of X.
These functions give the obvious trigonometric functions.  Theyrespectively compute the cosine, sine, tangent, arc-cosine, arc-sine,arc-tangent, and the two-argument arc-tangent.
Create, coerce to or test for a double-precision vector.
These functions give the obvious hyperbolic functions.  Theyrespectively compute the hyperbolic cosine, sine, tangent, and theirinverses, arc-cosine, arc-sine, arc-tangent (or ‘area cosine’,etc).
sink diverts R output to a connection (and stops such diversions).
sink diverts R output to a connection (and stops such diversions).
These functions give the obvious trigonometric functions.  Theyrespectively compute the cosine, sine, tangent, arc-cosine, arc-sine,arc-tangent, and the two-argument arc-tangent.
Returns a matrix of integers indicating the number of their slice in agiven array.
Functions to create, open and close connections, i.e.,“generalized files”, such as possibly compressed files, URLs,pipes, etc.
Functions to create, open and close connections, i.e.,“generalized files”, such as possibly compressed files, URLs,pipes, etc.
Waits for the first of several socket connections and server socketsto become available.
Functions to create, open and close connections, i.e.,“generalized files”, such as possibly compressed files, URLs,pipes, etc.
This generic function solves the equation a %*% x = b for x,where b can be either a vector or a matrix.
This generic function solves the equation a %*% x = b for x,where b can be either a vector or a matrix.
qr computes the QR decomposition of a matrix.
Sort (or order) a vector or factor (partially) intoascending or descending order.  For ordering along more than onevariable, e.g., for sorting data frames, see order.
Sort (or order) a vector or factor (partially) intoascending or descending order.  For ordering along more than onevariable, e.g., for sorting data frames, see order.
Sort (or order) a vector or factor (partially) intoascending or descending order.  For ordering along more than onevariable, e.g., for sorting data frames, see order.
order returns a permutation which rearranges its firstargument into ascending or descending order, breaking ties by furtherarguments.  sort.list does the same, using only one argument.See the examples for how to use these functions to sort data frames,etc.
Sort (or order) a vector or factor (partially) intoascending or descending order.  For ordering along more than onevariable, e.g., for sorting data frames, see order.
source causes R to accept its input from the named file or URLor connection or expressions directly.  Input is read andparsed from that fileuntil the end of the file is reached, then the parsed expressions areevaluated sequentially in the chosen environment.
split divides the data in the vector x into the groupsdefined by f.  The replacement forms replace valuescorresponding to such a division.  unsplit reverses the effect ofsplit.
split divides the data in the vector x into the groupsdefined by f.  The replacement forms replace valuescorresponding to such a division.  unsplit reverses the effect ofsplit.
Description of the class "Date" representing calendar dates.
split divides the data in the vector x into the groupsdefined by f.  The replacement forms replace valuescorresponding to such a division.  unsplit reverses the effect ofsplit.
Description of the classes "POSIXlt" and "POSIXct"representing calendar dates and times.
split divides the data in the vector x into the groupsdefined by f.  The replacement forms replace valuescorresponding to such a division.  unsplit reverses the effect ofsplit.
split divides the data in the vector x into the groupsdefined by f.  The replacement forms replace valuescorresponding to such a division.  unsplit reverses the effect ofsplit.
split divides the data in the vector x into the groupsdefined by f.  The replacement forms replace valuescorresponding to such a division.  unsplit reverses the effect ofsplit.
A wrapper for the C function sprintf, that returns a charactervector containing a formatted combination of text and variable values.
abs(x) computes the absolute value of x, sqrt(x) computes the(principal) square root of x, √{x}.
Single or double quote text by combining with appropriate single ordouble left and right quotation marks.
These functions are for working with source files and more generallywith “source references” ("srcref"), i.e., references tosource code.  The resulting data is used for printing and source leveldebugging, and is typically available in interactive R sessions,namely when options(keep.source = TRUE).
These functions are for working with source files and more generallywith “source references” ("srcref"), i.e., references tosource code.  The resulting data is used for printing and source leveldebugging, and is typically available in interactive R sessions,namely when options(keep.source = TRUE).
These functions are for working with source files and more generallywith “source references” ("srcref"), i.e., references tosource code.  The resulting data is used for printing and source leveldebugging, and is typically available in interactive R sessions,namely when options(keep.source = TRUE).
These functions are for working with source files and more generallywith “source references” ("srcref"), i.e., references tosource code.  The resulting data is used for printing and source leveldebugging, and is typically available in interactive R sessions,namely when options(keep.source = TRUE).
The function standardGeneric initiates dispatch of S4methods: see the references and the documentation of themethods package.  Usually, calls to this function aregenerated automatically and not explicitly by the programmer.
Determines if entries of x start or end with string (entries of)prefix or suffix respectively, where strings arerecycled to common lengths.
Display aspects of connections.
Display aspects of connections.
Display aspects of connections.
stop stops execution of the current expression and executesan error action.
If any of the expressions (in ... or exprs) are notall TRUE, stop is called, producingan error message indicating the first expression which was not(all) true.
Get or set the ‘mode’ (a kind of ‘type’), or the storagemode of an R object.
Get or set the ‘mode’ (a kind of ‘type’), or the storagemode of an R object.
parse() returns the parsed but unevaluated expressions in anexpression, a “list” of calls.
parse() returns the parsed but unevaluated expressions in anexpression, a “list” of calls.
Functions to convert between character representations and objects ofclasses "POSIXlt" and "POSIXct" representing calendardates and times.
Functions to convert between character representations and objects ofclasses "POSIXlt" and "POSIXct" representing calendardates and times.
Repeat the character strings in a character vector a given number oftimes (i.e., concatenate the respective numbers of copies of thestrings).
Split the elements of a character vector x into substringsaccording to the matches to substring split within them.
Convert strings to integers according to the given base using the Cfunction strtol, or choose a suitable base following the C rules.
Trim character strings to specified display widths.
structure returns the given object with furtherattributes set.
Each character string in the input is first split into paragraphs (orlines containing whitespace only).  The paragraphs are then formattedby breaking lines at word boundaries.  The target columns for wrappinglines and the indentation of the first and all subsequent lines of aparagraph can be controlled independently.
grep, grepl, regexpr, gregexpr, regexec and gregexec search for matches to argumentpattern within each element of a character vector: they differ inthe format of and amount of detail in the results.
Return subsets of vectors, matrices or data frames which meet conditions.
Return subsets of vectors, matrices or data frames which meet conditions.
Return subsets of vectors, matrices or data frames which meet conditions.
Return subsets of vectors, matrices or data frames which meet conditions.
substitute returns the parse tree for the (unevaluated)expression expr, substituting any variables bound inenv.
Extract or replace substrings in a character vector.
Extract or replace substrings in a character vector.
Extract or replace substrings in a character vector.
Extract or replace substrings in a character vector.
sum returns the sum of all the valuespresent in its arguments.
summary is a generic function used to produce result summariesof the results of various model fitting functions.  The functioninvokes particular methods which depend on theclass of the first argument.
Functions to create, open and close connections, i.e.,“generalized files”, such as possibly compressed files, URLs,pipes, etc.
summary is a generic function used to produce result summariesof the results of various model fitting functions.  The functioninvokes particular methods which depend on theclass of the first argument.
Group generic methods can be defined for four pre-specified groups offunctions, Math, Ops, Summary and Complex.(There are no objects of these names in base R, but there are in themethods package.)
Description of the class "Date" representing calendar dates.
Description of the class "Date" representing calendar dates.
summary is a generic function used to produce result summariesof the results of various model fitting functions.  The functioninvokes particular methods which depend on theclass of the first argument.
Time intervals creation, printing, and some arithmetic.  Theprint() method calls these “time differences”.
summary is a generic function used to produce result summariesof the results of various model fitting functions.  The functioninvokes particular methods which depend on theclass of the first argument.
The function factor is used to encode a vector as a factor (theterms ‘category’ and ‘enumerated type’ are also used forfactors).  If argument ordered is TRUE, the factorlevels are assumed to be ordered.  For compatibility with S there isalso a function ordered.
summary is a generic function used to produce result summariesof the results of various model fitting functions.  The functioninvokes particular methods which depend on theclass of the first argument.
A simple S3 class for representing numeric versionsincluding package versions, and associated methods.
The function factor is used to encode a vector as a factor (theterms ‘category’ and ‘enumerated type’ are also used forfactors).  If argument ordered is TRUE, the factorlevels are assumed to be ordered.  For compatibility with S there isalso a function ordered.
Description of the classes "POSIXlt" and "POSIXct"representing calendar dates and times.
Description of the classes "POSIXlt" and "POSIXct"representing calendar dates and times.
Description of the classes "POSIXlt" and "POSIXct"representing calendar dates and times.
Description of the classes "POSIXlt" and "POSIXct"representing calendar dates and times.
proc.time determines how much real and CPU time (in seconds)the currently running R process has already taken.
These functions are for working with source files and more generallywith “source references” ("srcref"), i.e., references tosource code.  The resulting data is used for printing and source leveldebugging, and is typically available in interactive R sessions,namely when options(keep.source = TRUE).
These functions are for working with source files and more generallywith “source references” ("srcref"), i.e., references tosource code.  The resulting data is used for printing and source leveldebugging, and is typically available in interactive R sessions,namely when options(keep.source = TRUE).
table uses the cross-classifying factors to build a contingencytable of the counts at each combination of factor levels.
warnings and its print method print thevariable last.warning in a pleasing form.
Generate a diagnostic message from its arguments.
Generate a diagnostic message from its arguments.
Generates a warning message that corresponds to its argument(s) and(optionally) the expression or function from which it was called.
These functions provide a mechanism for handling unusual conditions,including errors and warnings.
Compute the singular-value decomposition of a rectangular matrix.
Return an array obtained from an input array by sweeping out a summarystatistic.
switch evaluates EXPR and accordingly chooses one of thefurther arguments (in ...).
These functions provide access to environments(‘frames’ in S terminology) associated with functions furtherup the calling stack.
These functions provide access to environments(‘frames’ in S terminology) associated with functions furtherup the calling stack.
These functions provide a low-level interface to the computer'sfile system.
Sys.time and Sys.Date returns the system's idea of thecurrent date with and without time.
These functions provide access to environments(‘frames’ in S terminology) associated with functions furtherup the calling stack.
These functions provide access to environments(‘frames’ in S terminology) associated with functions furtherup the calling stack.
These functions provide access to environments(‘frames’ in S terminology) associated with functions furtherup the calling stack.
Sys.getenv obtains the values of the environment variables.
Get details of or set aspects of the locale for the R process.
Get the process ID of the R Session.  It is guaranteed by theoperating system that two R sessions running simultaneously willhave different IDs, but it is possible that R sessions running atdifferent times will have the same ID.
Function to do wildcard expansion (also known as ‘globbing’) onfile paths.
Reports system and user information.
Internal objects in the base package most of which are only user-visiblebecause of the special nature of the base namespace.
Get details of the numerical and monetary representations in thecurrent locale.
These functions provide access to environments(‘frames’ in S terminology) associated with functions furtherup the calling stack.
These functions provide access to environments(‘frames’ in S terminology) associated with functions furtherup the calling stack.
These functions provide access to environments(‘frames’ in S terminology) associated with functions furtherup the calling stack.
These functions provide access to environments(‘frames’ in S terminology) associated with functions furtherup the calling stack.
Find out if a file path is a symbolic link, and if so what it islinked to, via the system call readlink.
Internal objects in the base package most of which are only user-visiblebecause of the special nature of the base namespace.
Sys.setenv sets environment variables (for other processescalled from within R or future calls to Sys.getenv fromthis R process).
Uses system calls to set the times on a file or directory.
Get details of or set aspects of the locale for the R process.
Suspend execution of R expressions for a specified time interval.
Parses expressions in the given file, and then successively evaluatesthem in the specified environment.
These functions provide access to environments(‘frames’ in S terminology) associated with functions furtherup the calling stack.
Sys.time and Sys.Date returns the system's idea of thecurrent date with and without time.
Information about time zones in R.  Sys.timezone returnsthe name of the current time zone.
These functions provide a low-level interface to the computer'sfile system.
Sys.setenv sets environment variables (for other processescalled from within R or future calls to Sys.getenv fromthis R process).
This is an interface to the system command which, or to anemulation on Windows.
system invokes the OS command specified by command.
Finds the full file names of files in packages etc.
Return CPU (and other) times that expr used.
system2 invokes the OS command specified by command.
Given a matrix or data.frame x,t returns the transpose of x.
Create or test for objects of type "logical", and the basiclogical constants.
Given a matrix or data.frame x,t returns the transpose of x.
Given a matrix or data.frame x,t returns the transpose of x.
table uses the cross-classifying factors to build a contingencytable of the counts at each combination of factor levels.
tabulate takes the integer-valued vector bin and countsthe number of times each integer occurs in it.
These functions give the obvious trigonometric functions.  Theyrespectively compute the cosine, sine, tangent, arc-cosine, arc-sine,arc-tangent, and the two-argument arc-tangent.
These functions give the obvious hyperbolic functions.  Theyrespectively compute the hyperbolic cosine, sine, tangent, and theirinverses, arc-cosine, arc-sine, arc-tangent (or ‘area cosine’,etc).
These functions give the obvious trigonometric functions.  Theyrespectively compute the cosine, sine, tangent, arc-cosine, arc-sine,arc-tangent, and the two-argument arc-tangent.
Apply a function to each cell of a ragged array, that is to each(non-empty) group of values given by a unique combination of thelevels of certain factors.
This provides an entirely R-language mechanismfor managing callbacks or actions  that are invoked atthe conclusion of each top-level task.  Essentially,we register a single R function from this managerwith the underlying, nativetask-callback mechanism and this function handles invoking the otherR callbacks under the control of the manager.The manager consists of a collection of functions that access sharedvariables to manage the list of user-level callbacks.
Given matrices x and y as arguments, return a matrixcross-product.  This is formally equivalent to (but usually slightlyfaster than) the call t(x) %*% y (crossprod) orx %*% t(y) (tcrossprod).
tempfile returns a vector of character strings which can be used asnames for temporary files.
tempfile returns a vector of character strings which can be used asnames for temporary files.
Input and output text connections.
Input and output text connections.
Translate characters in character vectors, in particular from upper tolower case or vice versa.
Finding the top level environment from an environmentenvir and its enclosing environments.
This is a helper function for format to produce a singlecharacter string describing an R object.
This is a helper function for format to produce a singlecharacter string describing an R object.
Translate characters in character vectors, in particular from upper tolower case or vice versa.
A call to trace allows you to insert debugging code (e.g., acall to browser or recover) at chosenplaces in any function.  A call to untrace cancels the tracing.Specified methods can be traced the same way, without tracing allcalls to the generic function.  Trace code (tracer) can be anyR expression.  Tracing can be temporarily turned on or off globallyby calling tracingState.
By default traceback() prints the call stack of the lastuncaught error, i.e., the sequence of calls that lead to the error.This is useful when an error occurs with an unidentifiable errormessage.  It can also be used to print the current stack orarbitrary lists of calls.
This function marks an object so that a message is printed whenever theinternal code copies the object.  It is amajor cause of hard-to-predict memory use in R.
A call to trace allows you to insert debugging code (e.g., acall to browser or recover) at chosenplaces in any function.  A call to untrace cancels the tracing.Specified methods can be traced the same way, without tracing allcalls to the generic function.  Trace code (tracer) can be anyR expression.  Tracing can be temporarily turned on or off globallyby calling tracingState.
transform is a generic function, which—at leastcurrently—only does anything useful withdata frames.  transform.default converts its first argument toa data frame if possible and calls transform.data.frame.
transform is a generic function, which—at leastcurrently—only does anything useful withdata frames.  transform.default converts its first argument toa data frame if possible and calls transform.data.frame.
transform is a generic function, which—at leastcurrently—only does anything useful withdata frames.  transform.default converts its first argument toa data frame if possible and calls transform.data.frame.
Special mathematical functions related to the beta and gammafunctions.
Remove leading and/or trailing whitespace from character strings.
ceiling takes a single numeric argument x and returns anumeric vector containing the smallest integers not less than thecorresponding elements of x.
Round or truncate date-time objects.
Round or truncate date-time objects.
Functions to re-position connections.
Functions to re-position connections.
try is a wrapper to run an expression that might fail and allowthe user's code to handle error-recovery.
These functions provide a mechanism for handling unusual conditions,including errors and warnings.
These functions provide a mechanism for handling unusual conditions,including errors and warnings.
typeof determines the (R internal)type or storage mode of any object
R possesses a simple generic function mechanism which can be used foran object-oriented style of programming.  Method dispatch takes placebased on the class of the first argument to the generic function.
Set, unset or query the debugging flag on a function.The text and condition arguments are the same as thosethat can be supplied via a call to browser.  They can be retrievedby the user once the browser has been entered, and provide a mechanism toallow users to identify which breakpoint has been activated.
Performs set union, intersection, (asymmetric!) difference,equality and membership on two vectors.
unique returns a vector, data frame or array like xbut with duplicate elements/rows removed.
unique returns a vector, data frame or array like xbut with duplicate elements/rows removed.
unique returns a vector, data frame or array like xbut with duplicate elements/rows removed.
unique returns a vector, data frame or array like xbut with duplicate elements/rows removed.
unique returns a vector, data frame or array like xbut with duplicate elements/rows removed.
A simple S3 class for representing numeric versionsincluding package versions, and associated methods.
Description of the classes "POSIXlt" and "POSIXct"representing calendar dates and times.
warnings and its print method print thevariable last.warning in a pleasing form.
Time intervals creation, printing, and some arithmetic.  Theprint() method calls these “time differences”.
Time intervals creation, printing, and some arithmetic.  Theprint() method calls these “time differences”.
Time intervals creation, printing, and some arithmetic.  Theprint() method calls these “time differences”.
Time intervals creation, printing, and some arithmetic.  Theprint() method calls these “time differences”.
These functions are provided for compatibility with older versions ofR only, and may be defunct as soon as the next release.
unlink deletes the file(s) or directories specified by x.
Given a list structure x, unlist simplifies it toproduce a vector which contains all the atomic componentswhich occur in x.
Functions to load and unload name spaces.
These functions represent an interface for adjustmentsto environments and bindings within environments.  They allow forlocking environments as well as individual bindings, and for linkinga variable to a function.
Remove the names or dimnames attribute ofan R object.
A simple low-level interface for serializing to connections.
split divides the data in the vector x into the groupsdefined by f.  The replacement forms replace valuescorresponding to such a division.  unsplit reverses the effect ofsplit.
A call to trace allows you to insert debugging code (e.g., acall to browser or recover) at chosenplaces in any function.  A call to untrace cancels the tracing.Specified methods can be traced the same way, without tracing allcalls to the generic function.  Trace code (tracer) can be anyR expression.  Tracing can be temporarily turned on or off globallyby calling tracingState.
This function marks an object so that a message is printed whenever theinternal code copies the object.  It is amajor cause of hard-to-predict memory use in R.
Functions to create, open and close connections, i.e.,“generalized files”, such as possibly compressed files, URLs,pipes, etc.
Returns a matrix of logicals the same size of a given matrix withentries TRUE in the lower or upper triangle.
Functions to create, open and close connections, i.e.,“generalized files”, such as possibly compressed files, URLs,pipes, etc.
R possesses a simple generic function mechanism which can be used foran object-oriented style of programming.  Method dispatch takes placebased on the class(es) of the first argument to the generic function or ofthe object supplied as an argument to UseMethod or NextMethod.
Conversion of UTF-8 encoded character vectors to and from integervectors representing a UTF-32 encoding.
Check if each element of a character vector is valid in its impliedencoding.
Check if each element of a character vector is valid in its impliedencoding.
lapply returns a list of the same length as X, eachelement of which is the result of applying FUN to thecorresponding element of X.
vector produces a vector of the given length and mode.
Vectorize creates a function wrapper that vectorizes theaction of its argument FUN.
R.Version() provides detailed information about the version ofR running.
Generates a warning message that corresponds to its argument(s) and(optionally) the expression or function from which it was called.
These functions provide a mechanism for handling unusual conditions,including errors and warnings.
warnings and its print method print thevariable last.warning in a pleasing form.
Extract the weekday, month or quarter, or the Julian time(days since some origin).  These are generic functions: the methodsfor the internal date-time classes are documented here.
Extract the weekday, month or quarter, or the Julian time(days since some origin).  These are generic functions: the methodsfor the internal date-time classes are documented here.
Extract the weekday, month or quarter, or the Julian time(days since some origin).  These are generic functions: the methodsfor the internal date-time classes are documented here.
Give the TRUE indices of a logical object, allowing for arrayindices.
Determines the location, i.e., index of the (first) minimum or maximumof a numeric (or logical) vector.
Determines the location, i.e., index of the (first) minimum or maximumof a numeric (or logical) vector.
These are the basic control-flow constructs of the R language.  Theyfunction in much the same way as control statements in any Algol-likelanguage.  They are all reserved words.
Evaluate an R expression in an environment constructed from data,possibly modifying (a copy of) the original data.
Evaluate an R expression in an environment constructed from data,possibly modifying (a copy of) the original data.
source causes R to accept its input from the named file or URLor connection or expressions directly.  Input is read andparsed from that fileuntil the end of the file is reached, then the parsed expressions areevaluated sequentially in the chosen environment.
These functions provide a mechanism for handling unusual conditions,including errors and warnings.
Evaluate an R expression in an environment constructed from data,possibly modifying (a copy of) the original data.
Evaluate an R expression in an environment constructed from data,possibly modifying (a copy of) the original data.
Evaluate an R expression in an environment constructed from data,possibly modifying (a copy of) the original data.
These functions provide a mechanism for handling unusual conditions,including errors and warnings.
This function evaluates an expression, returning it in a two element listcontaining its value and a flag showing whether it would automatically print.
The data (usually a matrix) x are written to file file.If x is a two-dimensional matrix you need to transpose it to get thecolumns in file the same as those in the internal representation.
Reads or writes an R object from/to a file in Debian Control Fileformat.
Read binary data from or write binary data to a connection or raw vector.
Transfer character strings to and from connections, without assumingthey are null-terminated on the connection.
Write text lines to a connection.
These operators act on raw, logical and number-like vectors.
Internal auxiliary functions for use with data frames.
A generic auxiliary function that produces a numeric vector whichwill sort in the same order as x.
A generic auxiliary function that produces a numeric vector whichwill sort in the same order as x.
A generic auxiliary function that produces a numeric vector whichwill sort in the same order as x.
A generic auxiliary function that produces a numeric vector whichwill sort in the same order as x.
A generic auxiliary function that produces a numeric vector whichwill sort in the same order as x.
A generic auxiliary function that produces a numeric vector whichwill sort in the same order as x.
A generic auxiliary function that produces a numeric vector whichwill sort in the same order as x.
A simple S3 class for representing numeric versionsincluding package versions, and associated methods.
A generic auxiliary function that produces a numeric vector whichwill sort in the same order as x.
A generic auxiliary function that produces a numeric vector whichwill sort in the same order as x.
Functions to create, open and close connections, i.e.,“generalized files”, such as possibly compressed files, URLs,pipes, etc.
zapsmall determines a digits argument dr forcalling round(x, digits = dr) such that values close tozero (compared with the maximal absolute value) are ‘zapped’,i.e., replaced by 0.
This function adds one or more straight lines through the current plot.
Draw arrows between pairs of points.
Produce a Cohen-Friendly association plot indicating deviations fromindependence of rows and columns in a 2-dimensional contingencytable.
Adds an axis to the current plot, allowing thespecification of the side, position, labels, and other options.
Generic function to add a suitable axis to the current plot.
Functions to plot objects of classes "POSIXlt","POSIXct" and "Date" representing calendar dates and times.
Functions to plot objects of classes "POSIXlt","POSIXct" and "Date" representing calendar dates and times.
Compute pretty tickmark locations, the same way as R does internally.This is only non-trivial when log coordinates are active.By default, gives the at values whichaxis(side) would use.
Creates a bar plot with vertical or horizontal bars.
Creates a bar plot with vertical or horizontal bars.
This function draws a box around the current plot in the given colorand linetype.  The bty parameter determinesthe type of box drawn.  See par for details.
Produce box-and-whisker plot(s) of the given (grouped) values.
Produce box-and-whisker plot(s) of the given (grouped) values.
Interpreting the columns (or rows) of a matrix as different groups, draw aboxplot for each.
bxp draws box plots based on the given summaries in z.It is usually called from within boxplot, but can beinvoked directly.
Computes and plots conditional densities describing how theconditional distribution of a categorical variable y changes over anumerical variable x.
Set clipping region in user coordinates
split.screen defines a number of regions within the currentdevice which can, to some extent, be treated as separate graphicsdevices.  It is useful for generating multiple plots on a singledevice.  Screens can themselves be split, allowing for quite complexarrangements of plots.
This function produces two variants of the conditioning plotsdiscussed in the reference below.
Create a contour plot, or add contour lines to an existing plot.
Create a contour plot, or add contour lines to an existing plot.
This function produces two variants of the conditioning plotsdiscussed in the reference below.
Draws a curve corresponding to a function over the interval[from, to]. curve can plot also an expression in the variablexname, default x.
Draw a Cleveland dot plot.
split.screen defines a number of regions within the currentdevice which can, to some extent, be treated as separate graphicsdevices.  It is useful for generating multiple plots on a singledevice.  Screens can themselves be split, allowing for quite complexarrangements of plots.
This function produces a contour plot with the areas between thecontours filled in solid color (Cleveland calls this a level plot).  Akey showing how the colors map to z values is shown to the right ofthe plot.
Creates a fourfold display of a 2 by 2 by k contingency table onthe current graphics device, allowing for the visual inspection of theassociation between two dichotomous variables in one or severalpopulations (strata).
This function (frame is an alias forplot.new) causes the completion of plotting in the current plot(if there is one) and an advance to a new graphics frame.  This isused in all high-level plotting functions and also useful for skippingplots when a multi-figure region is in use.
Convert between graphics coordinate systems.
Convert between graphics coordinate systems.
grid adds an nx by ny rectangular grid to anexisting plot.
The generic function hist computes a histogram of the givendata values.  If plot = TRUE, the resulting object ofclass "histogram" is plotted byplot.histogram, before it is returned.
The generic function hist computes a histogram of the givendata values.  If plot = TRUE, the resulting object ofclass "histogram" is plotted byplot.histogram, before it is returned.
identify reads the position of the graphics pointer when the(first) mouse button is pressed.  It then searches the coordinatesgiven in x and y for the point closest to the pointer.If this point is close enough to the pointer, its index will be returned aspart of the value of the call.
Creates a grid of colored or gray-scale rectangles with colorscorresponding to the values in z.  This can be used to displaythree-dimensional or spatial data aka images.This is a generic function.
Creates a grid of colored or gray-scale rectangles with colorscorresponding to the values in z.  This can be used to displaythree-dimensional or spatial data aka images.This is a generic function.
layout divides the device up into as many rows and columns asthere are in matrix mat, with the column-widths and therow-heights specified in the respective arguments.
layout divides the device up into as many rows and columns asthere are in matrix mat, with the column-widths and therow-heights specified in the respective arguments.
layout divides the device up into as many rows and columns asthere are in matrix mat, with the column-widths and therow-heights specified in the respective arguments.
This function can be used to add legends to plots.  Note that a callto the function locator(1) can be used in place of the xand y arguments.
A generic function taking coordinates given in various ways andjoining the corresponding points with line segments.
A generic function taking coordinates given in various ways andjoining the corresponding points with line segments.
Reads the position of the graphics cursor when the (first) mousebutton is pressed.
Plot the columns of one matrix against the columns of another (whichoften is just a vector treated as 1-column matrix).
Plot the columns of one matrix against the columns of another (whichoften is just a vector treated as 1-column matrix).
Plot the columns of one matrix against the columns of another (whichoften is just a vector treated as 1-column matrix).
Plots a mosaic on the current graphics device.
Text is written in one of the four margins of the current figure regionor one of the outer margins of the device region.
A matrix of scatterplots is produced.
A matrix of scatterplots is produced.
An example of a simple useful panel function to be used asargument in e.g., coplot or pairs.
par can be used to set or query graphical parameters.Parameters can be set by specifying them as arguments to par intag = value form, or by passing them as a list of taggedvalues.
This function draws perspective plots of a surface over thex–y plane.  persp is a generic function.
Draw a pie chart.
Draw a scatter plot with decorations such as axes and titlesin the active graphics window.
Draw a scatter plot with decorations such as axes and titlesin the active graphics window.
Plot univariate effects of one or more factors,typically for a designed experiment as analyzed by aov().
Draws a curve corresponding to a function over the interval[from, to]. curve can plot also an expression in the variablexname, default x.
This function (frame is an alias forplot.new) causes the completion of plotting in the current plot(if there is one) and an advance to a new graphics frame.  This isused in all high-level plotting functions and also useful for skippingplots when a multi-figure region is in use.
This function sets up the world coordinate system for a graphicswindow.  It is called by higher level functions such asplot.default (after plot.new).
This is the internal function that does the basic plotting ofpoints and lines.  Usually, one should rather use the higher levelfunctions instead and refer to their help pages for explanation of thearguments.
points is a generic function to draw a sequence of points atthe specified coordinates.  The specified character(s) are plotted,centered at the coordinates.
points is a generic function to draw a sequence of points atthe specified coordinates.  The specified character(s) are plotted,centered at the coordinates.
polygon draws the polygons whose vertices aregiven in x and y.
path draws a path whose vertices aregiven in x and y.
rasterImage draws a raster image at the given locations and sizes.
rect draws a rectangle (or sequence of rectangles) with thegiven coordinates, fill and border colors.
Adds a rug representation (1-d plot) of the data to the plot.
split.screen defines a number of regions within the currentdevice which can, to some extent, be treated as separate graphicsdevices.  It is useful for generating multiple plots on a singledevice.  Screens can themselves be split, allowing for quite complexarrangements of plots.
Draw line segments between pairs of points.
smoothScatter produces a smoothed color densityrepresentation of a scatterplot, obtained through a (2D) kerneldensity estimate.
Spine plots are a special cases of mosaic plots, and can be seen asa generalization of stacked (or highlighted) bar plots. Analogously,spinograms are an extension of histograms.
split.screen defines a number of regions within the currentdevice which can, to some extent, be treated as separate graphicsdevices.  It is useful for generating multiple plots on a singledevice.  Screens can themselves be split, allowing for quite complexarrangements of plots.
Draw star plots or segment diagrams of a multivariate data set.With one single location, also draws ‘spider’(or ‘radar’) plots.
stem produces a stem-and-leaf plot of the values in x.The parameter scale can be used to expand the scale of theplot.  A value of scale = 2 will cause the plot to be roughlytwice as long as the default.
These functions compute the width or height, respectively, of thegiven strings or mathematical expressions s[i] onthe current plotting device in user coordinates, inchesor as fraction of the figure width par("fin").
stripchart produces one dimensional scatter plots (or dotplots) of the given data.  These plots are a good alternative toboxplots when sample sizes are small.
These functions compute the width or height, respectively, of thegiven strings or mathematical expressions s[i] onthe current plotting device in user coordinates, inchesor as fraction of the figure width par("fin").
Multiple points are plotted as ‘sunflowers’ with multiple leaves(‘petals’) such that overplotting is visualized instead ofaccidental and invisible.
This function draws symbols on a plot.  One of six symbols;circles, squares, rectangles, stars,thermometers, and boxplots, can be plotted at aspecified set of x and y coordinates.  Specific aspects of thesymbols, such as relative size, can be customized by additionalparameters.
text draws the strings given in the vector labels at thecoordinates given by x and y.y may be missing since xy.coords(x, y) is used forconstruction of the coordinates.
text draws the strings given in the vector labels at thecoordinates given by x and y.y may be missing since xy.coords(x, y) is used forconstruction of the coordinates.
This function can be used to add labels to a plot.  Its first fourprincipal arguments can also be used as arguments in most high-levelplotting functions.  They must be of type character orexpression. In the latter case, quite a bit ofmathematical notation is available such as sub- and superscripts,greek letters, fractions, etc: see plotmath
xinch and yinch convert the specified number of inchesgiven as their arguments into the correct units for plotting withgraphics functions.  Usually, this only makes sense when normalcoordinates are used, i.e., no log scale (see thelog argument to par).
Draw an X-spline, a curve drawn relative to control points.
xinch and yinch convert the specified number of inchesgiven as their arguments into the correct units for plotting withgraphics functions.  Usually, this only makes sense when normalcoordinates are used, i.e., no log scale (see thelog argument to par).
xinch and yinch convert the specified number of inchesgiven as their arguments into the correct units for plotting withgraphics functions.  Usually, this only makes sense when normalcoordinates are used, i.e., no log scale (see thelog argument to par).
It is sometimes convenient to add two vectors or matrices in an operation analogous to matrix multiplication. For matrices nXm and mYp, the matrix sum  of the i,jth element of nSp = sum(over m) of iXm + mYj. 
This is a set of minor, if not trivial, helper functions.lowerCor finds the correlation of x variables and then prints them using lowerMat which is a trivial, but useful, function to round off and print the lower triangle of a matrix.reflect reflects the output of a factor analysis or principal components analysis so that one or more factors is reflected. (Requested by Alexander Weiss.)progressBar prints out ...  as a calling routine (e.g., tetrachoric) works through a tedious calculation.  shannon finds the Shannon index (H) of diversity or of information. test.all tests all the examples in a package.  best.items sorts a factor matrix for absolute values and displays the expanded items names. fa.lookup returns sorted factor analysis output with item labels. cor2 correlates two data.frames (of equal length). levels2numeric and char2numeric convert dataframe columns that are categorical/levels to numeric values. 
Internal consistency measures of reliability range from omega_hierchical to alpha to omega_total.  This function reports two estimates: Cronbach's coefficient alpha and Guttman's lambda_6.  Also reported are item - whole correlations, alpha if an item is omitted, and item means and standard deviations.
Internal consistency measures of reliability range from omega_hierchical to alpha to omega_total.  This function reports two estimates: Cronbach's coefficient alpha and Guttman's lambda_6.  Also reported are item - whole correlations, alpha if an item is omitted, and item means and standard deviations.
When doing regressions from the data or from a correlation matrix using setCor or doing a mediation analysis using link{mediate}, it is useful to compare alternative models.  Since these are both regression models, the appropriate test is an Analysis of Variance.  Similar tests, using Chi Square may be done for factor analytic models. 
In many fields, decisions and outcomes are categorical even though the underlying phenomenon are probably continuous.  E.g. students are accepted to graduate school or not, they finish or not. X-Rays are diagnosed as patients having cancer or not.   Outcomes of such decisions are usually labeled as Valid Positives, Valid Negatives, False Positives and False Negatives. In hypothesis testing, False Positives are known as Type I errors, while False Negatives are Type II errors.  The relationship between these four cells depends upon the correlation between the decision rule and the outcome as well as the level of evidence needed for a decision (the criterion).  Signal Detection Theory and Decision Theory have a number of related measures of performance (accuracy = VP + VN), Sensitivity (VP/(VP + FN)), Specificity (1 - FP), d prime (d'), and the area under the Response Operating Characteristic Curve (AUC). More generally, these are examples of correlations based upon dichotomous data.  AUC addresses some of these questions.  
Von Neuman et al. (1941) discussed the Mean Square of Successive Differences as a measure of variability that takes into account gradual shifts in mean. This is appropriate when studying errors in ballistics or variability and stability in mood when studying affect. For random data, this will be twice the variance, but for data with a sequential order and a positive autocorrelation, this will be much smaller. Since the mssd is just twice the variance - the autocorrelation, it is thus possible to also find the autocorrelation for a particular lag. 
Goldberg (2006) described a hierarchical factor structure organization from the “top down".  The original idea was to do successive factor analyses from 1 to nf factors organized by factor score correlations from  one level to the next.  Waller (2007) discussed a simple way of doing this for components without finding the scores.  Using the factor correlations (from Gorsuch) to organize factors hierarchically results may be organized at many different levels. The algorithm may be applied to principal components (pca) or to true factor analysis.
Goldberg (2006) described a hierarchical factor structure organization from the “top down".  The original idea was to do successive factor analyses from 1 to nf factors organized by factor score correlations from  one level to the next.  Waller (2007) discussed a simple way of doing this for components without finding the scores.  Using the factor correlations (from Gorsuch) to organize factors hierarchically results may be organized at many different levels. The algorithm may be applied to principal components (pca) or to true factor analysis.
Holzinger-Swineford (1937) introduced the bifactor model of a general factor and uncorrelated group factors. The Holzinger data sets are   original 14 * 14 matrix from their paper as well as a 9 *9 matrix used as an example by Joreskog. The Thurstone correlation matrix is a 9 * 9 matrix of correlations of ability items.  The Reise data set is 16 * 16 correlation matrix of mental health items. The Bechtholdt data sets are both 17 x 17 correlation matrices of ability tests.  
Holzinger-Swineford (1937) introduced the bifactor model of a general factor and uncorrelated group factors. The Holzinger data sets are   original 14 * 14 matrix from their paper as well as a 9 *9 matrix used as an example by Joreskog. The Thurstone correlation matrix is a 9 * 9 matrix of correlations of ability items.  The Reise data set is 16 * 16 correlation matrix of mental health items. The Bechtholdt data sets are both 17 x 17 correlation matrices of ability tests.  
Holzinger-Swineford (1937) introduced the bifactor model of a general factor and uncorrelated group factors. The Holzinger data sets are   original 14 * 14 matrix from their paper as well as a 9 *9 matrix used as an example by Joreskog. The Thurstone correlation matrix is a 9 * 9 matrix of correlations of ability items.  The Reise data set is 16 * 16 correlation matrix of mental health items. The Bechtholdt data sets are both 17 x 17 correlation matrices of ability tests.  
bestScales forms scales from the items/scales most correlated with a particular criterion and then cross validates on a hold out sample using unit weighted scales.  This may be repeated n.iter times using either basic bootstrap aggregation (bagging) techniques or K-fold cross validation. Thus, the technique is known as BISCUIT (Best Items Scales that are Cross validated, Unit weighted, Informative, and Transparent).  Given a dictionary of item content, bestScales will sort by criteria correlations and display the item content. Options for bagging (bootstrap aggregation) are included. An alternative to unit weighting is to weight items by their zero order correlations (cross validated) with the criteria. This weighted version is called BISCWIT and is an optional output. 
bestScales forms scales from the items/scales most correlated with a particular criterion and then cross validates on a hold out sample using unit weighted scales.  This may be repeated n.iter times using either basic bootstrap aggregation (bagging) techniques or K-fold cross validation. Thus, the technique is known as BISCUIT (Best Items Scales that are Cross validated, Unit weighted, Informative, and Transparent).  Given a dictionary of item content, bestScales will sort by criteria correlations and display the item content. Options for bagging (bootstrap aggregation) are included. An alternative to unit weighting is to weight items by their zero order correlations (cross validated) with the criteria. This weighted version is called BISCWIT and is an optional output. 
25 personality self report items taken from the International Personality Item Pool (ipip.ori.org) were included as part of the Synthetic Aperture Personality Assessment (SAPA) web based personality assessment project.  The data from 2800 subjects are included here as a demonstration set for scale construction, factor analysis, and Item Response Theory analysis.  Three additional demographic variables (sex, education, and age) are also included. This data set is deprecated and users are encouraged to use bfi.
25 personality self report items taken from the International Personality Item Pool (ipip.ori.org) were included as part of the Synthetic Aperture Personality Assessment (SAPA) web based personality assessment project.  The data from 2800 subjects are included here as a demonstration set for scale construction, factor analysis, and Item Response Theory analysis.  Three additional demographic variables (sex, education, and age) are also included. This data set is deprecated and users are encouraged to use bfi.
When showing e.g., age or education distributions for two groups, it is convenient to plot them back to back.  bi.bars will do so.
The bifactor rotation implements the rotation introduced by Jennrich and Bentler (2011) by calling GPForth in the GPArotation package.  promax is an oblique rotation function introduced by Hendrickson and White (1964) and implemented in the promax function in the stats package.  Unfortunately, promax does not report the inter factor correlations.  Promax does.  TargetQ does a target rotation with elements that can be missing (NA), or numeric (e.g., 0, 1).  It uses the GPArotation package. target.rot does general target rotations to an arbitrary target matrix. The default target rotation is for an independent cluster solution. equamax facilitates the call to GPArotation to do an equamax rotation.  Equamax, although available as a specific option within GPArotation is easier to call by name if using equamax.  The varimin rotation suggested by Ertl (2013) is implemented by appropriate calls to GPArotation.
When analyzing many subjects (ie. 100,000 or more) with many variables (i.e. 1000 or more) core R can take a long time and sometime exceed  memory limits (i.e. with 600K subjects and 6K variables).  bigCor runs (in parallel if multicores are available) by breaking the variables into subsets (of size=size), finding all subset correlations, and then stitches the resulting matrices into one large matrix.   Noticeable improvements in speed compared to cor.  
Extends the biplot function to the output of fa, fa.poly  or principal. Will plot factor scores and factor loadings in the same graph.  If the number of factors > 2, then all pairs of factors are plotted. Factor score histograms are plotted on the diagonal. The input is the resulting object from fa, principal, or }code{linkfa.poly with the scores=TRUE option. Points may be colored according to other criteria.
The bifactor rotation implements the rotation introduced by Jennrich and Bentler (2011) by calling GPForth in the GPArotation package.  promax is an oblique rotation function introduced by Hendrickson and White (1964) and implemented in the promax function in the stats package.  Unfortunately, promax does not report the inter factor correlations.  Promax does.  TargetQ does a target rotation with elements that can be missing (NA), or numeric (e.g., 0, 1).  It uses the GPArotation package. target.rot does general target rotations to an arbitrary target matrix. The default target rotation is for an independent cluster solution. equamax facilitates the call to GPArotation to do an equamax rotation.  Equamax, although available as a specific option within GPArotation is easier to call by name if using equamax.  The varimin rotation suggested by Ertl (2013) is implemented by appropriate calls to GPArotation.
The tetrachoric correlation is the inferred Pearson Correlation from a two x two table with the assumption of bivariate normality. The polychoric correlation generalizes this to the n x m table. Particularly important when doing Item Response Theory or converting comorbidity statistics using normal theory to correlations. Input may be a 2 x 2 table of cell frequencies, a vector of cell frequencies, or a data.frame or matrix of dichotomous data (for tetrachoric) or of numeric data (for polychoric).The biserial correlation is between a continuous y variable and a dichotmous x variable, which is assumed to have resulted from a dichotomized normal variable. Biserial is a special case of the polyserial correlation, which is the inferred latent correlation between a continuous variable (X) and a ordered categorical variable (e.g., an item response). Input for these later two are data frames or matrices.  Requires the mnormt package.
Random assignment of n subjects with an equal number in all of N conditions may  done by block randomization, where the block size is the number of experimental conditions. The number of Independent Variables and the number of levels in each IV are specified as input. The output is a the block randomized design.
An example data set used by McDonald (1999) as well as other discussions of Item Response Theory makes use of a data table on 10 items (two sets of 5) from the Law School Admissions Test (LSAT).  Included in this data set is the original table as well as the reponses for 1000 subjects on the first set (Figure Classification) and second set (Debate). 
Rindskopf and Rose (1988) use this data set to demonstrate confirmatory second order factor models.  It is a nice example data set to explore hierarchical structure and alternative factor solutions. It contains measures of fluid and crystallized intelligence.
This is a set of minor, if not trivial, helper functions.lowerCor finds the correlation of x variables and then prints them using lowerMat which is a trivial, but useful, function to round off and print the lower triangle of a matrix.reflect reflects the output of a factor analysis or principal components analysis so that one or more factors is reflected. (Requested by Alexander Weiss.)progressBar prints out ...  as a calling routine (e.g., tetrachoric) works through a tedious calculation.  shannon finds the Shannon index (H) of diversity or of information. test.all tests all the examples in a package.  best.items sorts a factor matrix for absolute values and displays the expanded items names. fa.lookup returns sorted factor analysis output with item labels. cor2 correlates two data.frames (of equal length). levels2numeric and char2numeric convert dataframe columns that are categorical/levels to numeric values. 
John Schmid and John M. Leiman (1957) discuss how to transform a hierarchical factor structure to a bifactor structure. Schmid contains the example 12 x 12 correlation matrix. schmid.leiman is a 12 x 12 correlation matrix with communalities on the diagonal. This can be used to show the effect of correcting for attenuation. Two additional data sets are taken from Chen et al. (2006).
Convert a correlation to a z or t, or d, or chi or covariance matrixor z to r using the Fisher transformation or find the confidence intervals for a specified correlation.  r2d converts a correlation to an effect size (Cohen's d) and d2r converts a d into an r. g2r converts Hedge's g to a correlation.   t2r converts a t test to r, r2t converts a correlation to a t-test value. chi2r converts a chi square to r, r2chi converts it back.  r2c and cor2cov convert a correlation matrix to a covariance matrix. d2t and t2d convert cohen's d into a t and a t into a cohen d.  See cohen.d for other conversions.
Rotations of factor analysis and principal components analysis solutions typically try to represent correlation matrices as simple structured.  An alternative structure, appealing to some, is a circumplex structure where the variables are uniformly spaced on the perimeter of a circle in a two dimensional space.  Generating simple structure and circumplex data is straightforward, and is useful for exploring alternative solutions to affect and personality structure. A generalization to 3 dimensional (spherical) data is straightforward.
Rotations of factor analysis and principal components analysis solutions typically try to represent correlation matrices as simple structured.  An alternative structure, appealing to some, is a circumplex structure where the variables are uniformly spaced on the perimeter of a circle in a two dimensional space.  Generating these data is straightforward, and is useful for exploring alternative solutions to affect and personality structure.
Rotations of factor analysis and principal components analysis solutions typically try to represent correlation matrices as simple structured.  An alternative structure, appealing to some, is a circumplex structure where the variables are uniformly spaced on the perimeter of a circle in a two dimensional space.  Generating these data is straightforward, and is useful for exploring alternative solutions to affect and personality structure.
Rotations of factor analysis and principal components analysis solutions typically try to represent correlation matrices as simple structured.  An alternative structure, appealing to some, is a circumplex structure where the variables are uniformly spaced on the perimeter of a circle in a two dimensional space.  Generating these data is straightforward, and is useful for exploring alternative solutions to affect and personality structure.
Circadian data are periodic with a phase of 24 hours. These functions  find the best fitting phase angle (cosinor), the circular mean,  circular correlation with circadian data, and the linear by circular correlation
Circadian data are periodic with a phase of 24 hours. These functions  find the best fitting phase angle (cosinor), the circular mean,  circular correlation with circadian data, and the linear by circular correlation
Circadian data are periodic with a phase of 24 hours. These functions  find the best fitting phase angle (cosinor), the circular mean,  circular correlation with circadian data, and the linear by circular correlation
Circadian data are periodic with a phase of 24 hours. These functions  find the best fitting phase angle (cosinor), the circular mean,  circular correlation with circadian data, and the linear by circular correlation
Circadian data are periodic with a phase of 24 hours. These functions  find the best fitting phase angle (cosinor), the circular mean,  circular correlation with circadian data, and the linear by circular correlation
Circadian data are periodic with a phase of 24 hours. These functions  find the best fitting phase angle (cosinor), the circular mean,  circular correlation with circadian data, and the linear by circular correlation
Circadian data are periodic with a phase of 24 hours. These functions  find the best fitting phase angle (cosinor), the circular mean,  circular correlation with circadian data, and the linear by circular correlation
Circadian data are periodic with a phase of 24 hours. These functions  find the best fitting phase angle (cosinor), the circular mean,  circular correlation with circadian data, and the linear by circular correlation
Circadian data are periodic with a phase of 24 hours. These functions  find the best fitting phase angle (cosinor), the circular mean,  circular correlation with circadian data, and the linear by circular correlation
Circadian data are periodic with a phase of 24 hours. These functions  find the best fitting phase angle (cosinor), the circular mean,  circular correlation with circadian data, and the linear by circular correlation
Given a  n x c cluster definition matrix of -1s, 0s, and 1s (the keys) , and a n x n correlation matrix, or an N x n data matrix, find the correlations of the composite clusters.  The keys matrix can be entered by hand, copied from the clipboard (read.clipboard), or taken as output from the factor2cluster or make.keys functions.  Similar functionality to scoreItems which also gives item by cluster correlations. scoreBy does this for individual subjects after a call to statsBy.
How well does the cluster model found by ICLUST fit the original correlation matrix?  A similar algorithm  factor.fit is found in VSS. This function is internal to ICLUST but has more general use as well.
Given a n x n correlation matrix and a n x c matrix of -1,0,1 cluster weights for those n items on  c clusters, find the correlation of each item with each cluster.  If the item is part of the cluster, correct for item overlap.  Part of the ICLUST set of functions, but useful for many item analysis problems.
Cluster analysis and factor analysis are procedures for grouping items in terms of a smaller number of (latent) factors or (observed) clusters.  Graphical presentations of clusters typically show tree structures, although they can be represented in terms of item by cluster correlations.  
The output of the kmeans clustering function produces a vector of cluster membership.  The score.items and cluster.cor functions require a matrix of keys.  cluster2keys does this.
Given a data.frame or matrix, find the standardized mean difference (Cohen's d) and confidence intervals for each variable depending upon a grouping variable.  Convert the d statistic to the r equivalent, report the student's t statistic and associated p values, and return statistics for both values of the grouping variable.  The Mahalanobis distance between the centroids of the two groups in the space defined by all the variables ia also found.  Confidence intervals for Cohen d for one group (difference from 0) may also be found. Several measures of the distributional overlap (e.g. OVL, OVL2, etc.) are available.
Given a data.frame or matrix, find the standardized mean difference (Cohen's d) and confidence intervals for each variable depending upon a grouping variable.  Convert the d statistic to the r equivalent, report the student's t statistic and associated p values, and return statistics for both values of the grouping variable.  The Mahalanobis distance between the centroids of the two groups in the space defined by all the variables ia also found.  Confidence intervals for Cohen d for one group (difference from 0) may also be found. Several measures of the distributional overlap (e.g. OVL, OVL2, etc.) are available.
Given a data.frame or matrix, find the standardized mean difference (Cohen's d) and confidence intervals for each variable depending upon a grouping variable.  Convert the d statistic to the r equivalent, report the student's t statistic and associated p values, and return statistics for both values of the grouping variable.  The Mahalanobis distance between the centroids of the two groups in the space defined by all the variables ia also found.  Confidence intervals for Cohen d for one group (difference from 0) may also be found. Several measures of the distributional overlap (e.g. OVL, OVL2, etc.) are available.
Cohen's kappa (Cohen, 1960) and weighted kappa (Cohen, 1968) may be used to find the agreement of two raters when using nominal scores.  Light's kappa is just the average cohen.kappa if using more than 2 raters. 
The congruence coefficient two matrices is just the cross product of their respective values divided by the square root of their sums of squares. If the columns are zero centered, this is just the correlation. If the columns are centered around the scale neutral point, this is Cohen's profile correlation. A set of distances (city block, euclidean, Minkowski) may be found by the distance function. 
In medicine and clinical psychology, diagnoses tend to be categorical (someone is depressed or not, someone has an anxiety disorder or not).  Cooccurrence  of both of these symptoms is called comorbidity.   Diagnostic categories vary in their degree of comorbidity with other diagnostic categories.  From the point of view of correlation, comorbidity is just a name applied to one cell in a four fold table.  It is thus possible to analyze comorbidity rates by considering the probability of the separate diagnoses and the probability of the joint diagnosis.  This gives the two by two table needed for a phi, Yule, or tetrachoric correlation.
Rotations of factor analysis and principal components analysis solutions typically try to represent correlation matrices as simple structured.  An alternative structure, appealing to some, is a circumplex structure where the variables are uniformly spaced on the perimeter of a circle in a two dimensional space.  Generating simple structure and circumplex data is straightforward, and is useful for exploring alternative solutions to affect and personality structure. A generalization to 3 dimensional (spherical) data is straightforward.
Classical Test Theory (CTT) considers four or more tests to be congenerically equivalent if all tests may be expressed in terms of one factor and a residual error.  Parallel tests are the special case where (usually two) tests have equal factor loadings.  Tau equivalent tests have equal factor loadings but may have unequal errors.  Congeneric tests may differ in both factor loading and error variances.
The congruence coefficient two matrices is just the cross product of their respective values divided by the square root of their sums of squares. If the columns are zero centered, this is just the correlation. If the columns are centered around the scale neutral point, this is Cohen's profile correlation. A set of distances (city block, euclidean, Minkowski) may be found by the distance function. 
Although normal theory provides confidence intervals for correlations, this is particularly problematic with Synthetic Aperture Personality Assessment (SAPA) data where the individual items are Massively Missing at Random.  Bootstrapped confidence intervals are found for Pearson, Spearman, Kendall, tetrachoric, or polychoric correlations and for scales made from those correlations. If given a correlation matrix and sample size(s), normal theory confidence intervals are provided.
Correlation matrices may be shown graphically by using the image function to emphasize structure.  This is a particularly useful tool for showing the structure of  correlation matrices with a clear structure.  Partially meant for the pedagogical value of the graphic for teaching or discussing factor analysis and other multivariate techniques.
Correlation matrices may be shown graphically by using the image function to emphasize structure.  This is a particularly useful tool for showing the structure of  correlation matrices with a clear structure.  Partially meant for the pedagogical value of the graphic for teaching or discussing factor analysis and other multivariate techniques.
Factor analysis requires positive definite correlation matrices.  Unfortunately, with pairwise deletion of missing data or if using tetrachoric or polychoric correlations, not all correlation matrices are positive definite.  cor.smooth does a eigenvector (principal components) smoothing.  Negative eigen values are replaced with 100  * eig.tol, the matrix is reproduced and forced to a correlation matrix using cov2cor.
Factor analysis requires positive definite correlation matrices.  Unfortunately, with pairwise deletion of missing data or if using tetrachoric or polychoric correlations, not all correlation matrices are positive definite.  cor.smooth does a eigenvector (principal components) smoothing.  Negative eigen values are replaced with 100  * eig.tol, the matrix is reproduced and forced to a correlation matrix using cov2cor.
If using aggregated data, the correlation of the means does not reflect the sample size used for each mean. cov.wt in RCore does this and returns a covariance matrix or the correlation matrix.  The cor.wt function weights by sample size or by standard errors and by default return correlations. 
This is a set of minor, if not trivial, helper functions.lowerCor finds the correlation of x variables and then prints them using lowerMat which is a trivial, but useful, function to round off and print the lower triangle of a matrix.reflect reflects the output of a factor analysis or principal components analysis so that one or more factors is reflected. (Requested by Alexander Weiss.)progressBar prints out ...  as a calling routine (e.g., tetrachoric) works through a tedious calculation.  shannon finds the Shannon index (H) of diversity or of information. test.all tests all the examples in a package.  best.items sorts a factor matrix for absolute values and displays the expanded items names. fa.lookup returns sorted factor analysis output with item labels. cor2 correlates two data.frames (of equal length). levels2numeric and char2numeric convert dataframe columns that are categorical/levels to numeric values. 
Convert a correlation to a z or t, or d, or chi or covariance matrixor z to r using the Fisher transformation or find the confidence intervals for a specified correlation.  r2d converts a correlation to an effect size (Cohen's d) and d2r converts a d into an r. g2r converts Hedge's g to a correlation.   t2r converts a t test to r, r2t converts a correlation to a t-test value. chi2r converts a chi square to r, r2chi converts it back.  r2c and cor2cov convert a correlation matrix to a covariance matrix. d2t and t2d convert cohen's d into a t and a t into a cohen d.  See cohen.d for other conversions.
A minor helper function to convert correlations (ranging from -1 to 1) to distances (ranging from 0 to 2). d = √{(2(1-r))}. 
Although normal theory provides confidence intervals for correlations, this is particularly problematic with Synthetic Aperture Personality Assessment (SAPA) data where the individual items are Massively Missing at Random.  Bootstrapped confidence intervals are found for Pearson, Spearman, Kendall, tetrachoric, or polychoric correlations and for scales made from those correlations. If given a correlation matrix and sample size(s), normal theory confidence intervals are provided.
Makes use of functions adapted from the lavaan package to find FIML covariance/correlation matrices.  FIML can be much slower than the normal pairwise deletion option of cor, but provides slightly more precise estimates.
Correlation matrices may be shown graphically by using the image function to emphasize structure.  This is a particularly useful tool for showing the structure of  correlation matrices with a clear structure.  Partially meant for the pedagogical value of the graphic for teaching or discussing factor analysis and other multivariate techniques.
Correlation matrices may be shown graphically by using the image function to emphasize structure.  This is a particularly useful tool for showing the structure of  correlation matrices with a clear structure.  Partially meant for the pedagogical value of the graphic for teaching or discussing factor analysis and other multivariate techniques.
Although the cor function finds the correlations for a matrix,  it does not report probability values.  cor.test does, but for only one pair of variables at a time.  corr.test uses cor to find the correlations for either complete or pairwise data and reports the sample sizes and probability values as well. For symmetric matrices, raw probabilites are reported below the diagonal and correlations adjusted for multiple comparisons above the diagonal. In the case of different x and ys, the default is to adjust the probabilities for multiple tests. Both corr.test and corr.p return raw and adjusted confidence intervals for each correlation. 
Although the cor function finds the correlations for a matrix,  it does not report probability values.  cor.test does, but for only one pair of variables at a time.  corr.test uses cor to find the correlations for either complete or pairwise data and reports the sample sizes and probability values as well. For symmetric matrices, raw probabilites are reported below the diagonal and correlations adjusted for multiple comparisons above the diagonal. In the case of different x and ys, the default is to adjust the probabilities for multiple tests. Both corr.test and corr.p return raw and adjusted confidence intervals for each correlation. 
Given a raw correlation matrix and a vector of reliabilities, report the disattenuated correlations above the diagonal.
Steiger (1980) pointed out that the sum of the squared elements of a correlation matrix, or the Fisher z score equivalents, is distributed as chi square under the null hypothesis that the values are zero (i.e., elements of the identity matrix).  This is particularly useful for examining whether correlations in a single matrix differ from zero or for comparing two matrices. Jennrich (1970) also examined tests of differences between matrices.
Bartlett (1951) proposed that -ln(det(R)*(N-1 - (2p+5)/6) was distributed as chi square if R were an identity matrix.  A useful test that residuals correlations are all zero. Contrast to the Kaiser-Meyer-Olkin test.
Steiger (1980) pointed out that the sum of the squared elements of a correlation matrix, or the Fisher z score equivalents, is distributed as chi square under the null hypothesis that the values are zero (i.e., elements of the identity matrix).  This is particularly useful for examining whether correlations in a single matrix differ from zero or for comparing two matrices. Jennrich (1970) also examined tests of differences between matrices.
Steiger (1980) pointed out that the sum of the squared elements of a correlation matrix, or the Fisher z score equivalents, is distributed as chi square under the null hypothesis that the values are zero (i.e., elements of the identity matrix).  This is particularly useful for examining whether correlations in a single matrix differ from zero or for comparing two matrices. Jennrich (1970) also examined tests of differences between matrices.
Steiger (1980) pointed out that the sum of the squared elements of a correlation matrix, or the Fisher z score equivalents, is distributed as chi square under the null hypothesis that the values are zero (i.e., elements of the identity matrix).  This is particularly useful for examining whether correlations in a single matrix differ from zero or for comparing two matrices. Jennrich (1970) also examined tests of differences between matrices.
Circadian data are periodic with a phase of 24 hours. These functions  find the best fitting phase angle (cosinor), the circular mean,  circular correlation with circadian data, and the linear by circular correlation
Circadian data are periodic with a phase of 24 hours. These functions  find the best fitting phase angle (cosinor), the circular mean,  circular correlation with circadian data, and the linear by circular correlation
Circadian data are periodic with a phase of 24 hours. These functions  find the best fitting phase angle (cosinor), the circular mean,  circular correlation with circadian data, and the linear by circular correlation
When doing cor(x, use= "pairwise"), it is nice to know the number of cases for each pairwise correlation.  This is particularly useful when doing SAPA type analyses. More importantly, when there are some missing pairs, it is useful to supply imputed values so that further analyses may be done.  This is useful if using the Massively Missing Completely at Random (MMCAR) designs used by the SAPA project.  The specific pairs missing may be identified by pairwiseZero.  Summaries of the counts are given by pairwiseDescribe.
Given a correlation matrix or a  matrix or dataframe of raw data, find the multiple regressions and draw a path diagram relating a set of y variables as a function of a set of x variables.  A set of covariates (z) can be partialled from the x and y sets. Regression diagrams are automatically included.   Model can be specified in conventional formula form, or in terms of x variables and y variables.  Multiplicative models (interactions) and quadratic terms may be specified in the formula mode if using raw data. By default, the data may be  zero centered before finding the interactions.  Will also find Cohen's Set Correlation between a predictor set of variables (x) and a criterion set (y). Also finds the canonical correlations between the x and y sets.
This is a set of minor, if not trivial, helper functions.lowerCor finds the correlation of x variables and then prints them using lowerMat which is a trivial, but useful, function to round off and print the lower triangle of a matrix.reflect reflects the output of a factor analysis or principal components analysis so that one or more factors is reflected. (Requested by Alexander Weiss.)progressBar prints out ...  as a calling routine (e.g., tetrachoric) works through a tedious calculation.  shannon finds the Shannon index (H) of diversity or of information. test.all tests all the examples in a package.  best.items sorts a factor matrix for absolute values and displays the expanded items names. fa.lookup returns sorted factor analysis output with item labels. cor2 correlates two data.frames (of equal length). levels2numeric and char2numeric convert dataframe columns that are categorical/levels to numeric values. 
Dynamic motivational models such as the Dynamics of Action (Atkinson and Birch, 1970, Revelle, 1986) may be reparameterized as a simple pair of differential (matrix) equations (Revelle, 1986, 2008). This function simulates the dynamic aspects of the CTA.  The CTA model is discussed in detail in Revelle and Condon (2015).
Dynamic motivational models such as the Dynamics of Action (Atkinson and Birch, 1970, Revelle, 1986) may be reparameterized as a simple pair of differential (matrix) equations (Revelle, 1986, 2008). This function simulates the dynamic aspects of the CTA.  The CTA model is discussed in detail in Revelle and Condon (2015).
Given a data.frame or matrix, find the standardized mean difference (Cohen's d) and confidence intervals for each variable depending upon a grouping variable.  Convert the d statistic to the r equivalent, report the student's t statistic and associated p values, and return statistics for both values of the grouping variable.  The Mahalanobis distance between the centroids of the two groups in the space defined by all the variables ia also found.  Confidence intervals for Cohen d for one group (difference from 0) may also be found. Several measures of the distributional overlap (e.g. OVL, OVL2, etc.) are available.
Given a data.frame or matrix, find the standardized mean difference (Cohen's d) and confidence intervals for each variable depending upon a grouping variable.  Convert the d statistic to the r equivalent, report the student's t statistic and associated p values, and return statistics for both values of the grouping variable.  The Mahalanobis distance between the centroids of the two groups in the space defined by all the variables ia also found.  Confidence intervals for Cohen d for one group (difference from 0) may also be found. Several measures of the distributional overlap (e.g. OVL, OVL2, etc.) are available.
Given a data.frame or matrix, find the standardized mean difference (Cohen's d) and confidence intervals for each variable depending upon a grouping variable.  Convert the d statistic to the r equivalent, report the student's t statistic and associated p values, and return statistics for both values of the grouping variable.  The Mahalanobis distance between the centroids of the two groups in the space defined by all the variables ia also found.  Confidence intervals for Cohen d for one group (difference from 0) may also be found. Several measures of the distributional overlap (e.g. OVL, OVL2, etc.) are available.
Given a data.frame or matrix, find the standardized mean difference (Cohen's d) and confidence intervals for each variable depending upon a grouping variable.  Convert the d statistic to the r equivalent, report the student's t statistic and associated p values, and return statistics for both values of the grouping variable.  The Mahalanobis distance between the centroids of the two groups in the space defined by all the variables ia also found.  Confidence intervals for Cohen d for one group (difference from 0) may also be found. Several measures of the distributional overlap (e.g. OVL, OVL2, etc.) are available.
Given a data.frame or matrix, find the standardized mean difference (Cohen's d) and confidence intervals for each variable depending upon a grouping variable.  Convert the d statistic to the r equivalent, report the student's t statistic and associated p values, and return statistics for both values of the grouping variable.  The Mahalanobis distance between the centroids of the two groups in the space defined by all the variables ia also found.  Confidence intervals for Cohen d for one group (difference from 0) may also be found. Several measures of the distributional overlap (e.g. OVL, OVL2, etc.) are available.
Given a data.frame or matrix, find the standardized mean difference (Cohen's d) and confidence intervals for each variable depending upon a grouping variable.  Convert the d statistic to the r equivalent, report the student's t statistic and associated p values, and return statistics for both values of the grouping variable.  The Mahalanobis distance between the centroids of the two groups in the space defined by all the variables ia also found.  Confidence intervals for Cohen d for one group (difference from 0) may also be found. Several measures of the distributional overlap (e.g. OVL, OVL2, etc.) are available.
Given a data.frame or matrix, find the standardized mean difference (Cohen's d) and confidence intervals for each variable depending upon a grouping variable.  Convert the d statistic to the r equivalent, report the student's t statistic and associated p values, and return statistics for both values of the grouping variable.  The Mahalanobis distance between the centroids of the two groups in the space defined by all the variables ia also found.  Confidence intervals for Cohen d for one group (difference from 0) may also be found. Several measures of the distributional overlap (e.g. OVL, OVL2, etc.) are available.
Given a data.frame or matrix, find the standardized mean difference (Cohen's d) and confidence intervals for each variable depending upon a grouping variable.  Convert the d statistic to the r equivalent, report the student's t statistic and associated p values, and return statistics for both values of the grouping variable.  The Mahalanobis distance between the centroids of the two groups in the space defined by all the variables ia also found.  Confidence intervals for Cohen d for one group (difference from 0) may also be found. Several measures of the distributional overlap (e.g. OVL, OVL2, etc.) are available.
Among the many ways to describe a data set, one is a density plot for each value of a grouping variable and another is violin plot of multiple variables.  A density plot shows the density for different groups to show effect sizes. A violin plot is similar to a box plot but shows the actual distribution.Median and 25th and 75th percentile lines are added to the display. If a grouping variable is specified, violinBy will draw violin plots for each variable and for each group. Data points may be drawn as well.
There are many summary statistics available in R; this functionprovides the ones most useful for scale construction and item analysis in classic psychometrics. Range is most useful for the first pass in a data set, to check for coding errors.  
Report basic summary statistics by a grouping variable.  Useful if the grouping variable is some experimental variable and data are to be aggregated for plotting.  Partly a wrapper for by and describe
Report basic summary statistics by a grouping variable.  Useful if the grouping variable is some experimental variable and data are to be aggregated for plotting.  Partly a wrapper for by and describe
There are many summary statistics available in R; this functionprovides the ones most useful for scale construction and item analysis in classic psychometrics. Range is most useful for the first pass in a data set, to check for coding errors.  
There are many summary statistics available in R; this functionprovides the ones most useful for scale construction and item analysis in classic psychometrics. Range is most useful for the first pass in a data set, to check for coding errors.  
Path models are used to describe structural equation models or cluster analytic output.  These functions provide the primitives for drawing path models.  Used as a substitute for some of the functionality of Rgraphviz.
Path models are used to describe structural equation models or cluster analytic output.  These functions provide the primitives for drawing path models.  Used as a substitute for some of the functionality of Rgraphviz.
Path models are used to describe structural equation models or cluster analytic output.  These functions provide the primitives for drawing path models.  Used as a substitute for some of the functionality of Rgraphviz.
Path models are used to describe structural equation models or cluster analytic output.  These functions provide the primitives for drawing path models.  Used as a substitute for some of the functionality of Rgraphviz.
Path models are used to describe structural equation models or cluster analytic output.  These functions provide the primitives for drawing path models.  Used as a substitute for some of the functionality of Rgraphviz.
Path models are used to describe structural equation models or cluster analytic output.  These functions provide the primitives for drawing path models.  Used as a substitute for some of the functionality of Rgraphviz.
Path models are used to describe structural equation models or cluster analytic output.  These functions provide the primitives for drawing path models.  Used as a substitute for some of the functionality of Rgraphviz.
Path models are used to describe structural equation models or cluster analytic output.  These functions provide the primitives for drawing path models.  Used as a substitute for some of the functionality of Rgraphviz.
Path models are used to describe structural equation models or cluster analytic output.  These functions provide the primitives for drawing path models.  Used as a substitute for some of the functionality of Rgraphviz.
Path models are used to describe structural equation models or cluster analytic output.  These functions provide the primitives for drawing path models.  Used as a substitute for some of the functionality of Rgraphviz.
Path models are used to describe structural equation models or cluster analytic output.  These functions provide the primitives for drawing path models.  Used as a substitute for some of the functionality of Rgraphviz.
McDonald has proposed coefficient omega as an estimate of the general factor saturation of a test.  One way to find omega is to do a factor analysis of the original data set, rotate the factors obliquely, do a Schmid Leiman transformation, and then find omega. This function estimates omega as suggested by McDonald by using hierarchical factor analysis (following Jensen). A related option is to define the model using omega and then perform a confirmatory (bi-factor) analysis using the sem or lavaan packages.  This is done by omegaSem and omegaFromSem. omegaFromSem will convert appropriate sem/lavaan objects to find omega.  Yet another option is to do the direct Schmid-Leiman of Waller.
The congruence coefficient two matrices is just the cross product of their respective values divided by the square root of their sums of squares. If the columns are zero centered, this is just the correlation. If the columns are centered around the scale neutral point, this is Cohen's profile correlation. A set of distances (city block, euclidean, Minkowski) may be found by the distance function. 
A graphic of a correlation ellipse divided into 4 regions based upon x and y cutpoints on two normal distributions.  This is also an example of using the layout function. Draw a bivariate density plot to show how tetrachorics work.
A graphic of a correlation ellipse divided into 4 regions based upon x and y cutpoints on two normal distributions.  This is also an example of using the layout function. Draw a bivariate density plot to show how tetrachorics work.
Given a variable x with n distinct values, create n new dummy coded variables coded 0/1 for presence (1) or absence (0) of each variable.  A typical application would be to create dummy coded college majors from a vector of college majors. Can also combine categories by group.  By default, NA values of x are returned as NA (added 10/20/17)
Dwyer (1937) introduced a technique for factor extension and used 8 cognitive variables from Thurstone.  This is the example data set used in his paper.
 The default procedures for principal component returns values not immediately equivalent to the loadings from a factor analysis.  eigen.loadings translates them into the more typical metric of eigen vectors multiplied by the squareroot of the eigenvalues.   This lets us find pseudo factor loadings if we have used princomp  or eigen. If we use principal to do our principal components analysis, then we do not need this routine.
For teaching correlation, it is useful to draw ellipses around the mean to reflect the correlation.  This variation of the ellipse function from John Fox's car package does so.  Input may be either two vectors or a matrix or data.frame.  In the latter cases, if the number of variables >2, then the ellipses are done in the pairs.panels function. Ellipses may be added to existing plots. The minkowski function is included as a generalized ellipse.
The bifactor rotation implements the rotation introduced by Jennrich and Bentler (2011) by calling GPForth in the GPArotation package.  promax is an oblique rotation function introduced by Hendrickson and White (1964) and implemented in the promax function in the stats package.  Unfortunately, promax does not report the inter factor correlations.  Promax does.  TargetQ does a target rotation with elements that can be missing (NA), or numeric (e.g., 0, 1).  It uses the GPArotation package. target.rot does general target rotations to an arbitrary target matrix. The default target rotation is for an independent cluster solution. equamax facilitates the call to GPArotation to do an equamax rotation.  Equamax, although available as a specific option within GPArotation is easier to call by name if using equamax.  The varimin rotation suggested by Ertl (2013) is implemented by appropriate calls to GPArotation.
One of the many functions in R to plot means and confidence intervals. Can be done using barplots if desired.  Can also be combined with such functions as boxplot to summarize distributions.  Means and standard errors are calculated from the raw data using describe. Alternatively, plots of means +/- one standard deviation may be drawn.
One of the many functions in R to plot means and confidence intervals.  Meant mainly for demonstration purposes for showing the probabilty of replication from multiple samples.  Can also be combined with such functions as boxplot to summarize distributions.  Means and standard errors for each group are calculated using describeBy.
One of the many functions in R to plot means and confidence intervals. Can be done using barplots if desired.  Can also be combined with such functions as boxplot to summarize distributions.  Means and standard errors are calculated from the raw data using describe. Alternatively, plots of means +/- one standard deviation may be drawn.
Given two vectors of data (X and Y), plot the means and show standard errors in both X and Y directions. 
Yet one more of the graphical ways of showing data with error bars for different groups.A dot.chart with error bars for different groups or variables is found using from describe,  describeBy,  statsBy or data from bestScales.
Given a matrix or data frame, data, find statistics based upon a grouping variable and then plot x and y means with error bars for each value of the grouping variable.  If the data are paired (e.g. by gender), then plot means and error bars for the two groups on all variables. 
Structural Equation Modeling (SEM) is a powerful tool for confirming multivariate structures and is well done by the lavaan, sem, or OpenMx packages. Because they are confirmatory, SEM  models test specific models.  Exploratory Structural Equation Modeling (ESEM), on the other hand, takes a more exploratory approach.  By using factor extension, it is possible to extend the factors of one set of variables (X) into the variable space of another set (Y). Using this technique, it is then possible to estimate the correlations between the two sets of latent variables, much the way normal SEM would do.  Based upon exploratory factor analysis (EFA) this approach provides a quick and easy approach to do exploratory structural equation modeling.  
Structural Equation Modeling (SEM) is a powerful tool for confirming multivariate structures and is well done by the lavaan, sem, or OpenMx packages. Because they are confirmatory, SEM  models test specific models.  Exploratory Structural Equation Modeling (ESEM), on the other hand, takes a more exploratory approach.  By using factor extension, it is possible to extend the factors of one set of variables (X) into the variable space of another set (Y). Using this technique, it is then possible to estimate the correlations between the two sets of latent variables, much the way normal SEM would do.  Based upon exploratory factor analysis (EFA) this approach provides a quick and easy approach to do exploratory structural equation modeling.  
Factor analysis or principal components analysis results are typically interpreted in terms of the major loadings on each factor.  These structures may be represented as a table of loadings or graphically, where all loadings with an absolute value > some cut point are represented as an edge (path). fa.diagram uses the various diagram functions to draw the diagram. fa.graph generates dot code for external plotting.  fa.rgraph uses the Rgraphviz package (if available) to draw the graph. het.diagram will draw "heterarchy" diagrams of factor/scale solutions at different levels.
Among the many ways to do latent variable exploratory factor analysis (EFA), one of the better is to use Ordinary Least Squares (OLS) to find the minimum residual (minres) solution. This produces solutions very similar to maximum likelihood even for badly behaved matrices. A variation on minres is to do weighted least squares (WLS). Perhaps the most conventional technique is principal axes (PAF).  An eigen value decomposition of a correlation matrix is done and then the communalities for each variable are estimated by the first n factors. These communalities are entered onto the diagonal and the procedure is repeated until the sum(diag(r)) does not vary.   Yet another estimate procedure is maximum likelihood. For well behaved matrices, maximum likelihood factor analysis (either in the fa or in the factanal function) is probably preferred.  Bootstrapped confidence intervals of the loadings and interfactor correlations are found by fa  with n.iter > 1. 
Given two sets of factor loadings, report their degree of congruence (vector cosine). Although first reported by Burt (1937,1  1948), this is frequently known as the Tucker index of factor congruence. Cohen's Profile similarity may be found as well. 
Factor analysis or principal components analysis results are typically interpreted in terms of the major loadings on each factor.  These structures may be represented as a table of loadings or graphically, where all loadings with an absolute value > some cut point are represented as an edge (path). fa.diagram uses the various diagram functions to draw the diagram. fa.graph generates dot code for external plotting.  fa.rgraph uses the Rgraphviz package (if available) to draw the graph. het.diagram will draw "heterarchy" diagrams of factor/scale solutions at different levels.
Dwyer (1937) introduced a method for finding factor loadings for variables not included in the original analysis.  This is basically finding the unattenuated correlation of the extension variables with the factor scores.  An alternative, which does not correct for factor reliability was proposed by Gorsuch (1997). Both options are an application of exploratory factor analysis with extensions to new variables. Also useful for finding the validities of variables in the factor space.  
Dwyer (1937) introduced a method for finding factor loadings for variables not included in the original analysis.  This is basically finding the unattenuated correlation of the extension variables with the factor scores.  An alternative, which does not correct for factor reliability was proposed by Gorsuch (1997). Both options are an application of exploratory factor analysis with extensions to new variables. Also useful for finding the validities of variables in the factor space.  
Factor analysis or principal components analysis results are typically interpreted in terms of the major loadings on each factor.  These structures may be represented as a table of loadings or graphically, where all loadings with an absolute value > some cut point are represented as an edge (path). fa.diagram uses the various diagram functions to draw the diagram. fa.graph generates dot code for external plotting.  fa.rgraph uses the Rgraphviz package (if available) to draw the graph. het.diagram will draw "heterarchy" diagrams of factor/scale solutions at different levels.
 When constructing scales through rational, factorial, or empirical means, it is useful to examine the content of the items that relate most highly to each other (e.g., the factor loadings of fa.lookup of a set of items) , or to some specific set of criteria  (e.g., bestScales). Given a dictionary of item content, these routines will sort by factor loading or criteria correlations and display the item content. 
Some factor analytic solutions produce correlated factors which may in turn be factored.  If the solution has one higher order, the omega function is most appropriate.  But, in the case of multi higher order factors, then the faMulti function will do a lower level factoring and then factor the resulting correlation matrix.  Multi level factor diagrams are also shown.
Some factor analytic solutions produce correlated factors which may in turn be factored.  If the solution has one higher order, the omega function is most appropriate.  But, in the case of multi higher order factors, then the faMulti function will do a lower level factoring and then factor the resulting correlation matrix.  Multi level factor diagrams are also shown.
Although the print.psych function will sort factor analysis loadings, sometimes it is useful to do this outside of the print function. fa.sort takes the output from the fa or principal functions and sorts the loadings for each factor.  Items are located in terms of their greatest loading.  The new order is returned as an element in the fa list. fa.organize allows for the columns or rows to be reorganized.
One way to determine the number of factors or components in a data matrix or a correlation matrix is to examine the “scree" plot of the successive eigenvalues.  Sharp breaks in the plot suggest the appropriate number of components or factors to extract.  “Parallel" analyis is an alternative technique that compares the scree of factors of the observed data with that of a random data matrix of the same size as the original. This may be done for continuous , dichotomous, or polytomous data using Pearson, tetrachoric or polychoric correlations.
One way to determine the number of factors or components in a data matrix or a correlation matrix is to examine the “scree" plot of the successive eigenvalues.  Sharp breaks in the plot suggest the appropriate number of components or factors to extract.  “Parallel" analyis is an alternative technique that compares the scree of factors of the observed data with that of a random data matrix of the same size as the original. This may be done for continuous , dichotomous, or polytomous data using Pearson, tetrachoric or polychoric correlations.
Cluster analysis and factor analysis are procedures for grouping items in terms of a smaller number of (latent) factors or (observed) clusters.  Graphical presentations of clusters typically show tree structures, although they can be represented in terms of item by cluster correlations.  
After 6  years, it is time to stop using these deprecated functions!  Please see fa which includes all of the functionality of these older functions.  
Among the many ways to do latent variable exploratory factor analysis (EFA), one of the better is to use Ordinary Least Squares (OLS) to find the minimum residual (minres) solution. This produces solutions very similar to maximum likelihood even for badly behaved matrices. A variation on minres is to do weighted least squares (WLS). Perhaps the most conventional technique is principal axes (PAF).  An eigen value decomposition of a correlation matrix is done and then the communalities for each variable are estimated by the first n factors. These communalities are entered onto the diagonal and the procedure is repeated until the sum(diag(r)) does not vary.   Yet another estimate procedure is maximum likelihood. For well behaved matrices, maximum likelihood factor analysis (either in the fa or in the factanal function) is probably preferred.  Bootstrapped confidence intervals of the loadings and interfactor correlations are found by fa  with n.iter > 1. 
Inspired, in part, by the wprifm function in the profileR package, fa.random removes between subject differences in mean level and then does a normal exploratory factor analysis of the ipsatized data.  Functionally, this removes a general factor of the data before factoring. To prevent non-positive definiteness of the residual data matrix, a very small amount of random noise is added to each variable. This is just a call to fa after removing the between subjects effect. Read the help file for fa for a detailed explanation of all of the input parameters and the output objects. 
Factor analysis or principal components analysis results are typically interpreted in terms of the major loadings on each factor.  These structures may be represented as a table of loadings or graphically, where all loadings with an absolute value > some cut point are represented as an edge (path). fa.diagram uses the various diagram functions to draw the diagram. fa.graph generates dot code for external plotting.  fa.rgraph uses the Rgraphviz package (if available) to draw the graph. het.diagram will draw "heterarchy" diagrams of factor/scale solutions at different levels.
Among the many ways to do latent variable exploratory factor analysis (EFA), one of the better is to use Ordinary Least Squares (OLS) to find the minimum residual (minres) solution. This produces solutions very similar to maximum likelihood even for badly behaved matrices. A variation on minres is to do weighted least squares (WLS). Perhaps the most conventional technique is principal axes (PAF).  An eigen value decomposition of a correlation matrix is done and then the communalities for each variable are estimated by the first n factors. These communalities are entered onto the diagonal and the procedure is repeated until the sum(diag(r)) does not vary.   Yet another estimate procedure is maximum likelihood. For well behaved matrices, maximum likelihood factor analysis (either in the fa or in the factanal function) is probably preferred.  Bootstrapped confidence intervals of the loadings and interfactor correlations are found by fa  with n.iter > 1. 
Although the print.psych function will sort factor analysis loadings, sometimes it is useful to do this outside of the print function. fa.sort takes the output from the fa or principal functions and sorts the loadings for each factor.  Items are located in terms of their greatest loading.  The new order is returned as an element in the fa list. fa.organize allows for the columns or rows to be reorganized.
Chi square and other goodness of fit statistics are found based upon the fit of a factor or components model to a correlation matrix.  Although these statistics are normally associated with a maximum likelihood solution, they can be found for minimal residual (OLS), principal axis, or principal component solutions as well.  Primarily called from within these functions, factor.stats can be used by itself. Measures of factorial adequacy and validity follow the paper by Grice, 2001.
Although exploratory factor analysis and Item Response Theory seem to be very different models of binary data, they can provide equivalent parameter estimates of item difficulty and item discrimination.  Tetrachoric or polychoric correlations of a data set of dichotomous or polytomous items may be factor analysed using a minimum residual or maximum likelihood factor analysis and the result loadings transformed to item discrimination parameters.  The tau parameter from the tetrachoric/polychoric correlations combined with the item factor loading may be used to estimate item difficulties. 
When examining data at two levels (e.g., the individual and by some set of grouping variables), it is useful to find basic descriptive statistics (means, sds, ns per group, within group correlations) as well as between group statistics (over all descriptive statistics, and overall between group correlations). Of particular use is the ability to decompose a matrix of correlations at the individual level into correlations within group and correlations between groups. 
Among the many ways to do latent variable exploratory factor analysis (EFA), one of the better is to use Ordinary Least Squares (OLS) to find the minimum residual (minres) solution. This produces solutions very similar to maximum likelihood even for badly behaved matrices. A variation on minres is to do weighted least squares (WLS). Perhaps the most conventional technique is principal axes (PAF).  An eigen value decomposition of a correlation matrix is done and then the communalities for each variable are estimated by the first n factors. These communalities are entered onto the diagonal and the procedure is repeated until the sum(diag(r)) does not vary.   Yet another estimate procedure is maximum likelihood. For well behaved matrices, maximum likelihood factor analysis (either in the fa or in the factanal function) is probably preferred.  Bootstrapped confidence intervals of the loadings and interfactor correlations are found by fa  with n.iter > 1. 
Given two factor analysis or pca solutions to a data matrix or correlation, what are the similarities between the two solutions. This may be found by factor correlations as well as factor congruences.  Factor correlations are found by the matrix product of the factor weights and the correlation matrix and are estimates of what the factor score correlations would be.  Factor congruence (aka Tucker or Burt coefficient) is the cosine of the vectors of factor loadings.
Given two sets of factor loadings, report their degree of congruence (vector cosine). Although first reported by Burt (1937,1  1948), this is frequently known as the Tucker index of factor congruence. Cohen's Profile similarity may be found as well. 
The basic factor or principal components model is that a correlation or covariance matrix may be reproduced by the product of a factor loading matrix times its transpose: F'F or P'P.  One simple index of fit is the 1 - sum squared residuals/sum squared original correlations. This fit index is used by VSS, ICLUST, etc. 
After 6  years, it is time to stop using these deprecated functions!  Please see fa which includes all of the functionality of these older functions.  
The basic factor or principal components model is that a correlation or covariance matrix may be reproduced by the product of a factor loading matrix times its transpose.  Find this reproduced matrix.  Used by factor.fit, VSS, ICLUST, etc.
After 6  years, it is time to stop using these deprecated functions!  Please see fa which includes all of the functionality of these older functions.  
Cluster analysis and factor analysis are procedures for grouping items in terms of a smaller number of (latent) factors or (observed) clusters.  Graphical presentations of clusters typically show tree structures, although they can be represented in terms of item by cluster correlations.  
The basic factor or principal components model is that a correlation or covariance matrix may be reproduced by the product of a factor loading matrix times its transpose.  Find the residuals of the original minus the  reproduced matrix.  Used by factor.fit, VSS, ICLUST, etc.
Given a factor or components matrix, it is sometimes useful to do arbitrary rotations of particular pairs of variables.  This supplements the much more powerful rotation package GPArotation and is meant for specific requirements to do unusual rotations.
A fundamental problem with factor analysis is that although the model is defined at the structural level, it is indeterminate at the data level. This problem of factor indeterminancy leads to alternative ways of estimating factor scores, none of which is ideal.  Following Grice (2001) four different methods are available here.
Chi square and other goodness of fit statistics are found based upon the fit of a factor or components model to a correlation matrix.  Although these statistics are normally associated with a maximum likelihood solution, they can be found for minimal residual (OLS), principal axis, or principal component solutions as well.  Primarily called from within these functions, factor.stats can be used by itself. Measures of factorial adequacy and validity follow the paper by Grice, 2001.
After 6  years, it is time to stop using these deprecated functions!  Please see fa which includes all of the functionality of these older functions.  
Given a factor or principal components loading matrix, assign each item to a cluster corresponding to the largest (signed) factor loading for that item.  Essentially, this is a Very Simple Structure approach to cluster definition that corresponds to what most people actually do: highlight the largest loading for each item and ignore the rest.
The bifactor rotation implements the rotation introduced by Jennrich and Bentler (2011) by calling GPForth in the GPArotation package.  promax is an oblique rotation function introduced by Hendrickson and White (1964) and implemented in the promax function in the stats package.  Unfortunately, promax does not report the inter factor correlations.  Promax does.  TargetQ does a target rotation with elements that can be missing (NA), or numeric (e.g., 0, 1).  It uses the GPArotation package. target.rot does general target rotations to an arbitrary target matrix. The default target rotation is for an independent cluster solution. equamax facilitates the call to GPArotation to do an equamax rotation.  Equamax, although available as a specific option within GPArotation is easier to call by name if using equamax.  The varimin rotation suggested by Ertl (2013) is implemented by appropriate calls to GPArotation.
A dirty little secret of factor rotation algorithms is the problem of local minima (Nguyen and Waller,2022).  Following ideas in that article, we allow for multiple random restarts and then return the global optimal solution.  Used as part of the fa function or available as a stand alone function. 
Convert a correlation to a z or t, or d, or chi or covariance matrixor z to r using the Fisher transformation or find the confidence intervals for a specified correlation.  r2d converts a correlation to an effect size (Cohen's d) and d2r converts a d into an r. g2r converts Hedge's g to a correlation.   t2r converts a t test to r, r2t converts a correlation to a t-test value. chi2r converts a chi square to r, r2chi converts it back.  r2c and cor2cov convert a correlation matrix to a covariance matrix. d2t and t2d convert cohen's d into a t and a t into a cohen d.  See cohen.d for other conversions.
Convert a correlation to a z or t, or d, or chi or covariance matrixor z to r using the Fisher transformation or find the confidence intervals for a specified correlation.  r2d converts a correlation to an effect size (Cohen's d) and d2r converts a d into an r. g2r converts Hedge's g to a correlation.   t2r converts a t test to r, r2t converts a correlation to a t-test value. chi2r converts a chi square to r, r2chi converts it back.  r2c and cor2cov convert a correlation matrix to a covariance matrix. d2t and t2d convert cohen's d into a t and a t into a cohen d.  See cohen.d for other conversions.
Formula input from e.g., lm,  may be extended to include mediators,  quadratic and partial terms using a standard syntax. This is use by setCor and mediate.
This is a set of minor, if not trivial, helper functions.lowerCor finds the correlation of x variables and then prints them using lowerMat which is a trivial, but useful, function to round off and print the lower triangle of a matrix.reflect reflects the output of a factor analysis or principal components analysis so that one or more factors is reflected. (Requested by Alexander Weiss.)progressBar prints out ...  as a calling routine (e.g., tetrachoric) works through a tedious calculation.  shannon finds the Shannon index (H) of diversity or of information. test.all tests all the examples in a package.  best.items sorts a factor matrix for absolute values and displays the expanded items names. fa.lookup returns sorted factor analysis output with item labels. cor2 correlates two data.frames (of equal length). levels2numeric and char2numeric convert dataframe columns that are categorical/levels to numeric values. 
Convert a correlation to a z or t, or d, or chi or covariance matrixor z to r using the Fisher transformation or find the confidence intervals for a specified correlation.  r2d converts a correlation to an effect size (Cohen's d) and d2r converts a d into an r. g2r converts Hedge's g to a correlation.   t2r converts a t test to r, r2t converts a correlation to a t-test value. chi2r converts a chi square to r, r2chi converts it back.  r2c and cor2cov convert a correlation matrix to a covariance matrix. d2t and t2d convert cohen's d into a t and a t into a cohen d.  See cohen.d for other conversions.
Garcia, Schmitt, Branscombe, and Ellemers (2010) report data for 129 subjects on the effects of perceived sexism on anger and liking of women's reactions to ingroup members who protest discrimination. This data set is also used as the ‘protest’ data set by Hayes (2013 and 2018).  It is a useful example of mediation and moderation in regression. It may also be used as an example of plotting interactions.
The geometric mean is the nth root of n products or e to the mean log of x.Useful for describing non-normal, i.e., geometric distributions.
Eight alternative estimates of test reliability include the six discussed by Guttman (1945), four discussed by ten Berge and Zergers (1978) (μ_0 … μ_3) as well as β (the worst split half, Revelle, 1979),  the glb (greatest lowest bound) discussed by Bentler and Woodward (1980), and ω_h and ω_t (McDonald, 1999; Zinbarg et al., 2005). Greatest and lowest split-half values are found by brute force or sampling. 
The greatest lower bound solves the “educational testing problem". That is, what is the reliability of a test? (See guttman for a discussion of the problem). Although there are many estimates of a test reliability (Guttman, 1945) most underestimate the true reliability of a test.
Eight alternative estimates of test reliability include the six discussed by Guttman (1945), four discussed by ten Berge and Zergers (1978) (μ_0 … μ_3) as well as β (the worst split half, Revelle, 1979),  the glb (greatest lowest bound) discussed by Bentler and Woodward (1980), and ω_h and ω_t (McDonald, 1999; Zinbarg et al., 2005). Greatest and lowest split-half values are found by brute force or sampling. 
Gleser, Cronbach and Rajaratnam (1965) discuss the estimation of variance components and their ratios as part of their introduction to generalizability theory.  This is a adaptation of their "illustrative data for a completely matched G study" (Table 3).  12 patients are rated on 6 symptoms by two judges.  Components of variance are derived from the ANOVA. 
Gorsuch (1997) suggests an alternative to the classic Dwyer (1937) factor extension technique.  This data set is taken from that article.  Useful for comparing link{fa.extension} with and without the correct=TRUE option.  
Eight alternative estimates of test reliability include the six discussed by Guttman (1945), four discussed by ten Berge and Zergers (1978) (μ_0 … μ_3) as well as β (the worst split half, Revelle, 1979),  the glb (greatest lowest bound) discussed by Bentler and Woodward (1980), and ω_h and ω_t (McDonald, 1999; Zinbarg et al., 2005). Greatest and lowest split-half values are found by brute force or sampling. 
Five classic data sets reported by Harman (1967) are 9 psychological (cognitive) variables taken from Holzinger  and 8 emotional variables taken from Burt. Two others are socioeconomic and political data sets. Additionally, 8 physical variables.  All five of these are used for tests and demonstrations of various factoring algortithms.
Five classic data sets reported by Harman (1967) are 9 psychological (cognitive) variables taken from Holzinger  and 8 emotional variables taken from Burt. Two others are socioeconomic and political data sets. Additionally, 8 physical variables.  All five of these are used for tests and demonstrations of various factoring algortithms.
Five classic data sets reported by Harman (1967) are 9 psychological (cognitive) variables taken from Holzinger  and 8 emotional variables taken from Burt. Two others are socioeconomic and political data sets. Additionally, 8 physical variables.  All five of these are used for tests and demonstrations of various factoring algortithms.
Five classic data sets reported by Harman (1967) are 9 psychological (cognitive) variables taken from Holzinger  and 8 emotional variables taken from Burt. Two others are socioeconomic and political data sets. Additionally, 8 physical variables.  All five of these are used for tests and demonstrations of various factoring algortithms.
Five classic data sets reported by Harman (1967) are 9 psychological (cognitive) variables taken from Holzinger  and 8 emotional variables taken from Burt. Two others are socioeconomic and political data sets. Additionally, 8 physical variables.  All five of these are used for tests and demonstrations of various factoring algortithms.
The harmonic mean is merely the reciprocal of the arithmetic mean of the reciprocals.
A quick way to show the first and last n lines of a data.frame, matrix, or a text object.  Just a pretty call to head and tail or View
A quick way to show the first and last n lines of a data.frame, matrix, or a text object.  Just a pretty call to head and tail or View
Factor analysis or principal components analysis results are typically interpreted in terms of the major loadings on each factor.  These structures may be represented as a table of loadings or graphically, where all loadings with an absolute value > some cut point are represented as an edge (path). fa.diagram uses the various diagram functions to draw the diagram. fa.graph generates dot code for external plotting.  fa.rgraph uses the Rgraphviz package (if available) to draw the graph. het.diagram will draw "heterarchy" diagrams of factor/scale solutions at different levels.
Given a matrix or data.frame, produce histograms for each variable in a "matrix" form. Include normal fits and density distributions for each plot.
Holzinger-Swineford (1937) introduced the bifactor model of a general factor and uncorrelated group factors. The Holzinger data sets are   original 14 * 14 matrix from their paper as well as a 9 *9 matrix used as an example by Joreskog. The Thurstone correlation matrix is a 9 * 9 matrix of correlations of ability items.  The Reise data set is 16 * 16 correlation matrix of mental health items. The Bechtholdt data sets are both 17 x 17 correlation matrices of ability tests.  
Holzinger-Swineford (1937) introduced the bifactor model of a general factor and uncorrelated group factors. The Holzinger data sets are   original 14 * 14 matrix from their paper as well as a 9 *9 matrix used as an example by Joreskog. The Thurstone correlation matrix is a 9 * 9 matrix of correlations of ability items.  The Reise data set is 16 * 16 correlation matrix of mental health items. The Bechtholdt data sets are both 17 x 17 correlation matrices of ability tests.  
The Intraclass correlation is used as a measure of association when studying the reliability of raters.  Shrout and Fleiss (1979) outline 6 different estimates, that depend upon the particular experimental design. All are implemented and given confidence limits.  Uses either aov or lmer depending upon options.  lmer allows for missing values.
A common data reduction technique is to cluster cases (subjects). Less common, but particularly useful in psychological research, is to cluster items (variables). This may be thought of as an alternative to factor analysis, based upon a much simpler model. The cluster model is that the correlations between variables reflect that each item loads on at most one cluster, and that items that load on those clusters correlate as a function of their respective loadings on that cluster and items that define different clusters correlate as a function of their respective cluster loadings and the intercluster correlations. Essentially, the cluster model is a Very Simple Structure factor model of complexity one (see VSS).
A common data reduction technique is to cluster cases (subjects). Less common, but particularly useful in psychological research, is to cluster items (variables). This may be thought of as an alternative to factor analysis, based upon a much simpler model. The cluster model is that the correlations between variables reflect that each item loads on at most one cluster, and that items that load on those clusters correlate as a function of their respective loadings on that cluster and items that define different clusters correlate as a function of their respective cluster loadings and the intercluster correlations. Essentially, the cluster model is a Very Simple Structure factor model of complexity one (see VSS).
The guts of the  ICLUST algorithm.  Called by ICLUST See ICLUST for description.
Given a cluster structure determined by ICLUST, create a graphic structural diagram using graphic functions in the psych package To create dot code to describe the ICLUST output with more precision, use ICLUST.graph. If Rgraphviz has been successfully installed, the alternative is to use ICLUST.rgraph.
Given a cluster structure determined by ICLUST, create dot code to describe the ICLUST output.  To use the dot code, use either https://www.graphviz.org/ Graphviz or a commercial viewer (e.g., OmniGraffle).  This function parallels ICLUST.rgraph which uses Rgraphviz.  
Given a cluster structure determined by ICLUST, create a rgraphic directly using Rgraphviz.  To create dot code to describe the ICLUST output with more precision, use ICLUST.graph.  As an option, dot code is also generated and saved in a file. To  use the dot code, use either https://www.graphviz.org/ Graphviz or a commercial viewer (e.g., OmniGraffle).
Given a cluster analysis or factor analysis loadings matrix, sort the items by the (absolute) size of each column of loadings.  Used as part of ICLUST and SAPA analyses. The columns are rearranged by the 
Given a cluster analysis or factor analysis loadings matrix, sort the items by the (absolute) size of each column of loadings.  Used as part of ICLUST and SAPA analyses. The columns are rearranged by the 
Structural Equation Modeling (SEM) is a powerful tool for confirming multivariate structures and is well done by the lavaan, sem, or OpenMx packages. Because they are confirmatory, SEM  models test specific models.  Exploratory Structural Equation Modeling (ESEM), on the other hand, takes a more exploratory approach.  By using factor extension, it is possible to extend the factors of one set of variables (X) into the variable space of another set (Y). Using this technique, it is then possible to estimate the correlations between the two sets of latent variables, much the way normal SEM would do.  Based upon exploratory factor analysis (EFA) this approach provides a quick and easy approach to do exploratory structural equation modeling.  
For data with a limited number of response categories (e.g., attitude items), it is useful treat each response category as range with width, w and linearly interpolate the median, quartiles, or any quantile value within the median response.   
For data with a limited number of response categories (e.g., attitude items), it is useful treat each response category as range with width, w and linearly interpolate the median, quartiles, or any quantile value within the median response.   
For data with a limited number of response categories (e.g., attitude items), it is useful treat each response category as range with width, w and linearly interpolate the median, quartiles, or any quantile value within the median response.   
For data with a limited number of response categories (e.g., attitude items), it is useful treat each response category as range with width, w and linearly interpolate the median, quartiles, or any quantile value within the median response.   
For data with a limited number of response categories (e.g., attitude items), it is useful treat each response category as range with width, w and linearly interpolate the median, quartiles, or any quantile value within the median response.   
For data with a limited number of response categories (e.g., attitude items), it is useful treat each response category as range with width, w and linearly interpolate the median, quartiles, or any quantile value within the median response.   
For data with a limited number of response categories (e.g., attitude items), it is useful treat each response category as range with width, w and linearly interpolate the median, quartiles, or any quantile value within the median response.   
For data with a limited number of response categories (e.g., attitude items), it is useful treat each response category as range with width, w and linearly interpolate the median, quartiles, or any quantile value within the median response.   
Item Response Theory models individual responses to items by estimating individual ability (theta) and item difficulty (diff) parameters.  This is an early and crude attempt to capture this modeling procedure. A better procedure is to use  irt.fa. 
Item Response Theory models individual responses to items by estimating individual ability (theta) and item difficulty (diff) parameters.  This is an early and crude attempt to capture this modeling procedure. A better procedure is to use  irt.fa. 
Item Response Theory models individual responses to items by estimating individual ability (theta) and item difficulty (diff) parameters.  This is an early and crude attempt to capture this modeling procedure. A better procedure is to use  irt.fa. 
Steps toward a  very crude and preliminary IRT program. These two functions  estimate item difficulty and discrimination parameters.  A better procedure is to use irt.fa or the ltm package.
Although exploratory factor analysis and Item Response Theory seem to be very different models of binary data, they can provide equivalent parameter estimates of item difficulty and item discrimination.  Tetrachoric or polychoric correlations of a data set of dichotomous or polytomous items may be factor analysed using a minimum residual or maximum likelihood factor analysis and the result loadings transformed to item discrimination parameters.  The tau parameter from the tetrachoric/polychoric correlations combined with the item factor loading may be used to estimate item difficulties. 
Steps toward a  very crude and preliminary IRT program. These two functions  estimate item difficulty and discrimination parameters.  A better procedure is to use irt.fa or the ltm package.
Item Response Theory models individual responses to items by estimating individual ability (theta) and item difficulty (diff) parameters.  This is an early and crude attempt to capture this modeling procedure. A better procedure is to use  irt.fa. 
When analyzing ability tests, it is important to consider how the distractor alternatives vary as a function of the latent trait.  The simple graphical solution is to plot response endorsement frequencies against the values of the latent trait found from multiple items. A good item is one in which the probability of the distractors decrease and the keyed answer increases as the latent trait increases. 
irt.fa finds Item Response Theory (IRT) parameters through factor analysis of the tetrachoric or polychoric correlations of dichtomous or polytomous items. scoreIrt uses these parameter estimates of discrimination and location to find IRT based scores for the responses. As many factors as found for the correlation matrix will be scored. scoreIrt.2pl will score lists of scales.
Although exploratory factor analysis and Item Response Theory seem to be very different models of binary data, they can provide equivalent parameter estimates of item difficulty and item discrimination.  Tetrachoric or polychoric correlations of a data set of dichotomous or polytomous items may be factor analysed using a minimum residual or maximum likelihood factor analysis and the result loadings transformed to item discrimination parameters.  The tau parameter from the tetrachoric/polychoric correlations combined with the item factor loading may be used to estimate item difficulties. 
irt.fa finds Item Response Theory (IRT) parameters through factor analysis of the tetrachoric or polychoric correlations of dichtomous or polytomous items. scoreIrt uses these parameter estimates of discrimination and location to find IRT based scores for the responses. As many factors as found for the correlation matrix will be scored. scoreIrt.2pl will score lists of scales.
irt.fa finds Item Response Theory (IRT) parameters through factor analysis of the tetrachoric or polychoric correlations of dichtomous or polytomous items. scoreIrt uses these parameter estimates of discrimination and location to find IRT based scores for the responses. As many factors as found for the correlation matrix will be scored. scoreIrt.2pl will score lists of scales.
This is a set of minor, if not trivial, helper functions.lowerCor finds the correlation of x variables and then prints them using lowerMat which is a trivial, but useful, function to round off and print the lower triangle of a matrix.reflect reflects the output of a factor analysis or principal components analysis so that one or more factors is reflected. (Requested by Alexander Weiss.)progressBar prints out ...  as a calling routine (e.g., tetrachoric) works through a tedious calculation.  shannon finds the Shannon index (H) of diversity or of information. test.all tests all the examples in a package.  best.items sorts a factor matrix for absolute values and displays the expanded items names. fa.lookup returns sorted factor analysis output with item labels. cor2 correlates two data.frames (of equal length). levels2numeric and char2numeric convert dataframe columns that are categorical/levels to numeric values. 
This is a set of minor, if not trivial, helper functions.lowerCor finds the correlation of x variables and then prints them using lowerMat which is a trivial, but useful, function to round off and print the lower triangle of a matrix.reflect reflects the output of a factor analysis or principal components analysis so that one or more factors is reflected. (Requested by Alexander Weiss.)progressBar prints out ...  as a calling routine (e.g., tetrachoric) works through a tedious calculation.  shannon finds the Shannon index (H) of diversity or of information. test.all tests all the examples in a package.  best.items sorts a factor matrix for absolute values and displays the expanded items names. fa.lookup returns sorted factor analysis output with item labels. cor2 correlates two data.frames (of equal length). levels2numeric and char2numeric convert dataframe columns that are categorical/levels to numeric values. 
Rotations of factor analysis and principal components analysis solutions typically try to represent correlation matrices as simple structured.  An alternative structure, appealing to some, is a circumplex structure where the variables are uniformly spaced on the perimeter of a circle in a two dimensional space.  Generating simple structure and circumplex data is straightforward, and is useful for exploring alternative solutions to affect and personality structure. A generalization to 3 dimensional (spherical) data is straightforward.
 When constructing scales through rational, factorial, or empirical means, it is useful to examine the content of the items that relate most highly to each other (e.g., the factor loadings of fa.lookup of a set of items) , or to some specific set of criteria  (e.g., bestScales). Given a dictionary of item content, these routines will sort by factor loading or criteria correlations and display the item content. 
Rotations of factor analysis and principal components analysis solutions typically try to represent correlation matrices as simple structured.  An alternative structure, appealing to some, is a circumplex structure where the variables are uniformly spaced on the perimeter of a circle in a two dimensional space.  Generating simple structure and circumplex data is straightforward, and is useful for exploring alternative solutions to affect and personality structure. A generalization to 3 dimensional (spherical) data is straightforward.
The validity of a scale varies as a function of the number of items in the scale, their average intercorrelation, and their average validity. The asymptotic limit of a scales validity for any particular criterion is just the average validity divided by the square root of the average within scale item correlation.  predicted.validity will find the predicted validity for a set of scales (defined by a keys.list) and the average item validity for various criteria.  
Kaiser (1958) suggested normalizing factor loadings before rotating them, and then denormalizing them after rotation.  The GPArotation package does not (by default) normalize, nor does the fa function. Then, to make it more confusing, varimax in stats does,Varimax in GPArotation does not. kaiser will take the output of a non-normalized solution and report the normalized solution. 
 When constructing scales through rational, factorial, or empirical means, it is useful to examine the content of the items that relate most highly to each other (e.g., the factor loadings of fa.lookup of a set of items) , or to some specific set of criteria  (e.g., bestScales). Given a dictionary of item content, these routines will sort by factor loading or criteria correlations and display the item content. 
 When scoring items by forming composite scales either from the raw data using scoreItems or from the correlation matrix using cluster.cor, it used to be  necessary to create a keys matrix. This is no longer necessary as most of the scoring functions will directly use a keys list. make.keys  is just a short cut for creating a keys matrix.  The keys matrix is a nvar x nscales matrix of -1,0, 1 and defines the membership for each scale. Items can be specified by location or by name.
Given a set of n items, form n/2 or n/3 mini scales or parcels of the most similar pairs or triplets of items.  These may be used as the basis for subsequent scale construction or multivariate (e.g., factor) analysis.
Henry Kaiser (1970) introduced an Measure of Sampling Adequacy (MSA) of factor analytic data matrices. Kaiser and Rice (1974) then modified it. This is just a function of the squared elements of the ‘image’ matrix compared to the squares of the original correlations.  The overall MSA as well as estimates for each item are found. The index is known as the Kaiser-Meyer-Olkin (KMO) index.
Find the skew and kurtosis for each variable in a data.frame or matrix.  Unlike skew and kurtosis in e1071, this calculates a different skew for each variable or column of a data.frame/matrix. mardia applies Mardia's tests for multivariate skew and kurtosis
Graphic presentations of structural equation models are a very useful way to conceptualize sem and confirmatory factor models. Given a measurement model on x (xmodel) and on y (ymodel) as well as a path model connecting x and y (phi), draw the graph.  If the ymodel is not specified, just draw the measurement model (xmodel + phi). If the Rx or Ry matrices are specified, show the correlations between the x variables, or y variables.
This is a set of minor, if not trivial, helper functions.lowerCor finds the correlation of x variables and then prints them using lowerMat which is a trivial, but useful, function to round off and print the lower triangle of a matrix.reflect reflects the output of a factor analysis or principal components analysis so that one or more factors is reflected. (Requested by Alexander Weiss.)progressBar prints out ...  as a calling routine (e.g., tetrachoric) works through a tedious calculation.  shannon finds the Shannon index (H) of diversity or of information. test.all tests all the examples in a package.  best.items sorts a factor matrix for absolute values and displays the expanded items names. fa.lookup returns sorted factor analysis output with item labels. cor2 correlates two data.frames (of equal length). levels2numeric and char2numeric convert dataframe columns that are categorical/levels to numeric values. 
The logistic function (1/(1+exp(-x)) and logit function (log(p/(1-p)) are fundamental to Item Response Theory.  Although just one line functions, they are included here for ease of demonstrations and in drawing IRT models. Also included is the logistic.grm for a graded response model.
The logistic function (1/(1+exp(-x)) and logit function (log(p/(1-p)) are fundamental to Item Response Theory.  Although just one line functions, they are included here for ease of demonstrations and in drawing IRT models. Also included is the logistic.grm for a graded response model.
The logistic function (1/(1+exp(-x)) and logit function (log(p/(1-p)) are fundamental to Item Response Theory.  Although just one line functions, they are included here for ease of demonstrations and in drawing IRT models. Also included is the logistic.grm for a graded response model.
 When constructing scales through rational, factorial, or empirical means, it is useful to examine the content of the items that relate most highly to each other (e.g., the factor loadings of fa.lookup of a set of items) , or to some specific set of criteria  (e.g., bestScales). Given a dictionary of item content, these routines will sort by factor loading or criteria correlations and display the item content. 
 When constructing scales through rational, factorial, or empirical means, it is useful to examine the content of the items that relate most highly to each other (e.g., the factor loadings of fa.lookup of a set of items) , or to some specific set of criteria  (e.g., bestScales). Given a dictionary of item content, these routines will sort by factor loading or criteria correlations and display the item content. 
 When constructing scales through rational, factorial, or empirical means, it is useful to examine the content of the items that relate most highly to each other (e.g., the factor loadings of fa.lookup of a set of items) , or to some specific set of criteria  (e.g., bestScales). Given a dictionary of item content, these routines will sort by factor loading or criteria correlations and display the item content. 
This is a set of minor, if not trivial, helper functions.lowerCor finds the correlation of x variables and then prints them using lowerMat which is a trivial, but useful, function to round off and print the lower triangle of a matrix.reflect reflects the output of a factor analysis or principal components analysis so that one or more factors is reflected. (Requested by Alexander Weiss.)progressBar prints out ...  as a calling routine (e.g., tetrachoric) works through a tedious calculation.  shannon finds the Shannon index (H) of diversity or of information. test.all tests all the examples in a package.  best.items sorts a factor matrix for absolute values and displays the expanded items names. fa.lookup returns sorted factor analysis output with item labels. cor2 correlates two data.frames (of equal length). levels2numeric and char2numeric convert dataframe columns that are categorical/levels to numeric values. 
This is a set of minor, if not trivial, helper functions.lowerCor finds the correlation of x variables and then prints them using lowerMat which is a trivial, but useful, function to round off and print the lower triangle of a matrix.reflect reflects the output of a factor analysis or principal components analysis so that one or more factors is reflected. (Requested by Alexander Weiss.)progressBar prints out ...  as a calling routine (e.g., tetrachoric) works through a tedious calculation.  shannon finds the Shannon index (H) of diversity or of information. test.all tests all the examples in a package.  best.items sorts a factor matrix for absolute values and displays the expanded items names. fa.lookup returns sorted factor analysis output with item labels. cor2 correlates two data.frames (of equal length). levels2numeric and char2numeric convert dataframe columns that are categorical/levels to numeric values. 
When reporting correlation matrices for two samples (e.g., males and females), it is convenient to show them as one matrix, with entries below the diagonal representing one matrix, and entries above the diagonal the other matrix.  It is also useful to compare a correlation matrix with the residuals from a fitted (e.g., factor) model.  
An example data set used by McDonald (1999) as well as other discussions of Item Response Theory makes use of a data table on 10 items (two sets of 5) from the Law School Admissions Test (LSAT).  Included in this data set is the original table as well as the reponses for 1000 subjects on the first set (Figure Classification) and second set (Debate). 
An example data set used by McDonald (1999) as well as other discussions of Item Response Theory makes use of a data table on 10 items (two sets of 5) from the Law School Admissions Test (LSAT).  Included in this data set is the original table as well as the reponses for 1000 subjects on the first set (Figure Classification) and second set (Debate). 
Given a data.frame or matrix, find the standardized mean difference (Cohen's d) and confidence intervals for each variable depending upon a grouping variable.  Convert the d statistic to the r equivalent, report the student's t statistic and associated p values, and return statistics for both values of the grouping variable.  The Mahalanobis distance between the centroids of the two groups in the space defined by all the variables ia also found.  Confidence intervals for Cohen d for one group (difference from 0) may also be found. Several measures of the distributional overlap (e.g. OVL, OVL2, etc.) are available.
Given a data.frame or matrix, find the standardized mean difference (Cohen's d) and confidence intervals for each variable depending upon a grouping variable.  Convert the d statistic to the r equivalent, report the student's t statistic and associated p values, and return statistics for both values of the grouping variable.  The Mahalanobis distance between the centroids of the two groups in the space defined by all the variables ia also found.  Confidence intervals for Cohen d for one group (difference from 0) may also be found. Several measures of the distributional overlap (e.g. OVL, OVL2, etc.) are available.
Classical Test Theory (CTT) considers four or more tests to be congenerically equivalent if all tests may be expressed in terms of one factor and a residual error.  Parallel tests are the special case where (usually two) tests have equal factor loadings.  Tau equivalent tests have equal factor loadings but may have unequal errors.  Congeneric tests may differ in both factor loading and error variances.
Create a population orthogonal or hierarchical correlation matrix from a set of factor loadings and factor intercorrelations. Samples of size n may be then be drawn from this population.  Return either the sample data, sample correlations, or population correlations.  This is used to create sample data sets for instruction and demonstration.
irt.fa finds Item Response Theory (IRT) parameters through factor analysis of the tetrachoric or polychoric correlations of dichtomous or polytomous items. scoreIrt uses these parameter estimates of discrimination and location to find IRT based scores for the responses. As many factors as found for the correlation matrix will be scored. scoreIrt.2pl will score lists of scales.
 When scoring items by forming composite scales either from the raw data using scoreItems or from the correlation matrix using cluster.cor, it used to be  necessary to create a keys matrix. This is no longer necessary as most of the scoring functions will directly use a keys list. make.keys  is just a short cut for creating a keys matrix.  The keys matrix is a nvar x nscales matrix of -1,0, 1 and defines the membership for each scale. Items can be specified by location or by name.
 When scoring items by forming composite scales either from the raw data using scoreItems or from the correlation matrix using cluster.cor, it used to be  necessary to create a keys matrix. This is no longer necessary as most of the scoring functions will directly use a keys list. make.keys  is just a short cut for creating a keys matrix.  The keys matrix is a nvar x nscales matrix of -1,0, 1 and defines the membership for each scale. Items can be specified by location or by name.
A useful way of showing the strength of many correlations with a particular criterion is the Manhattan plot.  This is just a plot of correlations ordered by some keying variable.  Useful to understand the basis of items used in bestScales.
Find the skew and kurtosis for each variable in a data.frame or matrix.  Unlike skew and kurtosis in e1071, this calculates a different skew for each variable or column of a data.frame/matrix. mardia applies Mardia's tests for multivariate skew and kurtosis
Given a correlation matrix or a  matrix or dataframe of raw data, find the multiple regressions and draw a path diagram relating a set of y variables as a function of a set of x variables.  A set of covariates (z) can be partialled from the x and y sets. Regression diagrams are automatically included.   Model can be specified in conventional formula form, or in terms of x variables and y variables.  Multiplicative models (interactions) and quadratic terms may be specified in the formula mode if using raw data. By default, the data may be  zero centered before finding the interactions.  Will also find Cohen's Set Correlation between a predictor set of variables (x) and a criterion set (y). Also finds the canonical correlations between the x and y sets.
To see the structure of a correlation matrix, it is helpful to organize the items so that the similar items are grouped together. One such grouping technique is factor analysis.  mat.sort will sort the items by a factor model (if specified), or any other order, or by the loadings on the first factor (if unspecified)
Given a correlation matrix or a  matrix or dataframe of raw data, find the multiple regressions and draw a path diagram relating a set of y variables as a function of a set of x variables.  A set of covariates (z) can be partialled from the x and y sets. Regression diagrams are automatically included.   Model can be specified in conventional formula form, or in terms of x variables and y variables.  Multiplicative models (interactions) and quadratic terms may be specified in the formula mode if using raw data. By default, the data may be  zero centered before finding the interactions.  Will also find Cohen's Set Correlation between a predictor set of variables (x) and a criterion set (y). Also finds the canonical correlations between the x and y sets.
Given a correlation matrix or a  matrix or dataframe of raw data, find the multiple regressions and draw a path diagram relating a set of y variables as a function of a set of x variables.  A set of covariates (z) can be partialled from the x and y sets. Regression diagrams are automatically included.   Model can be specified in conventional formula form, or in terms of x variables and y variables.  Multiplicative models (interactions) and quadratic terms may be specified in the formula mode if using raw data. By default, the data may be  zero centered before finding the interactions.  Will also find Cohen's Set Correlation between a predictor set of variables (x) and a criterion set (y). Also finds the canonical correlations between the x and y sets.
To see the structure of a correlation matrix, it is helpful to organize the items so that the similar items are grouped together. One such grouping technique is factor analysis.  mat.sort will sort the items by a factor model (if specified), or any other order, or by the loadings on the first factor (if unspecified)
Find the direct and indirect effects of a predictor in path models of mediation and moderation. Bootstrap confidence intervals for the indirect effects.  Mediation models are just extended regression models making explicit the effect of particular covariates in the model. Moderation is done by multiplication of the predictor variables.   This function supplies basic mediation/moderation analyses for some of the classic problem types. 
Find the direct and indirect effects of a predictor in path models of mediation and moderation. Bootstrap confidence intervals for the indirect effects.  Mediation models are just extended regression models making explicit the effect of particular covariates in the model. Moderation is done by multiplication of the predictor variables.   This function supplies basic mediation/moderation analyses for some of the classic problem types. 
For teaching correlation, it is useful to draw ellipses around the mean to reflect the correlation.  This variation of the ellipse function from John Fox's car package does so.  Input may be either two vectors or a matrix or data.frame.  In the latter cases, if the number of variables >2, then the ellipses are done in the pairs.panels function. Ellipses may be added to existing plots. The minkowski function is included as a generalized ellipse.
For data sets with continuous, polytomous and dichotmous variables, the absolute Pearson correlation is downward biased from the underlying latent correlation.  mixedCor finds Pearson correlations for the continous variables, polychorics for the polytomous items, tetrachorics for the dichotomous items, and the polyserial or biserial correlations for the various mixed variables. Results include the complete correlation matrix, as well as the separate correlation matrices and difficulties for the polychoric and tetrachoric correlations.
For data sets with continuous, polytomous and dichotmous variables, the absolute Pearson correlation is downward biased from the underlying latent correlation.  mixedCor finds Pearson correlations for the continous variables, polychorics for the polytomous items, tetrachorics for the dichotomous items, and the polyserial or biserial correlations for the various mixed variables. Results include the complete correlation matrix, as well as the separate correlation matrices and difficulties for the polychoric and tetrachoric correlations.
Various indicators of reliability of multilevel data (e.g., items over time nested within subjects) may be found using generalizability theory.  A basic three way anova is applied to the data from which variance components are extracted. Random effects for a nested design are found by lme.    These are, in turn, converted to several reliability/generalizability coefficients.  An optional call to lme4 to use lmer may be used for unbalanced designs with missing data. mlArrange is a  helper function to convert wide to long format.  Data can be rearranged from wide to long format, and multiple lattice plots of observations overtime for multiple variables and multiple subjects are created.
Various indicators of reliability of multilevel data (e.g., items over time nested within subjects) may be found using generalizability theory.  A basic three way anova is applied to the data from which variance components are extracted. Random effects for a nested design are found by lme.    These are, in turn, converted to several reliability/generalizability coefficients.  An optional call to lme4 to use lmer may be used for unbalanced designs with missing data. mlArrange is a  helper function to convert wide to long format.  Data can be rearranged from wide to long format, and multiple lattice plots of observations overtime for multiple variables and multiple subjects are created.
Various indicators of reliability of multilevel data (e.g., items over time nested within subjects) may be found using generalizability theory.  A basic three way anova is applied to the data from which variance components are extracted. Random effects for a nested design are found by lme.    These are, in turn, converted to several reliability/generalizability coefficients.  An optional call to lme4 to use lmer may be used for unbalanced designs with missing data. mlArrange is a  helper function to convert wide to long format.  Data can be rearranged from wide to long format, and multiple lattice plots of observations overtime for multiple variables and multiple subjects are created.
Find the direct and indirect effects of a predictor in path models of mediation and moderation. Bootstrap confidence intervals for the indirect effects.  Mediation models are just extended regression models making explicit the effect of particular covariates in the model. Moderation is done by multiplication of the predictor variables.   This function supplies basic mediation/moderation analyses for some of the classic problem types. 
Von Neuman et al. (1941) discussed the Mean Square of Successive Differences as a measure of variability that takes into account gradual shifts in mean. This is appropriate when studying errors in ballistics or variability and stability in mood when studying affect. For random data, this will be twice the variance, but for data with a sequential order and a positive autocorrelation, this will be much smaller. Since the mssd is just twice the variance - the autocorrelation, it is thus possible to also find the autocorrelation for a particular lag. 
Path models are used to describe structural equation models or cluster analytic output.  These functions provide the primitives for drawing path models.  Used as a substitute for some of the functionality of Rgraphviz.
Path models are used to describe structural equation models or cluster analytic output.  These functions provide the primitives for drawing path models.  Used as a substitute for some of the functionality of Rgraphviz.
Given a matrix or data.frame, produce histograms for each variable in a "matrix" form. Include normal fits and density distributions for each plot.
Path models are used to describe structural equation models or cluster analytic output.  These functions provide the primitives for drawing path models.  Used as a substitute for some of the functionality of Rgraphviz.
Path models are used to describe structural equation models or cluster analytic output.  These functions provide the primitives for drawing path models.  Used as a substitute for some of the functionality of Rgraphviz.
Various indicators of reliability of multilevel data (e.g., items over time nested within subjects) may be found using generalizability theory.  A basic three way anova is applied to the data from which variance components are extracted. Random effects for a nested design are found by lme.    These are, in turn, converted to several reliability/generalizability coefficients.  An optional call to lme4 to use lmer may be used for unbalanced designs with missing data. mlArrange is a  helper function to convert wide to long format.  Data can be rearranged from wide to long format, and multiple lattice plots of observations overtime for multiple variables and multiple subjects are created.
This is a set of minor, if not trivial, helper functions.lowerCor finds the correlation of x variables and then prints them using lowerMat which is a trivial, but useful, function to round off and print the lower triangle of a matrix.reflect reflects the output of a factor analysis or principal components analysis so that one or more factors is reflected. (Requested by Alexander Weiss.)progressBar prints out ...  as a calling routine (e.g., tetrachoric) works through a tedious calculation.  shannon finds the Shannon index (H) of diversity or of information. test.all tests all the examples in a package.  best.items sorts a factor matrix for absolute values and displays the expanded items names. fa.lookup returns sorted factor analysis output with item labels. cor2 correlates two data.frames (of equal length). levels2numeric and char2numeric convert dataframe columns that are categorical/levels to numeric values. 
There are multiple ways to determine the appropriate number of factors in exploratory factor analysis. Routines for the Very Simple Structure (VSS) criterion allow one to compare solutions of varying complexity and for different number of factors. Graphic output indicates the "optimal" number of factors for different levels of complexity.  The Velicer MAP criterion is another good choice. nfactors finds and plots several of these alternative estimates.
McDonald has proposed coefficient omega as an estimate of the general factor saturation of a test.  One way to find omega is to do a factor analysis of the original data set, rotate the factors obliquely, do a Schmid Leiman transformation, and then find omega. This function estimates omega as suggested by McDonald by using hierarchical factor analysis (following Jensen). A related option is to define the model using omega and then perform a confirmatory (bi-factor) analysis using the sem or lavaan packages.  This is done by omegaSem and omegaFromSem. omegaFromSem will convert appropriate sem/lavaan objects to find omega.  Yet another option is to do the direct Schmid-Leiman of Waller.
Hierarchical factor structures represent the correlations between variables in terms of a smaller set of correlated factors which themselves can be represented by a higher order factor.
Hierarchical factor structures represent the correlations between variables in terms of a smaller set of correlated factors which themselves can be represented by a higher order factor.
McDonald has proposed coefficient omega as an estimate of the general factor saturation of a test.  One way to find omega is to do a factor analysis of the original data set, rotate the factors obliquely, do a Schmid Leiman transformation, and then find omega. This function estimates omega as suggested by McDonald by using hierarchical factor analysis (following Jensen). A related option is to define the model using omega and then perform a confirmatory (bi-factor) analysis using the sem or lavaan packages.  This is done by omegaSem and omegaFromSem. omegaFromSem will convert appropriate sem/lavaan objects to find omega.  Yet another option is to do the direct Schmid-Leiman of Waller.
McDonald has proposed coefficient omega as an estimate of the general factor saturation of a test.  One way to find omega is to do a factor analysis of the original data set, rotate the factors obliquely, do a Schmid Leiman transformation, and then find omega. This function estimates omega as suggested by McDonald by using hierarchical factor analysis (following Jensen). A related option is to define the model using omega and then perform a confirmatory (bi-factor) analysis using the sem or lavaan packages.  This is done by omegaSem and omegaFromSem. omegaFromSem will convert appropriate sem/lavaan objects to find omega.  Yet another option is to do the direct Schmid-Leiman of Waller.
McDonald has proposed coefficient omega as an estimate of the general factor saturation of a test.  One way to find omega is to do a factor analysis of the original data set, rotate the factors obliquely, do a Schmid Leiman transformation, and then find omega. This function estimates omega as suggested by McDonald by using hierarchical factor analysis (following Jensen). A related option is to define the model using omega and then perform a confirmatory (bi-factor) analysis using the sem or lavaan packages.  This is done by omegaSem and omegaFromSem. omegaFromSem will convert appropriate sem/lavaan objects to find omega.  Yet another option is to do the direct Schmid-Leiman of Waller.
McDonald has proposed coefficient omega as an estimate of the general factor saturation of a test.  One way to find omega is to do a factor analysis of the original data set, rotate the factors obliquely, do a Schmid Leiman transformation, and then find omega. This function estimates omega as suggested by McDonald by using hierarchical factor analysis (following Jensen). A related option is to define the model using omega and then perform a confirmatory (bi-factor) analysis using the sem or lavaan packages.  This is done by omegaSem and omegaFromSem. omegaFromSem will convert appropriate sem/lavaan objects to find omega.  Yet another option is to do the direct Schmid-Leiman of Waller.
The Mahalanobis distance is D^2 = (x-μ)' Σ^-1 (x-μ) where Σ is the covariance of the x matrix.  D2 may be used as a way of detecting outliers in distribution.  Large D2 values, compared to the expected Chi Square values indicate an unusual response pattern.  The mahalanobis function in stats does not handle missing data.
The probability of replication of an experimental or correlational finding as discussed by Peter Killeen (2005) is the probability of finding an effect in the same direction upon an exact replication.  For articles submitted to Psychological Science, p.rep needs to be reported. 
The probability of replication of an experimental or correlational finding as discussed by Peter Killeen (2005) is the probability of finding an effect in the same direction upon an exact replication.  For articles submitted to Psychological Science, p.rep needs to be reported. 
The probability of replication of an experimental or correlational finding as discussed by Peter Killeen (2005) is the probability of finding an effect in the same direction upon an exact replication.  For articles submitted to Psychological Science, p.rep needs to be reported. 
The probability of replication of an experimental or correlational finding as discussed by Peter Killeen (2005) is the probability of finding an effect in the same direction upon an exact replication.  For articles submitted to Psychological Science, p.rep needs to be reported. 
   Test the difference between two (paired or unpaired) correlations. Given 3 variables, x, y, z,  is the correlation between xy different than that between xz?  If y and z are independent, this is a simple t-test of the z transformed rs.  But, if they are dependent, it is a bit more complicated. 
Adapted from the  help page for pairs, pairs.panels shows a scatter plot of matrices (SPLOM), with bivariate scatter plots below the diagonal, histograms on the diagonal, and the Pearson correlation above the diagonal. Useful for descriptive statistics of small data sets.  If lm=TRUE, linear regression fits are shown for both y by x and x by y.  Correlation ellipses are also shown. Points may be given different colors depending upon some grouping variable.  Robust fitting is done using lowess or loess regression. Confidence intervals of either the lm or loess are drawn if requested.
When doing cor(x, use= "pairwise"), it is nice to know the number of cases for each pairwise correlation.  This is particularly useful when doing SAPA type analyses. More importantly, when there are some missing pairs, it is useful to supply imputed values so that further analyses may be done.  This is useful if using the Massively Missing Completely at Random (MMCAR) designs used by the SAPA project.  The specific pairs missing may be identified by pairwiseZero.  Summaries of the counts are given by pairwiseDescribe.
When doing cor(x, use= "pairwise"), it is nice to know the number of cases for each pairwise correlation.  This is particularly useful when doing SAPA type analyses. More importantly, when there are some missing pairs, it is useful to supply imputed values so that further analyses may be done.  This is useful if using the Massively Missing Completely at Random (MMCAR) designs used by the SAPA project.  The specific pairs missing may be identified by pairwiseZero.  Summaries of the counts are given by pairwiseDescribe.
When doing cor(x, use= "pairwise"), it is nice to know the number of cases for each pairwise correlation.  This is particularly useful when doing SAPA type analyses. More importantly, when there are some missing pairs, it is useful to supply imputed values so that further analyses may be done.  This is useful if using the Massively Missing Completely at Random (MMCAR) designs used by the SAPA project.  The specific pairs missing may be identified by pairwiseZero.  Summaries of the counts are given by pairwiseDescribe.
When doing cor(x, use= "pairwise"), it is nice to know the number of cases for each pairwise correlation.  This is particularly useful when doing SAPA type analyses. More importantly, when there are some missing pairs, it is useful to supply imputed values so that further analyses may be done.  This is useful if using the Massively Missing Completely at Random (MMCAR) designs used by the SAPA project.  The specific pairs missing may be identified by pairwiseZero.  Summaries of the counts are given by pairwiseDescribe.
When doing cor(x, use= "pairwise"), it is nice to know the number of cases for each pairwise correlation.  This is particularly useful when doing SAPA type analyses. More importantly, when there are some missing pairs, it is useful to supply imputed values so that further analyses may be done.  This is useful if using the Massively Missing Completely at Random (MMCAR) designs used by the SAPA project.  The specific pairs missing may be identified by pairwiseZero.  Summaries of the counts are given by pairwiseDescribe.
When doing cor(x, use= "pairwise"), it is nice to know the number of cases for each pairwise correlation.  This is particularly useful when doing SAPA type analyses. More importantly, when there are some missing pairs, it is useful to supply imputed values so that further analyses may be done.  This is useful if using the Massively Missing Completely at Random (MMCAR) designs used by the SAPA project.  The specific pairs missing may be identified by pairwiseZero.  Summaries of the counts are given by pairwiseDescribe.
When doing cor(x, use= "pairwise"), it is nice to know the number of cases for each pairwise correlation.  This is particularly useful when doing SAPA type analyses. More importantly, when there are some missing pairs, it is useful to supply imputed values so that further analyses may be done.  This is useful if using the Massively Missing Completely at Random (MMCAR) designs used by the SAPA project.  The specific pairs missing may be identified by pairwiseZero.  Summaries of the counts are given by pairwiseDescribe.
When doing cor(x, use= "pairwise"), it is nice to know the number of cases for each pairwise correlation.  This is particularly useful when doing SAPA type analyses. More importantly, when there are some missing pairs, it is useful to supply imputed values so that further analyses may be done.  This is useful if using the Massively Missing Completely at Random (MMCAR) designs used by the SAPA project.  The specific pairs missing may be identified by pairwiseZero.  Summaries of the counts are given by pairwiseDescribe.
Given a set of n items, form n/2 or n/3 mini scales or parcels of the most similar pairs or triplets of items.  These may be used as the basis for subsequent scale construction or multivariate (e.g., factor) analysis.
A straightforward application of matrix algebra to remove the effect of the variables in the y set from the x set. Input may be either a data matrix or a correlation matrix.  Variables in x and y are specified by location.  If x and y are not specified, then the effect of all variables are partialled from all the other correlations.  May also be done using formula input which is more convenient when comparing results to regression models
Does an eigen value decomposition and returns eigen values, loadings, and degree of fit for a specified number of components.  Basically it is just  doing a principal components analysis (PCA) for n principal components of either a correlation or covariance matrix.  Can show the residual correlations as well. The quality of reduction in the squared correlations is reported by comparing residual correlations to original correlations. Unlike princomp, this returns a subset of just the best nfactors. The eigen vectors are rescaled by the sqrt of the eigen values to produce the component loadings more typical in factor analysis.
Given a 1 x 4 vector or a 2 x 2 matrix of frequencies, find the phi coefficient of correlation.  Typical use is in the case of predicting a dichotomous criterion from a dichotomous predictor.
A not very interesting demo of what happens if bivariate continuous data are dichotomized.  Bascially a demo of r, phi, and polychor.  
When creating a structural diagram or a structural model, it is convenient to not have to specify all of the zero loadings in a structural matrix.  structure.list converts list input into a design matrix.  phi.list does the same for a correlation matrix. Factors with NULL values are filled with 0s.
Given a phi coefficient (a Pearson r calculated on two dichotomous variables), and the marginal frequencies (in percentages), what is the corresponding estimate of the tetrachoric correlation?
A set of deprecated functions that have replaced by Yule2tetra and Yule2phi. 
Given a phi coefficient (a Pearson r calculated on two dichotomous variables), and the marginal frequencies (in percentages), what is the corresponding estimate of the tetrachoric correlation?
Given a matrix of less than full rank, the conventional inverse function will fail.  The pseudoinverse or generalized inverse resolves this problem by using just the postive  values of the singular value decomposition d matrix. An adaptation of the ginv function from MASS and the pinv function from pracma. 
Combines several plotting functions into one for objects of class “psych".  This can be used to plot the results of fa, irt.fa, VSS, ICLUST, omega, factor.pa, or principal. 
Combines several plotting functions into one for objects of class “psych".  This can be used to plot the results of fa, irt.fa, VSS, ICLUST, omega, factor.pa, or principal. 
One way to determine the number of factors or components in a data matrix or a correlation matrix is to examine the “scree" plot of the successive eigenvalues.  Sharp breaks in the plot suggest the appropriate number of components or factors to extract.  “Parallel" analyis is an alternative technique that compares the scree of factors of the observed data with that of a random data matrix of the same size as the original. This may be done for continuous , dichotomous, or polytomous data using Pearson, tetrachoric or polychoric correlations.
Combines several plotting functions into one for objects of class “psych".  This can be used to plot the results of fa, irt.fa, VSS, ICLUST, omega, factor.pa, or principal. 
Revelle and Condon, (2019) reviewed the problem of reliability in a tutorial meant to useful to the theoretician as well as the practitioner.  Although there are a number of functions in psych for estimating reliability of single scales, (e.g. alpha and omega), for split half reliability splitHalf or for finding test-retest reliability testRetest or multilevel reliability mlr, the reliability function  combines several of these functions to report these recommended measures for multiple scales. 
Combines several plotting functions into one for objects of class “psych".  This can be used to plot the results of fa, irt.fa, VSS, ICLUST, omega, factor.pa, or principal. 
Factor and cluster analysis output typically presents item by factor correlations (loadings).  Tables of factor loadings are frequently sorted by the size of loadings.  This style of presentation tends to make it difficult to notice the pattern of loadings on other, secondary, dimensions.  By converting to polar coordinates, it is easier to see the pattern of the secondary loadings. 
The tetrachoric correlation is the inferred Pearson Correlation from a two x two table with the assumption of bivariate normality. The polychoric correlation generalizes this to the n x m table. Particularly important when doing Item Response Theory or converting comorbidity statistics using normal theory to correlations. Input may be a 2 x 2 table of cell frequencies, a vector of cell frequencies, or a data.frame or matrix of dichotomous data (for tetrachoric) or of numeric data (for polychoric).The biserial correlation is between a continuous y variable and a dichotmous x variable, which is assumed to have resulted from a dichotomized normal variable. Biserial is a special case of the polyserial correlation, which is the inferred latent correlation between a continuous variable (X) and a ordered categorical variable (e.g., an item response). Input for these later two are data frames or matrices.  Requires the mnormt package.
The tetrachoric correlation is the inferred Pearson Correlation from a two x two table with the assumption of bivariate normality. The polychoric correlation generalizes this to the n x m table. Particularly important when doing Item Response Theory or converting comorbidity statistics using normal theory to correlations. Input may be a 2 x 2 table of cell frequencies, a vector of cell frequencies, or a data.frame or matrix of dichotomous data (for tetrachoric) or of numeric data (for polychoric).The biserial correlation is between a continuous y variable and a dichotmous x variable, which is assumed to have resulted from a dichotomized normal variable. Biserial is a special case of the polyserial correlation, which is the inferred latent correlation between a continuous variable (X) and a ordered categorical variable (e.g., an item response). Input for these later two are data frames or matrices.  Requires the mnormt package.
The tetrachoric correlation is the inferred Pearson Correlation from a two x two table with the assumption of bivariate normality. The polychoric correlation generalizes this to the n x m table. Particularly important when doing Item Response Theory or converting comorbidity statistics using normal theory to correlations. Input may be a 2 x 2 table of cell frequencies, a vector of cell frequencies, or a data.frame or matrix of dichotomous data (for tetrachoric) or of numeric data (for polychoric).The biserial correlation is between a continuous y variable and a dichotmous x variable, which is assumed to have resulted from a dichotomized normal variable. Biserial is a special case of the polyserial correlation, which is the inferred latent correlation between a continuous variable (X) and a ordered categorical variable (e.g., an item response). Input for these later two are data frames or matrices.  Requires the mnormt package.
The tetrachoric correlation is the inferred Pearson Correlation from a two x two table with the assumption of bivariate normality. The polychoric correlation generalizes this to the n x m table. Particularly important when doing Item Response Theory or converting comorbidity statistics using normal theory to correlations. Input may be a 2 x 2 table of cell frequencies, a vector of cell frequencies, or a data.frame or matrix of dichotomous data (for tetrachoric) or of numeric data (for polychoric).The biserial correlation is between a continuous y variable and a dichotmous x variable, which is assumed to have resulted from a dichotomized normal variable. Biserial is a special case of the polyserial correlation, which is the inferred latent correlation between a continuous variable (X) and a ordered categorical variable (e.g., an item response). Input for these later two are data frames or matrices.  Requires the mnormt package.
Finds predicted factor/component scores from a factor analysis or principal components analysis (pca) of data set A predicted to data set B.  Predicted factor scores use the weights matrix used to find estimated factor scores, predicted components use the loadings matrix. Scores are either standardized with respect to the prediction sample or based upon the original data. Predicted scores from a bestScales model are based upon the statistics from the original sample.
The validity of a scale varies as a function of the number of items in the scale, their average intercorrelation, and their average validity. The asymptotic limit of a scales validity for any particular criterion is just the average validity divided by the square root of the average within scale item correlation.  predicted.validity will find the predicted validity for a set of scales (defined by a keys.list) and the average item validity for various criteria.  
Does an eigen value decomposition and returns eigen values, loadings, and degree of fit for a specified number of components.  Basically it is just  doing a principal components analysis (PCA) for n principal components of either a correlation or covariance matrix.  Can show the residual correlations as well. The quality of reduction in the squared correlations is reported by comparing residual correlations to original correlations. Unlike princomp, this returns a subset of just the best nfactors. The eigen vectors are rescaled by the sqrt of the eigen values to produce the component loadings more typical in factor analysis.
Give limited output (print) or somewhat more detailed (summary) for most of the functions in psych. 
The bifactor rotation implements the rotation introduced by Jennrich and Bentler (2011) by calling GPForth in the GPArotation package.  promax is an oblique rotation function introduced by Hendrickson and White (1964) and implemented in the promax function in the stats package.  Unfortunately, promax does not report the inter factor correlations.  Promax does.  TargetQ does a target rotation with elements that can be missing (NA), or numeric (e.g., 0, 1).  It uses the GPArotation package. target.rot does general target rotations to an arbitrary target matrix. The default target rotation is for an independent cluster solution. equamax facilitates the call to GPArotation to do an equamax rotation.  Equamax, although available as a specific option within GPArotation is easier to call by name if using equamax.  The varimin rotation suggested by Ertl (2013) is implemented by appropriate calls to GPArotation.
This is a set of minor, if not trivial, helper functions.lowerCor finds the correlation of x variables and then prints them using lowerMat which is a trivial, but useful, function to round off and print the lower triangle of a matrix.reflect reflects the output of a factor analysis or principal components analysis so that one or more factors is reflected. (Requested by Alexander Weiss.)progressBar prints out ...  as a calling routine (e.g., tetrachoric) works through a tedious calculation.  shannon finds the Shannon index (H) of diversity or of information. test.all tests all the examples in a package.  best.items sorts a factor matrix for absolute values and displays the expanded items names. fa.lookup returns sorted factor analysis output with item labels. cor2 correlates two data.frames (of equal length). levels2numeric and char2numeric convert dataframe columns that are categorical/levels to numeric values. 
The bifactor rotation implements the rotation introduced by Jennrich and Bentler (2011) by calling GPForth in the GPArotation package.  promax is an oblique rotation function introduced by Hendrickson and White (1964) and implemented in the promax function in the stats package.  Unfortunately, promax does not report the inter factor correlations.  Promax does.  TargetQ does a target rotation with elements that can be missing (NA), or numeric (e.g., 0, 1).  It uses the GPArotation package. target.rot does general target rotations to an arbitrary target matrix. The default target rotation is for an independent cluster solution. equamax facilitates the call to GPArotation to do an equamax rotation.  Equamax, although available as a specific option within GPArotation is easier to call by name if using equamax.  The varimin rotation suggested by Ertl (2013) is implemented by appropriate calls to GPArotation.
Overview of the psych package.
This is a set of minor, if not trivial, helper functions.lowerCor finds the correlation of x variables and then prints them using lowerMat which is a trivial, but useful, function to round off and print the lower triangle of a matrix.reflect reflects the output of a factor analysis or principal components analysis so that one or more factors is reflected. (Requested by Alexander Weiss.)progressBar prints out ...  as a calling routine (e.g., tetrachoric) works through a tedious calculation.  shannon finds the Shannon index (H) of diversity or of information. test.all tests all the examples in a package.  best.items sorts a factor matrix for absolute values and displays the expanded items names. fa.lookup returns sorted factor analysis output with item labels. cor2 correlates two data.frames (of equal length). levels2numeric and char2numeric convert dataframe columns that are categorical/levels to numeric values. 
A quick way to show the first and last n lines of a data.frame, matrix, or a text object.  Just a pretty call to head and tail or View
Convert a correlation to a z or t, or d, or chi or covariance matrixor z to r using the Fisher transformation or find the confidence intervals for a specified correlation.  r2d converts a correlation to an effect size (Cohen's d) and d2r converts a d into an r. g2r converts Hedge's g to a correlation.   t2r converts a t test to r, r2t converts a correlation to a t-test value. chi2r converts a chi square to r, r2chi converts it back.  r2c and cor2cov convert a correlation matrix to a covariance matrix. d2t and t2d convert cohen's d into a t and a t into a cohen d.  See cohen.d for other conversions.
Tests the significance of a single correlation, the difference between two independent correlations, the difference between two dependent correlations sharing one variable (Williams's Test), or the difference between two dependent correlations with different variables (Steiger Tests).
Convert a correlation to a z or t, or d, or chi or covariance matrixor z to r using the Fisher transformation or find the confidence intervals for a specified correlation.  r2d converts a correlation to an effect size (Cohen's d) and d2r converts a d into an r. g2r converts Hedge's g to a correlation.   t2r converts a t test to r, r2t converts a correlation to a t-test value. chi2r converts a chi square to r, r2chi converts it back.  r2c and cor2cov convert a correlation matrix to a covariance matrix. d2t and t2d convert cohen's d into a t and a t into a cohen d.  See cohen.d for other conversions.
Convert a correlation to a z or t, or d, or chi or covariance matrixor z to r using the Fisher transformation or find the confidence intervals for a specified correlation.  r2d converts a correlation to an effect size (Cohen's d) and d2r converts a d into an r. g2r converts Hedge's g to a correlation.   t2r converts a t test to r, r2t converts a correlation to a t-test value. chi2r converts a chi square to r, r2chi converts it back.  r2c and cor2cov convert a correlation matrix to a covariance matrix. d2t and t2d convert cohen's d into a t and a t into a cohen d.  See cohen.d for other conversions.
Given a data.frame or matrix, find the standardized mean difference (Cohen's d) and confidence intervals for each variable depending upon a grouping variable.  Convert the d statistic to the r equivalent, report the student's t statistic and associated p values, and return statistics for both values of the grouping variable.  The Mahalanobis distance between the centroids of the two groups in the space defined by all the variables ia also found.  Confidence intervals for Cohen d for one group (difference from 0) may also be found. Several measures of the distributional overlap (e.g. OVL, OVL2, etc.) are available.
Convert a correlation to a z or t, or d, or chi or covariance matrixor z to r using the Fisher transformation or find the confidence intervals for a specified correlation.  r2d converts a correlation to an effect size (Cohen's d) and d2r converts a d into an r. g2r converts Hedge's g to a correlation.   t2r converts a t test to r, r2t converts a correlation to a t-test value. chi2r converts a chi square to r, r2chi converts it back.  r2c and cor2cov convert a correlation matrix to a covariance matrix. d2t and t2d convert cohen's d into a t and a t into a cohen d.  See cohen.d for other conversions.
Radar plots and spider plots are just two of the many ways to show multivariate data.  radar  plots correlations as vectors ranging in length from 0 (corresponding to r=-1) to 1 (corresponding to an r=1).  The vectors are arranged radially around a circle. Spider plots connect the end points of each vector. The plots are most appropriate if the variables are organized in some meaningful manner. 
In applied settings, it is typical to find a correlation between a predictor and some criterion.  Unfortunately, if the predictor is used to choose the subjects, the range of the predictor is seriously reduced.  This restricts the observed correlation to be less than would be observed in the full range of the predictor.  A correction for this problem is well known as Thorndike Case 2:
This is a set of minor, if not trivial, helper functions.lowerCor finds the correlation of x variables and then prints them using lowerMat which is a trivial, but useful, function to round off and print the lower triangle of a matrix.reflect reflects the output of a factor analysis or principal components analysis so that one or more factors is reflected. (Requested by Alexander Weiss.)progressBar prints out ...  as a calling routine (e.g., tetrachoric) works through a tedious calculation.  shannon finds the Shannon index (H) of diversity or of information. test.all tests all the examples in a package.  best.items sorts a factor matrix for absolute values and displays the expanded items names. fa.lookup returns sorted factor analysis output with item labels. cor2 correlates two data.frames (of equal length). levels2numeric and char2numeric convert dataframe columns that are categorical/levels to numeric values. 
Holzinger-Swineford (1937) introduced the bifactor model of a general factor and uncorrelated group factors. The Holzinger data sets are   original 14 * 14 matrix from their paper as well as a 9 *9 matrix used as an example by Joreskog. The Thurstone correlation matrix is a 9 * 9 matrix of correlations of ability items.  The Reise data set is 16 * 16 correlation matrix of mental health items. The Bechtholdt data sets are both 17 x 17 correlation matrices of ability tests.  
Revelle and Condon, (2019) reviewed the problem of reliability in a tutorial meant to useful to the theoretician as well as the practitioner.  Although there are a number of functions in psych for estimating reliability of single scales, (e.g. alpha and omega), for split half reliability splitHalf or for finding test-retest reliability testRetest or multilevel reliability mlr, the reliability function  combines several of these functions to report these recommended measures for multiple scales. 
Psychologists frequently report data in terms of transformed scales such as “IQ" (mean=100, sd=15, “SAT/GRE" (mean=500, sd=100), “ACT" (mean=18, sd=6), “T-scores" (mean=50, sd=10), or “Stanines" (mean=5, sd=2). The rescale function converts the data to standard scores and then rescales to the specified mean(s) and standard deviation(s). 
Residuals in the various psych functions are extracted and then may be "pretty" printed.
Residuals in the various psych functions are extracted and then may be "pretty" printed.
Given a data.frame or matrix of n items and N observations and a list of the direction to score them (a keys.list with k keys)  find the sum scores or average scores for each person and each scale.  In addition, report Cronbach's alpha, Guttman's Lambda 6,  the average r, the scale intercorrelations, and the item by scale correlations (raw and corrected for item overlap).  Replace missing values with the item median or mean if desired. Items may be keyed 1 (score it), -1 ) (reverse score it), or 0 (do not score it). Negatively keyed items will be reverse scored.  Although prior versions used a keys matrix, it is now recommended to just use a list of scoring keys. See make.keys for a convenient way to make the keys file.  If the input is a square matrix, then it is assumed that the input is a covariance or correlation matix and scores are not found, but the item statistics are reported. (Similar functionality to cluster.cor). response.frequencies reports the frequency of item endorsements fore each response category for polytomous or multiple choice items. scoreFast and   scoreVeryFast just find sums/mean scores and do not report reliabilities.  Much faster for large data sets.
Given a data.frame or matrix of n items and N observations and a list of the direction to score them (a keys.list with k keys)  find the sum scores or average scores for each person and each scale.  In addition, report Cronbach's alpha, Guttman's Lambda 6,  the average r, the scale intercorrelations, and the item by scale correlations (raw and corrected for item overlap).  Replace missing values with the item median or mean if desired. Items may be keyed 1 (score it), -1 ) (reverse score it), or 0 (do not score it). Negatively keyed items will be reverse scored.  Although prior versions used a keys matrix, it is now recommended to just use a list of scoring keys. See make.keys for a convenient way to make the keys file.  If the input is a square matrix, then it is assumed that the input is a covariance or correlation matix and scores are not found, but the item statistics are reported. (Similar functionality to cluster.cor). response.frequencies reports the frequency of item endorsements fore each response category for polytomous or multiple choice items. scoreFast and   scoreVeryFast just find sums/mean scores and do not report reliabilities.  Much faster for large data sets.
Some IRT functions require all items to be coded in the same direction.  Some data sets have items that need to be reverse coded (e.g., 6 -> 1, 1 -> 6).  reverse.code will flip items based upon a keys vector of 1s and -1s.  Reversed items are subtracted from the item max + item min.  These may be specified or may be calculated.
Von Neuman et al. (1941) discussed the Mean Square of Successive Differences as a measure of variability that takes into account gradual shifts in mean. This is appropriate when studying errors in ballistics or variability and stability in mood when studying affect. For random data, this will be twice the variance, but for data with a sequential order and a positive autocorrelation, this will be much smaller. Since the mssd is just twice the variance - the autocorrelation, it is thus possible to also find the autocorrelation for a particular lag. 
Self reported scores on the SAT Verbal, SAT Quantitative and ACT   were collected as part of the Synthetic Aperture Personality Assessment (SAPA) web based personality assessment project.  Age, gender, and education are also reported. The data from 700 subjects are included here as a demonstration set for correlation and analysis.
Given a matrix of choices and a vector of scale values, how well do the scale values capture the choices?  That is, what is size of the squared residuals given the model versus the size of the squared choice values?
Draw a X Y scatter plot with associated X and Y histograms with estimated densities.  Will also draw density plots by groups, as well as distribution ellipses by group. Partly a demonstration of the use of layout. Also includes lowess smooth or linear model slope, as well as correlation. 
Draw a X Y scatter plot with associated X and Y histograms with estimated densities.  Will also draw density plots by groups, as well as distribution ellipses by group. Partly a demonstration of the use of layout. Also includes lowess smooth or linear model slope, as well as correlation. 
One way to find omega is to do a factor analysis of the original data set, rotate the factors obliquely, do a Schmid Leiman transformation, and then find omega. Here is the code for Schmid Leiman.  The S-L transform takes a factor or PC solution, transforms it to an oblique solution, factors the oblique solution to find a higher order (g ) factor, and then residualizes g out of the the group factors.
John Schmid and John M. Leiman (1957) discuss how to transform a hierarchical factor structure to a bifactor structure. Schmid contains the example 12 x 12 correlation matrix. schmid.leiman is a 12 x 12 correlation matrix with communalities on the diagonal. This can be used to show the effect of correcting for attenuation. Two additional data sets are taken from Chen et al. (2006).
John Schmid and John M. Leiman (1957) discuss how to transform a hierarchical factor structure to a bifactor structure. Schmid contains the example 12 x 12 correlation matrix. schmid.leiman is a 12 x 12 correlation matrix with communalities on the diagonal. This can be used to show the effect of correcting for attenuation. Two additional data sets are taken from Chen et al. (2006).
Given a matrix or data.frame of k keys for m items (-1, 0, 1), and a matrix or data.frame of items scores for m items and n people, find the sum scores or average scores for each person and each scale.  In addition, report Cronbach's alpha, the average r, the scale intercorrelations, and the item by scale correlations.  (Superseded by  score.items). 
irt.fa finds Item Response Theory (IRT) parameters through factor analysis of the tetrachoric or polychoric correlations of dichtomous or polytomous items. scoreIrt uses these parameter estimates of discrimination and location to find IRT based scores for the responses. As many factors as found for the correlation matrix will be scored. scoreIrt.2pl will score lists of scales.
irt.fa finds Item Response Theory (IRT) parameters through factor analysis of the tetrachoric or polychoric correlations of dichtomous or polytomous items. scoreIrt uses these parameter estimates of discrimination and location to find IRT based scores for the responses. As many factors as found for the correlation matrix will be scored. scoreIrt.2pl will score lists of scales.
irt.fa finds Item Response Theory (IRT) parameters through factor analysis of the tetrachoric or polychoric correlations of dichtomous or polytomous items. scoreIrt uses these parameter estimates of discrimination and location to find IRT based scores for the responses. As many factors as found for the correlation matrix will be scored. scoreIrt.2pl will score lists of scales.
Given a data.frame or matrix of n items and N observations and a list of the direction to score them (a keys.list with k keys)  find the sum scores or average scores for each person and each scale.  In addition, report Cronbach's alpha, Guttman's Lambda 6,  the average r, the scale intercorrelations, and the item by scale correlations (raw and corrected for item overlap).  Replace missing values with the item median or mean if desired. Items may be keyed 1 (score it), -1 ) (reverse score it), or 0 (do not score it). Negatively keyed items will be reverse scored.  Although prior versions used a keys matrix, it is now recommended to just use a list of scoring keys. See make.keys for a convenient way to make the keys file.  If the input is a square matrix, then it is assumed that the input is a covariance or correlation matix and scores are not found, but the item statistics are reported. (Similar functionality to cluster.cor). response.frequencies reports the frequency of item endorsements fore each response category for polytomous or multiple choice items. scoreFast and   scoreVeryFast just find sums/mean scores and do not report reliabilities.  Much faster for large data sets.
Ability tests are typically multiple choice with one right answer.  score.multiple.choice takes a scoring key and a data matrix (or data.frame) and finds total or average number right for each participant.  Basic test statistics (alpha, average r, item means, item-whole correlations) are also reported. 
Given a  n x c cluster definition matrix of -1s, 0s, and 1s (the keys) , and a n x n correlation matrix, or an N x n data matrix, find the correlations of the composite clusters.  The keys matrix can be entered by hand, copied from the clipboard (read.clipboard), or taken as output from the factor2cluster or make.keys functions.  Similar functionality to scoreItems which also gives item by cluster correlations. scoreBy does this for individual subjects after a call to statsBy.
Given a data.frame or matrix of n items and N observations and a list of the direction to score them (a keys.list with k keys)  find the sum scores or average scores for each person and each scale.  In addition, report Cronbach's alpha, Guttman's Lambda 6,  the average r, the scale intercorrelations, and the item by scale correlations (raw and corrected for item overlap).  Replace missing values with the item median or mean if desired. Items may be keyed 1 (score it), -1 ) (reverse score it), or 0 (do not score it). Negatively keyed items will be reverse scored.  Although prior versions used a keys matrix, it is now recommended to just use a list of scoring keys. See make.keys for a convenient way to make the keys file.  If the input is a square matrix, then it is assumed that the input is a covariance or correlation matix and scores are not found, but the item statistics are reported. (Similar functionality to cluster.cor). response.frequencies reports the frequency of item endorsements fore each response category for polytomous or multiple choice items. scoreFast and   scoreVeryFast just find sums/mean scores and do not report reliabilities.  Much faster for large data sets.
irt.fa finds Item Response Theory (IRT) parameters through factor analysis of the tetrachoric or polychoric correlations of dichtomous or polytomous items. scoreIrt uses these parameter estimates of discrimination and location to find IRT based scores for the responses. As many factors as found for the correlation matrix will be scored. scoreIrt.2pl will score lists of scales.
irt.fa finds Item Response Theory (IRT) parameters through factor analysis of the tetrachoric or polychoric correlations of dichtomous or polytomous items. scoreIrt uses these parameter estimates of discrimination and location to find IRT based scores for the responses. As many factors as found for the correlation matrix will be scored. scoreIrt.2pl will score lists of scales.
irt.fa finds Item Response Theory (IRT) parameters through factor analysis of the tetrachoric or polychoric correlations of dichtomous or polytomous items. scoreIrt uses these parameter estimates of discrimination and location to find IRT based scores for the responses. As many factors as found for the correlation matrix will be scored. scoreIrt.2pl will score lists of scales.
Given a data.frame or matrix of n items and N observations and a list of the direction to score them (a keys.list with k keys)  find the sum scores or average scores for each person and each scale.  In addition, report Cronbach's alpha, Guttman's Lambda 6,  the average r, the scale intercorrelations, and the item by scale correlations (raw and corrected for item overlap).  Replace missing values with the item median or mean if desired. Items may be keyed 1 (score it), -1 ) (reverse score it), or 0 (do not score it). Negatively keyed items will be reverse scored.  Although prior versions used a keys matrix, it is now recommended to just use a list of scoring keys. See make.keys for a convenient way to make the keys file.  If the input is a square matrix, then it is assumed that the input is a covariance or correlation matix and scores are not found, but the item statistics are reported. (Similar functionality to cluster.cor). response.frequencies reports the frequency of item endorsements fore each response category for polytomous or multiple choice items. scoreFast and   scoreVeryFast just find sums/mean scores and do not report reliabilities.  Much faster for large data sets.
Given a  n x c cluster definition matrix of -1s, 0s, and 1s (the keys) , and a n x n correlation matrix, or an N x n data matrix, find the correlations of the composite clusters.  The keys matrix can be entered by hand, copied from the clipboard (read.clipboard), or taken as output from the factor2cluster or make.keys functions.  Similar functionality to scoreItems which also gives item by cluster correlations. scoreBy does this for individual subjects after a call to statsBy.
Given a data.frame or matrix of n items and N observations and a list of the direction to score them (a keys.list with k keys)  find the sum scores or average scores for each person and each scale.  In addition, report Cronbach's alpha, Guttman's Lambda 6,  the average r, the scale intercorrelations, and the item by scale correlations (raw and corrected for item overlap).  Replace missing values with the item median or mean if desired. Items may be keyed 1 (score it), -1 ) (reverse score it), or 0 (do not score it). Negatively keyed items will be reverse scored.  Although prior versions used a keys matrix, it is now recommended to just use a list of scoring keys. See make.keys for a convenient way to make the keys file.  If the input is a square matrix, then it is assumed that the input is a covariance or correlation matix and scores are not found, but the item statistics are reported. (Similar functionality to cluster.cor). response.frequencies reports the frequency of item endorsements fore each response category for polytomous or multiple choice items. scoreFast and   scoreVeryFast just find sums/mean scores and do not report reliabilities.  Much faster for large data sets.
Item weights from bestScales or setCor are used to find weighted scale scores. In contrast to the unit weights used in scoreItems, scoreWtd will multiply the data by a set of weights to find scale scores.  These weight may come from a regression (e.g., lm or setCor) or may be the zero order correlation weights from bestScales.
Cattell's scree test is one of most simple ways of testing the number of components or factors in  a correlation matrix. Here we plot the  eigen values of a correlation matrix as well as the eigen values of a factor analysis.
A tedious part of data analysis is addressing the problem of miscoded data that need to be converted to NA or some other value.  For a given data.frame or matrix, scrub will set all values of columns from=from to to=to that are less than a set (vector) of min values or more than a vector of max values to NA. Can also be used to do basic recoding of data for all values=isvalue to newvalue. Will also recode continuus variables into fewer categories.  Will convert Nan, -Inf and Inf to NA
Find the standard deviation of a vector, matrix, or data.frame.  In the latter two cases, return the sd of each column.  Unlike the sd function, return NA if there are no observations rather than throw an error.
 When scoring items by forming composite scales either from the raw data using scoreItems or from the correlation matrix using cluster.cor, it used to be  necessary to create a keys matrix. This is no longer necessary as most of the scoring functions will directly use a keys list. make.keys  is just a short cut for creating a keys matrix.  The keys matrix is a nvar x nscales matrix of -1,0, 1 and defines the membership for each scale. Items can be specified by location or by name.
Graphic presentations of structural equation models are a very useful way to conceptualize sem and confirmatory factor models. Given a measurement model on x (xmodel) and on y (ymodel) as well as a path model connecting x and y (phi), draw the graph.  If the ymodel is not specified, just draw the measurement model (xmodel + phi). If the Rx or Ry matrices are specified, show the correlations between the x variables, or y variables.
Graphic presentations of structural equation models are a very useful way to conceptualize sem and confirmatory factor models. Given a measurement model on x (xmodel) and on y (ymodel) as well as a path model connecting x and y (phi), draw the graph.  If the ymodel is not specified, just draw the measurement model (xmodel + phi). If the Rx or Ry matrices are specified, show the correlations between the x variables, or y variables.
Given a correlation matrix or a  matrix or dataframe of raw data, find the multiple regressions and draw a path diagram relating a set of y variables as a function of a set of x variables.  A set of covariates (z) can be partialled from the x and y sets. Regression diagrams are automatically included.   Model can be specified in conventional formula form, or in terms of x variables and y variables.  Multiplicative models (interactions) and quadratic terms may be specified in the formula mode if using raw data. By default, the data may be  zero centered before finding the interactions.  Will also find Cohen's Set Correlation between a predictor set of variables (x) and a criterion set (y). Also finds the canonical correlations between the x and y sets.
Given a correlation matrix or a  matrix or dataframe of raw data, find the multiple regressions and draw a path diagram relating a set of y variables as a function of a set of x variables.  A set of covariates (z) can be partialled from the x and y sets. Regression diagrams are automatically included.   Model can be specified in conventional formula form, or in terms of x variables and y variables.  Multiplicative models (interactions) and quadratic terms may be specified in the formula mode if using raw data. By default, the data may be  zero centered before finding the interactions.  Will also find Cohen's Set Correlation between a predictor set of variables (x) and a criterion set (y). Also finds the canonical correlations between the x and y sets.
Given a correlation matrix or a  matrix or dataframe of raw data, find the multiple regressions and draw a path diagram relating a set of y variables as a function of a set of x variables.  A set of covariates (z) can be partialled from the x and y sets. Regression diagrams are automatically included.   Model can be specified in conventional formula form, or in terms of x variables and y variables.  Multiplicative models (interactions) and quadratic terms may be specified in the formula mode if using raw data. By default, the data may be  zero centered before finding the interactions.  Will also find Cohen's Set Correlation between a predictor set of variables (x) and a criterion set (y). Also finds the canonical correlations between the x and y sets.
 When constructing scales through rational, factorial, or empirical means, it is useful to examine the content of the items that relate most highly to each other (e.g., the factor loadings of fa.lookup of a set of items) , or to some specific set of criteria  (e.g., bestScales). Given a dictionary of item content, these routines will sort by factor loading or criteria correlations and display the item content. 
This is a set of minor, if not trivial, helper functions.lowerCor finds the correlation of x variables and then prints them using lowerMat which is a trivial, but useful, function to round off and print the lower triangle of a matrix.reflect reflects the output of a factor analysis or principal components analysis so that one or more factors is reflected. (Requested by Alexander Weiss.)progressBar prints out ...  as a calling routine (e.g., tetrachoric) works through a tedious calculation.  shannon finds the Shannon index (H) of diversity or of information. test.all tests all the examples in a package.  best.items sorts a factor matrix for absolute values and displays the expanded items names. fa.lookup returns sorted factor analysis output with item labels. cor2 correlates two data.frames (of equal length). levels2numeric and char2numeric convert dataframe columns that are categorical/levels to numeric values. 
A number of functions in the psych package will generate simulated data with particular structures.  These functions includesim for a factor simplex, and sim.simplex for a data simplex, sim.circ for a circumplex structure, sim.congeneric for a one factor factor congeneric model, sim.dichot to simulate dichotomous items, sim.hierarchical to create a hierarchical factor model, sim.item a more general item simulation,sim.minor to simulate major and minor factors,sim.omega to test various examples of omega,sim.parallel to compare the efficiency of various ways of deterimining the number of factors.   See the help pages for some more simulation functions here: sim.rasch to create simulated rasch data, sim.irt to create general 1 to 4 parameter IRT data by calling sim.npl 1 to 4 parameter logistic IRT or sim.npn 1 to 4 paramater normal IRT,sim.poly to create polytomous ideas by callingsim.poly.npn 1-4 parameter polytomous normal theory items orsim.poly.npl 1-4 parameter polytomous logistic items, and sim.poly.ideal which creates data following an ideal point or unfolding model by calling sim.poly.ideal.npn 1-4 parameter polytomous normal theory ideal point model or sim.poly.ideal.npl 1-4 parameter polytomous logistic ideal point model.
For teaching basic statistics, it is useful to be able to generate examples suitable for analysis of variance or simple linear models.  sim.anova will generate the design matrix of three independent variables (IV1, IV2, IV3) with an arbitrary number of levels and effect sizes for each main effect and interaction.  IVs can be either continuous or categorical and can have linear or quadratic effects. Either a single dependent variable or multiple (within subject) dependent variables are generated according to the specified model. The repeated measures are assumed to be tau equivalent with a specified reliability.
Create a population orthogonal or hierarchical correlation matrix from a set of factor loadings and factor intercorrelations. Samples of size n may be then be drawn from this population.  Return either the sample data, sample correlations, or population correlations.  This is used to create sample data sets for instruction and demonstration.
Rotations of factor analysis and principal components analysis solutions typically try to represent correlation matrices as simple structured.  An alternative structure, appealing to some, is a circumplex structure where the variables are uniformly spaced on the perimeter of a circle in a two dimensional space.  Generating simple structure and circumplex data is straightforward, and is useful for exploring alternative solutions to affect and personality structure. A generalization to 3 dimensional (spherical) data is straightforward.
Classical Test Theory (CTT) considers four or more tests to be congenerically equivalent if all tests may be expressed in terms of one factor and a residual error.  Parallel tests are the special case where (usually two) tests have equal factor loadings.  Tau equivalent tests have equal factor loadings but may have unequal errors.  Congeneric tests may differ in both factor loading and error variances.
Structural Equation Models decompose correlation or correlation matrices into a measurement (factor) model and a structural (regression) model.  sim.structural creates data sets with known measurement and structural properties. Population or sample correlation matrices with known properties are generated. Optionally raw data are produced. 
Rotations of factor analysis and principal components analysis solutions typically try to represent correlation matrices as simple structured.  An alternative structure, appealing to some, is a circumplex structure where the variables are uniformly spaced on the perimeter of a circle in a two dimensional space.  Generating simple structure and circumplex data is straightforward, and is useful for exploring alternative solutions to affect and personality structure. A generalization to 3 dimensional (spherical) data is straightforward.
A number of functions in the psych package will generate simulated data with particular structures.  These functions includesim for a factor simplex, and sim.simplex for a data simplex, sim.circ for a circumplex structure, sim.congeneric for a one factor factor congeneric model, sim.dichot to simulate dichotomous items, sim.hierarchical to create a hierarchical factor model, sim.item a more general item simulation,sim.minor to simulate major and minor factors,sim.omega to test various examples of omega,sim.parallel to compare the efficiency of various ways of deterimining the number of factors.   See the help pages for some more simulation functions here: sim.rasch to create simulated rasch data, sim.irt to create general 1 to 4 parameter IRT data by calling sim.npl 1 to 4 parameter logistic IRT or sim.npn 1 to 4 paramater normal IRT,sim.poly to create polytomous ideas by callingsim.poly.npn 1-4 parameter polytomous normal theory items orsim.poly.npl 1-4 parameter polytomous logistic items, and sim.poly.ideal which creates data following an ideal point or unfolding model by calling sim.poly.ideal.npn 1-4 parameter polytomous normal theory ideal point model or sim.poly.ideal.npl 1-4 parameter polytomous logistic ideal point model.
Create a population orthogonal or hierarchical correlation matrix from a set of factor loadings and factor intercorrelations. Samples of size n may be then be drawn from this population.  Return either the sample data, sample correlations, or population correlations.  This is used to create sample data sets for instruction and demonstration.
A number of functions in the psych package will generate simulated data with particular structures.  These functions includesim for a factor simplex, and sim.simplex for a data simplex, sim.circ for a circumplex structure, sim.congeneric for a one factor factor congeneric model, sim.dichot to simulate dichotomous items, sim.hierarchical to create a hierarchical factor model, sim.item a more general item simulation,sim.minor to simulate major and minor factors,sim.omega to test various examples of omega,sim.parallel to compare the efficiency of various ways of deterimining the number of factors,sim.rasch to create simulated rasch data, sim.irt to create general 1 to 4 parameter IRT data by calling sim.npl 1 to 4 parameter logistic IRT or sim.npn 1 to 4 paramater normal IRT,sim.poly to create polytomous ideas by callingsim.poly.npn 1-4 parameter polytomous normal theory items orsim.poly.npl 1-4 parameter polytomous logistic items, and sim.poly.ideal which creates data following an ideal point or unfolding model by calling sim.poly.ideal.npn 1-4 parameter polytomous normal theory ideal point model or sim.poly.ideal.npl 1-4 parameter polytomous logistic ideal point model.
Rotations of factor analysis and principal components analysis solutions typically try to represent correlation matrices as simple structured.  An alternative structure, appealing to some, is a circumplex structure where the variables are uniformly spaced on the perimeter of a circle in a two dimensional space.  Generating simple structure and circumplex data is straightforward, and is useful for exploring alternative solutions to affect and personality structure. A generalization to 3 dimensional (spherical) data is straightforward.
A number of functions in the psych package will generate simulated data with particular structures.  These functions includesim for a factor simplex, and sim.simplex for a data simplex, sim.circ for a circumplex structure, sim.congeneric for a one factor factor congeneric model, sim.dichot to simulate dichotomous items, sim.hierarchical to create a hierarchical factor model, sim.item a more general item simulation,sim.minor to simulate major and minor factors,sim.omega to test various examples of omega,sim.parallel to compare the efficiency of various ways of deterimining the number of factors.   See the help pages for some more simulation functions here: sim.rasch to create simulated rasch data, sim.irt to create general 1 to 4 parameter IRT data by calling sim.npl 1 to 4 parameter logistic IRT or sim.npn 1 to 4 paramater normal IRT,sim.poly to create polytomous ideas by callingsim.poly.npn 1-4 parameter polytomous normal theory items orsim.poly.npl 1-4 parameter polytomous logistic items, and sim.poly.ideal which creates data following an ideal point or unfolding model by calling sim.poly.ideal.npn 1-4 parameter polytomous normal theory ideal point model or sim.poly.ideal.npl 1-4 parameter polytomous logistic ideal point model.
Multilevel data occur when observations are nested within groups. This can produce correlational structures that are sometimes difficult to understand. These two simulations allow for demonstrations that correlations within groups do not imply, nor are implied by, correlations between group means. The correlations of aggregated data is sometimes called an 'ecological correlation'. That group level and individual level correlations are independent makes such inferences problematic.  Within individual data are simulated in sim.multi with a variety of possible within person structures.  
Multilevel data occur when observations are nested within groups. This can produce correlational structures that are sometimes difficult to understand. These two simulations allow for demonstrations that correlations within groups do not imply, nor are implied by, correlations between group means. The correlations of aggregated data is sometimes called an 'ecological correlation'. That group level and individual level correlations are independent makes such inferences problematic.  Within individual data are simulated in sim.multi with a variety of possible within person structures.  
A number of functions in the psych package will generate simulated data with particular structures.  These functions includesim for a factor simplex, and sim.simplex for a data simplex, sim.circ for a circumplex structure, sim.congeneric for a one factor factor congeneric model, sim.dichot to simulate dichotomous items, sim.hierarchical to create a hierarchical factor model, sim.item a more general item simulation,sim.minor to simulate major and minor factors,sim.omega to test various examples of omega,sim.parallel to compare the efficiency of various ways of deterimining the number of factors,sim.rasch to create simulated rasch data, sim.irt to create general 1 to 4 parameter IRT data by calling sim.npl 1 to 4 parameter logistic IRT or sim.npn 1 to 4 paramater normal IRT,sim.poly to create polytomous ideas by callingsim.poly.npn 1-4 parameter polytomous normal theory items orsim.poly.npl 1-4 parameter polytomous logistic items, and sim.poly.ideal which creates data following an ideal point or unfolding model by calling sim.poly.ideal.npn 1-4 parameter polytomous normal theory ideal point model or sim.poly.ideal.npl 1-4 parameter polytomous logistic ideal point model.
A number of functions in the psych package will generate simulated data with particular structures.  These functions includesim for a factor simplex, and sim.simplex for a data simplex, sim.circ for a circumplex structure, sim.congeneric for a one factor factor congeneric model, sim.dichot to simulate dichotomous items, sim.hierarchical to create a hierarchical factor model, sim.item a more general item simulation,sim.minor to simulate major and minor factors,sim.omega to test various examples of omega,sim.parallel to compare the efficiency of various ways of deterimining the number of factors,sim.rasch to create simulated rasch data, sim.irt to create general 1 to 4 parameter IRT data by calling sim.npl 1 to 4 parameter logistic IRT or sim.npn 1 to 4 paramater normal IRT,sim.poly to create polytomous ideas by callingsim.poly.npn 1-4 parameter polytomous normal theory items orsim.poly.npl 1-4 parameter polytomous logistic items, and sim.poly.ideal which creates data following an ideal point or unfolding model by calling sim.poly.ideal.npn 1-4 parameter polytomous normal theory ideal point model or sim.poly.ideal.npl 1-4 parameter polytomous logistic ideal point model.
A number of functions in the psych package will generate simulated data with particular structures.  These functions includesim for a factor simplex, and sim.simplex for a data simplex, sim.circ for a circumplex structure, sim.congeneric for a one factor factor congeneric model, sim.dichot to simulate dichotomous items, sim.hierarchical to create a hierarchical factor model, sim.item a more general item simulation,sim.minor to simulate major and minor factors,sim.omega to test various examples of omega,sim.parallel to compare the efficiency of various ways of deterimining the number of factors.   See the help pages for some more simulation functions here: sim.rasch to create simulated rasch data, sim.irt to create general 1 to 4 parameter IRT data by calling sim.npl 1 to 4 parameter logistic IRT or sim.npn 1 to 4 paramater normal IRT,sim.poly to create polytomous ideas by callingsim.poly.npn 1-4 parameter polytomous normal theory items orsim.poly.npl 1-4 parameter polytomous logistic items, and sim.poly.ideal which creates data following an ideal point or unfolding model by calling sim.poly.ideal.npn 1-4 parameter polytomous normal theory ideal point model or sim.poly.ideal.npl 1-4 parameter polytomous logistic ideal point model.
A number of functions in the psych package will generate simulated data with particular structures.  These functions includesim for a factor simplex, and sim.simplex for a data simplex, sim.circ for a circumplex structure, sim.congeneric for a one factor factor congeneric model, sim.dichot to simulate dichotomous items, sim.hierarchical to create a hierarchical factor model, sim.item a more general item simulation,sim.minor to simulate major and minor factors,sim.omega to test various examples of omega,sim.parallel to compare the efficiency of various ways of deterimining the number of factors.   See the help pages for some more simulation functions here: sim.rasch to create simulated rasch data, sim.irt to create general 1 to 4 parameter IRT data by calling sim.npl 1 to 4 parameter logistic IRT or sim.npn 1 to 4 paramater normal IRT,sim.poly to create polytomous ideas by callingsim.poly.npn 1-4 parameter polytomous normal theory items orsim.poly.npl 1-4 parameter polytomous logistic items, and sim.poly.ideal which creates data following an ideal point or unfolding model by calling sim.poly.ideal.npn 1-4 parameter polytomous normal theory ideal point model or sim.poly.ideal.npl 1-4 parameter polytomous logistic ideal point model.
A number of functions in the psych package will generate simulated data with particular structures.  These functions includesim for a factor simplex, and sim.simplex for a data simplex, sim.circ for a circumplex structure, sim.congeneric for a one factor factor congeneric model, sim.dichot to simulate dichotomous items, sim.hierarchical to create a hierarchical factor model, sim.item a more general item simulation,sim.minor to simulate major and minor factors,sim.omega to test various examples of omega,sim.parallel to compare the efficiency of various ways of deterimining the number of factors,sim.rasch to create simulated rasch data, sim.irt to create general 1 to 4 parameter IRT data by calling sim.npl 1 to 4 parameter logistic IRT or sim.npn 1 to 4 paramater normal IRT,sim.poly to create polytomous ideas by callingsim.poly.npn 1-4 parameter polytomous normal theory items orsim.poly.npl 1-4 parameter polytomous logistic items, and sim.poly.ideal which creates data following an ideal point or unfolding model by calling sim.poly.ideal.npn 1-4 parameter polytomous normal theory ideal point model or sim.poly.ideal.npl 1-4 parameter polytomous logistic ideal point model.
A number of functions in the psych package will generate simulated data with particular structures.  These functions includesim for a factor simplex, and sim.simplex for a data simplex, sim.circ for a circumplex structure, sim.congeneric for a one factor factor congeneric model, sim.dichot to simulate dichotomous items, sim.hierarchical to create a hierarchical factor model, sim.item a more general item simulation,sim.minor to simulate major and minor factors,sim.omega to test various examples of omega,sim.parallel to compare the efficiency of various ways of deterimining the number of factors,sim.rasch to create simulated rasch data, sim.irt to create general 1 to 4 parameter IRT data by calling sim.npl 1 to 4 parameter logistic IRT or sim.npn 1 to 4 paramater normal IRT,sim.poly to create polytomous ideas by callingsim.poly.npn 1-4 parameter polytomous normal theory items orsim.poly.npl 1-4 parameter polytomous logistic items, and sim.poly.ideal which creates data following an ideal point or unfolding model by calling sim.poly.ideal.npn 1-4 parameter polytomous normal theory ideal point model or sim.poly.ideal.npl 1-4 parameter polytomous logistic ideal point model.
A number of functions in the psych package will generate simulated data with particular structures.  These functions includesim for a factor simplex, and sim.simplex for a data simplex, sim.circ for a circumplex structure, sim.congeneric for a one factor factor congeneric model, sim.dichot to simulate dichotomous items, sim.hierarchical to create a hierarchical factor model, sim.item a more general item simulation,sim.minor to simulate major and minor factors,sim.omega to test various examples of omega,sim.parallel to compare the efficiency of various ways of deterimining the number of factors,sim.rasch to create simulated rasch data, sim.irt to create general 1 to 4 parameter IRT data by calling sim.npl 1 to 4 parameter logistic IRT or sim.npn 1 to 4 paramater normal IRT,sim.poly to create polytomous ideas by callingsim.poly.npn 1-4 parameter polytomous normal theory items orsim.poly.npl 1-4 parameter polytomous logistic items, and sim.poly.ideal which creates data following an ideal point or unfolding model by calling sim.poly.ideal.npn 1-4 parameter polytomous normal theory ideal point model or sim.poly.ideal.npl 1-4 parameter polytomous logistic ideal point model.
A number of functions in the psych package will generate simulated data with particular structures.  These functions includesim for a factor simplex, and sim.simplex for a data simplex, sim.circ for a circumplex structure, sim.congeneric for a one factor factor congeneric model, sim.dichot to simulate dichotomous items, sim.hierarchical to create a hierarchical factor model, sim.item a more general item simulation,sim.minor to simulate major and minor factors,sim.omega to test various examples of omega,sim.parallel to compare the efficiency of various ways of deterimining the number of factors,sim.rasch to create simulated rasch data, sim.irt to create general 1 to 4 parameter IRT data by calling sim.npl 1 to 4 parameter logistic IRT or sim.npn 1 to 4 paramater normal IRT,sim.poly to create polytomous ideas by callingsim.poly.npn 1-4 parameter polytomous normal theory items orsim.poly.npl 1-4 parameter polytomous logistic items, and sim.poly.ideal which creates data following an ideal point or unfolding model by calling sim.poly.ideal.npn 1-4 parameter polytomous normal theory ideal point model or sim.poly.ideal.npl 1-4 parameter polytomous logistic ideal point model.
A number of functions in the psych package will generate simulated data with particular structures.  These functions includesim for a factor simplex, and sim.simplex for a data simplex, sim.circ for a circumplex structure, sim.congeneric for a one factor factor congeneric model, sim.dichot to simulate dichotomous items, sim.hierarchical to create a hierarchical factor model, sim.item a more general item simulation,sim.minor to simulate major and minor factors,sim.omega to test various examples of omega,sim.parallel to compare the efficiency of various ways of deterimining the number of factors,sim.rasch to create simulated rasch data, sim.irt to create general 1 to 4 parameter IRT data by calling sim.npl 1 to 4 parameter logistic IRT or sim.npn 1 to 4 paramater normal IRT,sim.poly to create polytomous ideas by callingsim.poly.npn 1-4 parameter polytomous normal theory items orsim.poly.npl 1-4 parameter polytomous logistic items, and sim.poly.ideal which creates data following an ideal point or unfolding model by calling sim.poly.ideal.npn 1-4 parameter polytomous normal theory ideal point model or sim.poly.ideal.npl 1-4 parameter polytomous logistic ideal point model.
A number of functions in the psych package will generate simulated data with particular structures.  These functions includesim for a factor simplex, and sim.simplex for a data simplex, sim.circ for a circumplex structure, sim.congeneric for a one factor factor congeneric model, sim.dichot to simulate dichotomous items, sim.hierarchical to create a hierarchical factor model, sim.item a more general item simulation,sim.minor to simulate major and minor factors,sim.omega to test various examples of omega,sim.parallel to compare the efficiency of various ways of deterimining the number of factors,sim.rasch to create simulated rasch data, sim.irt to create general 1 to 4 parameter IRT data by calling sim.npl 1 to 4 parameter logistic IRT or sim.npn 1 to 4 paramater normal IRT,sim.poly to create polytomous ideas by callingsim.poly.npn 1-4 parameter polytomous normal theory items orsim.poly.npl 1-4 parameter polytomous logistic items, and sim.poly.ideal which creates data following an ideal point or unfolding model by calling sim.poly.ideal.npn 1-4 parameter polytomous normal theory ideal point model or sim.poly.ideal.npl 1-4 parameter polytomous logistic ideal point model.
A number of functions in the psych package will generate simulated data with particular structures.  These functions includesim for a factor simplex, and sim.simplex for a data simplex, sim.circ for a circumplex structure, sim.congeneric for a one factor factor congeneric model, sim.dichot to simulate dichotomous items, sim.hierarchical to create a hierarchical factor model, sim.item a more general item simulation,sim.minor to simulate major and minor factors,sim.omega to test various examples of omega,sim.parallel to compare the efficiency of various ways of deterimining the number of factors,sim.rasch to create simulated rasch data, sim.irt to create general 1 to 4 parameter IRT data by calling sim.npl 1 to 4 parameter logistic IRT or sim.npn 1 to 4 paramater normal IRT,sim.poly to create polytomous ideas by callingsim.poly.npn 1-4 parameter polytomous normal theory items orsim.poly.npl 1-4 parameter polytomous logistic items, and sim.poly.ideal which creates data following an ideal point or unfolding model by calling sim.poly.ideal.npn 1-4 parameter polytomous normal theory ideal point model or sim.poly.ideal.npl 1-4 parameter polytomous logistic ideal point model.
A number of functions in the psych package will generate simulated data with particular structures.  These functions includesim for a factor simplex, and sim.simplex for a data simplex, sim.circ for a circumplex structure, sim.congeneric for a one factor factor congeneric model, sim.dichot to simulate dichotomous items, sim.hierarchical to create a hierarchical factor model, sim.item a more general item simulation,sim.minor to simulate major and minor factors,sim.omega to test various examples of omega,sim.parallel to compare the efficiency of various ways of deterimining the number of factors,sim.rasch to create simulated rasch data, sim.irt to create general 1 to 4 parameter IRT data by calling sim.npl 1 to 4 parameter logistic IRT or sim.npn 1 to 4 paramater normal IRT,sim.poly to create polytomous ideas by callingsim.poly.npn 1-4 parameter polytomous normal theory items orsim.poly.npl 1-4 parameter polytomous logistic items, and sim.poly.ideal which creates data following an ideal point or unfolding model by calling sim.poly.ideal.npn 1-4 parameter polytomous normal theory ideal point model or sim.poly.ideal.npl 1-4 parameter polytomous logistic ideal point model.
A number of functions in the psych package will generate simulated data with particular structures.  These functions includesim for a factor simplex, and sim.simplex for a data simplex, sim.circ for a circumplex structure, sim.congeneric for a one factor factor congeneric model, sim.dichot to simulate dichotomous items, sim.hierarchical to create a hierarchical factor model, sim.item a more general item simulation,sim.minor to simulate major and minor factors,sim.omega to test various examples of omega,sim.parallel to compare the efficiency of various ways of deterimining the number of factors.   See the help pages for some more simulation functions here: sim.rasch to create simulated rasch data, sim.irt to create general 1 to 4 parameter IRT data by calling sim.npl 1 to 4 parameter logistic IRT or sim.npn 1 to 4 paramater normal IRT,sim.poly to create polytomous ideas by callingsim.poly.npn 1-4 parameter polytomous normal theory items orsim.poly.npl 1-4 parameter polytomous logistic items, and sim.poly.ideal which creates data following an ideal point or unfolding model by calling sim.poly.ideal.npn 1-4 parameter polytomous normal theory ideal point model or sim.poly.ideal.npl 1-4 parameter polytomous logistic ideal point model.
Rotations of factor analysis and principal components analysis solutions typically try to represent correlation matrices as simple structured.  An alternative structure, appealing to some, is a circumplex structure where the variables are uniformly spaced on the perimeter of a circle in a two dimensional space.  Generating simple structure and circumplex data is straightforward, and is useful for exploring alternative solutions to affect and personality structure. A generalization to 3 dimensional (spherical) data is straightforward.
Structural Equation Models decompose correlation or correlation matrices into a measurement (factor) model and a structural (regression) model.  sim.structural creates data sets with known measurement and structural properties. Population or sample correlation matrices with known properties are generated. Optionally raw data are produced. 
Structural Equation Models decompose correlation or correlation matrices into a measurement (factor) model and a structural (regression) model.  sim.structural creates data sets with known measurement and structural properties. Population or sample correlation matrices with known properties are generated. Optionally raw data are produced. 
Simulation is one of most useful techniques in statistics and psychometrics.  Here we simulate a correlation matrix with a simple structure composed of a specified number of factors.  Each item is assumed to have complexity one.  See circ.sim and item.sim for alternative simulations.
Structural Equation Models decompose correlation or correlation matrices into a measurement (factor) model and a structural (regression) model.  sim.structural creates data sets with known measurement and structural properties. Population or sample correlation matrices with known properties are generated. Optionally raw data are produced. 
Rotations of factor analysis and principal components analysis solutions typically try to represent correlation matrices as simple structured.  An alternative structure, appealing to some, is a circumplex structure where the variables are uniformly spaced on the perimeter of a circle in a two dimensional space.  Generating these data is straightforward, and is useful for exploring alternative solutions to affect and personality structure.
Find the skew and kurtosis for each variable in a data.frame or matrix.  Unlike skew and kurtosis in e1071, this calculates a different skew for each variable or column of a data.frame/matrix. mardia applies Mardia's tests for multivariate skew and kurtosis
The squared multiple correlation of a variable with the remaining variables in a matrix is sometimes used as initial estimates of the communality of a variable.
Radar plots and spider plots are just two of the many ways to show multivariate data.  radar  plots correlations as vectors ranging in length from 0 (corresponding to r=-1) to 1 (corresponding to an r=1).  The vectors are arranged radially around a circle. Spider plots connect the end points of each vector. The plots are most appropriate if the variables are organized in some meaningful manner. 
Eight alternative estimates of test reliability include the six discussed by Guttman (1945), four discussed by ten Berge and Zergers (1978) (μ_0 … μ_3) as well as β (the worst split half, Revelle, 1979),  the glb (greatest lowest bound) discussed by Bentler and Woodward (1980), and ω_h and ω_t (McDonald, 1999; Zinbarg et al., 2005). Greatest and lowest split-half values are found by brute force or sampling. 
When examining data at two levels (e.g., the individual and by some set of grouping variables), it is useful to find basic descriptive statistics (means, sds, ns per group, within group correlations) as well as between group statistics (over all descriptive statistics, and overall between group correlations). Of particular use is the ability to decompose a matrix of correlations at the individual level into correlations within group and correlations between groups. 
When examining data at two levels (e.g., the individual and by some set of grouping variables), it is useful to find basic descriptive statistics (means, sds, ns per group, within group correlations) as well as between group statistics (over all descriptive statistics, and overall between group correlations). Of particular use is the ability to decompose a matrix of correlations at the individual level into correlations within group and correlations between groups. 
When examining data at two levels (e.g., the individual and by some set of grouping variables), it is useful to find basic descriptive statistics (means, sds, ns per group, within group correlations) as well as between group statistics (over all descriptive statistics, and overall between group correlations). Of particular use is the ability to decompose a matrix of correlations at the individual level into correlations within group and correlations between groups. 
Graphic presentations of structural equation models are a very useful way to conceptualize sem and confirmatory factor models. Given a measurement model on x (xmodel) and on y (ymodel) as well as a path model connecting x and y (phi), draw the graph.  If the ymodel is not specified, just draw the measurement model (xmodel + phi). If the Rx or Ry matrices are specified, show the correlations between the x variables, or y variables.
Graphic presentations of structural equation models are a very useful way to conceptualize sem and confirmatory factor models. Given a measurement model on x (xmodel) and on y (ymodel) as well as a path model connecting x and y (phi), draw the graph.  If the ymodel is not specified, just draw the measurement model (xmodel + phi). If the Rx or Ry matrices are specified, show the correlations between the x variables, or y variables.
When creating a structural diagram or a structural model, it is convenient to not have to specify all of the zero loadings in a structural matrix.  structure.list converts list input into a design matrix.  phi.list does the same for a correlation matrix. Factors with NULL values are filled with 0s.
Graphic presentations of structural equation models are a very useful way to conceptualize sem and confirmatory factor models. Given a measurement model on x (xmodel) and on y (ymodel) as well as a path model connecting x and y (phi), draw the graph.  If the ymodel is not specified, just draw the measurement model (xmodel + phi). If the Rx or Ry matrices are specified, show the correlations between the x variables, or y variables.
Give limited output (print) or somewhat more detailed (summary) for most of the functions in psych. 
Given the matrices nXm, and jYk, form the super matrix of dimensions (n+j) and (m+k) with  with elements x and y along the super diagonal. Useful when considering structural equations.  The measurement models x and y can be combined into a larger measurement model of all of the variables.  If either x or y is a list of matrices, then recursively form a super matrix of all of those elements.  superCor will form a matrix from two matrices and the intercorrelation of the elements of the two.
Given the matrices nXm, and jYk, form the super matrix of dimensions (n+j) and (m+k) with  with elements x and y along the super diagonal. Useful when considering structural equations.  The measurement models x and y can be combined into a larger measurement model of all of the variables.  If either x or y is a list of matrices, then recursively form a super matrix of all of those elements.  superCor will form a matrix from two matrices and the intercorrelation of the elements of the two.
Given the matrices nXm, and jYk, form the super matrix of dimensions (n+j) and (m+k) with  with elements x and y along the super diagonal. Useful when considering structural equations.  The measurement models x and y can be combined into a larger measurement model of all of the variables.  If either x or y is a list of matrices, then recursively form a super matrix of all of those elements.  superCor will form a matrix from two matrices and the intercorrelation of the elements of the two.
Given a data.frame or matrix, find the standardized mean difference (Cohen's d) and confidence intervals for each variable depending upon a grouping variable.  Convert the d statistic to the r equivalent, report the student's t statistic and associated p values, and return statistics for both values of the grouping variable.  The Mahalanobis distance between the centroids of the two groups in the space defined by all the variables ia also found.  Confidence intervals for Cohen d for one group (difference from 0) may also be found. Several measures of the distributional overlap (e.g. OVL, OVL2, etc.) are available.
Convert a correlation to a z or t, or d, or chi or covariance matrixor z to r using the Fisher transformation or find the confidence intervals for a specified correlation.  r2d converts a correlation to an effect size (Cohen's d) and d2r converts a d into an r. g2r converts Hedge's g to a correlation.   t2r converts a t test to r, r2t converts a correlation to a t-test value. chi2r converts a chi square to r, r2chi converts it back.  r2c and cor2cov convert a correlation matrix to a covariance matrix. d2t and t2d convert cohen's d into a t and a t into a cohen d.  See cohen.d for other conversions.
Some historical sets are reported as summary tables of counts in a limited number of bins.  Transforming these tables to data.frames representing the original values is useful for pedagogical purposes.  (E.g., transforming the original Galton table of height x cubits in order to demonstrate regression.) The column and row names must be able to be converted to numeric values.
Some historical sets are reported as summary tables of counts in a limited number of bins.  Transforming these tables to data.frames representing the original values is useful for pedagogical purposes.  (E.g., transforming the original Galton table of height x cubits in order to demonstrate regression.) The column and row names must be able to be converted to numeric values.
This is a set of minor, if not trivial, helper functions.lowerCor finds the correlation of x variables and then prints them using lowerMat which is a trivial, but useful, function to round off and print the lower triangle of a matrix.reflect reflects the output of a factor analysis or principal components analysis so that one or more factors is reflected. (Requested by Alexander Weiss.)progressBar prints out ...  as a calling routine (e.g., tetrachoric) works through a tedious calculation.  shannon finds the Shannon index (H) of diversity or of information. test.all tests all the examples in a package.  best.items sorts a factor matrix for absolute values and displays the expanded items names. fa.lookup returns sorted factor analysis output with item labels. cor2 correlates two data.frames (of equal length). levels2numeric and char2numeric convert dataframe columns that are categorical/levels to numeric values. 
Nurit Tal-Or, Jonanathan Cohen, Yariv Tasfati, and Albert Gunther (2010) examined the presumed effect of media on other people and change in attitudes.  This data set is from Study 2, and examined the effect of presumed influence of the media upon subsequent actions.  It is used as an example of mediation by Hayes (2013) and for the mediate function. 
Nurit Tal-Or, Jonanathan Cohen, Yariv Tasfati, and Albert Gunther (2010) examined the presumed effect of media on other people and change in attitudes.  This data set is from Study 2, and examined the effect of presumed influence of the media upon subsequent actions.  It is used as an example of mediation by Hayes (2013) and for the mediate function. 
The bifactor rotation implements the rotation introduced by Jennrich and Bentler (2011) by calling GPForth in the GPArotation package.  promax is an oblique rotation function introduced by Hendrickson and White (1964) and implemented in the promax function in the stats package.  Unfortunately, promax does not report the inter factor correlations.  Promax does.  TargetQ does a target rotation with elements that can be missing (NA), or numeric (e.g., 0, 1).  It uses the GPArotation package. target.rot does general target rotations to an arbitrary target matrix. The default target rotation is for an independent cluster solution. equamax facilitates the call to GPArotation to do an equamax rotation.  Equamax, although available as a specific option within GPArotation is easier to call by name if using equamax.  The varimin rotation suggested by Ertl (2013) is implemented by appropriate calls to GPArotation.
The bifactor rotation implements the rotation introduced by Jennrich and Bentler (2011) by calling GPForth in the GPArotation package.  promax is an oblique rotation function introduced by Hendrickson and White (1964) and implemented in the promax function in the stats package.  Unfortunately, promax does not report the inter factor correlations.  Promax does.  TargetQ does a target rotation with elements that can be missing (NA), or numeric (e.g., 0, 1).  It uses the GPArotation package. target.rot does general target rotations to an arbitrary target matrix. The default target rotation is for an independent cluster solution. equamax facilitates the call to GPArotation to do an equamax rotation.  Equamax, although available as a specific option within GPArotation is easier to call by name if using equamax.  The varimin rotation suggested by Ertl (2013) is implemented by appropriate calls to GPArotation.
The bifactor rotation implements the rotation introduced by Jennrich and Bentler (2011) by calling GPForth in the GPArotation package.  promax is an oblique rotation function introduced by Hendrickson and White (1964) and implemented in the promax function in the stats package.  Unfortunately, promax does not report the inter factor correlations.  Promax does.  TargetQ does a target rotation with elements that can be missing (NA), or numeric (e.g., 0, 1).  It uses the GPArotation package. target.rot does general target rotations to an arbitrary target matrix. The default target rotation is for an independent cluster solution. equamax facilitates the call to GPArotation to do an equamax rotation.  Equamax, although available as a specific option within GPArotation is easier to call by name if using equamax.  The varimin rotation suggested by Ertl (2013) is implemented by appropriate calls to GPArotation.
Eight alternative estimates of test reliability include the six discussed by Guttman (1945), four discussed by ten Berge and Zergers (1978) (μ_0 … μ_3) as well as β (the worst split half, Revelle, 1979),  the glb (greatest lowest bound) discussed by Bentler and Woodward (1980), and ω_h and ω_t (McDonald, 1999; Zinbarg et al., 2005). Greatest and lowest split-half values are found by brute force or sampling. 
This is a set of minor, if not trivial, helper functions.lowerCor finds the correlation of x variables and then prints them using lowerMat which is a trivial, but useful, function to round off and print the lower triangle of a matrix.reflect reflects the output of a factor analysis or principal components analysis so that one or more factors is reflected. (Requested by Alexander Weiss.)progressBar prints out ...  as a calling routine (e.g., tetrachoric) works through a tedious calculation.  shannon finds the Shannon index (H) of diversity or of information. test.all tests all the examples in a package.  best.items sorts a factor matrix for absolute values and displays the expanded items names. fa.lookup returns sorted factor analysis output with item labels. cor2 correlates two data.frames (of equal length). levels2numeric and char2numeric convert dataframe columns that are categorical/levels to numeric values. 
 Item Response Theory provides a number of alternative ways of estimating latent scores.  Here we compare 6 different ways to estimate the latent variable associated with a pattern of responses. Originally developed as a test for scoreIrt, but perhaps useful for demonstration purposes.  Items are simulated using sim.irt and then scored using factor scores from factor.scores using statistics found using irt.fa, simple weighted models for 1 and 2 PL and 2 PN. Results show almost perfect agreement with estimates from MIRT and ltm for the dichotomous case and with MIRT for the polytomous case.  (Results from ltm are unstable for the polytomous case, sometimes agreeing with scoreIrt and MIRT, sometimes being much worse.)  
Test to make sure the psych functions run on basic test data sets
Given two presentations of a test, it is straightforward to find the test-retest reliablity, as well as the item reliability and person stability across items.  Using the multi-level structure of the data, it is also possible to do a variance deomposition to find variance components for people, items, time, people x time, people x items, and items x time as well as the residual variance. This leads to various generalizability cofficients.
The tetrachoric correlation is the inferred Pearson Correlation from a two x two table with the assumption of bivariate normality. The polychoric correlation generalizes this to the n x m table. Particularly important when doing Item Response Theory or converting comorbidity statistics using normal theory to correlations. Input may be a 2 x 2 table of cell frequencies, a vector of cell frequencies, or a data.frame or matrix of dichotomous data (for tetrachoric) or of numeric data (for polychoric).The biserial correlation is between a continuous y variable and a dichotmous x variable, which is assumed to have resulted from a dichotomized normal variable. Biserial is a special case of the polyserial correlation, which is the inferred latent correlation between a continuous variable (X) and a ordered categorical variable (e.g., an item response). Input for these later two are data frames or matrices.  Requires the mnormt package.
Thurstone Case V scaling allows for a scaling of objects compared to other objects. As one of the cases considered by Thurstone, Case V makes the assumption of equal variances and uncorrelated distributions. 
Holzinger-Swineford (1937) introduced the bifactor model of a general factor and uncorrelated group factors. The Holzinger data sets are   original 14 * 14 matrix from their paper as well as a 9 *9 matrix used as an example by Joreskog. The Thurstone correlation matrix is a 9 * 9 matrix of correlations of ability items.  The Reise data set is 16 * 16 correlation matrix of mental health items. The Bechtholdt data sets are both 17 x 17 correlation matrices of ability tests.  
Holzinger-Swineford (1937) introduced the bifactor model of a general factor and uncorrelated group factors. The Holzinger data sets are   original 14 * 14 matrix from their paper as well as a 9 *9 matrix used as an example by Joreskog. The Thurstone correlation matrix is a 9 * 9 matrix of correlations of ability items.  The Reise data set is 16 * 16 correlation matrix of mental health items. The Bechtholdt data sets are both 17 x 17 correlation matrices of ability tests.  
Holzinger-Swineford (1937) introduced the bifactor model of a general factor and uncorrelated group factors. The Holzinger data sets are   original 14 * 14 matrix from their paper as well as a 9 *9 matrix used as an example by Joreskog. The Thurstone correlation matrix is a 9 * 9 matrix of correlations of ability items.  The Reise data set is 16 * 16 correlation matrix of mental health items. The Bechtholdt data sets are both 17 x 17 correlation matrices of ability tests.  
A quick way to show the first and last n lines of a data.frame, matrix, or a text object.  Just a pretty call to head and tail or View
Hardly worth coding, if it didn't appear in so many formulae in psychometrics, the trace of a (square) matrix is just the sum of the diagonal elements. 
Tucker and Lewis (1973) introduced a reliability coefficient for ML factor analysis.  Their example data set was previously reported by Tucker (1958) and taken from Thurstone and Thurstone (1941).  The correlation matrix is a 9 x 9 for 710 subjects and has two correlated factors of ability: Word Fluency and Verbal.
There are a variety of ways of assessing whether a set of items measures one latent trait.  unidim is just one more way.  If a one factor model holds in the data, then the factor analytic decomposition F implies that FF' should reproduce the correlations with communalities along the diagonal. In this case, the fit FF' should be identical to the correlation matrix minus the uniquenesses.  unidim is just the ratio of these two estimates.  The higher it is, the more the evidence for unidimensionality. A number of alternative statistics are estimated.
The bifactor rotation implements the rotation introduced by Jennrich and Bentler (2011) by calling GPForth in the GPArotation package.  promax is an oblique rotation function introduced by Hendrickson and White (1964) and implemented in the promax function in the stats package.  Unfortunately, promax does not report the inter factor correlations.  Promax does.  TargetQ does a target rotation with elements that can be missing (NA), or numeric (e.g., 0, 1).  It uses the GPArotation package. target.rot does general target rotations to an arbitrary target matrix. The default target rotation is for an independent cluster solution. equamax facilitates the call to GPArotation to do an equamax rotation.  Equamax, although available as a specific option within GPArotation is easier to call by name if using equamax.  The varimin rotation suggested by Ertl (2013) is implemented by appropriate calls to GPArotation.
The bifactor rotation implements the rotation introduced by Jennrich and Bentler (2011) by calling GPForth in the GPArotation package.  promax is an oblique rotation function introduced by Hendrickson and White (1964) and implemented in the promax function in the stats package.  Unfortunately, promax does not report the inter factor correlations.  Promax does.  TargetQ does a target rotation with elements that can be missing (NA), or numeric (e.g., 0, 1).  It uses the GPArotation package. target.rot does general target rotations to an arbitrary target matrix. The default target rotation is for an independent cluster solution. equamax facilitates the call to GPArotation to do an equamax rotation.  Equamax, although available as a specific option within GPArotation is easier to call by name if using equamax.  The varimin rotation suggested by Ertl (2013) is implemented by appropriate calls to GPArotation.
The bifactor rotation implements the rotation introduced by Jennrich and Bentler (2011) by calling GPForth in the GPArotation package.  promax is an oblique rotation function introduced by Hendrickson and White (1964) and implemented in the promax function in the stats package.  Unfortunately, promax does not report the inter factor correlations.  Promax does.  TargetQ does a target rotation with elements that can be missing (NA), or numeric (e.g., 0, 1).  It uses the GPArotation package. target.rot does general target rotations to an arbitrary target matrix. The default target rotation is for an independent cluster solution. equamax facilitates the call to GPArotation to do an equamax rotation.  Equamax, although available as a specific option within GPArotation is easier to call by name if using equamax.  The varimin rotation suggested by Ertl (2013) is implemented by appropriate calls to GPArotation.
The bifactor rotation implements the rotation introduced by Jennrich and Bentler (2011) by calling GPForth in the GPArotation package.  promax is an oblique rotation function introduced by Hendrickson and White (1964) and implemented in the promax function in the stats package.  Unfortunately, promax does not report the inter factor correlations.  Promax does.  TargetQ does a target rotation with elements that can be missing (NA), or numeric (e.g., 0, 1).  It uses the GPArotation package. target.rot does general target rotations to an arbitrary target matrix. The default target rotation is for an independent cluster solution. equamax facilitates the call to GPArotation to do an equamax rotation.  Equamax, although available as a specific option within GPArotation is easier to call by name if using equamax.  The varimin rotation suggested by Ertl (2013) is implemented by appropriate calls to GPArotation.
Among the many ways to describe a data set, one is a density plot for each value of a grouping variable and another is violin plot of multiple variables.  A density plot shows the density for different groups to show effect sizes. A violin plot is similar to a box plot but shows the actual distribution.Median and 25th and 75th percentile lines are added to the display. If a grouping variable is specified, violinBy will draw violin plots for each variable and for each group. Data points may be drawn as well.
Among the many ways to describe a data set, one is a density plot for each value of a grouping variable and another is violin plot of multiple variables.  A density plot shows the density for different groups to show effect sizes. A violin plot is similar to a box plot but shows the actual distribution.Median and 25th and 75th percentile lines are added to the display. If a grouping variable is specified, violinBy will draw violin plots for each variable and for each group. Data points may be drawn as well.
There are multiple ways to determine the appropriate number of factors in exploratory factor analysis. Routines for the Very Simple Structure (VSS) criterion allow one to compare solutions of varying complexity and for different number of factors. Graphic output indicates the "optimal" number of factors for different levels of complexity.  The Velicer MAP criterion is another good choice. nfactors finds and plots several of these alternative estimates.
There are multiple ways to determine the appropriate number of factors in exploratory factor analysis. Routines for the Very Simple Structure (VSS) criterion allow one to compare solutions of varying complexity and for different number of factors. Graphic output indicates the "optimal" number of factors for different levels of complexity.  The Velicer MAP criterion is another good choice. nfactors finds and plots several of these alternative estimates.
Another useful test for the number of factors is when the eigen values of a random matrix are greater than the eigen values of a a real matrix. Here we show VSS solutions to random data. A better test is probably fa.parallel.
The Very Simple Structure criterion ( VSS) for estimating the optimal number of factors is plotted as a function of the increasing complexity and increasing number of factors.  
Cattell's scree test is one of most simple ways of testing the number of components or factors in  a correlation matrix. Here we plot the  eigen values of a correlation matrix as well as the eigen values of a factor analysis.
Simulation is one of most useful techniques in statistics and psychometrics.  Here we simulate a correlation matrix with a simple structure composed of a specified number of factors.  Each item is assumed to have complexity one.  See circ.sim and item.sim for alternative simulations.
Simulation is one of most useful techniques in statistics and psychometrics.  Here we simulate a correlation matrix with a simple structure composed of a specified number of factors.  Each item is assumed to have complexity one.  See circ.sim and item.sim for alternative simulations.
John Schmid and John M. Leiman (1957) discuss how to transform a hierarchical factor structure to a bifactor structure. Schmid contains the example 12 x 12 correlation matrix. schmid.leiman is a 12 x 12 correlation matrix with communalities on the diagonal. This can be used to show the effect of correcting for attenuation. Two additional data sets are taken from Chen et al. (2006).
Among the  robust estimates of central tendency are trimmed means and Winsorized means.  This function finds the Winsorized scores.   The top and bottom trim values are given values of the trimmed and 1- trimmed quantiles.  Then means, sds, and variances are found.    
Among the  robust estimates of central tendency are trimmed means and Winsorized means.  This function finds the Winsorized scores.   The top and bottom trim values are given values of the trimmed and 1- trimmed quantiles.  Then means, sds, and variances are found.    
Among the  robust estimates of central tendency are trimmed means and Winsorized means.  This function finds the Winsorized scores.   The top and bottom trim values are given values of the trimmed and 1- trimmed quantiles.  Then means, sds, and variances are found.    
Among the  robust estimates of central tendency are trimmed means and Winsorized means.  This function finds the Winsorized scores.   The top and bottom trim values are given values of the trimmed and 1- trimmed quantiles.  Then means, sds, and variances are found.    
Among the  robust estimates of central tendency are trimmed means and Winsorized means.  This function finds the Winsorized scores.   The top and bottom trim values are given values of the trimmed and 1- trimmed quantiles.  Then means, sds, and variances are found.    
A demonstration that a correlation may be decomposed to a within group correlation  and a between group correlations and these two correlations are independent.  Between group correlations are sometimes called ecological correlations, the decomposition into  within and between group correlations is a basic concept in multilevel modeling.  This data set shows the composite correlations between 9 variables, representing 16 cases with four groups.    
Cohen's kappa (Cohen, 1960) and weighted kappa (Cohen, 1968) may be used to find the agreement of two raters when using nominal scores.  Light's kappa is just the average cohen.kappa if using more than 2 raters. 
One of the many measures of association is the Yule coefficient.  Given a two x two table of counts 
One of the many measures of association is the Yule coefficient.  Given a two x two table of counts 
One of the many measures of association is the Yule coefficient.  Given a two x two table of counts 
A set of deprecated functions that have replaced by Yule2tetra and Yule2phi. 
One of the many measures of association is the Yule coefficient.  Given a two x two table of counts 
A set of deprecated functions that have replaced by Yule2tetra and Yule2phi. 
One of the many measures of association is the Yule coefficient.  Given a two x two table of counts 
One of the many measures of association is the Yule coefficient.  Given a two x two table of counts 
One of the many measures of association is the Yule coefficient.  Given a two x two table of counts 
The function acf computes (and by default plots) estimates ofthe autocovariance or autocorrelation function.  Function pacfis the function used for the partial autocorrelations.  Functionccf computes the cross-correlation or cross-covariance of twounivariate series.
Compute an AR process exactly fitting an autocorrelation function.
add.scope and drop.scope compute those terms that can beindividually added to or dropped from a model while respecting thehierarchy of terms.
Compute all the single terms in the scope argument that can beadded to or dropped from the model, fit those models and compute atable of the changes in fit.
For a given table one can specify which of the classifying factors toexpand by one or more levels to hold margins to be calculated.  One may forexample form sums and means over the first dimension and medians over thesecond.  The resulting table will then have two extra levels for the firstdimension and one extra level for the second.  The default is to sum overall margins in the table.  Other possibilities may give results thatdepend on the order in which the margins are computed.  This is flaggedin the printed output from the function.
Splits the data into subsets, computes summary statistics for each,and returns the result in a convenient form.
Splits the data into subsets, computes summary statistics for each,and returns the result in a convenient form.
Splits the data into subsets, computes summary statistics for each,and returns the result in a convenient form.
Generic function calculating Akaike's ‘An Information Criterion’ forone or several fitted model objects for which a log-likelihood valuecan be obtained, according to the formula-2*log-likelihood + k*npar,where npar represents the number of parameters in thefitted model, and k = 2 for the usual AIC, ork = log(n)(n being the number of observations) for the so-called BIC or SBC(Schwarz's Bayesian criterion).
Find aliases (linearly dependent terms) in a linear model specified bya formula.
Compute analysis of variance (or deviance) tables for one or morefitted model objects.
Performs the Ansari-Bradley two-sample test for a difference in scaleparameters.
Fit an analysis of variance model by a call to lm for each stratum.
Return a list of points which linearly interpolate given data points,or a function performing the linear (or constant) interpolation.
Return a list of points which linearly interpolate given data points,or a function performing the linear (or constant) interpolation.
Fit an autoregressive time series model to the data, by defaultselecting the complexity by AIC.
Fit an autoregressive time series model to the data, by defaultselecting the complexity by AIC.
Fit an autoregressive time series model to the data, by defaultselecting the complexity by AIC.
Fit an autoregressive time series model to the data by ordinaryleast squares, by default selecting the complexity by AIC.
Fit an autoregressive time series model to the data, by defaultselecting the complexity by AIC.
Fit an ARIMA model to a univariate time series.
Simulate from an ARIMA model.
Fit an ARIMA model to a univariate time series, and forecast fromthe fitted model.
The functions or variables listed here are no longer part of R asthey are not needed (any more).
Compute the theoretical autocorrelation function or partialautocorrelation function for an ARMA process.
Convert ARMA process to infinite MA process.
Class "dendrogram" provides general functions for handlingtree-like structures.  It is intended as a replacement for similarfunctions in hierarchical clustering and classification/regressiontrees, such that all of these can use the same engine for plotting orcutting trees.
This function computes and returns the distance matrix computed byusing the specified distance measure to compute the distances betweenthe rows of a data matrix.
The generic function formula and its specific methods provide away of extracting formulae which have been included in other objects.
Converts objects from other hierarchical clustering functions toclass "hclust".
Given the vectors (x[1], …, x[n]) and(y[0], y[1], …, y[n]) (one valuemore!), stepfun(x, y, ...) returns an interpolating‘step’ function, say fn. I.e., fn(t) =    c[i] (constant) for t in (    x[i], x[i+1]) and at the abscissa values, if (by default)right = FALSE, fn(x[i]) = y[i] and forright = TRUE, fn(x[i]) = y[i-1], fori=1, …, n.
The function ts is used to create time-series objects.
Names, expressions, numeric values, and character strings are converted toone-sided formulae. If object is a formula, it must beone-sided, in which case it is returned unaltered.
Subsets of x[] are averaged, where each subset consist of thoseobservations with the same factor levels.
The "tskernel" class is designed to represent discretesymmetric normalized smoothing kernels.  These kernels can be used tosmooth vectors, matrices, or time series objects.
Performs Bartlett's test of the null that the variances in each of thegroups (samples) are the same.
Generic function calculating Akaike's ‘An Information Criterion’ forone or several fitted model objects for which a log-likelihood valuecan be obtained, according to the formula-2*log-likelihood + k*npar,where npar represents the number of parameters in thefitted model, and k = 2 for the usual AIC, ork = log(n)(n being the number of observations) for the so-called BIC or SBC(Schwarz's Bayesian criterion).
Performs an exact test of a simple null hypothesis about theprobability of success in a Bernoulli experiment.
Family objects provide a convenient way to specify the details of themodels used by functions such as glm.  See thedocumentation for glm for the details on how such modelfitting takes place.
Plot a biplot on the current graphics device.
Perform cubic (or Hermite) spline interpolation of given data points,returning either a list of points obtained by the interpolation or afunction performing the interpolation.
Bandwidth selectors for Gaussian kernels in density.
Bandwidth selectors for Gaussian kernels in density.
Bandwidth selectors for Gaussian kernels in density.
Bandwidth selectors for Gaussian kernels in density.
Bandwidth selectors for Gaussian kernels in density.
Sets the "contrasts" attribute for the factor.
Compute the canonical correlations between two data matrices.
Simple utilities returning (non-missing) case names, and(non-eliminated) variable names.
The function acf computes (and by default plots) estimates ofthe autocovariance or autocorrelation function.  Function pacfis the function used for the partial autocorrelations.  Functionccf computes the cross-correlation or cross-covariance of twounivariate series.
chisq.test performs chi-squared contingency table testsand goodness-of-fit tests.
Classical multidimensional scaling (MDS) of a data matrix.Also known as principal coordinates analysis (Gower, 1966).
coef is a generic function which extracts model coefficientsfrom objects returned by modeling functions.  coefficients isan alias for it.
coef is a generic function which extracts model coefficientsfrom objects returned by modeling functions.  coefficients isan alias for it.
Return a logical vector indicating which cases are complete, i.e.,have no missing values.
Computes confidence intervals for one or more parameters in a fittedmodel.  There is a default and a method for objects inheriting from class"lm".
Computes confidence intervals for one or more parameters in a fittedmodel.  There is a default and a method for objects inheriting from class"lm".
Computes confidence intervals for one or more parameters in a fittedmodel.  There is a default and a method for objects inheriting from class"lm".
Minimise a function subject to linear inequality constraints using anadaptive barrier algorithm.
Return a matrix of contrasts.
Return a matrix of contrasts.
Return a matrix of contrasts.
Return a matrix of contrasts.
Return a matrix of contrasts.
Set and view the contrasts associated with a factor.
Set and view the contrasts associated with a factor.
Use the Fast Fourier Transform to compute the several kinds ofconvolutions of two sequences.
This suite of functions can be used to compute some of the regression(leave-one-out deletion) diagnostics for linear and generalized linearmodels discussed in Belsley, Kuh and Welsch (1980), Cook and Weisberg (1982),etc.
Computes the cophenetic distances for a hierarchical clustering.
var, cov and cor compute the variance of xand the covariance or correlation of x and y if theseare vectors.   If x and y are matrices then thecovariances (or correlations) between the columns of x and thecolumns of y are computed.
Test for association between paired samples, using one ofPearson's product moment correlation coefficient,Kendall's tau or Spearman's rho.
var, cov and cor compute the variance of xand the covariance or correlation of x and y if theseare vectors.   If x and y are matrices then thecovariances (or correlations) between the columns of x and thecolumns of y are computed.
Returns a list containing estimates of the weighted covariance matrixand the mean of the data, and optionally of the (weighted) correlationmatrix.
var, cov and cor compute the variance of xand the covariance or correlation of x and y if theseare vectors.   If x and y are matrices then thecovariances (or correlations) between the columns of x and thecolumns of y are computed.
This suite of functions can be used to compute some of the regression(leave-one-out deletion) diagnostics for linear and generalized linearmodels discussed in Belsley, Kuh and Welsch (1980), Cook and Weisberg (1982),etc.
Plots a cumulative periodogram.
Cuts a tree, e.g., as resulting from hclust, into severalgroups either by specifying the desired number(s) of groups or the cutheight(s).
time creates the vector of times at which a time series was sampled.
Compute derivatives of simple expressions, symbolically and algorithmically.
Density, distribution function, quantile function and randomgeneration for the Beta distribution with parameters shape1 andshape2 (and optional non-centrality parameter ncp).
Density, distribution function, quantile function and randomgeneration for the binomial distribution with parameters sizeand prob.
Density, distribution function, quantile function and randomgeneration for the Cauchy distribution with location parameterlocation and scale parameter scale.
Density, distribution function, quantile function and randomgeneration for the chi-squared (chi^2) distribution withdf degrees of freedom and optional non-centrality parameterncp.
Decompose a time series into seasonal, trend and irregular componentsusing moving averages.  Deals with additive or multiplicativeseasonal component.
delete.response returns a terms object for the samemodel but with no response variable.
time creates the vector of times at which a time series was sampled.
Apply function FUN to each node of a dendrogramrecursively.  When  y <- dendrapply(x, fn), then y is adendrogram of the same graph structure as x and for each node,y.node[j] <- FUN( x.node[j], ...) (where y.node[j] is an(invalid!) notation for the j-th node of y).
The (S3) generic function density computes kernel densityestimates.  Its default method does so with the given kernel andbandwidth for univariate observations.
The (S3) generic function density computes kernel densityestimates.  Its default method does so with the given kernel andbandwidth for univariate observations.
Compute derivatives of simple expressions, symbolically and algorithmically.
Compute derivatives of simple expressions, symbolically and algorithmically.
Returns the deviance of a fitted model object.
Density, distribution function, quantile function and randomgeneration for the exponential distribution with rate rate(i.e., mean 1/rate).
Density, distribution function, quantile function and randomgeneration for the F distribution with df1 and df2degrees of freedom (and optional non-centrality parameter ncp).
The "tskernel" class is designed to represent discretesymmetric normalized smoothing kernels.  These kernels can be used tosmooth vectors, matrices, or time series objects.
Returns the residual degrees-of-freedom extracted from a fitted modelobject.
The generic function formula and its specific methods provide away of extracting formulae which have been included in other objects.
This suite of functions can be used to compute some of the regression(leave-one-out deletion) diagnostics for linear and generalized linearmodels discussed in Belsley, Kuh and Welsch (1980), Cook and Weisberg (1982),etc.
This suite of functions can be used to compute some of the regression(leave-one-out deletion) diagnostics for linear and generalized linearmodels discussed in Belsley, Kuh and Welsch (1980), Cook and Weisberg (1982),etc.
This suite of functions can be used to compute some of the regression(leave-one-out deletion) diagnostics for linear and generalized linearmodels discussed in Belsley, Kuh and Welsch (1980), Cook and Weisberg (1982),etc.
Density, distribution function, quantile function and randomgeneration for the Gamma distribution with parameters shape andscale.
Density, distribution function, quantile function and randomgeneration for the geometric distribution with parameter prob.
Density, distribution function, quantile function and randomgeneration for the hypergeometric distribution.
Computes the inverse function of the lagged differences functiondiff.
This function computes and returns the distance matrix computed byusing the specified distance measure to compute the distances betweenthe rows of a data matrix.
Density, distribution function, quantile function and randomgeneration for the log normal distribution whose logarithm has meanequal to meanlog and standard deviation equal to sdlog.
Density, distribution function, quantile function and randomgeneration for the logistic distribution with parameterslocation and scale.
Generate multinomially distributed random number vectors andcompute multinomial probabilities.
Density, distribution function, quantile function and randomgeneration for the negative binomial distribution with parameterssize and prob.
Density, distribution function, quantile function and randomgeneration for the normal distribution with mean equal to meanand standard deviation equal to sd.
Density, distribution function, quantile function and randomgeneration for the Poisson distribution with parameter lambda.
add.scope and drop.scope compute those terms that can beindividually added to or dropped from a model while respecting thehierarchy of terms.
delete.response returns a terms object for the samemodel but with no response variable.
Compute all the single terms in the scope argument that can beadded to or dropped from the model, fit those models and compute atable of the changes in fit.
Density, distribution function, quantile function and randomgeneration for the distribution of the Wilcoxon Signed Rank statisticobtained from a sample with size n.
Density, distribution function, quantile function and randomgeneration for the t distribution with df degrees of freedom(and optional non-centrality parameter ncp).
This extracts coefficients in terms of the original levels of thecoefficients rather than the coded variables.
This extracts coefficients in terms of the original levels of thecoefficients rather than the coded variables.
These functions provide information about the uniform distributionon the interval from min to max.  dunif gives thedensity, punif gives the distribution function qunifgives the quantile function and runif generates randomdeviates.
Density, distribution function, quantile function and randomgeneration for the Weibull distribution with parameters shapeand scale.
Density, distribution function, quantile function and randomgeneration for the distribution of the Wilcoxon rank sum statisticobtained from samples with size m and n, respectively.
Compute an empirical cumulative distribution function, with severalmethods for plotting, printing and computing with such an“ecdf” object.
Computes the efficiencies of fixed-effect terms in an analysis ofvariance model with multiple strata.
Returns (orthogonal) effects from a fitted model, usually a linearmodel. This is a generic function, but currently only has a methods forobjects inheriting from classes "lm" and "glm".
Embeds the time series x into a low-dimensionalEuclidean space.
Extract and encode the times the first and last observations weretaken. Provided only for compatibility with S version 2.
Functions to compute matrix of residual sums of squares and products,or the estimated variance matrix for multivariate linear models.
Evaluates new variables as if they had been part of the formula of thespecified model.  This ensures that the same na.action andsubset arguments are applied and allows, for example, xto be recovered for a model using sin(x) as a predictor.
Computes the (generalized) Akaike An InformationCriterion for a fitted parametric model.
Perform maximum-likelihood factor analysis on a covariance matrix ordata matrix.
add.scope and drop.scope compute those terms that can beindividually added to or dropped from a model while respecting thehierarchy of terms.
Family objects provide a convenient way to specify the details of themodels used by functions such as glm.  See thedocumentation for glm for the details on how such modelfitting takes place.
Computes the Discrete Fourier Transform (DFT) of an array with a fastalgorithm, the “Fast Fourier Transform” (FFT).
Applies linear filtering to a univariate time series or to each seriesseparately of a multivariate time series.
Performs Fisher's exact test for testing the null of independence ofrows and columns in a contingency table with fixed marginals.
fitted is a generic function which extracts fitted values fromobjects returned by modeling functions.  fitted.values is analias for it.
fitted is a generic function which extracts fitted values fromobjects returned by modeling functions.  fitted.values is analias for it.
Returns Tukey's five number summary (minimum, lower-hinge, median,upper-hinge, maximum) for the input data.
Performs a Fligner-Killeen (median) test of the null that thevariances in each of the groups (samples) are the same.
The generic function formula and its specific methods provide away of extracting formulae which have been included in other objects.
time creates the vector of times at which a time series was sampled.
Performs a Friedman rank sum test with unreplicated blocked data.
Create ‘flat’ contingency tables.
Family objects provide a convenient way to specify the details of themodels used by functions such as glm.  See thedocumentation for glm for the details on how such modelfitting takes place.
Family objects provide a convenient way to specify the details of themodels used by functions such as glm.  See thedocumentation for glm for the details on how such modelfitting takes place.
model.frame (a generic function) and its methods return adata.frame with the variables needed to useformula and any ... arguments.
update will update and (by default) re-fit a model.  It does thisby extracting the call stored in the object, updating the call and (bydefault) evaluating that call.  Sometimes it is useful to callupdate with only one argument, for example if the data frame hasbeen corrected.
This function evaluates initial parameter estimates for a nonlinearregression model.  If data is a parameterized data frame orpframe object, its parameters attribute is returned.Otherwise the object is examined to see if it contains a call to aselfStart object whose initial attribute can beevaluated.
glm is used to fit generalized linear models, specified bygiving a symbolic description of the linear predictor and adescription of the error distribution.
Auxiliary function for glm fitting.Typically only used internally by glm.fit, but may beused to construct a control argument to either function.
glm is used to fit generalized linear models, specified bygiving a symbolic description of the linear predictor and adescription of the error distribution.
tsp returns the tsp attribute (or NULL).It is included for compatibility with S version 2. tsp<-sets the tsp attribute. hasTsp ensures x has atsp attribute, by adding one if needed.
This suite of functions can be used to compute some of the regression(leave-one-out deletion) diagnostics for linear and generalized linearmodels discussed in Belsley, Kuh and Welsch (1980), Cook and Weisberg (1982),etc.
This suite of functions can be used to compute some of the regression(leave-one-out deletion) diagnostics for linear and generalized linearmodels discussed in Belsley, Kuh and Welsch (1980), Cook and Weisberg (1982),etc.
Hierarchical cluster analysis on a set of dissimilarities andmethods for analyzing it.
A heat map is a false color image (basicallyimage(t(x))) with a dendrogram added to the left sideand to the top.  Typically, reordering of the rows and columnsaccording to some set of values (row or column means) within therestrictions imposed by the dendrogram is carried out.
Computes Holt-Winters Filtering of a given time series.Unknown parameters are determined by minimizing the squaredprediction error.
This function provides the basic quantities which areused in forming a wide variety of diagnostics forchecking the quality of regression fits.
This suite of functions can be used to compute some of the regression(leave-one-out deletion) diagnostics for linear and generalized linearmodels discussed in Belsley, Kuh and Welsch (1980), Cook and Weisberg (1982),etc.
Adaptive quadrature of functions of one variable over a finite orinfinite interval.
Plots the mean (or other summary) of the response for two-waycombinations of factors, thereby illustrating possible interactions.
Family objects provide a convenient way to specify the details of themodels used by functions such as glm.  See thedocumentation for glm for the details on how such modelfitting takes place.
computes interquartile range of the x values.
R's formula notation allows models with no intercept and nopredictors. These require special handling internally.is.empty.model() checks whether an object describes an emptymodel.
Class "dendrogram" provides general functions for handlingtree-like structures.  It is intended as a replacement for similarfunctions in hierarchical clustering and classification/regressiontrees, such that all of these can use the same engine for plotting orcutting trees.
The function ts is used to create time-series objects.
Given the vectors (x[1], …, x[n]) and(y[0], y[1], …, y[n]) (one valuemore!), stepfun(x, y, ...) returns an interpolating‘step’ function, say fn. I.e., fn(t) =    c[i] (constant) for t in (    x[i], x[i+1]) and at the abscissa values, if (by default)right = FALSE, fn(x[i]) = y[i] and forright = TRUE, fn(x[i]) = y[i-1], fori=1, …, n.
The function ts is used to create time-series objects.
The "tskernel" class is designed to represent discretesymmetric normalized smoothing kernels.  These kernels can be used tosmooth vectors, matrices, or time series objects.
Compute the isotonic (monotonely increasing nonparametric) leastsquares regression which is piecewise constant.
Use Kalman Filtering to find the (Gaussian) log-likelihood, or forforecasting or smoothing.
Use Kalman Filtering to find the (Gaussian) log-likelihood, or forforecasting or smoothing.
Use Kalman Filtering to find the (Gaussian) log-likelihood, or forforecasting or smoothing.
Use Kalman Filtering to find the (Gaussian) log-likelihood, or forforecasting or smoothing.
kernapply computes the convolution between an input sequenceand a specific kernel.
The "tskernel" class is designed to represent discretesymmetric normalized smoothing kernels.  These kernels can be used tosmooth vectors, matrices, or time series objects.
Perform k-means clustering on a data matrix.
Given the vectors (x[1], …, x[n]) and(y[0], y[1], …, y[n]) (one valuemore!), stepfun(x, y, ...) returns an interpolating‘step’ function, say fn. I.e., fn(t) =    c[i] (constant) for t in (    x[i], x[i+1]) and at the abscissa values, if (by default)right = FALSE, fn(x[i]) = y[i] and forright = TRUE, fn(x[i]) = y[i-1], fori=1, …, n.
Performs a Kruskal-Wallis rank sum test.
Perform a one- or two-sample Kolmogorov-Smirnov test.
The Nadaraya–Watson kernel regression estimate.
Compute a lagged version of a time series, shifting the time baseback by a given number of observations.
Plot time series against lagged versions of themselves.Helps visualizing ‘auto-dependence’ even when auto-correlationsvanish.
Fit a line robustly as recommended in Exploratory Data Analysis.
lm is used to fit linear models.It can be used to carry out regression,single stratum analysis of variance andanalysis of covariance (although aov may provide a moreconvenient interface for these).
These are the basic computing engines called by lm usedto fit linear models.  These should usually not be useddirectly unless by experienced users.  .lm.fit() is bare bonewrapper to the innermost QR-based C code, on whichglm.fit and lsfit are based as well, foreven more experienced users.
This function provides the basic quantities which areused in forming a wide variety of diagnostics forchecking the quality of regression fits.
These are the basic computing engines called by lm usedto fit linear models.  These should usually not be useddirectly unless by experienced users.  .lm.fit() is bare bonewrapper to the innermost QR-based C code, on whichglm.fit and lsfit are based as well, foreven more experienced users.
Extract or print loadings in factor analysis (or principalcomponents analysis).
Fit a polynomial surface determined by one or more numericalpredictors, using local fitting.
Set control parameters for loess fits.
Plot and add a smooth curve computed by loess to a scatter plot.
This function is generic; method functions can be written to handlespecific classes of objects.  Classes which have methods for thisfunction include: "glm", "lm", "nls" and"Arima".  Packages contain methods for other classes, such as"fitdistr", "negbin" and "polr" in packageMASS, "multinom" in package nnet and"gls", "gnls" "lme" and others in packagenlme.
loglin is used to fit log-linear models to multidimensionalcontingency tables by Iterative Proportional Fitting.
This function performs the computations for theLOWESS smoother which uses locally-weighted polynomialregression (see the references).
Computes basic statistics, including standard errors, t- and p-valuesfor the regression coefficients.
Computes basic statistics, including standard errors, t- and p-valuesfor the regression coefficients and prints them if print.it isTRUE.
The least squares estimate of b in the model
Compute the median absolute deviation, i.e., the (lo-/hi-) median ofthe absolute deviations from the median, and (by default) adjust by afactor for asymptotically normal consistency.
Returns the squared Mahalanobis distance of all rows in x and thevector mu = center with respect toSigma = cov.This is (for vector x) defined as
This function is used with the family functions inglm().Given the name of a link, it returns a link function, an inverse linkfunction, the derivative dmu/deta and a functionfor domain checking.
Use Kalman Filtering to find the (Gaussian) log-likelihood, or forforecasting or smoothing.
A utility to help model.frame.default create the rightmatrices when predicting from models with terms like (univariate)poly or ns.
A class for the multivariate analysis of variance.
Performs a Cochran-Mantel-Haenszel chi-squared test of the null thattwo nominal variables are conditionally independent in each stratum,assuming that there is no three-way interaction.
Tests whether a Wishart-distributed covariance matrix (ortransformation thereof) is proportional to a given matrix.
Performs McNemar's chi-squared test for symmetry of rows and columnsin a two-dimensional contingency table.
Compute the sample median.
Compute the sample median.
Fits an additive model (twoway decomposition) using Tukey'smedian polish procedure.
Returns the response, offset, subset, weights or otherspecial components of a model frame passed as optional arguments tomodel.frame.
model.frame (a generic function) and its methods return adata.frame with the variables needed to useformula and any ... arguments.
model.frame (a generic function) and its methods return adata.frame with the variables needed to useformula and any ... arguments.
model.matrix creates a design (or model) matrix, e.g., byexpanding factors to a set of dummy variables (depending on thecontrasts) and expanding interactions similarly.
model.matrix creates a design (or model) matrix, e.g., byexpanding factors to a set of dummy variables (depending on thecontrasts) and expanding interactions similarly.
model.matrix creates a design (or model) matrix, e.g., byexpanding factors to a set of dummy variables (depending on thecontrasts) and expanding interactions similarly.
Returns the response, offset, subset, weights or otherspecial components of a model frame passed as optional arguments tomodel.frame.
Returns the response, offset, subset, weights or otherspecial components of a model frame passed as optional arguments tomodel.frame.
Computes summary tables for model fits, especially complex aovfits.
Returns the response, offset, subset, weights or otherspecial components of a model frame passed as optional arguments tomodel.frame.
These functions plot seasonal (or other) subseries of a time series.For each season (or other category), a time series is plotted.
Performs Mood's two-sample test for a difference in scale parameters.
Computes the Discrete Fourier Transform (DFT) of an array with a fastalgorithm, the “Fast Fourier Transform” (FFT).
Extract information on the NA action used to create an object.
Find the longest consecutive stretch of non-missing values in a timeseries object.  (In the event of a tie, the first such stretch.)
These generic functions are useful for dealing with NAsin e.g., data frames.na.fail returns the object if it does not contain anymissing values, and signals an error otherwise.na.omit returns the object with incomplete cases removed.na.pass returns the object unchanged.
These generic functions are useful for dealing with NAsin e.g., data frames.na.fail returns the object if it does not contain anymissing values, and signals an error otherwise.na.omit returns the object with incomplete cases removed.na.pass returns the object unchanged.
These generic functions are useful for dealing with NAsin e.g., data frames.na.fail returns the object if it does not contain anymissing values, and signals an error otherwise.na.omit returns the object with incomplete cases removed.na.pass returns the object unchanged.
These generic functions are useful for dealing with NAsin e.g., data frames.na.fail returns the object if it does not contain anymissing values, and signals an error otherwise.na.omit returns the object with incomplete cases removed.na.pass returns the object unchanged.
Use missing value information to adjust residuals and predictions.
Use missing value information to report the effects of an na.action.
Use missing value information to adjust residuals and predictions.
nextn returns the smallest integer,greater than or equal to n, which can be obtainedas a product of powers of the values contained in factors.
This function carries out a minimization of the function fusing a Newton-type algorithm.  See the references for details.
Unconstrained and box-constrained optimization using PORT routines.
Determine the nonlinear (weighted) least-squares estimates of theparameters of a nonlinear model.
Allow the user to set some characteristics of the nlsnonlinear least squares algorithm.
Fits the asymptotic regression model, in the form b0 +      b1*(1-exp(-exp(lrc) * x)) to the xy data.This can be used as a building block in determining starting estimatesfor more complicated models.
Use inverse linear interpolation to approximate the x value atwhich the function represented by xy is equal to yval.
Provide an initial guess at the horizontal asymptote on the left side(i.e., small values of x) of the graph of y versusx from the xy object.  Primarily used withininitial functions for self-starting nonlinear regressionmodels.
Provide an initial guess at the horizontal asymptote on the right side(i.e., large values of x) of the graph of y versusx from the xy object.  Primarily used withininitial functions for self-starting nonlinear regressionmodels.
Extract the number of ‘observations’ from a model fit.  This isprincipally intended to be used in computing BIC (see AIC).
numericDeriv numerically evaluates the gradient of an expression.
An offset is a term to be added to a linear predictor, such as in ageneralised linear model, with known coefficient 1 rather than anestimated coefficient.
Test whether two or more samples from normal distributions have thesame means.  The variances are not necessarily assumed to be equal.
General-purpose optimization based on Nelder–Mead, quasi-Newton andconjugate-gradient algorithms. It includes an option forbox-constrained optimization and simulated annealing.
General-purpose optimization based on Nelder–Mead, quasi-Newton andconjugate-gradient algorithms. It includes an option forbox-constrained optimization and simulated annealing.
The function optimize searches the interval fromlower to upper for a minimum or maximum ofthe function f with respect to its first argument.
The function optimize searches the interval fromlower to upper for a minimum or maximum ofthe function f with respect to its first argument.
Theses functions return the order (index) or the "label"attribute for the leaves in adendrogram.  These indices can then be used to access the appropriatecomponents of any additional data.
Given a set of p-values, returns p-values adjusted usingone of several methods.
Given a set of p-values, returns p-values adjusted usingone of several methods.
The function acf computes (and by default plots) estimates ofthe autocovariance or autocorrelation function.  Function pacfis the function used for the partial autocorrelations.  Functionccf computes the cross-correlation or cross-covariance of twounivariate series.
Combines two vectors into an object of class "Pair"
Calculate pairwise comparisons between pairs of proportions withcorrection for multiple testing
Calculate pairwise comparisons between group levels with correctionsfor multiple testing
Creates  table of p values for pairwise comparisonswith corrections for multiple testing.
Calculate pairwise comparisons between group levels with correctionsfor multiple testing.
Density, distribution function, quantile function and randomgeneration for the Beta distribution with parameters shape1 andshape2 (and optional non-centrality parameter ncp).
Density, distribution function, quantile function and randomgeneration for the binomial distribution with parameters sizeand prob.
Computes answers to a generalised birthday paradox problem.pbirthday computes the probability of a coincidence andqbirthday computes the smallest number of observations neededto have at least a specified probability of coincidence.
Density, distribution function, quantile function and randomgeneration for the Cauchy distribution with location parameterlocation and scale parameter scale.
Density, distribution function, quantile function and randomgeneration for the chi-squared (chi^2) distribution withdf degrees of freedom and optional non-centrality parameterncp.
Density, distribution function, quantile function and randomgeneration for the exponential distribution with rate rate(i.e., mean 1/rate).
Density, distribution function, quantile function and randomgeneration for the F distribution with df1 and df2degrees of freedom (and optional non-centrality parameter ncp).
Density, distribution function, quantile function and randomgeneration for the Gamma distribution with parameters shape andscale.
Density, distribution function, quantile function and randomgeneration for the geometric distribution with parameter prob.
Density, distribution function, quantile function and randomgeneration for the hypergeometric distribution.
The functions or variables listed here are no longer part of R asthey are not needed (any more).
Density, distribution function, quantile function and randomgeneration for the log normal distribution whose logarithm has meanequal to meanlog and standard deviation equal to sdlog.
Density, distribution function, quantile function and randomgeneration for the logistic distribution with parameterslocation and scale.
Compute an empirical cumulative distribution function, with severalmethods for plotting, printing and computing with such an“ecdf” object.
Plotting method for objects of class "spec".  For multivariatetime series it plots the marginal spectra of the series or pairs plotsof the coherency and phase of the cross-spectra.
Plotting method for objects of class "spec".  For multivariatetime series it plots the marginal spectra of the series or pairs plotsof the coherency and phase of the cross-spectra.
Method of the generic plot for stepfunobjects and utility for plotting piecewise constant functions.
Plotting method for objects inheriting from class "ts".
Density, distribution function, quantile function and randomgeneration for the negative binomial distribution with parameterssize and prob.
Density, distribution function, quantile function and randomgeneration for the normal distribution with mean equal to meanand standard deviation equal to sd.
Family objects provide a convenient way to specify the details of themodels used by functions such as glm.  See thedocumentation for glm for the details on how such modelfitting takes place.
Performs an exact test of a simple null hypothesis about therate parameter in Poisson distribution, or for theratio between two rate parameters.
Returns or evaluates orthogonal polynomials of degree 1 todegree over the specified set of points x: these are allorthogonal to the constant polynomial of degree 0.  Alternatively,evaluate raw polynomials.
Returns or evaluates orthogonal polynomials of degree 1 todegree over the specified set of points x: these are allorthogonal to the constant polynomial of degree 0.  Alternatively,evaluate raw polynomials.
Creates a link object based on the link functionη = μ ^ λ.
Compute power of test or determine parameters to obtain target power.
Compute the power of the two-sample test for proportions, or determineparameters to obtain a target power.
Compute the power of the one- or two- sample t test,or determine parameters to obtain a target power.
Computes the Phillips-Perron test for the null hypothesis thatx has a unit root against a stationary alternative.
Generates the sequence of probability points(1:m - a)/(m + (1-a)-a)where m is either n, if length(n)==1, orlength(n).
Density, distribution function, quantile function and randomgeneration for the Poisson distribution with parameter lambda.
Fit a projection pursuit regression model.
Performs a principal components analysis on the given data matrixand returns the results as an object of class prcomp.
predict is a generic function for predictions from the results ofvarious model fitting functions.  The function invokes particularmethods which depend on the class ofthe first argument.
Obtains predictions and optionally estimates standard errors of thosepredictions from a fitted generalized linear model object.
Predicted values based on linear model object.
Compute an object to be used for plots relating to the given model object.
princomp performs a principal components analysis on the givennumeric data matrix and returns the results as an object of classprincomp.
Utility function to be used in higher-level printmethods, such as those for summary.lm,summary.glm and anova.  Thegoal is to provide a flexible interface with smart defaults suchthat often, only x needs to be specified.
Investigates behavior of objective function near the solutionrepresented by fitted.
proj returns a matrix or list of matrices giving the projectionsof the data onto the terms of a linear model.  It is most frequentlyused for aov models.
These functions ‘rotate’ loading matrices in factor analysis.
prop.test can be used for testing the null that theproportions (probabilities of success) in several groups are thesame, or that they equal certain given values.
Performs chi-squared test for trend in proportions, i.e., a testasymptotically optimal for local alternatives where the log odds varyin proportion with score.  By default, score is chosenas the group numbers.
Density, distribution function, quantile function and randomgeneration for the distribution of the Wilcoxon Signed Rank statisticobtained from a sample with size n.
Density, distribution function, quantile function and randomgeneration for the t distribution with df degrees of freedom(and optional non-centrality parameter ncp).
Functions of the distribution of the studentized range, R/s,where R is the range of a standard normal sample anddf*s^2 is independently distributed aschi-squared with df degrees of freedom, see pchisq.
These functions provide information about the uniform distributionon the interval from min to max.  dunif gives thedensity, punif gives the distribution function qunifgives the quantile function and runif generates randomdeviates.
Density, distribution function, quantile function and randomgeneration for the Weibull distribution with parameters shapeand scale.
Density, distribution function, quantile function and randomgeneration for the distribution of the Wilcoxon rank sum statisticobtained from samples with size m and n, respectively.
Density, distribution function, quantile function and randomgeneration for the Beta distribution with parameters shape1 andshape2 (and optional non-centrality parameter ncp).
Density, distribution function, quantile function and randomgeneration for the binomial distribution with parameters sizeand prob.
Computes answers to a generalised birthday paradox problem.pbirthday computes the probability of a coincidence andqbirthday computes the smallest number of observations neededto have at least a specified probability of coincidence.
Density, distribution function, quantile function and randomgeneration for the Cauchy distribution with location parameterlocation and scale parameter scale.
Density, distribution function, quantile function and randomgeneration for the chi-squared (chi^2) distribution withdf degrees of freedom and optional non-centrality parameterncp.
Density, distribution function, quantile function and randomgeneration for the exponential distribution with rate rate(i.e., mean 1/rate).
Density, distribution function, quantile function and randomgeneration for the F distribution with df1 and df2degrees of freedom (and optional non-centrality parameter ncp).
Density, distribution function, quantile function and randomgeneration for the Gamma distribution with parameters shape andscale.
Density, distribution function, quantile function and randomgeneration for the geometric distribution with parameter prob.
Density, distribution function, quantile function and randomgeneration for the hypergeometric distribution.
Density, distribution function, quantile function and randomgeneration for the log normal distribution whose logarithm has meanequal to meanlog and standard deviation equal to sdlog.
Density, distribution function, quantile function and randomgeneration for the logistic distribution with parameterslocation and scale.
Density, distribution function, quantile function and randomgeneration for the negative binomial distribution with parameterssize and prob.
Density, distribution function, quantile function and randomgeneration for the normal distribution with mean equal to meanand standard deviation equal to sd.
Density, distribution function, quantile function and randomgeneration for the Poisson distribution with parameter lambda.
qqnorm is a generic function the default method of whichproduces a normal QQ plot of the values in y.qqline adds a line to a “theoretical”, by defaultnormal, quantile-quantile plot which passes through the probsquantiles, by default the first and third quartiles.
qqnorm is a generic function the default method of whichproduces a normal QQ plot of the values in y.qqline adds a line to a “theoretical”, by defaultnormal, quantile-quantile plot which passes through the probsquantiles, by default the first and third quartiles.
qqnorm is a generic function the default method of whichproduces a normal QQ plot of the values in y.qqline adds a line to a “theoretical”, by defaultnormal, quantile-quantile plot which passes through the probsquantiles, by default the first and third quartiles.
Density, distribution function, quantile function and randomgeneration for the distribution of the Wilcoxon Signed Rank statisticobtained from a sample with size n.
Density, distribution function, quantile function and randomgeneration for the t distribution with df degrees of freedom(and optional non-centrality parameter ncp).
Functions of the distribution of the studentized range, R/s,where R is the range of a standard normal sample anddf*s^2 is independently distributed aschi-squared with df degrees of freedom, see pchisq.
Performs a Quade test with unreplicated blocked data.
The generic function quantile produces sample quantilescorresponding to the given probabilities.The smallest observation corresponds to a probability of 0 and thelargest to a probability of 1.
Family objects provide a convenient way to specify the details of themodels used by functions such as glm.  See thedocumentation for glm for the details on how such modelfitting takes place.
Family objects provide a convenient way to specify the details of themodels used by functions such as glm.  See thedocumentation for glm for the details on how such modelfitting takes place.
Family objects provide a convenient way to specify the details of themodels used by functions such as glm.  See thedocumentation for glm for the details on how such modelfitting takes place.
These functions provide information about the uniform distributionon the interval from min to max.  dunif gives thedensity, punif gives the distribution function qunifgives the quantile function and runif generates randomdeviates.
Density, distribution function, quantile function and randomgeneration for the Weibull distribution with parameters shapeand scale.
Density, distribution function, quantile function and randomgeneration for the distribution of the Wilcoxon rank sum statisticobtained from samples with size m and n, respectively.
Generate random 2-way tables with given marginals using Patefield'salgorithm.
Density, distribution function, quantile function and randomgeneration for the Beta distribution with parameters shape1 andshape2 (and optional non-centrality parameter ncp).
Density, distribution function, quantile function and randomgeneration for the binomial distribution with parameters sizeand prob.
Density, distribution function, quantile function and randomgeneration for the Cauchy distribution with location parameterlocation and scale parameter scale.
Density, distribution function, quantile function and randomgeneration for the chi-squared (chi^2) distribution withdf degrees of freedom and optional non-centrality parameterncp.
Read, write and coerce ‘flat’ (contingency) tables, akaftables.
Draws rectangles around the branches of a dendrogram highlighting thecorresponding clusters. First the dendrogram is cut at a certainlevel, then a rectangle is drawn around selected branches.
delete.response returns a terms object for the samemodel but with no response variable.
The levels of a factor are re-ordered so that the level specified byref is first and the others are moved down. This is usefulfor contr.treatment contrasts which take the first level asthe reference.
reorder is a generic function.  The "default" methodtreats its first argument as a categorical variable, and reorders itslevels based on the values of a second variable, usually numeric.
Returns a vector or a list of the number of replicates foreach term in the formula.
This function reshapes a data frame between ‘wide’ format (withrepeated measurements in separate columns of the same row) and‘long’ format (with the repeated measurements in separaterows).
residuals is a generic function which extracts model residualsfrom objects returned by modeling functions.
residuals is a generic function which extracts model residualsfrom objects returned by modeling functions.
These functions are all methods for class glm orsummary.glm objects.
All these functions are methods for class "lm"  objects.
Density, distribution function, quantile function and randomgeneration for the exponential distribution with rate rate(i.e., mean 1/rate).
Density, distribution function, quantile function and randomgeneration for the F distribution with df1 and df2degrees of freedom (and optional non-centrality parameter ncp).
Density, distribution function, quantile function and randomgeneration for the Gamma distribution with parameters shape andscale.
Density, distribution function, quantile function and randomgeneration for the geometric distribution with parameter prob.
Density, distribution function, quantile function and randomgeneration for the hypergeometric distribution.
Density, distribution function, quantile function and randomgeneration for the log normal distribution whose logarithm has meanequal to meanlog and standard deviation equal to sdlog.
Density, distribution function, quantile function and randomgeneration for the logistic distribution with parameterslocation and scale.
Generate multinomially distributed random number vectors andcompute multinomial probabilities.
Density, distribution function, quantile function and randomgeneration for the negative binomial distribution with parameterssize and prob.
Density, distribution function, quantile function and randomgeneration for the normal distribution with mean equal to meanand standard deviation equal to sd.
Density, distribution function, quantile function and randomgeneration for the Poisson distribution with parameter lambda.
Density, distribution function, quantile function and randomgeneration for the distribution of the Wilcoxon Signed Rank statisticobtained from a sample with size n.
This suite of functions can be used to compute some of the regression(leave-one-out deletion) diagnostics for linear and generalized linearmodels discussed in Belsley, Kuh and Welsch (1980), Cook and Weisberg (1982),etc.
This suite of functions can be used to compute some of the regression(leave-one-out deletion) diagnostics for linear and generalized linearmodels discussed in Belsley, Kuh and Welsch (1980), Cook and Weisberg (1982),etc.
Density, distribution function, quantile function and randomgeneration for the t distribution with df degrees of freedom(and optional non-centrality parameter ncp).
These functions provide information about the uniform distributionon the interval from min to max.  dunif gives thedensity, punif gives the distribution function qunifgives the quantile function and runif generates randomdeviates.
Compute running medians of odd span.  This is the ‘most robust’scatter plot smoothing possible.  For efficiency (and historicalreason), you can use one of two different algorithms giving identicalresults.
Density, distribution function, quantile function and randomgeneration for the Weibull distribution with parameters shapeand scale.
Density, distribution function, quantile function and randomgeneration for the distribution of the Wilcoxon rank sum statisticobtained from samples with size m and n, respectively.
Generate n random matrices, distributed according to theWishart distribution with parameters Sigma and df,W_p(Sigma, df).
Plot and add a smooth curve computed by loess to a scatter plot.
screeplot.default plots the variances against the number of theprincipal component. This is also the plot method for classes"princomp" and "prcomp".
This function computes the standard deviation of the values inx.If na.rm is TRUE then missing values are removed beforecomputation proceeds.
Returns the standard errors for one or more contrasts in an aovobject.
Construct self-starting nonlinear models to be used innls, etc.  Via function initial to computeapproximate parameter values from data, such models are“self-starting”, i.e., do not need a start argument in,e.g., nls().
This is a convenience function that sets the names on an object andreturns the object.  It is most useful at the end of a functiondefinition where one is creating the object to be returned and wouldprefer not to store it under a name just so the names can be assigned.
Performs the Shapiro-Wilk test of normality.
Extract the estimated standard deviation of the errors, the“residual standard deviation” (misnamed also“residual standard error”, e.g., insummary.lm()'s output, from a fitted model).
Simulate one or more responses from the distributioncorresponding to a fitted model object.
Tukey's smoothers, 3RS3R, 3RSS, 3R, etc.
Fits a cubic smoothing spline to the supplied data.
Smooth end points of a vector y using subsequently smallermedians and Tukey's end point rule at the very end. (of odd span),
This is a constructor function for the class of sortedXyDataobjects.  These objects are mostly used in the initialfunction for a self-starting nonlinear regression model, which will beof the selfStart class.
Fits an AR model to x (or uses the existing fit) and computes(and by default plots) the spectral density of the fitted model.
spec.pgram calculates the periodogram using a fast Fouriertransform, and optionally smooths the result with a series ofmodified Daniell smoothers (moving averages giving half weight tothe end values).
Apply a cosine-bell taper to a time series.
The spectrum function estimates the spectral density of atime series.
Perform cubic (or Hermite) spline interpolation of given data points,returning either a list of points obtained by the interpolation or afunction performing the interpolation.
Perform cubic (or Hermite) spline interpolation of given data points,returning either a list of points obtained by the interpolation or afunction performing the interpolation.
Perform cubic (or Hermite) spline interpolation of given data points,returning either a list of points obtained by the interpolation or afunction performing the interpolation.
This selfStart model evaluates the asymptotic regressionfunction and its gradient.  It has an initial attribute thatwill evaluate initial estimates of the parameters Asym, R0,and lrc for a given set of data.
This selfStart model evaluates an alternative parametrizationof the asymptoticregression function and the gradient with respect to those parameters.It has an initialattribute that creates initial estimates of the parametersAsym, lrc, and c0.
This selfStart model evaluates the asymptotic regressionfunction through the origin and its gradient.  It has aninitial attribute that will evaluate initial estimates of theparameters Asym and lrc for a given set of data.
This selfStart model evaluates the biexponential model functionand its gradient.  It has an initial attribute thatcreates initial estimates of the parameters A1, lrc1,A2, and lrc2.
Functions to compute matrix of residual sums of squares and products,or the estimated variance matrix for multivariate linear models.
This selfStart model evaluates the first-order compartmentfunction and its gradient.  It has an initial attribute thatcreates initial estimates of the parameters lKe, lKa,and lCl.
This selfStart model evaluates the four-parameter logisticfunction and its gradient.  It has an initial attribute computinginitial estimates of the parameters A, B,xmid, and scal for a given set of data.
This selfStart model evaluates the Gompertz growth modeland its gradient.  It has an initial attribute thatcreates initial estimates of the parameters Asym,b2, and b3.
This selfStart model evaluates the logisticfunction and its gradient.  It has an initial attribute thatcreates initial estimates of the parameters Asym,xmid, and scal.   In R 3.4.2 and earlier, thatinit function failed when min(input) was exactly zero.
This selfStart model evaluates the Michaelis-Menten model andits gradient.  It has an initial attribute thatwill evaluate initial estimates of the parameters Vm and K
This selfStart model evaluates the Weibull model for growthcurve data and its gradient.  It has an initial attribute thatwill evaluate initial estimates of the parameters Asym, Drop,lrc, and pwr for a given set of data.
Extract and encode the times the first and last observations weretaken. Provided only for compatibility with S version 2.
This is a utility function, used in lm andglm methods for anova(..., test != NULL)and should not be used by the average user.
Select a formula-based model by AIC.
Given the vectors (x[1], …, x[n]) and(y[0], y[1], …, y[n]) (one valuemore!), stepfun(x, y, ...) returns an interpolating‘step’ function, say fn. I.e., fn(t) =    c[i] (constant) for t in (    x[i], x[i+1]) and at the abscissa values, if (by default)right = FALSE, fn(x[i]) = y[i] and forright = TRUE, fn(x[i]) = y[i-1], fori=1, …, n.
Decompose a time series into seasonal, trend and irregular componentsusing loess, acronym STL.
Fit a structural model for a time series by maximum likelihood.
Summarize an analysis of variance model.
These functions are all methods for class glm orsummary.glm objects.
summary method for class "lm".
A summary method for class "manova".
Given the vectors (x[1], …, x[n]) and(y[0], y[1], …, y[n]) (one valuemore!), stepfun(x, y, ...) returns an interpolating‘step’ function, say fn. I.e., fn(t) =    c[i] (constant) for t in (    x[i], x[i+1]) and at the abscissa values, if (by default)right = FALSE, fn(x[i]) = y[i] and forright = TRUE, fn(x[i]) = y[i-1], fori=1, …, n.
Smooth the (x, y) values by Friedman's ‘super smoother’.
Symbolically encode a given numeric or logical vector or array.Particularly useful for visualization of structured matrices,e.g., correlation, sparse, or logical ones.
Performs one and two sample t-tests on vectors of data.
Plots regression terms against their predictors, optionally withstandard errors and partial residuals added.
The function terms is a generic functionwhich can be used to extract terms objectsfrom various kinds of R data objects.
This function takes a formula and some optional arguments andconstructs a terms object. The terms object can then be used toconstruct a model.matrix.
time creates the vector of times at which a time series was sampled.
Forms a symmetric Toeplitz matrix given its first row.
The function ts is used to create time-series objects.
Bind time series which have a common frequency. ts.union padswith NAs to the total time coverage, ts.intersectrestricts to the time covered by all the series.
Plot several time series on a common plot. Unlikeplot.ts the series can have a different time bases,but they should have the same frequency.
Bind time series which have a common frequency. ts.union padswith NAs to the total time coverage, ts.intersectrestricts to the time covered by all the series.
A generic function to plot time-series diagnostics.
tsp returns the tsp attribute (or NULL).It is included for compatibility with S version 2. tsp<-sets the tsp attribute. hasTsp ensures x has atsp attribute, by adding one if needed.
tsp returns the tsp attribute (or NULL).It is included for compatibility with S version 2. tsp<-sets the tsp attribute. hasTsp ensures x has atsp attribute, by adding one if needed.
Performs fixed-interval smoothing on a univariate time series via astate-space model.  Fixed-interval smoothing gives the best estimateof the state at each time point based on the whole observed series.
Create a set of confidence intervals on the differences between themeans of the levels of a factor with the specified family-wiseprobability of coverage.  The intervals are based on the Studentizedrange statistic, Tukey's ‘Honest Significant Difference’method.
The function uniroot searches the interval from lowerto upper for a root (i.e., zero) of the function f withrespect to its first argument.
update will update and (by default) re-fit a model.  It does thisby extracting the call stored in the object, updating the call and (bydefault) evaluating that call.  Sometimes it is useful to callupdate with only one argument, for example if the data frame hasbeen corrected.
update will update and (by default) re-fit a model.  It does thisby extracting the call stored in the object, updating the call and (bydefault) evaluating that call.  Sometimes it is useful to callupdate with only one argument, for example if the data frame hasbeen corrected.
update.formula is used to update model formulae.This typically involves adding or dropping terms,but updates can be more general.
var, cov and cor compute the variance of xand the covariance or correlation of x and y if theseare vectors.   If x and y are matrices then thecovariances (or correlations) between the columns of x and thecolumns of y are computed.
Performs an F test to compare the variances of two samples from normalpopulations.
Simple utilities returning (non-missing) case names, and(non-eliminated) variable names.
These functions ‘rotate’ loading matrices in factor analysis.
Returns the variance-covariance matrix of the main parameters ofa fitted model object.  The “main” parameters of modelcorrespond to those returned by coef, and typically donot contain a nuisance scale parameter (sigma).
Compute a weighted mean.
Computed weighted residuals from a linear model fit.
weights is a generic function which extracts fitting weights fromobjects returned by modeling functions.
Performs one- and two-sample Wilcoxon tests on vectors of data; thelatter is also known as ‘Mann-Whitney’ test.
window is a generic function whichextracts the subset of the object xobserved between the times start and end. If afrequency is specified, the series is then re-sampled at the newfrequency.
window is a generic function whichextracts the subset of the object xobserved between the times start and end. If afrequency is specified, the series is then re-sampled at the newfrequency.
Read, write and coerce ‘flat’ (contingency) tables, akaftables.
Create a contingency table (optionally a sparse matrix) fromcross-classifying factors, usually contained in a data frame,using a formula interface.
