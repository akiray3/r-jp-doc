x
The unary and binary arithmetic operators are generic functions:methods can be written for them individually or via theOps group generic function.  (SeeOps for how dispatch is computed.)
x does not need to be integer if specified as a numeric vector,but see the comments about fractional days in the help forDates.
There are two basic classes of date/times.  Class "POSIXct"represents the (signed) number of seconds since the beginning of 1970(in the UTC time zone) as a numeric vector.  Class "POSIXlt" isa named list of vectors representing
The binary operator : has two meanings: for factors a:b isequivalent to interaction(a, b) (but the levels areordered and labelled differently).
For a package pkg, pkg::name returns the value of theexported variable name in namespace pkg, whereaspkg:::name returns the value of the internal variablename.  The package namespace will be loaded if it was notloaded before the call, but the package will not be attached to thesearch path.
For a package pkg, pkg::name returns the value of theexported variable name in namespace pkg, whereaspkg:::name returns the value of the internal variablename.  The package namespace will be loaded if it was notloaded before the call, but the package will not be attached to thesearch path.
! indicates logical negation (NOT).
Class "hexmode" consists of integer vectors with that classattribute, used merely to ensure that they are printed in hex.
Class "octmode" consists of integer vectors with that classattribute, used merely to ensure that they are printed in octalnotation, specifically for Unix-like file permissions such as755.  Subsetting ([) works too.
The binary comparison operators are generic functions: methods can bewritten for them individually or via theOps group generic function.  (SeeOps for how dispatch is computed.)
NA
These operators are generic.  You can write methods to handle indexingof specific classes of objects, see InternalMethods as well as[.data.frame and [.factor.  Thedescriptions here apply only to the default methods.  Note thatseparate methods are required for the replacement functions[<-, [[<- and $<- for use when indexing occurs onthe assignment side of an expression.
Function I has two main uses.
Data frames can be indexed in several modes.  When [ and[[ are used with a single vector index (x[i] orx[[i]]), they index the data frame as if it were a list.  Inthis usage a drop argument is ignored, with a warning.
Dates are represented as the number of days since 1970-01-01, withnegative values for earlier dates.  They are always printedfollowing the rules of the current Gregorian calendar, even thoughthat calendar was not in use long ago (it was adopted in 1752 inGreat Britain and its colonies).
Function difftime calculates a difference of two date/timeobjects and returns an object of class "difftime" with anattribute indicating the units.  TheMath group method providesround, signif, floor,ceiling, trunc, abs, andsign methods for objects of this class, and there aremethods for the group-generic (seeOps) logical and arithmeticoperations.
These operators are generic.  You can write methods to handle indexingof specific classes of objects, see InternalMethods as well as[.data.frame and [.factor.  Thedescriptions here apply only to the default methods.  Note thatseparate methods are required for the replacement functions[<-, [[<- and $<- for use when indexing occurs onthe assignment side of an expression.
This queries the internal table that manages the DLLs.
When unused levels are dropped the ordering of the remaining levels ispreserved.
Class "hexmode" consists of integer vectors with that classattribute, used merely to ensure that they are printed in hex.
These operators are generic.  You can write methods to handle indexingof specific classes of objects, see InternalMethods as well as[.data.frame and [.factor.  Thedescriptions here apply only to the default methods.  Note thatseparate methods are required for the replacement functions[<-, [[<- and $<- for use when indexing occurs onthe assignment side of an expression.
noquote returns its argument as an object of class"noquote".  There is a method for c() and subscriptmethod ("[.noquote") which ensures that the class is not lostby subsetting.  The print method (print.noquote) printscharacter strings without quotes ("...." is printed as ....).
Numeric versions are sequences of one or more non-negative integers,usually (e.g., in package ‘DESCRIPTION’ files) represented ascharacter strings with the elements of the sequence concatenated andseparated by single . or - characters.  R packageversions consist of at least two such integers, an R system versionof exactly three (major, minor and patchlevel).
Class "octmode" consists of integer vectors with that classattribute, used merely to ensure that they are printed in octalnotation, specifically for Unix-like file permissions such as755.  Subsetting ([) works too.
There are two basic classes of date/times.  Class "POSIXct"represents the (signed) number of seconds since the beginning of 1970(in the UTC time zone) as a numeric vector.  Class "POSIXlt" isa named list of vectors representing
There are two basic classes of date/times.  Class "POSIXct"represents the (signed) number of seconds since the beginning of 1970(in the UTC time zone) as a numeric vector.  Class "POSIXlt" isa named list of vectors representing
These operators are generic.  You can write methods to handle indexingof specific classes of objects, see InternalMethods as well as[.data.frame and [.factor.  Thedescriptions here apply only to the default methods.  Note thatseparate methods are required for the replacement functions[<-, [[<- and $<- for use when indexing occurs onthe assignment side of an expression.
If the argument dnn is not supplied, the internal functionlist.names is called to compute the ‘dimname names’.  If thearguments in ... are named, those names are used.  For theremaining arguments, deparse.level = 0 gives an empty name,deparse.level = 1 uses the supplied argument if it is a symbol,and deparse.level = 2 will deparse the argument.
See the description of options("warn") for thecircumstances under which there is a last.warning object andwarnings() is used.  In essence this is if options(warn =    0) and warning has been called at least once.
These operators are generic.  You can write methods to handle indexingof specific classes of objects, see InternalMethods as well as[.data.frame and [.factor.  Thedescriptions here apply only to the default methods.  Note thatseparate methods are required for the replacement functions[<-, [[<- and $<- for use when indexing occurs onthe assignment side of an expression.
Data frames can be indexed in several modes.  When [ and[[ are used with a single vector index (x[i] orx[[i]]), they index the data frame as if it were a list.  Inthis usage a drop argument is ignored, with a warning.
Dates are represented as the number of days since 1970-01-01, withnegative values for earlier dates.  They are always printedfollowing the rules of the current Gregorian calendar, even thoughthat calendar was not in use long ago (it was adopted in 1752 inGreat Britain and its colonies).
When unused levels are dropped the ordering of the remaining levels ispreserved.
Numeric versions are sequences of one or more non-negative integers,usually (e.g., in package ‘DESCRIPTION’ files) represented ascharacter strings with the elements of the sequence concatenated andseparated by single . or - characters.  R packageversions consist of at least two such integers, an R system versionof exactly three (major, minor and patchlevel).
There are two basic classes of date/times.  Class "POSIXct"represents the (signed) number of seconds since the beginning of 1970(in the UTC time zone) as a numeric vector.  Class "POSIXlt" isa named list of vectors representing
There are two basic classes of date/times.  Class "POSIXct"represents the (signed) number of seconds since the beginning of 1970(in the UTC time zone) as a numeric vector.  Class "POSIXlt" isa named list of vectors representing
These operators are generic.  You can write methods to handle indexingof specific classes of objects, see InternalMethods as well as[.data.frame and [.factor.  Thedescriptions here apply only to the default methods.  Note thatseparate methods are required for the replacement functions[<-, [[<- and $<- for use when indexing occurs onthe assignment side of an expression.
Data frames can be indexed in several modes.  When [ and[[ are used with a single vector index (x[i] orx[[i]]), they index the data frame as if it were a list.  Inthis usage a drop argument is ignored, with a warning.
When unused levels are dropped the ordering of the remaining levels ispreserved.
Numeric versions are sequences of one or more non-negative integers,usually (e.g., in package ‘DESCRIPTION’ files) represented ascharacter strings with the elements of the sequence concatenated andseparated by single . or - characters.  R packageversions consist of at least two such integers, an R system versionof exactly three (major, minor and patchlevel).
There are two basic classes of date/times.  Class "POSIXct"represents the (signed) number of seconds since the beginning of 1970(in the UTC time zone) as a numeric vector.  Class "POSIXlt" isa named list of vectors representing
These operators are generic.  You can write methods to handle indexingof specific classes of objects, see InternalMethods as well as[.data.frame and [.factor.  Thedescriptions here apply only to the default methods.  Note thatseparate methods are required for the replacement functions[<-, [[<- and $<- for use when indexing occurs onthe assignment side of an expression.
Data frames can be indexed in several modes.  When [ and[[ are used with a single vector index (x[i] orx[[i]]), they index the data frame as if it were a list.  Inthis usage a drop argument is ignored, with a warning.
Dates are represented as the number of days since 1970-01-01, withnegative values for earlier dates.  They are always printedfollowing the rules of the current Gregorian calendar, even thoughthat calendar was not in use long ago (it was adopted in 1752 inGreat Britain and its colonies).
Function difftime calculates a difference of two date/timeobjects and returns an object of class "difftime" with anattribute indicating the units.  TheMath group method providesround, signif, floor,ceiling, trunc, abs, andsign methods for objects of this class, and there aremethods for the group-generic (seeOps) logical and arithmeticoperations.
When unused levels are dropped the ordering of the remaining levels ispreserved.
Numeric versions are sequences of one or more non-negative integers,usually (e.g., in package ‘DESCRIPTION’ files) represented ascharacter strings with the elements of the sequence concatenated andseparated by single . or - characters.  R packageversions consist of at least two such integers, an R system versionof exactly three (major, minor and patchlevel).
There are two basic classes of date/times.  Class "POSIXct"represents the (signed) number of seconds since the beginning of 1970(in the UTC time zone) as a numeric vector.  Class "POSIXlt" isa named list of vectors representing
There are two basic classes of date/times.  Class "POSIXct"represents the (signed) number of seconds since the beginning of 1970(in the UTC time zone) as a numeric vector.  Class "POSIXlt" isa named list of vectors representing
NA
These operators support the formal classes of package methods,and are enabled only when package methods is loaded (as perdefault).  See slot for further details, in particularfor the differences between slot() and the @ operator.
These operators support the formal classes of package methods,and are enabled only when package methods is loaded (as perdefault).  See slot for further details, in particularfor the differences between slot() and the @ operator.
The unary and binary arithmetic operators are generic functions:methods can be written for them individually or via theOps group generic function.  (SeeOps for how dispatch is computed.)
Function difftime calculates a difference of two date/timeobjects and returns an object of class "difftime" with anattribute indicating the units.  TheMath group method providesround, signif, floor,ceiling, trunc, abs, andsign methods for objects of this class, and there aremethods for the group-generic (seeOps) logical and arithmeticoperations.
The unary and binary arithmetic operators are generic functions:methods can be written for them individually or via theOps group generic function.  (SeeOps for how dispatch is computed.)
Function difftime calculates a difference of two date/timeobjects and returns an object of class "difftime" with anattribute indicating the units.  TheMath group method providesround, signif, floor,ceiling, trunc, abs, andsign methods for objects of this class, and there aremethods for the group-generic (seeOps) logical and arithmeticoperations.
! indicates logical negation (NOT).
Class "hexmode" consists of integer vectors with that classattribute, used merely to ensure that they are printed in hex.
Class "octmode" consists of integer vectors with that classattribute, used merely to ensure that they are printed in octalnotation, specifically for Unix-like file permissions such as755.  Subsetting ([) works too.
! indicates logical negation (NOT).
When a vector is promoted to a matrix, its names are notpromoted to row or column names, unlike as.matrix.
The unary and binary arithmetic operators are generic functions:methods can be written for them individually or via theOps group generic function.  (SeeOps for how dispatch is computed.)
The unary and binary arithmetic operators are generic functions:methods can be written for them individually or via theOps group generic function.  (SeeOps for how dispatch is computed.)
%in% is currently defined as "%in%" <- function(x, table) match(x, table, nomatch = 0) > 0
X and Y must be suitable arguments for FUN.  Eachwill be extended by rep to length the products of thelengths of X and Y before FUN is called.
If X and Y do not have the same number ofdimensions, the smaller array is padded with dimensions of sizeone.  The returned array comprises submatrices constructed bytaking X one term at a time and expanding that term asFUN(x, Y, ...).
The unary and binary arithmetic operators are generic functions:methods can be written for them individually or via theOps group generic function.  (SeeOps for how dispatch is computed.)
The unary and binary arithmetic operators are generic functions:methods can be written for them individually or via theOps group generic function.  (SeeOps for how dispatch is computed.)
x does not need to be integer if specified as a numeric vector,but see the comments about fractional days in the help forDates.
There are two basic classes of date/times.  Class "POSIXct"represents the (signed) number of seconds since the beginning of 1970(in the UTC time zone) as a numeric vector.  Class "POSIXlt" isa named list of vectors representing
The binary comparison operators are generic functions: methods can bewritten for them individually or via theOps group generic function.  (SeeOps for how dispatch is computed.)
There are three different assignment operators: two of themhave leftwards and rightwards forms.
There are three different assignment operators: two of themhave leftwards and rightwards forms.
The binary comparison operators are generic functions: methods can bewritten for them individually or via theOps group generic function.  (SeeOps for how dispatch is computed.)
There are three different assignment operators: two of themhave leftwards and rightwards forms.
The binary comparison operators are generic functions: methods can bewritten for them individually or via theOps group generic function.  (SeeOps for how dispatch is computed.)
The binary comparison operators are generic functions: methods can bewritten for them individually or via theOps group generic function.  (SeeOps for how dispatch is computed.)
The binary comparison operators are generic functions: methods can bewritten for them individually or via theOps group generic function.  (SeeOps for how dispatch is computed.)
! indicates logical negation (NOT).
Class "hexmode" consists of integer vectors with that classattribute, used merely to ensure that they are printed in hex.
Class "octmode" consists of integer vectors with that classattribute, used merely to ensure that they are printed in octalnotation, specifically for Unix-like file permissions such as755.  Subsetting ([) works too.
! indicates logical negation (NOT).
The left-hand side is optional, and one-sided formulae are used insome contexts.
These operators are generic.  You can write methods to handle indexingof specific classes of objects, see InternalMethods as well as[.data.frame and [.factor.  Thedescriptions here apply only to the default methods.  Note thatseparate methods are required for the replacement functions[<-, [[<- and $<- for use when indexing occurs onthe assignment side of an expression.
This queries the internal table that manages the DLLs.
Numeric versions are sequences of one or more non-negative integers,usually (e.g., in package ‘DESCRIPTION’ files) represented ascharacter strings with the elements of the sequence concatenated andseparated by single . or - characters.  R packageversions consist of at least two such integers, an R system versionof exactly three (major, minor and patchlevel).
These operators are generic.  You can write methods to handle indexingof specific classes of objects, see InternalMethods as well as[.data.frame and [.factor.  Thedescriptions here apply only to the default methods.  Note thatseparate methods are required for the replacement functions[<-, [[<- and $<- for use when indexing occurs onthe assignment side of an expression.
Data frames can be indexed in several modes.  When [ and[[ are used with a single vector index (x[i] orx[[i]]), they index the data frame as if it were a list.  Inthis usage a drop argument is ignored, with a warning.
The default algorithm (method = "left.kept") used is similarto that of S.  For a single string it works as follows.First spaces at the ends of the string are stripped.Then (if necessary) any other spaces are stripped.Next, lower case vowels are removed followed by lower case consonants.Finally if the abbreviation is still longer than minlengthupper case letters and symbols are stripped.
These are internal generic primitive functions: methodscan be defined for them individually or via theMath group generic.  For complexarguments (and the default method), z, abs(z) ==  Mod(z) and sqrt(z) == z^0.5.
The arc-tangent of two arguments atan2(y, x) returns the anglebetween the x-axis and the vector from the origin to (x, y),i.e., for positive arguments atan2(y, x) == atan(y/x).
These are internal generic primitive functions: methodscan be defined for them individually or via theMath group generic.
The function lockEnvironment locks its environment argument.Locking theenvironment prevents adding or removing variable bindings from theenvironment.  Changing the value of a variable is still possible unlessthe binding has been locked.  The namespace environments of packageswith namespaces are locked when loaded.
The type of the vector x is not restricted; it only must havean as.character method and be sortable (byorder).
Top-level tasks are individual expressionsrather than entire lines of input.  Thus an inputline of the form expression1 ; expression2will give rise to 2 top-level tasks.
The Levenshtein edit distance is used as measure of approximateness:it is the (possibly cost-weighted) total number of insertions,deletions and substitutions required to transform one string intoanother.
The Levenshtein edit distance is used as measure of approximateness:it is the (possibly cost-weighted) total number of insertions,deletions and substitutions required to transform one string intoanother.
Almost all lists in R internally are Generic Vectors, whereastraditional dotted pair lists (as in LISP) remain available butrarely seen by users (except as formals of functions).
This is a generic function: methods can be defined for itdirectly or via the Summary group generic.For this to work properly, the arguments ... should beunnamed, and dispatch is on the first argument.
all.equal is a generic function, dispatching methods on thetarget argument.  To see the available methods, usemethods("all.equal"), but note that the default methodalso does some dispatching, e.g. using the raw method for logicaltargets.
all.equal is a generic function, dispatching methods on thetarget argument.  To see the available methods, usemethods("all.equal"), but note that the default methodalso does some dispatching, e.g. using the raw method for logicaltargets.
all.equal is a generic function, dispatching methods on thetarget argument.  To see the available methods, usemethods("all.equal"), but note that the default methodalso does some dispatching, e.g. using the raw method for logicaltargets.
all.equal is a generic function, dispatching methods on thetarget argument.  To see the available methods, usemethods("all.equal"), but note that the default methodalso does some dispatching, e.g. using the raw method for logicaltargets.
all.equal is a generic function, dispatching methods on thetarget argument.  To see the available methods, usemethods("all.equal"), but note that the default methodalso does some dispatching, e.g. using the raw method for logicaltargets.
all.equal is a generic function, dispatching methods on thetarget argument.  To see the available methods, usemethods("all.equal"), but note that the default methodalso does some dispatching, e.g. using the raw method for logicaltargets.
all.equal is a generic function, dispatching methods on thetarget argument.  To see the available methods, usemethods("all.equal"), but note that the default methodalso does some dispatching, e.g. using the raw method for logicaltargets.
all.equal is a generic function, dispatching methods on thetarget argument.  To see the available methods, usemethods("all.equal"), but note that the default methodalso does some dispatching, e.g. using the raw method for logicaltargets.
all.equal is a generic function, dispatching methods on thetarget argument.  To see the available methods, usemethods("all.equal"), but note that the default methodalso does some dispatching, e.g. using the raw method for logicaltargets.
all.equal is a generic function, dispatching methods on thetarget argument.  To see the available methods, usemethods("all.equal"), but note that the default methodalso does some dispatching, e.g. using the raw method for logicaltargets.
all.equal is a generic function, dispatching methods on thetarget argument.  To see the available methods, usemethods("all.equal"), but note that the default methodalso does some dispatching, e.g. using the raw method for logicaltargets.
all.equal is a generic function, dispatching methods on thetarget argument.  To see the available methods, usemethods("all.equal"), but note that the default methodalso does some dispatching, e.g. using the raw method for logicaltargets.
all.equal is a generic function, dispatching methods on thetarget argument.  To see the available methods, usemethods("all.equal"), but note that the default methodalso does some dispatching, e.g. using the raw method for logicaltargets.
These functions differ only in the default values for theirarguments.
These functions differ only in the default values for theirarguments.
The condition system provides a mechanism for signaling andhandling unusual conditions, including errors and warnings.Conditions are represented as objects that contain informationabout the condition that occurred, such as a message and the call inwhich the condition occurred.  Currently conditions are S3-styleobjects, though this may eventually change.
This is a generic function: methods can be defined for itdirectly or via the Summary group generic.For this to work properly, the arguments ... should beunnamed, and dispatch is on the first argument.
These are generic functions with methods for vectors (includinglists), data frames and arrays (including matrices).
These are generic functions with methods for vectors (includinglists), data frames and arrays (including matrices).
These are generic functions with methods for vectors (includinglists), data frames and arrays (including matrices).
These are generic functions with methods for vectors (includinglists), data frames and arrays (including matrices).
These are generic functions with methods for vectors (includinglists), data frames and arrays (including matrices).
The NA of character type is distinct from the string"NA".  Programmers who need to specify an explicit missingstring should use NA_character_ (rather than "NA") or setelements to NA using is.na<-.
The NA of character type is distinct from the string"NA".  Programmers who need to specify an explicit missingstring should use NA_character_ (rather than "NA") or setelements to NA using is.na<-.
Numeric versions are sequences of one or more non-negative integers,usually (e.g., in package ‘DESCRIPTION’ files) represented ascharacter strings with the elements of the sequence concatenated andseparated by single . or - characters.  R packageversions consist of at least two such integers, an R system versionof exactly three (major, minor and patchlevel).
There are two basic classes of date/times.  Class "POSIXct"represents the (signed) number of seconds since the beginning of 1970(in the UTC time zone) as a numeric vector.  Class "POSIXlt" isa named list of vectors representing
NA
NA
NA
NA
If X is not an array but an object of a class with a non-nulldim value (such as a data frame), apply attemptsto coerce it to an array via as.matrix if it is two-dimensional(e.g., a data frame) or via as.array.
Complex vectors can be created with complex.  The vector can bespecified either by giving its length, its real and imaginary parts, ormodulus and argument.  (Giving just the length generates a vector ofcomplex zeroes.)
This function is mainly used interactively to print the argument listof a function.  For programming, consider using formalsinstead.
An array in R can have one, two or more dimensions.  It is simply avector which is stored with additional attributes giving thedimensions (attribute "dim") and optionally names for thosedimensions (attribute "dimnames").
NA
An array in R can have one, two or more dimensions.  It is simply avector which is stored with additional attributes giving thedimensions (attribute "dim") and optionally names for thosedimensions (attribute "dimnames").
An array in R can have one, two or more dimensions.  It is simply avector which is stored with additional attributes giving thedimensions (attribute "dim") and optionally names for thosedimensions (attribute "dimnames").
returns an unevaluated function call, that is, anunevaluated expression which consists of the named function applied tothe given arguments (name must be a string which givesthe name of a function to be called).  Note that although the call isunevaluated, the arguments ... are evaluated.
as.character and is.character are generic: you canwrite methods to handle specific classes of objects,see InternalMethods.  Further, for as.character thedefault method calls as.vector, so dispatch is first onmethods for as.character and then for methods for as.vector.
The condition system provides a mechanism for signaling andhandling unusual conditions, including errors and warnings.Conditions are represented as objects that contain informationabout the condition that occurred, such as a message and the call inwhich the condition occurred.  Currently conditions are S3-styleobjects, though this may eventually change.
The usual vector re-cycling rules are applied to x andformat so the answer will be of length that of the longer of thevectors.
as.character and is.character are generic: you canwrite methods to handle specific classes of objects,see InternalMethods.  Further, for as.character thedefault method calls as.vector, so dispatch is first onmethods for as.character and then for methods for as.vector.
The condition system provides a mechanism for signaling andhandling unusual conditions, including errors and warnings.Conditions are represented as objects that contain informationabout the condition that occurred, such as a message and the call inwhich the condition occurred.  Currently conditions are S3-styleobjects, though this may eventually change.
as.character and is.character are generic: you canwrite methods to handle specific classes of objects,see InternalMethods.  Further, for as.character thedefault method calls as.vector, so dispatch is first onmethods for as.character and then for methods for as.vector.
Class "hexmode" consists of integer vectors with that classattribute, used merely to ensure that they are printed in hex.
Numeric versions are sequences of one or more non-negative integers,usually (e.g., in package ‘DESCRIPTION’ files) represented ascharacter strings with the elements of the sequence concatenated andseparated by single . or - characters.  R packageversions consist of at least two such integers, an R system versionof exactly three (major, minor and patchlevel).
Class "octmode" consists of integer vectors with that classattribute, used merely to ensure that they are printed in octalnotation, specifically for Unix-like file permissions such as755.  Subsetting ([) works too.
The format and as.character methods and strftimeconvert objects from the classes "POSIXlt" and"POSIXct" to character vectors.
These functions and classes handle source code references.
Complex vectors can be created with complex.  The vector can bespecified either by giving its length, its real and imaginary parts, ormodulus and argument.  (Giving just the length generates a vector ofcomplex zeroes.)
as.data.frame is a generic function with many methods, andusers and packages can supply further methods.  For classes that actas vectors, often a copy of as.data.frame.vector will workas the method.
as.data.frame is a generic function with many methods, andusers and packages can supply further methods.  For classes that actas vectors, often a copy of as.data.frame.vector will workas the method.
as.data.frame is a generic function with many methods, andusers and packages can supply further methods.  For classes that actas vectors, often a copy of as.data.frame.vector will workas the method.
as.data.frame is a generic function with many methods, andusers and packages can supply further methods.  For classes that actas vectors, often a copy of as.data.frame.vector will workas the method.
as.data.frame is a generic function with many methods, andusers and packages can supply further methods.  For classes that actas vectors, often a copy of as.data.frame.vector will workas the method.
as.data.frame is a generic function with many methods, andusers and packages can supply further methods.  For classes that actas vectors, often a copy of as.data.frame.vector will workas the method.
Dates are represented as the number of days since 1970-01-01, withnegative values for earlier dates.  They are always printedfollowing the rules of the current Gregorian calendar, even thoughthat calendar was not in use long ago (it was adopted in 1752 inGreat Britain and its colonies).
as.data.frame is a generic function with many methods, andusers and packages can supply further methods.  For classes that actas vectors, often a copy of as.data.frame.vector will workas the method.
as.data.frame is a generic function with many methods, andusers and packages can supply further methods.  For classes that actas vectors, often a copy of as.data.frame.vector will workas the method.
as.data.frame is a generic function with many methods, andusers and packages can supply further methods.  For classes that actas vectors, often a copy of as.data.frame.vector will workas the method.
as.data.frame is a generic function with many methods, andusers and packages can supply further methods.  For classes that actas vectors, often a copy of as.data.frame.vector will workas the method.
as.data.frame is a generic function with many methods, andusers and packages can supply further methods.  For classes that actas vectors, often a copy of as.data.frame.vector will workas the method.
as.data.frame is a generic function with many methods, andusers and packages can supply further methods.  For classes that actas vectors, often a copy of as.data.frame.vector will workas the method.
as.data.frame is a generic function with many methods, andusers and packages can supply further methods.  For classes that actas vectors, often a copy of as.data.frame.vector will workas the method.
as.data.frame is a generic function with many methods, andusers and packages can supply further methods.  For classes that actas vectors, often a copy of as.data.frame.vector will workas the method.
as.data.frame is a generic function with many methods, andusers and packages can supply further methods.  For classes that actas vectors, often a copy of as.data.frame.vector will workas the method.
as.data.frame is a generic function with many methods, andusers and packages can supply further methods.  For classes that actas vectors, often a copy of as.data.frame.vector will workas the method.
Numeric versions are sequences of one or more non-negative integers,usually (e.g., in package ‘DESCRIPTION’ files) represented ascharacter strings with the elements of the sequence concatenated andseparated by single . or - characters.  R packageversions consist of at least two such integers, an R system versionof exactly three (major, minor and patchlevel).
as.data.frame is a generic function with many methods, andusers and packages can supply further methods.  For classes that actas vectors, often a copy of as.data.frame.vector will workas the method.
There are two basic classes of date/times.  Class "POSIXct"represents the (signed) number of seconds since the beginning of 1970(in the UTC time zone) as a numeric vector.  Class "POSIXlt" isa named list of vectors representing
There are two basic classes of date/times.  Class "POSIXct"represents the (signed) number of seconds since the beginning of 1970(in the UTC time zone) as a numeric vector.  Class "POSIXlt" isa named list of vectors representing
as.data.frame is a generic function with many methods, andusers and packages can supply further methods.  For classes that actas vectors, often a copy of as.data.frame.vector will workas the method.
If the argument dnn is not supplied, the internal functionlist.names is called to compute the ‘dimname names’.  If thearguments in ... are named, those names are used.  For theremaining arguments, deparse.level = 0 gives an empty name,deparse.level = 1 uses the supplied argument if it is a symbol,and deparse.level = 2 will deparse the argument.
as.data.frame is a generic function with many methods, andusers and packages can supply further methods.  For classes that actas vectors, often a copy of as.data.frame.vector will workas the method.
as.data.frame is a generic function with many methods, andusers and packages can supply further methods.  For classes that actas vectors, often a copy of as.data.frame.vector will workas the method.
The usual vector re-cycling rules are applied to x andformat so the answer will be of length that of the longer of thevectors.
The usual vector re-cycling rules are applied to x andformat so the answer will be of length that of the longer of thevectors.
The usual vector re-cycling rules are applied to x andformat so the answer will be of length that of the longer of thevectors.
The usual vector re-cycling rules are applied to x andformat so the answer will be of length that of the longer of thevectors.
The usual vector re-cycling rules are applied to x andformat so the answer will be of length that of the longer of thevectors.
The usual vector re-cycling rules are applied to x andformat so the answer will be of length that of the longer of thevectors.
The usual vector re-cycling rules are applied to x andformat so the answer will be of length that of the longer of thevectors.
Function difftime calculates a difference of two date/timeobjects and returns an object of class "difftime" with anattribute indicating the units.  TheMath group method providesround, signif, floor,ceiling, trunc, abs, andsign methods for objects of this class, and there aremethods for the group-generic (seeOps) logical and arithmeticoperations.
double creates a double-precision vector of the specifiedlength.  The elements of the vector are all equal to 0.It is identical to numeric.
Function difftime calculates a difference of two date/timeobjects and returns an object of class "difftime" with anattribute indicating the units.  TheMath group method providesround, signif, floor,ceiling, trunc, abs, andsign methods for objects of this class, and there aremethods for the group-generic (seeOps) logical and arithmeticoperations.
The as.POSIX* functions convert an object to one of the twoclasses used to represent date/times (calendar dates plus time to thenearest second).  They can convert objects of the other class and ofclass "Date" to these classes.  Dates without times aretreated as being at midnight UTC.
This is a primitive generic function: you can write methods tohandle specific classes of objects, see InternalMethods.
‘Expression’ here is not being used in its colloquial sense,that of mathematical expressions.  Those are calls (seecall) in R, and an R expression vector is a list ofcalls, symbols etc, for example as returned by parse.
‘Expression’ here is not being used in its colloquial sense,that of mathematical expressions.  Those are calls (seecall) in R, and an R expression vector is a list ofcalls, symbols etc, for example as returned by parse.
The type of the vector x is not restricted; it only must havean as.character method and be sortable (byorder).
NA
NA
Class "hexmode" consists of integer vectors with that classattribute, used merely to ensure that they are printed in hex.
Integer vectors exist so that data can be passed to C or Fortran codewhich expects them, and so that (small) integer data can be representedexactly and compactly.
Almost all lists in R internally are Generic Vectors, whereastraditional dotted pair lists (as in LISP) remain available butrarely seen by users (except as formals of functions).
Almost all lists in R internally are Generic Vectors, whereastraditional dotted pair lists (as in LISP) remain available butrarely seen by users (except as formals of functions).
Dates are represented as the number of days since 1970-01-01, withnegative values for earlier dates.  They are always printedfollowing the rules of the current Gregorian calendar, even thoughthat calendar was not in use long ago (it was adopted in 1752 inGreat Britain and its colonies).
Almost all lists in R internally are Generic Vectors, whereastraditional dotted pair lists (as in LISP) remain available butrarely seen by users (except as formals of functions).
Function difftime calculates a difference of two date/timeobjects and returns an object of class "difftime" with anattribute indicating the units.  TheMath group method providesround, signif, floor,ceiling, trunc, abs, andsign methods for objects of this class, and there aremethods for the group-generic (seeOps) logical and arithmeticoperations.
Almost all lists in R internally are Generic Vectors, whereastraditional dotted pair lists (as in LISP) remain available butrarely seen by users (except as formals of functions).
Almost all lists in R internally are Generic Vectors, whereastraditional dotted pair lists (as in LISP) remain available butrarely seen by users (except as formals of functions).
Almost all lists in R internally are Generic Vectors, whereastraditional dotted pair lists (as in LISP) remain available butrarely seen by users (except as formals of functions).
Numeric versions are sequences of one or more non-negative integers,usually (e.g., in package ‘DESCRIPTION’ files) represented ascharacter strings with the elements of the sequence concatenated andseparated by single . or - characters.  R packageversions consist of at least two such integers, an R system versionof exactly three (major, minor and patchlevel).
There are two basic classes of date/times.  Class "POSIXct"represents the (signed) number of seconds since the beginning of 1970(in the UTC time zone) as a numeric vector.  Class "POSIXlt" isa named list of vectors representing
There are two basic classes of date/times.  Class "POSIXct"represents the (signed) number of seconds since the beginning of 1970(in the UTC time zone) as a numeric vector.  Class "POSIXlt" isa named list of vectors representing
TRUE and FALSE are reserved words denoting logicalconstants in the R language, whereas T and F are globalvariables whose initial values set to these.  All four arelogical(1) vectors.
TRUE and FALSE are reserved words denoting logicalconstants in the R language, whereas T and F are globalvariables whose initial values set to these.  All four arelogical(1) vectors.
If one of nrow or ncol is not given, an attempt ismade to infer it from the length of data and the otherparameter.  If neither is given, a one-column matrix is returned.
If one of nrow or ncol is not given, an attempt ismade to infer it from the length of data and the otherparameter.  If neither is given, a one-column matrix is returned.
If one of nrow or ncol is not given, an attempt ismade to infer it from the length of data and the otherparameter.  If neither is given, a one-column matrix is returned.
noquote returns its argument as an object of class"noquote".  There is a method for c() and subscriptmethod ("[.noquote") which ensures that the class is not lostby subsetting.  The print method (print.noquote) printscharacter strings without quotes ("...." is printed as ....).
There are two basic classes of date/times.  Class "POSIXct"represents the (signed) number of seconds since the beginning of 1970(in the UTC time zone) as a numeric vector.  Class "POSIXlt" isa named list of vectors representing
Names are limited to 10,000 bytes (and were to 256 bytes in versionsof R before 2.13.0).
NULL can be indexed (see Extract) in just about anysyntactically legal way: whether it makes sense or not, the result isalways NULL.  Objects with value NULL can be changed byreplacement operators and will be coerced to the type of theright-hand side.
NULL can be indexed (see Extract) in just about anysyntactically legal way: whether it makes sense or not, the result isalways NULL.  Objects with value NULL can be changed byreplacement operators and will be coerced to the type of theright-hand side.
numeric is identical to double (and real).It creates a double-precision vector of the specified length with eachelement equal to 0.
Numeric versions are sequences of one or more non-negative integers,usually (e.g., in package ‘DESCRIPTION’ files) represented ascharacter strings with the elements of the sequence concatenated andseparated by single . or - characters.  R packageversions consist of at least two such integers, an R system versionof exactly three (major, minor and patchlevel).
Class "octmode" consists of integer vectors with that classattribute, used merely to ensure that they are printed in octalnotation, specifically for Unix-like file permissions such as755.  Subsetting ([) works too.
The type of the vector x is not restricted; it only must havean as.character method and be sortable (byorder).
Numeric versions are sequences of one or more non-negative integers,usually (e.g., in package ‘DESCRIPTION’ files) represented ascharacter strings with the elements of the sequence concatenated andseparated by single . or - characters.  R packageversions consist of at least two such integers, an R system versionof exactly three (major, minor and patchlevel).
Almost all lists in R internally are Generic Vectors, whereastraditional dotted pair lists (as in LISP) remain available butrarely seen by users (except as formals of functions).
The as.POSIX* functions convert an object to one of the twoclasses used to represent date/times (calendar dates plus time to thenearest second).  They can convert objects of the other class and ofclass "Date" to these classes.  Dates without times aretreated as being at midnight UTC.
The as.POSIX* functions convert an object to one of the twoclasses used to represent date/times (calendar dates plus time to thenearest second).  They can convert objects of the other class and ofclass "Date" to these classes.  Dates without times aretreated as being at midnight UTC.
The as.POSIX* functions convert an object to one of the twoclasses used to represent date/times (calendar dates plus time to thenearest second).  They can convert objects of the other class and ofclass "Date" to these classes.  Dates without times aretreated as being at midnight UTC.
The as.POSIX* functions convert an object to one of the twoclasses used to represent date/times (calendar dates plus time to thenearest second).  They can convert objects of the other class and ofclass "Date" to these classes.  Dates without times aretreated as being at midnight UTC.
The as.POSIX* functions convert an object to one of the twoclasses used to represent date/times (calendar dates plus time to thenearest second).  They can convert objects of the other class and ofclass "Date" to these classes.  Dates without times aretreated as being at midnight UTC.
The as.POSIX* functions convert an object to one of the twoclasses used to represent date/times (calendar dates plus time to thenearest second).  They can convert objects of the other class and ofclass "Date" to these classes.  Dates without times aretreated as being at midnight UTC.
The as.POSIX* functions convert an object to one of the twoclasses used to represent date/times (calendar dates plus time to thenearest second).  They can convert objects of the other class and ofclass "Date" to these classes.  Dates without times aretreated as being at midnight UTC.
The as.POSIX* functions convert an object to one of the twoclasses used to represent date/times (calendar dates plus time to thenearest second).  They can convert objects of the other class and ofclass "Date" to these classes.  Dates without times aretreated as being at midnight UTC.
The as.POSIX* functions convert an object to one of the twoclasses used to represent date/times (calendar dates plus time to thenearest second).  They can convert objects of the other class and ofclass "Date" to these classes.  Dates without times aretreated as being at midnight UTC.
The as.POSIX* functions convert an object to one of the twoclasses used to represent date/times (calendar dates plus time to thenearest second).  They can convert objects of the other class and ofclass "Date" to these classes.  Dates without times aretreated as being at midnight UTC.
The as.POSIX* functions convert an object to one of the twoclasses used to represent date/times (calendar dates plus time to thenearest second).  They can convert objects of the other class and ofclass "Date" to these classes.  Dates without times aretreated as being at midnight UTC.
The as.POSIX* functions convert an object to one of the twoclasses used to represent date/times (calendar dates plus time to thenearest second).  They can convert objects of the other class and ofclass "Date" to these classes.  Dates without times aretreated as being at midnight UTC.
The QR decomposition plays an important role in manystatistical techniques.  In particular it can be used to solve theequation \bold{Ax} = \bold{b} for given matrix \bold{A},and vector \bold{b}.  It is useful for computing regressioncoefficients and in applying the Newton-Raphson algorithm.
The raw type is intended to hold raw bytes.  It is possible to extractsubsequences of bytes, and to replace elements (but only by elementsof a raw vector).  The relational operators (see Comparison,using the numerical order of the byte representation) work, as do thelogical operators (see Logic) with a bitwise interpretation.
double creates a double-precision vector of the specifiedlength.  The elements of the vector are all equal to 0.It is identical to numeric.
double creates a double-precision vector of the specifiedlength.  The elements of the vector are all equal to 0.It is identical to numeric.
Names are limited to 10,000 bytes (and were to 256 bytes in versionsof R before 2.13.0).
If the argument dnn is not supplied, the internal functionlist.names is called to compute the ‘dimname names’.  If thearguments in ... are named, those names are used.  For theremaining arguments, deparse.level = 0 gives an empty name,deparse.level = 1 uses the supplied argument if it is a symbol,and deparse.level = 2 will deparse the argument.
If the argument dnn is not supplied, the internal functionlist.names is called to compute the ‘dimname names’.  If thearguments in ... are named, those names are used.  For theremaining arguments, deparse.level = 0 gives an empty name,deparse.level = 1 uses the supplied argument if it is a symbol,and deparse.level = 2 will deparse the argument.
The atomic modes are "logical", "integer","numeric" (synonym "double"), "complex","character" and "raw".
The atomic modes are "logical", "integer","numeric" (synonym "double"), "complex","character" and "raw".
The arc-tangent of two arguments atan2(y, x) returns the anglebetween the x-axis and the vector from the origin to (x, y),i.e., for positive arguments atan2(y, x) == atan(y/x).
These are internal generic primitive functions: methodscan be defined for them individually or via theMath group generic.
packageHasNamespace does not indicate if the package has anamespace (all now do), rather if it has a ‘NAMESPACE’ file,which base and some legacy packages do not.  But then you arenot intended to be using it ....
The values of the splits can also be obtained (less efficiently) bysplit(x, slice.index(x, MARGIN)).
Note that isS4 does not rely on the methodspackage, so in particular it can be used to detect the need torequire that package.
Note that isS4 does not rely on the methodspackage, so in particular it can be used to detect the need torequire that package.
There are no restrictions on the name given as x: it can be anon-syntactic name (see make.names).
The arc-tangent of two arguments atan2(y, x) returns the anglebetween the x-axis and the vector from the origin to (x, y),i.e., for positive arguments atan2(y, x) == atan(y/x).
The arc-tangent of two arguments atan2(y, x) returns the anglebetween the x-axis and the vector from the origin to (x, y),i.e., for positive arguments atan2(y, x) == atan(y/x).
These are internal generic primitive functions: methodscan be defined for them individually or via theMath group generic.
When evaluating a variable or function name R searches forthat name in the databases listed by search.  The firstname of the appropriate type is used.
The functions loadNamespace and attachNamespace areusually called implicitly when library is used to load a namespace and any imports needed.  However it may be useful at times tocall these functions directly.
These functions provide access to a single attribute of an object.The replacement form causes the named attribute to take the valuespecified (or create a new attribute with the value given).
all.equal is a generic function, dispatching methods on thetarget argument.  To see the available methods, usemethods("all.equal"), but note that the default methodalso does some dispatching, e.g. using the raw method for logicaltargets.
These functions provide access to a single attribute of an object.The replacement form causes the named attribute to take the valuespecified (or create a new attribute with the value given).
Unlike attr it is not an error to set attributes on aNULL object: it will first be coerced to an empty list.
Unlike attr it is not an error to set attributes on aNULL object: it will first be coerced to an empty list.
NA
NA
Solves a system of linear equations where the coefficient matrix isupper (or ‘right’, ‘R’) or lower (‘left’,‘L’) triangular.
Environments consist of a frame, or collection of namedobjects, and a pointer to an enclosing environment.  The mostcommon example is the frame of variables local to a function call; itsenclosure is the environment where the function was defined(unless changed subsequently).  The enclosing environment isdistinguished from the parent frame: the latter (returned byparent.frame) refers to the environment of the caller ofa function.  Since confusion is so easy, it is best never to use‘parent’ in connection with an environment (despite thepresence of the function parent.env).
tilde expansion of the path is done except on Windows.
If expon.scaled = TRUE, exp(-x) I(x;nu),or exp(x) K(x;nu) are returned.
If expon.scaled = TRUE, exp(-x) I(x;nu),or exp(x) K(x;nu) are returned.
If expon.scaled = TRUE, exp(-x) I(x;nu),or exp(x) K(x;nu) are returned.
If expon.scaled = TRUE, exp(-x) I(x;nu),or exp(x) K(x;nu) are returned.
The functions beta and lbeta return the beta functionand the natural logarithm of the beta function,
The function lockEnvironment locks its environment argument.Locking theenvironment prevents adding or removing variable bindings from theenvironment.  Changing the value of a variable is still possible unlessthe binding has been locked.  The namespace environments of packageswith namespaces are locked when loaded.
The function lockEnvironment locks its environment argument.Locking theenvironment prevents adding or removing variable bindings from theenvironment.  Changing the value of a variable is still possible unlessthe binding has been locked.  The namespace environments of packageswith namespaces are locked when loaded.
If domain is NULL or "", and gettextor ngettext  is called from a function in the namespace ofpackage pkg the domain is set to "R-pkg".  Otherwisethere is no default domain.
Each element of an integer vector has 32 bits.
Each element of an integer vector has 32 bits.
Each element of an integer vector has 32 bits.
Each element of an integer vector has 32 bits.
Each element of an integer vector has 32 bits.
Each element of an integer vector has 32 bits.
For the first form, fun can be a character stringnaming the function to be manipulated, which is searched for from theparent frame.  If it is not specified, the function callingbody is used.
For the first form, fun can be a character stringnaming the function to be manipulated, which is searched for from theparent frame.  If it is not specified, the function callingbody is used.
NA
break breaks out of a for, while or repeatloop; control is transferred to the first statement outside theinner-most loop. next halts the processing of the currentiteration and advances the looping index.  Both break andnext apply only to the innermost of nested loops.
A call to browser can be included in the body of a function.When reached, this causes a pause in the execution of thecurrent expression and allows access to the R interpreter.
Each call to browser can supply either a text string or a condition.The functions browserText and browserCondition provide waysto retrieve those values.  Since there can be multiple browser contextsactive at any time we also support retrieving values from the differentcontexts.  The innermost (most recently initiated) browser context isnumbered 1: other contexts are numbered sequentially.
Each call to browser can supply either a text string or a condition.The functions browserText and browserCondition provide waysto retrieve those values.  Since there can be multiple browser contextsactive at any time we also support retrieving values from the differentcontexts.  The innermost (most recently initiated) browser context isnumbered 1: other contexts are numbered sequentially.
Each call to browser can supply either a text string or a condition.The functions browserText and browserCondition provide waysto retrieve those values.  Since there can be multiple browser contextsactive at any time we also support retrieving values from the differentcontexts.  The innermost (most recently initiated) browser context isnumbered 1: other contexts are numbered sequentially.
builtins() returns an unsorted list of the objects in thesymbol table, that is all the objects in the base environment.These are the built-in objects plus any that have been addedsubsequently when the base package was loaded.  It is less confusingto use ls(baseenv(), all.names = TRUE).
A data frame is split by row into data framessubsetted by the values of one or more factors, and functionFUN is applied to each subset in turn.
A data frame is split by row into data framessubsetted by the values of one or more factors, and functionFUN is applied to each subset in turn.
A data frame is split by row into data framessubsetted by the values of one or more factors, and functionFUN is applied to each subset in turn.
The first eleven functions create connections.  By default theconnection is not opened (except for a socket connection created bysocketConnection or socketAccept and for server socketconnection created by serverSocket), but maybe opened by setting a non-empty value of argument open.
The output type is determined from the highest type of the componentsin the hierarchy NULL < raw < logical < integer < double < complex < character< list < expression.  Pairlists are treated as lists, whereas non-vectorcomponents (such as names / symbols and calls)are treated as one-element listswhich cannot be unlisted even if recursive = TRUE.
Dates are represented as the number of days since 1970-01-01, withnegative values for earlier dates.  They are always printedfollowing the rules of the current Gregorian calendar, even thoughthat calendar was not in use long ago (it was adopted in 1752 inGreat Britain and its colonies).
Function difftime calculates a difference of two date/timeobjects and returns an object of class "difftime" with anattribute indicating the units.  TheMath group method providesround, signif, floor,ceiling, trunc, abs, andsign methods for objects of this class, and there aremethods for the group-generic (seeOps) logical and arithmeticoperations.
The type of the vector x is not restricted; it only must havean as.character method and be sortable (byorder).
noquote returns its argument as an object of class"noquote".  There is a method for c() and subscriptmethod ("[.noquote") which ensures that the class is not lostby subsetting.  The print method (print.noquote) printscharacter strings without quotes ("...." is printed as ....).
Numeric versions are sequences of one or more non-negative integers,usually (e.g., in package ‘DESCRIPTION’ files) represented ascharacter strings with the elements of the sequence concatenated andseparated by single . or - characters.  R packageversions consist of at least two such integers, an R system versionof exactly three (major, minor and patchlevel).
There are two basic classes of date/times.  Class "POSIXct"represents the (signed) number of seconds since the beginning of 1970(in the UTC time zone) as a numeric vector.  Class "POSIXlt" isa named list of vectors representing
There are two basic classes of date/times.  Class "POSIXct"represents the (signed) number of seconds since the beginning of 1970(in the UTC time zone) as a numeric vector.  Class "POSIXlt" isa named list of vectors representing
See the description of options("warn") for thecircumstances under which there is a last.warning object andwarnings() is used.  In essence this is if options(warn =    0) and warning has been called at least once.
returns an unevaluated function call, that is, anunevaluated expression which consists of the named function applied tothe given arguments (name must be a string which givesthe name of a function to be called).  Note that although the call isunevaluated, the arguments ... are evaluated.
callCC provides a non-local exit mechanism that can be usefulfor early termination of a computation.  callCC callsfun with one argument, an exit function.  The exitfunction takes a single argument, the intended return value.  If thebody of fun calls the exit function then the call tocallCC immediately returns, with the value supplied to the exitfunction as the value returned by callCC.
NA
chartr translates each character in x that is specifiedin old to the corresponding character specified in new.Ranges are supported in the specifications, but character classes andrepeated characters are not.  If old contains more charactersthan new, an error is signaled; if it contains fewer characters, theextra characters at the end of new are ignored.
cat is useful for producing output in user-defined functions.It converts its arguments to character vectors, concatenatesthem to a single character vector, appends the given sep = string(s) to each element and then outputs them.
The functions cbind and rbind are S3 generic, withmethods for data frames.  The data frame method will be used if atleast one argument is a data frame and the rest are vectors ormatrices.  There can be other methods; in particular, there is one fortime series objects.  See the section on ‘Dispatch’ for howthe method to be used is selected.  If some of the arguments are of anS4 class, i.e., isS4(.) is true, S4 methods are soughtalso, and the hidden cbind / rbind functionsfrom package methods maybe called, which in turn build oncbind2 or rbind2, respectively.  In thatcase, deparse.level is obeyed, similarly to the default method.
The functions cbind and rbind are S3 generic, withmethods for data frames.  The data frame method will be used if atleast one argument is a data frame and the rest are vectors ormatrices.  There can be other methods; in particular, there is one fortime series objects.  See the section on ‘Dispatch’ for howthe method to be used is selected.  If some of the arguments are of anS4 class, i.e., isS4(.) is true, S4 methods are soughtalso, and the hidden cbind / rbind functionsfrom package methods maybe called, which in turn build oncbind2 or rbind2, respectively.  In thatcase, deparse.level is obeyed, similarly to the default method.
These are generic functions: methods can be defined for themindividually or via the Math groupgeneric.
This function is particularly useful when abbreviations are allowed infunction arguments, and need to be uniquely expanded with respect to atarget table of possible values.
as.character and is.character are generic: you canwrite methods to handle specific classes of objects,see InternalMethods.  Further, for as.character thedefault method calls as.vector, so dispatch is first onmethods for as.character and then for methods for as.vector.
Exact matches are preferred to partial matches (those where the valueto be matched has an exact match to the initial part of the target,but the target is longer).
packBits accepts raw, integer or logical inputs, the last twowithout any NAs.
chartr translates each character in x that is specifiedin old to the corresponding character specified in new.Ranges are supported in the specifications, but character classes andrepeated characters are not.  If old contains more charactersthan new, an error is signaled; if it contains fewer characters, theextra characters at the end of new are ignored.
There are two basic classes of date/times.  Class "POSIXct"represents the (signed) number of seconds since the beginning of 1970(in the UTC time zone) as a numeric vector.  Class "POSIXlt" isa named list of vectors representing
NA
chol is generic: the description here applies to the defaultmethod.
chol is generic: the description here applies to the defaultmethod.
NA
The functions beta and lbeta return the beta functionand the natural logarithm of the beta function,
Here, we describe the so called “S3” classes (and methods). For“S4” classes (and methods), see ‘Formal classes’ below.
Here, we describe the so called “S3” classes (and methods). For“S4” classes (and methods), see ‘Formal classes’ below.
Several character strings can be pushed back on one or more occasions.The occasions form a stack, so the first line to be retrieved will bethe first string from the last call to pushBack.  Lines whichare pushed back are read prior to the normal input from theconnection, by the normal text-reading functions such asreadLines and scan.
The first eleven functions create connections.  By default theconnection is not opened (except for a socket connection created bysocketConnection or socketAccept and for server socketconnection created by serverSocket), but maybe opened by setting a non-empty value of argument open.
The first eleven functions create connections.  By default theconnection is not opened (except for a socket connection created bysocketConnection or socketAccept and for server socketconnection created by serverSocket), but maybe opened by setting a non-empty value of argument open.
These functions and classes handle source code references.
These functions and classes handle source code references.
stdin(), stdout() and stderr() are standardconnections corresponding to input, output and error on the consolerespectively (and not necessarily to file streams).  They are text-modeconnections of class "terminal" which cannot be opened orclosed, and are read-only, write-only and write-only respectively.The stdout() and stderr() connections can bere-directed by sink (and in some circumstances theoutput from stdout() can be split: see the help page).
NA
These functions are equivalent to use of apply withFUN = mean or FUN = sum with appropriate margins, butare a lot faster.  As they are written for speed, they blur over someof the subtleties of NaN and NA.  If na.rm =    FALSE and either NaN or NA appears in a sum, theresult will be one of NaN or NA, but which might beplatform-dependent.
The extractor functions try to do something sensible for anymatrix-like object x.  If the object has dimnamesthe first component is used as the row names, and the second component(if any) is used for the column names.  For a data frame, rownamesand colnames eventually call row.names andnames respectively, but the latter are preferred.
The extractor functions try to do something sensible for anymatrix-like object x.  If the object has dimnamesthe first component is used as the row names, and the second component(if any) is used for the column names.  For a data frame, rownamesand colnames eventually call row.names andnames respectively, but the latter are preferred.
These functions are equivalent to use of apply withFUN = mean or FUN = sum with appropriate margins, butare a lot faster.  As they are written for speed, they blur over someof the subtleties of NaN and NA.  If na.rm =    FALSE and either NaN or NA appears in a sum, theresult will be one of NaN or NA, but which might beplatform-dependent.
These arguments are captured before the standard R command lineprocessing takes place.  This means that they are the unmodifiedvalues.  This is especially useful with the --argscommand-line flag to R, as all of the command line after that flagis skipped.
NA
NA
Complex vectors can be created with complex.  The vector can bespecified either by giving its length, its real and imaginary parts, ormodulus and argument.  (Giving just the length generates a vector ofcomplex zeroes.)
The condition system provides a mechanism for signaling andhandling unusual conditions, including errors and warnings.Conditions are represented as objects that contain informationabout the condition that occurred, such as a message and the call inwhich the condition occurred.  Currently conditions are S3-styleobjects, though this may eventually change.
The condition system provides a mechanism for signaling andhandling unusual conditions, including errors and warnings.Conditions are represented as objects that contain informationabout the condition that occurred, such as a message and the call inwhich the condition occurred.  Currently conditions are S3-styleobjects, though this may eventually change.
The condition system provides a mechanism for signaling andhandling unusual conditions, including errors and warnings.Conditions are represented as objects that contain informationabout the condition that occurred, such as a message and the call inwhich the condition occurred.  Currently conditions are S3-styleobjects, though this may eventually change.
The condition system provides a mechanism for signaling andhandling unusual conditions, including errors and warnings.Conditions are represented as objects that contain informationabout the condition that occurred, such as a message and the call inwhich the condition occurred.  Currently conditions are S3-styleobjects, though this may eventually change.
The condition system provides a mechanism for signaling andhandling unusual conditions, including errors and warnings.Conditions are represented as objects that contain informationabout the condition that occurred, such as a message and the call inwhich the condition occurred.  Currently conditions are S3-styleobjects, though this may eventually change.
library(package) and require(package) both load thenamespace of the package with name package and attach it on thesearch list.  require is designed for use inside otherfunctions; it returns FALSE and gives a warning (rather than anerror as library() does by default) if the package does notexist.  Both functions check and update the list of currently attachedpackages and do not reload a namespace which is already loaded.  (Ifyou want to reload such a package, call detach(unload =  TRUE) or unloadNamespace first.)  If you want to load apackage without attaching it on the search list, seerequireNamespace.
NA
Complex vectors can be created with complex.  The vector can bespecified either by giving its length, its real and imaginary parts, ormodulus and argument.  (Giving just the length generates a vector ofcomplex zeroes.)
NA
The arc-tangent of two arguments atan2(y, x) returns the anglebetween the x-axis and the vector from the origin to (x, y),i.e., for positive arguments atan2(y, x) == atan(y/x).
These are internal generic primitive functions: methodscan be defined for them individually or via theMath group generic.
The arc-tangent of two arguments atan2(y, x) returns the anglebetween the x-axis and the vector from the origin to (x, y),i.e., for positive arguments atan2(y, x) == atan(y/x).
NA
On most platforms, C stack information is recorded when R isinitialized and used for stack-checking.  If this information isunavailable, the size will be returned as NA, andstack-checking is not performed.
These are generic functions: methods can be defined for themindividually or via the Math group generic.
These are generic functions: methods can be defined for themindividually or via the Math group generic.
These are generic functions: methods can be defined for themindividually or via the Math group generic.
These are generic functions: methods can be defined for themindividually or via the Math group generic.
This reports what curl -I -L or curl -I wouldreport.  For a ftp:// URL the ‘headers’ are a record ofthe conversation between client and server before data transfer.
When breaks is specified as a single number, the range of thedata is divided into breaks pieces of equal length, and thenthe outer limits are moved away by 0.1% of the range to ensure thatthe extreme values both fall within the break intervals.  (If xis a constant vector, equal-length intervals are created, one ofwhich includes the single value.)
Note that the default for right differs from thedefault method.  Using include.lowest =    TRUE will include both ends of the range of dates.
When breaks is specified as a single number, the range of thedata is divided into breaks pieces of equal length, and thenthe outer limits are moved away by 0.1% of the range to ensure thatthe extreme values both fall within the break intervals.  (If xis a constant vector, equal-length intervals are created, one ofwhich includes the single value.)
Note that the default for right differs from thedefault method.  Using include.lowest =    TRUE will include both ends of the range of dates.
NA
A data frame is a list of variables of the same number of rows withunique row names, given class "data.frame".  If no variablesare included, the row names determine the number of rows.
Logical and factor columns are converted to integers.  Charactercolumns are first converted to factors and then to integers. Any othercolumn which is not numeric (according to is.numeric) isconverted by as.numeric or, for S4 objects,as(, "numeric").  If all columns are integer (afterconversion) the result is an integer matrix, otherwise a numeric(double) matrix.
NA
When a function flagged for debugging is entered, normal executionis suspended and the body of function is executed one statement at atime.  A new browser context is initiated for each step(and the previous one destroyed).
When a function flagged for debugging is entered, normal executionis suspended and the body of function is executed one statement at atime.  A new browser context is initiated for each step(and the previous one destroyed).
When a function flagged for debugging is entered, normal executionis suspended and the body of function is executed one statement at atime.  A new browser context is initiated for each step(and the previous one destroyed).
A data frame is a list of variables of the same number of rows withunique row names, given class "data.frame".  If no variablesare included, the row names determine the number of rows.
Both eval.env and assign.env default to the currently activeenvironment.
These functions turn unevaluated expressions (where ‘expression’is taken in a wider sense than the strict concept of a vector ofmode and type (typeof)"expression" used in expression) into characterstrings (a kind of inverse to parse).
These functions turn unevaluated expressions (where ‘expression’is taken in a wider sense than the strict concept of a vector ofmode and type (typeof)"expression" used in expression) into characterstrings (a kind of inverse to parse).
The determinant function uses an LU decomposition and thedet function is simply a wrapper around a call todeterminant.
This is most commonly used with a single number argument referring to aposition on the search list, and can also be used with a unquoted orquoted name of an item on the search list such as package:tools.
The determinant function uses an LU decomposition and thedet function is simply a wrapper around a call todeterminant.
The determinant function uses an LU decomposition and thedet function is simply a wrapper around a call todeterminant.
dput opens file and deparses the object x intothat file.  The object name is not written (unlike dump).If x is a function the associated environment is stripped.Hence scoping information can be lost.
diag has four distinct usages:
diag has four distinct usages:
diff is a generic function with a default method and ones forclasses "ts", "POSIXt" and"Date".
diff is a generic function with a default method and ones forclasses "ts", "POSIXt" and"Date".
diff is a generic function with a default method and ones forclasses "ts", "POSIXt" and"Date".
Function difftime calculates a difference of two date/timeobjects and returns an object of class "difftime" with anattribute indicating the units.  TheMath group method providesround, signif, floor,ceiling, trunc, abs, andsign methods for objects of this class, and there aremethods for the group-generic (seeOps) logical and arithmeticoperations.
diff is a generic function with a default method and ones forclasses "ts", "POSIXt" and"Date".
Function difftime calculates a difference of two date/timeobjects and returns an object of class "difftime" with anattribute indicating the units.  TheMath group method providesround, signif, floor,ceiling, trunc, abs, andsign methods for objects of this class, and there aremethods for the group-generic (seeOps) logical and arithmeticoperations.
The functions beta and lbeta return the beta functionand the natural logarithm of the beta function,
The functions dim and dim<- are internal genericprimitive functions.
The functions dim and dim<- are internal genericprimitive functions.
The functions dim and dim<- are internal genericprimitive functions.
The functions dimnames and dimnames<- are generic.
The functions dimnames and dimnames<- are generic.
The functions dimnames and dimnames<- are generic.
The functions dimnames and dimnames<- are generic.
NA
dir.exists checks that the paths exist (in the same sense asfile.exists) and are directories.
dir.exists checks that the paths exist (in the same sense asfile.exists) and are directories.
tilde expansion of the path is done except on Windows.
If quote is FALSE, the default, then the arguments areevaluated (in the calling environment, not in envir).  Ifquote is TRUE then each argument is quoted (seequote) so that the effect of argument evaluation is toremove the quotes – leaving the original arguments unevaluated when thecall is constructed.
NA
double creates a double-precision vector of the specifiedlength.  The elements of the vector are all equal to 0.It is identical to numeric.
dput opens file and deparses the object x intothat file.  The object name is not written (unlike dump).If x is a function the associated environment is stripped.Hence scoping information can be lost.
The purpose of the functions is to provide a simple means of markupfor quoting text to be used in the R output, e.g., in warnings orerror messages.
NA
The method for class "factor" is currently equivalent tofactor(x, exclude=exclude).  For the data frame method, youshould rarely specify exclude “globally” for all factorcolumns; rather the default uses the same factor-specificexclude as the factor method itself.
The method for class "factor" is currently equivalent tofactor(x, exclude=exclude).  For the data frame method, youshould rarely specify exclude “globally” for all factorcolumns; rather the default uses the same factor-specificexclude as the factor method itself.
The method for class "factor" is currently equivalent tofactor(x, exclude=exclude).  For the data frame method, youshould rarely specify exclude “globally” for all factorcolumns; rather the default uses the same factor-specificexclude as the factor method itself.
If some of the objects named do not exist (in scope), they areomitted, with a warning.  If file is a file and no objectsexist then no file is created.
These are generic functions with methods for vectors (includinglists), data frames and arrays (including matrices).
These are generic functions with methods for vectors (includinglists), data frames and arrays (including matrices).
These are generic functions with methods for vectors (includinglists), data frames and arrays (including matrices).
These are generic functions with methods for vectors (includinglists), data frames and arrays (including matrices).
These are generic functions with methods for vectors (includinglists), data frames and arrays (including matrices).
Numeric versions are sequences of one or more non-negative integers,usually (e.g., in package ‘DESCRIPTION’ files) represented ascharacter strings with the elements of the sequence concatenated andseparated by single . or - characters.  R packageversions consist of at least two such integers, an R system versionof exactly three (major, minor and patchlevel).
There are two basic classes of date/times.  Class "POSIXct"represents the (signed) number of seconds since the beginning of 1970(in the UTC time zone) as a numeric vector.  Class "POSIXlt" isa named list of vectors representing
See the description of options("warn") for thecircumstances under which there is a last.warning object andwarnings() is used.  In essence this is if options(warn =    0) and warning has been called at least once.
The objects dyn.load loads are called ‘dynamicallyloadable libraries’ (abbreviated to ‘DLL’) on all platformsexcept macOS, which uses the term for a different sortof object.  On Unix-alikes they are also called ‘dynamicshared objects’ (‘DSO’), or ‘shared objects’ forshort.  (The POSIX standards use ‘executable object file’,but no one else does.)
The objects dyn.load loads are called ‘dynamicallyloadable libraries’ (abbreviated to ‘DLL’) on all platformsexcept macOS, which uses the term for a different sortof object.  On Unix-alikes they are also called ‘dynamicshared objects’ (‘DSO’), or ‘shared objects’ forshort.  (The POSIX standards use ‘executable object file’,but no one else does.)
The pos argument can specify the environment in which to lookfor the object in any of several ways: as a positive integer (theposition in the search list); as the character stringname of an element in the search list; or as anenvironment (including using sys.frameto access the currently active function calls).  The default of-1 indicates the current environment of the call toget. The envir argument is an alternative way tospecify an environment.
NA
If symmetric is unspecified, isSymmetric(x)determines if the matrix is symmetric up to plausible numericalinaccuracies.  It is surer and typically much faster to set the valueyourself.
Environments consist of a frame, or collection of namedobjects, and a pointer to an enclosing environment.  The mostcommon example is the frame of variables local to a function call; itsenclosure is the environment where the function was defined(unless changed subsequently).  The enclosing environment isdistinguished from the parent frame: the latter (returned byparent.frame) refers to the environment of the caller ofa function.  Since confusion is so easy, it is best never to use‘parent’ in connection with an environment (despite thepresence of the function parent.env).
Character strings in R can be declared to be encoded in"latin1" or "UTF-8" or as "bytes".  Thesedeclarations can be read by Encoding, which will return acharacter vector of values "latin1", "UTF-8""bytes" or "unknown", or set, when value isrecycled as needed and other values are silently treated as"unknown".  ASCII strings will never be marked with a declaredencoding, since their representation is the same in all supportedencodings.  Strings marked as "bytes" are intended to benon-ASCII strings which should be manipulated as bytes, and neverconverted to a character encoding (so writing them to a text file issupported only by writeLines(useBytes = TRUE)).
Character strings in R can be declared to be encoded in"latin1" or "UTF-8" or as "bytes".  Thesedeclarations can be read by Encoding, which will return acharacter vector of values "latin1", "UTF-8""bytes" or "unknown", or set, when value isrecycled as needed and other values are silently treated as"unknown".  ASCII strings will never be marked with a declaredencoding, since their representation is the same in all supportedencodings.  Strings marked as "bytes" are intended to benon-ASCII strings which should be manipulated as bytes, and neverconverted to a character encoding (so writing them to a text file issupported only by writeLines(useBytes = TRUE)).
This escapes backslash and the control characters \a (bell),\b (backspace), \f (formfeed), \n (line feed),\r (carriage return), \t (tab) and \v(vertical tab) as well as any non-printable characters in asingle-byte locale, which are printed in octal notation (\xyzwith leading zeroes).
Character strings in R can be declared to be encoded in"latin1" or "UTF-8" or as "bytes".  Thesedeclarations can be read by Encoding, which will return acharacter vector of values "latin1", "UTF-8""bytes" or "unknown", or set, when value isrecycled as needed and other values are silently treated as"unknown".  ASCII strings will never be marked with a declaredencoding, since their representation is the same in all supportedencodings.  Strings marked as "bytes" are intended to benon-ASCII strings which should be manipulated as bytes, and neverconverted to a character encoding (so writing them to a text file issupported only by writeLines(useBytes = TRUE)).
Character strings in R can be declared to be encoded in"latin1" or "UTF-8" or as "bytes".  Thesedeclarations can be read by Encoding, which will return acharacter vector of values "latin1", "UTF-8""bytes" or "unknown", or set, when value isrecycled as needed and other values are silently treated as"unknown".  ASCII strings will never be marked with a declaredencoding, since their representation is the same in all supportedencodings.  Strings marked as "bytes" are intended to benon-ASCII strings which should be manipulated as bytes, and neverconverted to a character encoding (so writing them to a text file issupported only by writeLines(useBytes = TRUE)).
startsWith() is equivalent to but much faster than
The typical use of substitute is to create informative labelsfor data sets and plots.The myplot example below shows a simple use of this facility.It uses the functions deparse and substituteto create labels for a plot which are character string versionsof the actual arguments to the function myplot.
Environments consist of a frame, or collection of namedobjects, and a pointer to an enclosing environment.  The mostcommon example is the frame of variables local to a function call; itsenclosure is the environment where the function was defined(unless changed subsequently).  The enclosing environment isdistinguished from the parent frame: the latter (returned byparent.frame) refers to the environment of the caller ofa function.  Since confusion is so easy, it is best never to use‘parent’ in connection with an environment (despite thepresence of the function parent.env).
Environments consist of a frame, or collection of namedobjects, and a pointer to an enclosing environment.  The mostcommon example is the frame of variables local to a function call; itsenclosure is the environment where the function was defined(unless changed subsequently).  The enclosing environment isdistinguished from the parent frame: the latter (returned byparent.frame) refers to the environment of the caller ofa function.  Since confusion is so easy, it is best never to use‘parent’ in connection with an environment (despite thepresence of the function parent.env).
Environments consist of a frame, or collection of namedobjects, and a pointer to an enclosing environment.  The mostcommon example is the frame of variables local to a function call; itsenclosure is the environment where the function was defined(unless changed subsequently).  The enclosing environment isdistinguished from the parent frame: the latter (returned byparent.frame) refers to the environment of the caller ofa function.  Since confusion is so easy, it is best never to use‘parent’ in connection with an environment (despite thepresence of the function parent.env).
The function lockEnvironment locks its environment argument.Locking theenvironment prevents adding or removing variable bindings from theenvironment.  Changing the value of a variable is still possible unlessthe binding has been locked.  The namespace environments of packageswith namespaces are locked when loaded.
Environments consist of a frame, or collection of namedobjects, and a pointer to an enclosing environment.  The mostcommon example is the frame of variables local to a function call; itsenclosure is the environment where the function was defined(unless changed subsequently).  The enclosing environment isdistinguished from the parent frame: the latter (returned byparent.frame) refers to the environment of the caller ofa function.  Since confusion is so easy, it is best never to use‘parent’ in connection with an environment (despite thepresence of the function parent.env).
The condition system provides a mechanism for signaling andhandling unusual conditions, including errors and warnings.Conditions are represented as objects that contain informationabout the condition that occurred, such as a message and the call inwhich the condition occurred.  Currently conditions are S3-styleobjects, though this may eventually change.
eval evaluates the expr argument in theenvironment specified by envir and returns the computed value.If envir is not specified, then the default isparent.frame() (the environment where the call toeval was made).
eval evaluates the expr argument in theenvironment specified by envir and returns the computed value.If envir is not specified, then the default isparent.frame() (the environment where the call toeval was made).
eval evaluates the expr argument in theenvironment specified by envir and returns the computed value.If envir is not specified, then the default isparent.frame() (the environment where the call toeval was made).
The where argument can specify the environment in which to lookfor the object in any of several ways: as an integer (the position inthe search list); as the character string name of anelement in the search list; or as an environment(including using sys.frame to access the currently activefunction calls).  The envir argument is an alternative way tospecify an environment, but is primarily there for back compatibility.
All except logb are generic functions: methods can be definedfor them individually or via the Mathgroup generic.
NA
All except logb are generic functions: methods can be definedfor them individually or via the Mathgroup generic.
‘Expression’ here is not being used in its colloquial sense,that of mathematical expressions.  Those are calls (seecall) in R, and an R expression vector is a list ofcalls, symbols etc, for example as returned by parse.
The reports the versions of third-party software libraries in use.These are often external but might have been compiled into R when itwas installed.
TRUE and FALSE are reserved words denoting logicalconstants in the R language, whereas T and F are globalvariables whose initial values set to these.  All four arelogical(1) vectors.
The type of the vector x is not restricted; it only must havean as.character method and be sortable (byorder).
The functions beta and lbeta return the beta functionand the natural logarithm of the beta function,
The first eleven functions create connections.  By default theconnection is not opened (except for a socket connection created bysocketConnection or socketAccept and for server socketconnection created by serverSocket), but maybe opened by setting a non-empty value of argument open.
The first eleven functions create connections.  By default theconnection is not opened (except for a socket connection created bysocketConnection or socketAccept and for server socketconnection created by serverSocket), but maybe opened by setting a non-empty value of argument open.
The mode value can be the exclusive or of the following values
The ... arguments are concatenated to form one characterstring: you can specify the files separately or as one vector.All of these functions expand path names: see path.expand.
NA
The ... arguments are concatenated to form one characterstring: you can specify the files separately or as one vector.All of these functions expand path names: see path.expand.
The ... arguments are concatenated to form one characterstring: you can specify the files separately or as one vector.All of these functions expand path names: see path.expand.
The ... arguments are concatenated to form one characterstring: you can specify the files separately or as one vector.All of these functions expand path names: see path.expand.
What constitutes a ‘file’ is OS-dependent but includesdirectories.  (However, directory names must not include a trailingbackslash or slash on Windows.)  See also the section in the help forfile.exists on case-insensitive file systems.
The ... arguments are concatenated to form one characterstring: you can specify the files separately or as one vector.All of these functions expand path names: see path.expand.
What constitutes a ‘file’ is OS-dependent but includesdirectories.  (However, directory names must not include a trailingbackslash or slash on Windows.)  See also the section in the help forfile.exists on case-insensitive file systems.
What constitutes a ‘file’ is OS-dependent but includesdirectories.  (However, directory names must not include a trailingbackslash or slash on Windows.)  See also the section in the help forfile.exists on case-insensitive file systems.
The implementation is designed to be fast (faster thanpaste) as this function is used extensively in R itself.
The ... arguments are concatenated to form one characterstring: you can specify the files separately or as one vector.All of these functions expand path names: see path.expand.
The ... arguments are concatenated to form one characterstring: you can specify the files separately or as one vector.All of these functions expand path names: see path.expand.
This function provides the core of the R help system, but it can beused for other purposes as well, such as page.
What constitutes a ‘file’ is OS-dependent but includesdirectories.  (However, directory names must not include a trailingbackslash or slash on Windows.)  See also the section in the help forfile.exists on case-insensitive file systems.
The ... arguments are concatenated to form one characterstring: you can specify the files separately or as one vector.All of these functions expand path names: see path.expand.
If init is given, Reduce logically adds it to the start(when proceeding left to right) or the end of x, respectively.If this possibly augmented vector v has n > 1 elements,Reduce successively applies f to the elements of vfrom left to right or right to left, respectively.  I.e., a leftreduce computes l_1 = f(v_1, v_2), l_2 = f(l_1, v_3), etc.,and returns l_{n-1} = f(l_{n-2}, v_n), and a right reduce doesr_{n-1} = f(v_{n-1}, v_n), r_{n-2} = f(v_{n-2}, r_{n-1})and returns r_1 = f(v_1, r_2).  (E.g., if v is thesequence (2, 3, 4) and f is division, left and right reduce give(2 / 3) / 4 = 1/6 and 2 / (3 / 4) = 8/3, respectively.)If v has only a single element, this is returned; if there areno elements, NULL is returned.  Thus, it is ensured thatf is always called with 2 arguments.
If init is given, Reduce logically adds it to the start(when proceeding left to right) or the end of x, respectively.If this possibly augmented vector v has n > 1 elements,Reduce successively applies f to the elements of vfrom left to right or right to left, respectively.  I.e., a leftreduce computes l_1 = f(v_1, v_2), l_2 = f(l_1, v_3), etc.,and returns l_{n-1} = f(l_{n-2}, v_n), and a right reduce doesr_{n-1} = f(v_{n-1}, v_n), r_{n-2} = f(v_{n-2}, r_{n-1})and returns r_1 = f(v_1, r_2).  (E.g., if v is thesequence (2, 3, 4) and f is division, left and right reduce give(2 / 3) / 4 = 1/6 and 2 / (3 / 4) = 8/3, respectively.)If v has only a single element, this is returned; if there areno elements, NULL is returned.  Thus, it is ensured thatf is always called with 2 arguments.
find.package returns path to the locations where thegiven packages are found.  If lib.loc is NULL, thenloaded namespaces are searched before the libraries.  If a package isfound more than once, the first match is used.  Unless quiet =  TRUE a warning will be given about the named packages which are notfound, and an error if none are.  If verbose is true, warningsabout packages found more than once are given.  For a package to bereturned it must contain a either a ‘Meta’ subdirectory or a‘DESCRIPTION’ file containing a valid version field, butit need not be installed (it could be a source package iflib.loc was set suitably).
The function findInterval finds the index of one vector x inanother, vec, where the latter must be non-decreasing.  Wherethis is trivial, equivalent to apply( outer(x, vec, ">="), 1, sum),as a matter of fact, the internal algorithm uses interval searchensuring O(n * log(N)) complexity wheren <- length(x) (and N <- length(vec)).  For (almost)sorted x, it will be even faster, basically O(n).
The functions .subset and .subset2 are essentiallyequivalent to the [ and [[ operators,except that methods dispatch does not take place.  This is to avoidexpensive unclassing when applying the default method to an object.  Theyshould not normally be invoked by end users.  Note that unlike theoperators they are builtins and not specials (all arguments areevaluated) and hence do not allow missing arguments.
The condition system provides a mechanism for signaling andhandling unusual conditions, including errors and warnings.Conditions are represented as objects that contain informationabout the condition that occurred, such as a message and the call inwhich the condition occurred.  Currently conditions are S3-styleobjects, though this may eventually change.
These are generic functions: methods can be defined for themindividually or via the Math groupgeneric.
The first eleven functions create connections.  By default theconnection is not opened (except for a socket connection created bysocketConnection or socketAccept and for server socketconnection created by serverSocket), but maybe opened by setting a non-empty value of argument open.
The first eleven functions create connections.  By default theconnection is not opened (except for a socket connection created bysocketConnection or socketAccept and for server socketconnection created by serverSocket), but maybe opened by setting a non-empty value of argument open.
break breaks out of a for, while or repeatloop; control is transferred to the first statement outside theinner-most loop. next halts the processing of the currentiteration and advances the looping index.  Both break andnext apply only to the innermost of nested loops.
force forces the evaluation of a formal argument.  This canbe useful if the argument will be captured in a closure by the lexicalscoping rules and will later be altered by an explicit assignment oran implicit assignment in a loop or an apply function.
forceAndCall calls the function FUN with argumentsspecified in ....  If the value of FUN is a closurethen the first n arguments to the function are evaluated(i.e. their delayed evaluation promises are forced) before executingthe function body.  If the value of FUN is a primitive thenthe call FUN(...) is evaluated in the usual way.
For the first form, fun can also be a character string namingthe function to be manipulated, which is searched for in envir,by default from the parentframe.  If it is not specified, the function calling formals isused.
For the first form, fun can also be a character string namingthe function to be manipulated, which is searched for in envir,by default from the parentframe.  If it is not specified, the function calling formals isused.
format is a generic function.  Apart from the methods describedhere there are methods for dates (see format.Date),date-times (see format.POSIXct) and for other classes suchas format.octmode and format.dist.
format is a generic function.  Apart from the methods describedhere there are methods for dates (see format.Date),date-times (see format.POSIXct) and for other classes suchas format.octmode and format.dist.
format is a generic function.  Apart from the methods describedhere there are methods for dates (see format.Date),date-times (see format.POSIXct) and for other classes suchas format.octmode and format.dist.
The usual vector re-cycling rules are applied to x andformat so the answer will be of length that of the longer of thevectors.
format is a generic function.  Apart from the methods describedhere there are methods for dates (see format.Date),date-times (see format.POSIXct) and for other classes suchas format.octmode and format.dist.
Function difftime calculates a difference of two date/timeobjects and returns an object of class "difftime" with anattribute indicating the units.  TheMath group method providesround, signif, floor,ceiling, trunc, abs, andsign methods for objects of this class, and there aremethods for the group-generic (seeOps) logical and arithmeticoperations.
format is a generic function.  Apart from the methods describedhere there are methods for dates (see format.Date),date-times (see format.POSIXct) and for other classes suchas format.octmode and format.dist.
Class "hexmode" consists of integer vectors with that classattribute, used merely to ensure that they are printed in hex.
NA
library(package) and require(package) both load thenamespace of the package with name package and attach it on thesearch list.  require is designed for use inside otherfunctions; it returns FALSE and gives a warning (rather than anerror as library() does by default) if the package does notexist.  Both functions check and update the list of currently attachedpackages and do not reload a namespace which is already loaded.  (Ifyou want to reload such a package, call detach(unload =  TRUE) or unloadNamespace first.)  If you want to load apackage without attaching it on the search list, seerequireNamespace.
Numeric versions are sequences of one or more non-negative integers,usually (e.g., in package ‘DESCRIPTION’ files) represented ascharacter strings with the elements of the sequence concatenated andseparated by single . or - characters.  R packageversions consist of at least two such integers, an R system versionof exactly three (major, minor and patchlevel).
Class "octmode" consists of integer vectors with that classattribute, used merely to ensure that they are printed in octalnotation, specifically for Unix-like file permissions such as755.  Subsetting ([) works too.
library(package) and require(package) both load thenamespace of the package with name package and attach it on thesearch list.  require is designed for use inside otherfunctions; it returns FALSE and gives a warning (rather than anerror as library() does by default) if the package does notexist.  Both functions check and update the list of currently attachedpackages and do not reload a namespace which is already loaded.  (Ifyou want to reload such a package, call detach(unload =  TRUE) or unloadNamespace first.)  If you want to load apackage without attaching it on the search list, seerequireNamespace.
The format and as.character methods and strftimeconvert objects from the classes "POSIXlt" and"POSIXct" to character vectors.
The format and as.character methods and strftimeconvert objects from the classes "POSIXlt" and"POSIXct" to character vectors.
format.pval is mainly an auxiliary function forprint.summary.lm etc., and does separate formatting forfixed, floating point and very small values; those less thaneps are formatted as "< [eps]" (where ‘[eps]’stands for format(eps, digits)).
For factors, the frequency of the first maxsum - 1most frequent levels is shown, and the less frequent levels aresummarized in "(Others)" (resulting in at most maxsumfrequencies).
For numbers, formatC() calls prettyNum() when neededwhich itself calls .format.zeros(*, replace=replace.zero).(“when needed”: when zero.print is notNULL, drop0trailing is true, or one of big.mark,small.mark, or decimal.mark is not at default.)
After extracting the vectors of items and corresponding descriptionsfrom the arguments, both are coerced to character vectors.
Solves a system of linear equations where the coefficient matrix isupper (or ‘right’, ‘R’) or lower (‘left’,‘L’) triangular.
The names in an argument list can be back-quoted non-standard names(see ‘backquote’).
The functions beta and lbeta return the beta functionand the natural logarithm of the beta function,
A call of gc causes a garbage collection to take place.This will also take place automatically without user intervention, and theprimary purpose of calling gc is for the report on memoryusage.  For an accurate report full = TRUE should be used.
Due to timer resolution this may be under-estimate.
A call of gc causes a garbage collection to take place.This will also take place automatically without user intervention, and theprimary purpose of calling gc is for the report on memoryusage.  For an accurate report full = TRUE should be used.
Calling gctorture(TRUE) instructs the memory manager to force afull GC on every allocation. gctorture2 provides a more refinedinterface that allows the start of the GC torture to be deferred andalso gives the option of running a GC only every stepallocations.
Calling gctorture(TRUE) instructs the memory manager to force afull GC on every allocation. gctorture2 provides a more refinedinterface that allows the start of the GC torture to be deferred andalso gives the option of running a GC only every stepallocations.
The pos argument can specify the environment in which to lookfor the object in any of several ways: as a positive integer (theposition in the search list); as the character stringname of an element in the search list; or as anenvironment (including using sys.frameto access the currently active function calls).  The default of-1 indicates the current environment of the call toget. The envir argument is an alternative way tospecify an environment.
The where argument can specify the environment in which to lookfor the object in any of several ways: as an integer (the position inthe search list); as the character string name of anelement in the search list; or as an environment(including using sys.frame to access the currently activefunction calls).  The envir argument is an alternative way tospecify an environment, but is primarily there for back compatibility.
stdin(), stdout() and stderr() are standardconnections corresponding to input, output and error on the consolerespectively (and not necessarily to file streams).  They are text-modeconnections of class "terminal" which cannot be opened orclosed, and are read-only, write-only and write-only respectively.The stdout() and stderr() connections can bere-directed by sink (and in some circumstances theoutput from stdout() can be split: see the help page).
NA
NA
stdin(), stdout() and stderr() are standardconnections corresponding to input, output and error on the consolerespectively (and not necessarily to file streams).  They are text-modeconnections of class "terminal" which cannot be opened orclosed, and are read-only, write-only and write-only respectively.The stdout() and stderr() connections can bere-directed by sink (and in some circumstances theoutput from stdout() can be split: see the help page).
This takes the registration information after it has been registeredand processed by the R internals.  In other words, it uses the extendedinformation.
This takes the registration information after it has been registeredand processed by the R internals.  In other words, it uses the extendedinformation.
This takes the registration information after it has been registeredand processed by the R internals.  In other words, it uses the extendedinformation.
These operators are generic.  You can write methods to handle indexingof specific classes of objects, see InternalMethods as well as[.data.frame and [.factor.  Thedescriptions here apply only to the default methods.  Note thatseparate methods are required for the replacement functions[<-, [[<- and $<- for use when indexing occurs onthe assignment side of an expression.
The error action is controlled by error handlers established withinthe executing code and by the current default error handler set byoptions(error=).  The error is first signaled as if usingsignalCondition().  If there are no handlers or if all handlersreturn, then the error message is printed (ifoptions("show.error.messages") is true) and the default errorhandler is used.  The default behaviour (the NULLerror-handler) in interactive use is to return to the top levelprompt or the top level browser, and in non-interactive use to(effectively) call q("no", status = 1, runLast = FALSE).The default handler stores the error message in a buffer; it can beretrieved by geterrmessage().  It also stores a trace ofthe call stack that can be retrieved by traceback().
getExportedValue returns the value of the exported variablename in namespace ns.
setHook provides a general mechanism for users to registerhooks, a list of functions to be called from system (or user)functions.  The initial set of hooks was associated with events onpackages/namespaces: these hooks are named via calls topackageEvent.
This queries the internal table that manages the DLLs.
getExportedValue returns the value of the exported variablename in namespace ns.
getExportedValue returns the value of the exported variablename in namespace ns.
getExportedValue returns the value of the exported variablename in namespace ns.
packageHasNamespace does not indicate if the package has anamespace (all now do), rather if it has a ‘NAMESPACE’ file,which base and some legacy packages do not.  But then you arenot intended to be using it ....
getExportedValue returns the value of the exported variablename in namespace ns.
getExportedValue returns the value of the exported variablename in namespace ns.
getExportedValue returns the value of the exported variablename in namespace ns.
This uses the same mechanism for resolving symbols as is usedin all the native interfaces (.Call, etc.).If the symbol has been explicitly registered by the DLLin which it is contained, information about the number of argumentsand the interface by which it should be called will be returned.Otherwise, a generic native symbol object is returned.
Invoking options() with no arguments returns a list with thecurrent values of the options.  Note that not all options listed beloware set initially.  To access the value of a single option, one shoulduse, e.g., getOption("width") rather thanoptions("width") which is a list of length one.
Numeric versions are sequences of one or more non-negative integers,usually (e.g., in package ‘DESCRIPTION’ files) represented ascharacter strings with the elements of the sequence concatenated andseparated by single . or - characters.  R packageversions consist of at least two such integers, an R system versionof exactly three (major, minor and patchlevel).
These functions and classes handle source code references.
NA
If domain is NULL or "", and gettextor ngettext  is called from a function in the namespace ofpackage pkg the domain is set to "R-pkg".  Otherwisethere is no default domain.
sprintf is a wrapper for the system sprintf C-libraryfunction.  Attempts are made to check that the mode of the valuespassed match the format supplied, and R's special values (NA,Inf, -Inf and NaN) are handled correctly.
See files for how file paths with marked encodings are interpreted.
NA
The condition system provides a mechanism for signaling andhandling unusual conditions, including errors and warnings.Conditions are represented as objects that contain informationabout the condition that occurred, such as a message and the call inwhich the condition occurred.  Currently conditions are S3-styleobjects, though this may eventually change.
Environments consist of a frame, or collection of namedobjects, and a pointer to an enclosing environment.  The mostcommon example is the frame of variables local to a function call; itsenclosure is the environment where the function was defined(unless changed subsequently).  The enclosing environment isdistinguished from the parent frame: the latter (returned byparent.frame) refers to the environment of the caller ofa function.  Since confusion is so easy, it is best never to use‘parent’ in connection with an environment (despite thepresence of the function parent.env).
Arguments which should be character strings or character vectors arecoerced to character if possible.
Arguments which should be character strings or character vectors arecoerced to character if possible.
Arguments which should be character strings or character vectors arecoerced to character if possible.
Arguments which should be character strings or character vectors arecoerced to character if possible.
Unlike grep, seeks matching patterns within the rawvector x . This has implications especially in the all =  TRUE case, e.g., patterns matching empty strings are inherentlyinfinite and thus may lead to unexpected results.
The function partially sorts the elements so that identical values areadjacent. NA values come last.  This is guaranteed to bestable, so ties are preserved, and if the data are alreadygrouped/sorted, the grouping is unchanged.  This is useful foraggregation and is particularly fast for character vectors.
Arguments which should be character strings or character vectors arecoerced to character if possible.
If con is open then the modified connection is opened.  Closingthe wrapper connection will also close the underlying connection.
The first eleven functions create connections.  By default theconnection is not opened (except for a socket connection created bysocketConnection or socketAccept and for server socketconnection created by serverSocket), but maybe opened by setting a non-empty value of argument open.
Function I has two main uses.
The names of encodings and which ones are available areplatform-dependent.  All R platforms support "" (for theencoding of the current locale), "latin1" and "UTF-8".Generally case is ignored when specifying an encoding.
The names of encodings and which ones are available areplatform-dependent.  All R platforms support "" (for theencoding of the current locale), "latin1" and "UTF-8".Generally case is ignored when specifying an encoding.
Optionally, R can be built to collate character strings by ICU(http://site.icu-project.org).  For such systems,icuSetCollate can be used to tune the way collation is done.On other builds calling this function does nothing, with a warning.
Optionally, R can be built to collate character strings by ICU(http://site.icu-project.org).  For such systems,icuSetCollate can be used to tune the way collation is done.On other builds calling this function does nothing, with a warning.
A call to identical is the way to test exact equality inif and while statements, as well as in logicalexpressions that use && or ||.  In all theseapplications you need to be assured of getting a single logicalvalue.
NA
break breaks out of a for, while or repeatloop; control is transferred to the first statement outside theinner-most loop. next halts the processing of the currentiteration and advances the looping index.  Both break andnext apply only to the innermost of nested loops.
If yes or no are too short, their elements are recycled.yes will be evaluated if and only if any element of testis true, and analogously for no.
Complex vectors can be created with complex.  The vector can bespecified either by giving its length, its real and imaginary parts, ormodulus and argument.  (Giving just the length generates a vector ofcomplex zeroes.)
packageHasNamespace does not indicate if the package has anamespace (all now do), rather if it has a ‘NAMESPACE’ file,which base and some legacy packages do not.  But then you arenot intended to be using it ....
saveRDS and readRDS provide the means to save a single Robject to a connection (typically a file) and to restore the object, quitepossibly under a different name.  This differs from save andload, which save and restore one or more named objects intoan environment.  They are widely used by R itself, for example to storemetadata for a package and to store the help.searchdatabases: the ".rds" file extension is most often used.
Here, we describe the so called “S3” classes (and methods). For“S4” classes (and methods), see ‘Formal classes’ below.
Integer vectors exist so that data can be passed to C or Fortran codewhich expects them, and so that (small) integer data can be representedexactly and compactly.
NA
An interactive R session is one in which it is assumed that there isa human operator to interact with, so for example R can prompt forcorrections to incorrect input or ask what to do next or if it is OKto move to the next plot.
Each of union, intersect, setdiff andsetequal will discard any duplicated values in the arguments,and they apply as.vector to their arguments (and soin particular coerce factors to character vectors).
packBits accepts raw, integer or logical inputs, the last twowithout any NAs.
These will work in any locale, including on platforms that do nototherwise support multi-byte character sets.
‘vector’ is used in the sense of is.vector.
This function can be useful when it is desired to have functionsreturn values which can be assigned, but which do not print when theyare not assigned.
The condition system provides a mechanism for signaling andhandling unusual conditions, including errors and warnings.Conditions are represented as objects that contain informationabout the condition that occurred, such as a message and the call inwhich the condition occurred.  Currently conditions are S3-styleobjects, though this may eventually change.
The condition system provides a mechanism for signaling andhandling unusual conditions, including errors and warnings.Conditions are represented as objects that contain informationabout the condition that occurred, such as a message and the call inwhich the condition occurred.  Currently conditions are S3-styleobjects, though this may eventually change.
An array in R can have one, two or more dimensions.  It is simply avector which is stored with additional attributes giving thedimensions (attribute "dim") and optionally names for thosedimensions (attribute "dimnames").
is.atomic is true for the atomic types("logical", "integer", "numeric","complex", "character" and "raw") and NULL.
returns an unevaluated function call, that is, anunevaluated expression which consists of the named function applied tothe given arguments (name must be a string which givesthe name of a function to be called).  Note that although the call isunevaluated, the arguments ... are evaluated.
as.character and is.character are generic: you canwrite methods to handle specific classes of objects,see InternalMethods.  Further, for as.character thedefault method calls as.vector, so dispatch is first onmethods for as.character and then for methods for as.vector.
Complex vectors can be created with complex.  The vector can bespecified either by giving its length, its real and imaginary parts, ormodulus and argument.  (Giving just the length generates a vector ofcomplex zeroes.)
as.data.frame is a generic function with many methods, andusers and packages can supply further methods.  For classes that actas vectors, often a copy of as.data.frame.vector will workas the method.
double creates a double-precision vector of the specifiedlength.  The elements of the vector are all equal to 0.It is identical to numeric.
Each of union, intersect, setdiff andsetequal will discard any duplicated values in the arguments,and they apply as.vector to their arguments (and soin particular coerce factors to character vectors).
Environments consist of a frame, or collection of namedobjects, and a pointer to an enclosing environment.  The mostcommon example is the frame of variables local to a function call; itsenclosure is the environment where the function was defined(unless changed subsequently).  The enclosing environment isdistinguished from the parent frame: the latter (returned byparent.frame) refers to the environment of the caller ofa function.  Since confusion is so easy, it is best never to use‘parent’ in connection with an environment (despite thepresence of the function parent.env).
‘Expression’ here is not being used in its colloquial sense,that of mathematical expressions.  Those are calls (seecall) in R, and an R expression vector is a list ofcalls, symbols etc, for example as returned by parse.
The type of the vector x is not restricted; it only must havean as.character method and be sortable (byorder).
is.finite returns a vector of the same length as x thejth element of which is TRUE if x[j] is finite (i.e., itis not one of the values NA, NaN, Inf or-Inf) and FALSE otherwise.  Complexnumbers are finite if both the real and imaginary parts are.
is.primitive(x) tests if x is a primitive function,i.e, if typeof(x) is either "builtin" or"special".
is.finite returns a vector of the same length as x thejth element of which is TRUE if x[j] is finite (i.e., itis not one of the values NA, NaN, Inf or-Inf) and FALSE otherwise.  Complexnumbers are finite if both the real and imaginary parts are.
Integer vectors exist so that data can be passed to C or Fortran codewhich expects them, and so that (small) integer data can be representedexactly and compactly.
NA
Almost all lists in R internally are Generic Vectors, whereastraditional dotted pair lists (as in LISP) remain available butrarely seen by users (except as formals of functions).
The objects dyn.load loads are called ‘dynamicallyloadable libraries’ (abbreviated to ‘DLL’) on all platformsexcept macOS, which uses the term for a different sortof object.  On Unix-alikes they are also called ‘dynamicshared objects’ (‘DSO’), or ‘shared objects’ forshort.  (The POSIX standards use ‘executable object file’,but no one else does.)
TRUE and FALSE are reserved words denoting logicalconstants in the R language, whereas T and F are globalvariables whose initial values set to these.  All four arelogical(1) vectors.
If one of nrow or ncol is not given, an attempt ismade to infer it from the length of data and the otherparameter.  If neither is given, a one-column matrix is returned.
The NA of character type is distinct from the string"NA".  Programmers who need to specify an explicit missingstring should use NA_character_ (rather than "NA") or setelements to NA using is.na<-.
The NA of character type is distinct from the string"NA".  Programmers who need to specify an explicit missingstring should use NA_character_ (rather than "NA") or setelements to NA using is.na<-.
Numeric versions are sequences of one or more non-negative integers,usually (e.g., in package ‘DESCRIPTION’ files) represented ascharacter strings with the elements of the sequence concatenated andseparated by single . or - characters.  R packageversions consist of at least two such integers, an R system versionof exactly three (major, minor and patchlevel).
There are two basic classes of date/times.  Class "POSIXct"represents the (signed) number of seconds since the beginning of 1970(in the UTC time zone) as a numeric vector.  Class "POSIXlt" isa named list of vectors representing
The NA of character type is distinct from the string"NA".  Programmers who need to specify an explicit missingstring should use NA_character_ (rather than "NA") or setelements to NA using is.na<-.
The NA of character type is distinct from the string"NA".  Programmers who need to specify an explicit missingstring should use NA_character_ (rather than "NA") or setelements to NA using is.na<-.
The type of the vector x is not restricted; it only must havean as.character method and be sortable (byorder).
Numeric versions are sequences of one or more non-negative integers,usually (e.g., in package ‘DESCRIPTION’ files) represented ascharacter strings with the elements of the sequence concatenated andseparated by single . or - characters.  R packageversions consist of at least two such integers, an R system versionof exactly three (major, minor and patchlevel).
Names are limited to 10,000 bytes (and were to 256 bytes in versionsof R before 2.13.0).
is.finite returns a vector of the same length as x thejth element of which is TRUE if x[j] is finite (i.e., itis not one of the values NA, NaN, Inf or-Inf) and FALSE otherwise.  Complexnumbers are finite if both the real and imaginary parts are.
NULL can be indexed (see Extract) in just about anysyntactically legal way: whether it makes sense or not, the result isalways NULL.  Objects with value NULL can be changed byreplacement operators and will be coerced to the type of theright-hand side.
numeric is identical to double (and real).It creates a double-precision vector of the specified length with eachelement equal to 0.
Numeric versions are sequences of one or more non-negative integers,usually (e.g., in package ‘DESCRIPTION’ files) represented ascharacter strings with the elements of the sequence concatenated andseparated by single . or - characters.  R packageversions consist of at least two such integers, an R system versionof exactly three (major, minor and patchlevel).
numeric is identical to double (and real).It creates a double-precision vector of the specified length with eachelement equal to 0.
Function difftime calculates a difference of two date/timeobjects and returns an object of class "difftime" with anattribute indicating the units.  TheMath group method providesround, signif, floor,ceiling, trunc, abs, andsign methods for objects of this class, and there aremethods for the group-generic (seeOps) logical and arithmeticoperations.
numeric is identical to double (and real).It creates a double-precision vector of the specified length with eachelement equal to 0.
NA
The type of the vector x is not restricted; it only must havean as.character method and be sortable (byorder).
Numeric versions are sequences of one or more non-negative integers,usually (e.g., in package ‘DESCRIPTION’ files) represented ascharacter strings with the elements of the sequence concatenated andseparated by single . or - characters.  R packageversions consist of at least two such integers, an R system versionof exactly three (major, minor and patchlevel).
Almost all lists in R internally are Generic Vectors, whereastraditional dotted pair lists (as in LISP) remain available butrarely seen by users (except as formals of functions).
is.primitive(x) tests if x is a primitive function,i.e, if typeof(x) is either "builtin" or"special".
The QR decomposition plays an important role in manystatistical techniques.  In particular it can be used to solve theequation \bold{Ax} = \bold{b} for given matrix \bold{A},and vector \bold{b}.  It is useful for computing regressioncoefficients and in applying the Newton-Raphson algorithm.
The function has been written such as to correctly run in all versionsof R, S and S-PLUS.In order for code to be runnable in both R and S dialects previous toS-PLUS 8.0, your code must either define is.R or use it as
The raw type is intended to hold raw bytes.  It is possible to extractsubsequences of bytes, and to replace elements (but only by elementsof a raw vector).  The relational operators (see Comparison,using the numerical order of the byte representation) work, as do thelogical operators (see Logic) with a bitwise interpretation.
is.atomic is true for the atomic types("logical", "integer", "numeric","complex", "character" and "raw") and NULL.
NA
Names are limited to 10,000 bytes (and were to 256 bytes in versionsof R before 2.13.0).
If the argument dnn is not supplied, the internal functionlist.names is called to compute the ‘dimname names’.  If thearguments in ... are named, those names are used.  For theremaining arguments, deparse.level = 0 gives an empty name,deparse.level = 1 uses the supplied argument if it is a symbol,and deparse.level = 2 will deparse the argument.
is.unsorted is generic: you can write methods to handlespecific classes of objects, see InternalMethods.
The atomic modes are "logical", "integer","numeric" (synonym "double"), "complex","character" and "raw".
Here, we describe the so called “S3” classes (and methods). For“S4” classes (and methods), see ‘Formal classes’ below.
stdin(), stdout() and stderr() are standardconnections corresponding to input, output and error on the consolerespectively (and not necessarily to file streams).  They are text-modeconnections of class "terminal" which cannot be opened orclosed, and are read-only, write-only and write-only respectively.The stdout() and stderr() connections can bere-directed by sink (and in some circumstances theoutput from stdout() can be split: see the help page).
packageHasNamespace does not indicate if the package has anamespace (all now do), rather if it has a ‘NAMESPACE’ file,which base and some legacy packages do not.  But then you arenot intended to be using it ....
When a function flagged for debugging is entered, normal executionis suspended and the body of function is executed one statement at atime.  A new browser context is initiated for each step(and the previous one destroyed).
! indicates logical negation (NOT).
The first eleven functions create connections.  By default theconnection is not opened (except for a socket connection created bysocketConnection or socketAccept and for server socketconnection created by serverSocket), but maybe opened by setting a non-empty value of argument open.
packageHasNamespace does not indicate if the package has anamespace (all now do), rather if it has a ‘NAMESPACE’ file,which base and some legacy packages do not.  But then you arenot intended to be using it ....
The functions loadNamespace and attachNamespace areusually called implicitly when library is used to load a namespace and any imports needed.  However it may be useful at times tocall these functions directly.
ISOdatetime and ISOdate are convenience wrappers forstrptime that differ only in their defaults and thatISOdate sets UTC as the time zone.  For dates without times itwould normally be better to use the "Date" class.
ISOdatetime and ISOdate are convenience wrappers forstrptime that differ only in their defaults and thatISOdate sets UTC as the time zone.  For dates without times itwould normally be better to use the "Date" class.
The first eleven functions create connections.  By default theconnection is not opened (except for a socket connection created bysocketConnection or socketAccept and for server socketconnection created by serverSocket), but maybe opened by setting a non-empty value of argument open.
The condition system provides a mechanism for signaling andhandling unusual conditions, including errors and warnings.Conditions are represented as objects that contain informationabout the condition that occurred, such as a message and the call inwhich the condition occurred.  Currently conditions are S3-styleobjects, though this may eventually change.
Note that isS4 does not rely on the methodspackage, so in particular it can be used to detect the need torequire that package.
seek with where = NA returns the current byte offsetof a connection (from the beginning), and with a non-missing whereargument the connection is re-positioned (if possible) to thespecified position.  isSeekable returns whether the connectionin principle supports seek: currently only (possiblygz-compressed) file connections do.
The matrix method is used inside eigen bydefault to test symmetry of matrices up to rounding error, usingall.equal.  It might not be appropriate in allsituations.
The matrix method is used inside eigen bydefault to test symmetry of matrices up to rounding error, usingall.equal.  It might not be appropriate in allsituations.
! indicates logical negation (NOT).
The result, say r, is r <- x + runif(n, -a, a)where n <- length(x) and a is the amountargument (if specified).
NA
NA
NA
For kappa(), if exact = FALSE (the default) the 2-normcondition number is estimated by a cheap approximation.  However, theexact calculation (via svd) is also likely to be quickenough.
For kappa(), if exact = FALSE (the default) the 2-normcondition number is estimated by a cheap approximation.  However, theexact calculation (via svd) is also likely to be quickenough.
For kappa(), if exact = FALSE (the default) the 2-normcondition number is estimated by a cheap approximation.  However, theexact calculation (via svd) is also likely to be quickenough.
For kappa(), if exact = FALSE (the default) the 2-normcondition number is estimated by a cheap approximation.  However, theexact calculation (via svd) is also likely to be quickenough.
If X and Y do not have the same number ofdimensions, the smaller array is padded with dimensions of sizeone.  The returned array comprises submatrices constructed bytaking X one term at a time and expanding that term asFUN(x, Y, ...).
‘A Latin-1 locale’ includes supersets (for printablecharacters) such as Windows codepage 1252 but not Latin-9 (ISO 8859-15).
NA
NA
The singular value decomposition plays an important role in manystatistical techniques.  svd and La.svd provide twointerfaces which differ in their return values.
NA
NA
FUN is found by a call to match.fun and typicallyis specified as a function or a symbol (e.g., a backquoted name) or acharacter string specifying a function to be searched for from theenvironment of the call to lapply.
These are internal functions for use only by R itself.
These are internal functions for use only by R itself.
The functions .subset and .subset2 are essentiallyequivalent to the [ and [[ operators,except that methods dispatch does not take place.  This is to avoidexpensive unclassing when applying the default method to an object.  Theyshould not normally be invoked by end users.  Note that unlike theoperators they are builtins and not specials (all arguments areevaluated) and hence do not allow missing arguments.
The functions beta and lbeta return the beta functionand the natural logarithm of the beta function,
The functions beta and lbeta return the beta functionand the natural logarithm of the beta function,
Both functions are generic: you can write methods to handle specificclasses of objects, see InternalMethods.  length<- has a"factor" method.
There are two basic classes of date/times.  Class "POSIXct"represents the (signed) number of seconds since the beginning of 1970(in the UTC time zone) as a numeric vector.  Class "POSIXlt" isa named list of vectors representing
Both functions are generic: you can write methods to handle specificclasses of objects, see InternalMethods.  length<- has a"factor" method.
Dates are represented as the number of days since 1970-01-01, withnegative values for earlier dates.  They are always printedfollowing the rules of the current Gregorian calendar, even thoughthat calendar was not in use long ago (it was adopted in 1752 inGreat Britain and its colonies).
Function difftime calculates a difference of two date/timeobjects and returns an object of class "difftime" with anattribute indicating the units.  TheMath group method providesround, signif, floor,ceiling, trunc, abs, andsign methods for objects of this class, and there aremethods for the group-generic (seeOps) logical and arithmeticoperations.
Both functions are generic: you can write methods to handle specificclasses of objects, see InternalMethods.  length<- has a"factor" method.
There are two basic classes of date/times.  Class "POSIXct"represents the (signed) number of seconds since the beginning of 1970(in the UTC time zone) as a numeric vector.  Class "POSIXlt" isa named list of vectors representing
There are two basic classes of date/times.  Class "POSIXct"represents the (signed) number of seconds since the beginning of 1970(in the UTC time zone) as a numeric vector.  Class "POSIXlt" isa named list of vectors representing
This function loops over x and returns a compatible vectorcontaining the length of each element in x.  Effectively,length(x[[i]]) is called for all i, so any methods onlength are considered.
R has a small number of built-in constants.
R has a small number of built-in constants.
Both the extractor and replacement forms are generic and new methodscan be written for them.  The most important method for the replacementfunction is that for factors.
Both the extractor and replacement forms are generic and new methodscan be written for them.  The most important method for the replacementfunction is that for factors.
Both the extractor and replacement forms are generic and new methodscan be written for them.  The most important method for the replacementfunction is that for factors.
Both the extractor and replacement forms are generic and new methodscan be written for them.  The most important method for the replacementfunction is that for factors.
The functions beta and lbeta return the beta functionand the natural logarithm of the beta function,
The functions beta and lbeta return the beta functionand the natural logarithm of the beta function,
NA
library(package) and require(package) both load thenamespace of the package with name package and attach it on thesearch list.  require is designed for use inside otherfunctions; it returns FALSE and gives a warning (rather than anerror as library() does by default) if the package does notexist.  Both functions check and update the list of currently attachedpackages and do not reload a namespace which is already loaded.  (Ifyou want to reload such a package, call detach(unload =  TRUE) or unloadNamespace first.)  If you want to load apackage without attaching it on the search list, seerequireNamespace.
See dyn.load for what sort of objects these functions handle.
See dyn.load for what sort of objects these functions handle.
R is distributed under the terms of the GNU GENERAL PUBLIC LICENSE,either Version 2, June 1991 or Version 3, June 2007.  A copy of theversion 2 license is in file ‘R_HOME/doc/COPYING’and can be viewed by RShowDoc("COPYING").  Version 3 of thelicense can be displayed by RShowDoc("GPL-3").
R is distributed under the terms of the GNU GENERAL PUBLIC LICENSE,either Version 2, June 1991 or Version 3, June 2007.  A copy of theversion 2 license is in file ‘R_HOME/doc/COPYING’and can be viewed by RShowDoc("COPYING").  Version 3 of thelicense can be displayed by RShowDoc("GPL-3").
Almost all lists in R internally are Generic Vectors, whereastraditional dotted pair lists (as in LISP) remain available butrarely seen by users (except as formals of functions).
NA
NA
Note that all list elements are taken “as is” (apart frompossibly replicating to the same length).
This will be very slow for large inputs unless hashing is used on theenvironment.
load can load R objects saved in the current or any earlierformat.  It can read a compressed file (see save)directly from a file or from a suitable connection (including a callto url).
The functions loadNamespace and attachNamespace areusually called implicitly when library is used to load a namespace and any imports needed.  However it may be useful at times tocall these functions directly.
packageHasNamespace does not indicate if the package has anamespace (all now do), rather if it has a ‘NAMESPACE’ file,which base and some legacy packages do not.  But then you arenot intended to be using it ....
The functions loadNamespace and attachNamespace areusually called implicitly when library is used to load a namespace and any imports needed.  However it may be useful at times tocall these functions directly.
eval evaluates the expr argument in theenvironment specified by envir and returns the computed value.If envir is not specified, then the default isparent.frame() (the environment where the call toeval was made).
The function lockEnvironment locks its environment argument.Locking theenvironment prevents adding or removing variable bindings from theenvironment.  Changing the value of a variable is still possible unlessthe binding has been locked.  The namespace environments of packageswith namespaces are locked when loaded.
The function lockEnvironment locks its environment argument.Locking theenvironment prevents adding or removing variable bindings from theenvironment.  Changing the value of a variable is still possible unlessthe binding has been locked.  The namespace environments of packageswith namespaces are locked when loaded.
All except logb are generic functions: methods can be definedfor them individually or via the Mathgroup generic.
All except logb are generic functions: methods can be definedfor them individually or via the Mathgroup generic.
All except logb are generic functions: methods can be definedfor them individually or via the Mathgroup generic.
All except logb are generic functions: methods can be definedfor them individually or via the Mathgroup generic.
All except logb are generic functions: methods can be definedfor them individually or via the Mathgroup generic.
TRUE and FALSE are reserved words denoting logicalconstants in the R language, whereas T and F are globalvariables whose initial values set to these.  All four arelogical(1) vectors.
NA
The name argument can specify the  environment from whichobject names are taken in one of several forms:as an integer (the position in the search list); asthe character string name of an element in the search list; or as anexplicit environment (including usingsys.frame to access the currently active function calls).By default, the environment of the call to ls or objectsis used. The pos and envir arguments are an alternativeway to specify an environment, but are primarily there for backcompatibility.
A syntactically valid name consists of letters, numbers and the dot orunderline characters and starts with a letter or the dot not followedby a number.  Names such as ".2way" are not valid, and neitherare the reserved words.
The algorithm used by make.unique has the property thatmake.unique(c(A, B)) == make.unique(c(make.unique(A), B)).
The function lockEnvironment locks its environment argument.Locking theenvironment prevents adding or removing variable bindings from theenvironment.  Changing the value of a variable is still possible unlessthe binding has been locked.  The namespace environments of packageswith namespaces are locked when loaded.
If init is given, Reduce logically adds it to the start(when proceeding left to right) or the end of x, respectively.If this possibly augmented vector v has n > 1 elements,Reduce successively applies f to the elements of vfrom left to right or right to left, respectively.  I.e., a leftreduce computes l_1 = f(v_1, v_2), l_2 = f(l_1, v_3), etc.,and returns l_{n-1} = f(l_{n-2}, v_n), and a right reduce doesr_{n-1} = f(v_{n-1}, v_n), r_{n-2} = f(v_{n-2}, r_{n-1})and returns r_1 = f(v_1, r_2).  (E.g., if v is thesequence (2, 3, 4) and f is division, left and right reduce give(2 / 3) / 4 = 1/6 and 2 / (3 / 4) = 8/3, respectively.)If v has only a single element, this is returned; if there areno elements, NULL is returned.  Thus, it is ensured thatf is always called with 2 arguments.
mapply calls FUN for the values of ...(re-cycled to the length of the longest, unless any have length zero),followed by the arguments given in MoreArgs.  The arguments inthe call will be named if ... or MoreArgs are named.
NA
NA
NA
%in% is currently defined as "%in%" <- function(x, table) match(x, table, nomatch = 0) > 0
In the one-argument form match.arg(arg), the choices areobtained from a default setting for the formal argument arg ofthe function from which match.arg was called.  (Since defaultargument matching will set arg to choices, this isallowed as an exception to the ‘length one unlessseveral.ok is TRUE’ rule, and returns the firstelement.)
‘function’ on this help page means an interpreted function(also known as a ‘closure’):  match.call does not supportprimitive functions (where argument matching is normallypositional).
match.fun is not intended to be used at the top level since itwill perform matching in the parent of the caller.
There are four groups for which S3 methods can be written,namely the "Math", "Ops", "Summary" and"Complex" groups.  These are not R objects in base R, butmethods can be supplied for them and base R containsfactor, data.frame anddifftime methods for the first three groups.  (There isalso a ordered method for Ops,POSIXt and Date methods for Mathand Ops, package_version methods for Opsand Summary, as well as a ts method forOps in package stats.)
Dates are represented as the number of days since 1970-01-01, withnegative values for earlier dates.  They are always printedfollowing the rules of the current Gregorian calendar, even thoughthat calendar was not in use long ago (it was adopted in 1752 inGreat Britain and its colonies).
Function difftime calculates a difference of two date/timeobjects and returns an object of class "difftime" with anattribute indicating the units.  TheMath group method providesround, signif, floor,ceiling, trunc, abs, andsign methods for objects of this class, and there aremethods for the group-generic (seeOps) logical and arithmeticoperations.
The type of the vector x is not restricted; it only must havean as.character method and be sortable (byorder).
There are two basic classes of date/times.  Class "POSIXct"represents the (signed) number of seconds since the beginning of 1970(in the UTC time zone) as a numeric vector.  Class "POSIXlt" isa named list of vectors representing
If one of nrow or ncol is not given, an attempt ismade to infer it from the length of data and the otherparameter.  If neither is given, a one-column matrix is returned.
max and min return the maximum or minimum of allthe  values present in their arguments, as integer ifall are logical or integer, as double ifall are numeric, and character otherwise.
When ties.method = "random", as per default, ties are broken atrandom.  In this case, the determination of a tie assumes thatthe entries are probabilities: there is a relative tolerance of1e-5, relative to the largest (in magnitude, omittinginfinity) entry in the row.
NA
Dates are represented as the number of days since 1970-01-01, withnegative values for earlier dates.  They are always printedfollowing the rules of the current Gregorian calendar, even thoughthat calendar was not in use long ago (it was adopted in 1752 inGreat Britain and its colonies).
NA
Function difftime calculates a difference of two date/timeobjects and returns an object of class "difftime" with anattribute indicating the units.  TheMath group method providesround, signif, floor,ceiling, trunc, abs, andsign methods for objects of this class, and there aremethods for the group-generic (seeOps) logical and arithmeticoperations.
There are two basic classes of date/times.  Class "POSIXct"represents the (signed) number of seconds since the beginning of 1970(in the UTC time zone) as a numeric vector.  Class "POSIXlt" isa named list of vectors representing
There are two basic classes of date/times.  Class "POSIXct"represents the (signed) number of seconds since the beginning of 1970(in the UTC time zone) as a numeric vector.  Class "POSIXlt" isa named list of vectors representing
New Limits lower than current usage are ignored.Specifying a size of Inf sets the limit to the maximal possiblevalue for the platform.
New Limits lower than current usage are ignored.Specifying a size of Inf sets the limit to the maximal possiblevalue for the platform.
type = "none" passes the input through unchanged, but may beuseful if type is a variable.
type = "none" passes the input through unchanged, but may beuseful if type is a variable.
The current types and their uses are listed in the include file‘Rinternals.h’.
merge is a generic function whose principal method is for dataframes: the default method coerces its arguments to data frames andcalls the "data.frame" method.
merge is a generic function whose principal method is for dataframes: the default method coerces its arguments to data frames andcalls the "data.frame" method.
merge is a generic function whose principal method is for dataframes: the default method coerces its arguments to data frames andcalls the "data.frame" method.
message is used for generating ‘simple’ diagnosticmessages which are neither warnings nor errors, but neverthelessrepresented as conditions.  Unlike warnings and errors, a finalnewline is regarded as part of the message, and is optional.The default handler sends the message to thestderr() connection.
The pos argument can specify the environment in which to lookfor the object in any of several ways: as a positive integer (theposition in the search list); as the character stringname of an element in the search list; or as anenvironment (including using sys.frameto access the currently active function calls).  The default of-1 indicates the current environment of the call toget. The envir argument is an alternative way tospecify an environment.
max and min return the maximum or minimum of allthe  values present in their arguments, as integer ifall are logical or integer, as double ifall are numeric, and character otherwise.
missing(x) is only reliable if x has not been alteredsince entering the function: in particular it will alwaysbe false after x <- match.arg(x).
Complex vectors can be created with complex.  The vector can bespecified either by giving its length, its real and imaginary parts, ormodulus and argument.  (Giving just the length generates a vector ofcomplex zeroes.)
Both mode and storage.mode return a character stringgiving the (storage) mode of the object — often the same — bothrelying on the output of typeof(x), see the examplebelow.
Both mode and storage.mode return a character stringgiving the (storage) mode of the object — often the same — bothrelying on the output of typeof(x), see the examplebelow.
R has a small number of built-in constants.
R has a small number of built-in constants.
NA
NA
NA
Unlike attr it is not an error to set attributes on aNULL object: it will first be coerced to an empty list.
names is a generic accessor function, and names<- is ageneric replacement function.  The default methods get and setthe "names" attribute of a vector (including a list) orpairlist.
There are two basic classes of date/times.  Class "POSIXct"represents the (signed) number of seconds since the beginning of 1970(in the UTC time zone) as a numeric vector.  Class "POSIXlt" isa named list of vectors representing
names is a generic accessor function, and names<- is ageneric replacement function.  The default methods get and setthe "names" attribute of a vector (including a list) orpairlist.
There are two basic classes of date/times.  Class "POSIXct"represents the (signed) number of seconds since the beginning of 1970(in the UTC time zone) as a numeric vector.  Class "POSIXlt" isa named list of vectors representing
packageHasNamespace does not indicate if the package has anamespace (all now do), rather if it has a ‘NAMESPACE’ file,which base and some legacy packages do not.  But then you arenot intended to be using it ....
packageHasNamespace does not indicate if the package has anamespace (all now do), rather if it has a ‘NAMESPACE’ file,which base and some legacy packages do not.  But then you arenot intended to be using it ....
packageHasNamespace does not indicate if the package has anamespace (all now do), rather if it has a ‘NAMESPACE’ file,which base and some legacy packages do not.  But then you arenot intended to be using it ....
packageHasNamespace does not indicate if the package has anamespace (all now do), rather if it has a ‘NAMESPACE’ file,which base and some legacy packages do not.  But then you arenot intended to be using it ....
packageHasNamespace does not indicate if the package has anamespace (all now do), rather if it has a ‘NAMESPACE’ file,which base and some legacy packages do not.  But then you arenot intended to be using it ....
The count includes empty (missing) arguments, so that foo(x,,z)will be considered to have three arguments (see ‘Examples’).This can occur in rather indirect ways, so for example x[]might dispatch a call to `[.some_method`(x, ) which isconsidered to have two arguments.
The ‘size’ of a character string can be measured in one ofthree ways (corresponding to the type argument):
NA
NA
If init is given, Reduce logically adds it to the start(when proceeding left to right) or the end of x, respectively.If this possibly augmented vector v has n > 1 elements,Reduce successively applies f to the elements of vfrom left to right or right to left, respectively.  I.e., a leftreduce computes l_1 = f(v_1, v_2), l_2 = f(l_1, v_3), etc.,and returns l_{n-1} = f(l_{n-2}, v_n), and a right reduce doesr_{n-1} = f(v_{n-1}, v_n), r_{n-2} = f(v_{n-2}, r_{n-1})and returns r_1 = f(v_1, r_2).  (E.g., if v is thesequence (2, 3, 4) and f is division, left and right reduce give(2 / 3) / 4 = 1/6 and 2 / (3 / 4) = 8/3, respectively.)If v has only a single element, this is returned; if there areno elements, NULL is returned.  Thus, it is ensured thatf is always called with 2 arguments.
Environments consist of a frame, or collection of namedobjects, and a pointer to an enclosing environment.  The mostcommon example is the frame of variables local to a function call; itsenclosure is the environment where the function was defined(unless changed subsequently).  The enclosing environment isdistinguished from the parent frame: the latter (returned byparent.frame) refers to the environment of the caller ofa function.  Since confusion is so easy, it is best never to use‘parent’ in connection with an environment (despite thepresence of the function parent.env).
break breaks out of a for, while or repeatloop; control is transferred to the first statement outside theinner-most loop. next halts the processing of the currentiteration and advances the looping index.  Both break andnext apply only to the innermost of nested loops.
An R object is a data object which has a classattribute (and this can be tested by is.object).A class attribute is a character vector giving the names ofthe classes from which the object inherits.If the object does not have a class attribute, it has an implicitclass.  Matrices and arrays have class "matrix"or"array" followed by the class of the underlying vector.Most vectors have class the result of mode(x), exceptthat integer vectors have class c("integer", "numeric") andreal vectors have class c("double", "numeric").
If domain is NULL or "", and gettextor ngettext  is called from a function in the namespace ofpackage pkg the domain is set to "R-pkg".  Otherwisethere is no default domain.
This is usually applied to a factor, but other objects can have levels.
noquote returns its argument as an object of class"noquote".  There is a method for c() and subscriptmethod ("[.noquote") which ensures that the class is not lostby subsetting.  The print method (print.noquote) printscharacter strings without quotes ("...." is printed as ....).
The base method of norm() calls the LAPACK functiondlange.
Tilde-expansion (see path.expand) is first done onpaths.
NA
NA
stdin(), stdout() and stderr() are standardconnections corresponding to input, output and error on the consolerespectively (and not necessarily to file streams).  They are text-modeconnections of class "terminal" which cannot be opened orclosed, and are read-only, write-only and write-only respectively.The stdout() and stderr() connections can bere-directed by sink (and in some circumstances theoutput from stdout() can be split: see the help page).
numeric is identical to double (and real).It creates a double-precision vector of the specified length with eachelement equal to 0.
Numeric versions are sequences of one or more non-negative integers,usually (e.g., in package ‘DESCRIPTION’ files) represented ascharacter strings with the elements of the sequence concatenated andseparated by single . or - characters.  R packageversions consist of at least two such integers, an R system versionof exactly three (major, minor and patchlevel).
packBits accepts raw, integer or logical inputs, the last twowithout any NAs.
packBits accepts raw, integer or logical inputs, the last twowithout any NAs.
The ‘size’ of a character string can be measured in one ofthree ways (corresponding to the type argument):
The name argument can specify the  environment from whichobject names are taken in one of several forms:as an integer (the position in the search list); asthe character string name of an element in the search list; or as anexplicit environment (including usingsys.frame to access the currently active function calls).By default, the environment of the call to ls or objectsis used. The pos and envir arguments are an alternativeway to specify an environment, but are primarily there for backcompatibility.
Here, we describe the so called “S3” classes (and methods). For“S4” classes (and methods), see ‘Formal classes’ below.
Here, we describe the so called “S3” classes (and methods). For“S4” classes (and methods), see ‘Formal classes’ below.
Time zones are a system-specific topic, but these days almost all Rplatforms use similar underlying code, used by Linux, macOS, Solaris,AIX and FreeBSD, and installed with R on Windows.  (Unfortunatelythere are many system-specific errors in the implementations.)  It ispossible to use the R sources' version of the code on Unix-alikes aswell as on Windows: this is the default for macOS and recommended forSolaris.
The expr argument passed to on.exit is recorded withoutevaluation.  If it is not subsequently removed/replaced by anotheron.exit call in the same function, it is evaluated in theevaluation frame of the function when it exits (including duringstandard error handling).  Thus any functions or variables in theexpression will be looked for in the function and its environment atthe time of exit: to capture the current value in expr usesubstitute or similar.
The first eleven functions create connections.  By default theconnection is not opened (except for a socket connection created bysocketConnection or socketAccept and for server socketconnection created by serverSocket), but maybe opened by setting a non-empty value of argument open.
The first eleven functions create connections.  By default theconnection is not opened (except for a socket connection created bysocketConnection or socketAccept and for server socketconnection created by serverSocket), but maybe opened by setting a non-empty value of argument open.
These functions and classes handle source code references.
These functions and classes handle source code references.
These functions and classes handle source code references.
There are four groups for which S3 methods can be written,namely the "Math", "Ops", "Summary" and"Complex" groups.  These are not R objects in base R, butmethods can be supplied for them and base R containsfactor, data.frame anddifftime methods for the first three groups.  (There isalso a ordered method for Ops,POSIXt and Date methods for Mathand Ops, package_version methods for Opsand Summary, as well as a ts method forOps in package stats.)
x does not need to be integer if specified as a numeric vector,but see the comments about fractional days in the help forDates.
Function difftime calculates a difference of two date/timeobjects and returns an object of class "difftime" with anattribute indicating the units.  TheMath group method providesround, signif, floor,ceiling, trunc, abs, andsign methods for objects of this class, and there aremethods for the group-generic (seeOps) logical and arithmeticoperations.
The type of the vector x is not restricted; it only must havean as.character method and be sortable (byorder).
Numeric versions are sequences of one or more non-negative integers,usually (e.g., in package ‘DESCRIPTION’ files) represented ascharacter strings with the elements of the sequence concatenated andseparated by single . or - characters.  R packageversions consist of at least two such integers, an R system versionof exactly three (major, minor and patchlevel).
The type of the vector x is not restricted; it only must havean as.character method and be sortable (byorder).
There are two basic classes of date/times.  Class "POSIXct"represents the (signed) number of seconds since the beginning of 1970(in the UTC time zone) as a numeric vector.  Class "POSIXlt" isa named list of vectors representing
Invoking options() with no arguments returns a list with thecurrent values of the options.  Note that not all options listed beloware set initially.  To access the value of a single option, one shoulduse, e.g., getOption("width") rather thanoptions("width") which is a list of length one.
In the case of ties in the first vector, values in the second are usedto break the ties.  If the values are still tied, values in the laterarguments are used to break the tie (see the first example).The sort used is stable (except for method = "quick"),so any unresolved ties will be left in their original ordering.
The type of the vector x is not restricted; it only must havean as.character method and be sortable (byorder).
X and Y must be suitable arguments for FUN.  Eachwill be extended by rep to length the products of thelengths of X and Y before FUN is called.
Numeric versions are sequences of one or more non-negative integers,usually (e.g., in package ‘DESCRIPTION’ files) represented ascharacter strings with the elements of the sequence concatenated andseparated by single . or - characters.  R packageversions consist of at least two such integers, an R system versionof exactly three (major, minor and patchlevel).
setHook provides a general mechanism for users to registerhooks, a list of functions to be called from system (or user)functions.  The initial set of hooks was associated with events onpackages/namespaces: these hooks are named via calls topackageEvent.
packageHasNamespace does not indicate if the package has anamespace (all now do), rather if it has a ‘NAMESPACE’ file,which base and some legacy packages do not.  But then you arenot intended to be using it ....
find.package returns path to the locations where thegiven packages are found.  If lib.loc is NULL, thenloaded namespaces are searched before the libraries.  If a package isfound more than once, the first match is used.  Unless quiet =  TRUE a warning will be given about the named packages which are notfound, and an error if none are.  If verbose is true, warningsabout packages found more than once are given.  For a package to bereturned it must contain a either a ‘Meta’ subdirectory or a‘DESCRIPTION’ file containing a valid version field, butit need not be installed (it could be a source package iflib.loc was set suitably).
message is used for generating ‘simple’ diagnosticmessages which are neither warnings nor errors, but neverthelessrepresented as conditions.  Unlike warnings and errors, a finalnewline is regarded as part of the message, and is optional.The default handler sends the message to thestderr() connection.
packBits accepts raw, integer or logical inputs, the last twowithout any NAs.
Almost all lists in R internally are Generic Vectors, whereastraditional dotted pair lists (as in LISP) remain available butrarely seen by users (except as formals of functions).
Environments consist of a frame, or collection of namedobjects, and a pointer to an enclosing environment.  The mostcommon example is the frame of variables local to a function call; itsenclosure is the environment where the function was defined(unless changed subsequently).  The enclosing environment isdistinguished from the parent frame: the latter (returned byparent.frame) refers to the environment of the caller ofa function.  Since confusion is so easy, it is best never to use‘parent’ in connection with an environment (despite thepresence of the function parent.env).
Environments consist of a frame, or collection of namedobjects, and a pointer to an enclosing environment.  The mostcommon example is the frame of variables local to a function call; itsenclosure is the environment where the function was defined(unless changed subsequently).  The enclosing environment isdistinguished from the parent frame: the latter (returned byparent.frame) refers to the environment of the caller ofa function.  Since confusion is so easy, it is best never to use‘parent’ in connection with an environment (despite thepresence of the function parent.env).
.GlobalEnv is given number 0 in the list of frames.Each subsequent function evaluation increases the frame stack by 1.The call, function definition and the environment for evaluationof that function are returned by sys.call, sys.functionand sys.frame with the appropriate index.
If text has length greater than zero (after coercion) it is used inpreference to file.
packageHasNamespace does not indicate if the package has anamespace (all now do), rather if it has a ‘NAMESPACE’ file,which base and some legacy packages do not.  But then you arenot intended to be using it ....
paste converts its arguments (viaas.character) to character strings, and concatenatesthem (separating them by the string given by sep).  If thearguments are vectors, they are concatenated term-by-term to give acharacter vector result.  Vector arguments are recycled as needed,with zero-length arguments being recycled to "" only ifrecycle0 is not true or collapse is notNULL.
paste converts its arguments (viaas.character) to character strings, and concatenatesthem (separating them by the string given by sep).  If thearguments are vectors, they are concatenated term-by-term to give acharacter vector result.  Vector arguments are recycled as needed,with zero-length arguments being recycled to "" only ifrecycle0 is not true or collapse is notNULL.
On most builds of R a leading ~user will expand to the homedirectory of user (since R 4.1.0 also without readlinein use).
find.package returns path to the locations where thegiven packages are found.  If lib.loc is NULL, thenloaded namespaces are searched before the libraries.  If a package isfound more than once, the first match is used.  Unless quiet =  TRUE a warning will be given about the named packages which are notfound, and an error if none are.  If verbose is true, warningsabout packages found more than once are given.  For a package to bereturned it must contain a either a ‘Meta’ subdirectory or a‘DESCRIPTION’ file containing a valid version field, butit need not be installed (it could be a source package iflib.loc was set suitably).
NA
R has a small number of built-in constants.
The first eleven functions create connections.  By default theconnection is not opened (except for a socket connection created bysocketConnection or socketAccept and for server socketconnection created by serverSocket), but maybe opened by setting a non-empty value of argument open.
The two step types differ in their x-y preference: Going from(x1,y1) to (x2,y2) with x1 < x2, type = "s"moves first horizontal, then vertical, whereas type = "S" movesthe other way around.
The behaviour differs by the value of duplicates.ok. Considerfirst the case if this is true.  First exact matches are considered,and the positions of the first exact matches are recorded. Then uniquepartial matches are considered, and if found recorded.  (A partialmatch occurs if the whole of the element of x matches thebeginning of the element of table.)  Finally,all remaining elements of x are regarded as unmatched.In addition, an empty string can match nothing, not even an exactmatch to an empty string.  This is the appropriate behaviour forpartial matching of character indices, for example.
max and min return the maximum or minimum of allthe  values present in their arguments, as integer ifall are logical or integer, as double ifall are numeric, and character otherwise.
max and min return the maximum or minimum of allthe  values present in their arguments, as integer ifall are logical or integer, as double ifall are numeric, and character otherwise.
max and min return the maximum or minimum of allthe  values present in their arguments, as integer ifall are logical or integer, as double ifall are numeric, and character otherwise.
max and min return the maximum or minimum of allthe  values present in their arguments, as integer ifall are logical or integer, as double ifall are numeric, and character otherwise.
A polynomial of degree n - 1,
Several R functions for manipulating objects in environments (such asget and ls) allow specifying environmentsvia corresponding positions in the search path.  pos.to.env isa convenience function for programmers which converts these positionsto corresponding environments; users will typically have no need forit.  It is primitive.
If init is given, Reduce logically adds it to the start(when proceeding left to right) or the end of x, respectively.If this possibly augmented vector v has n > 1 elements,Reduce successively applies f to the elements of vfrom left to right or right to left, respectively.  I.e., a leftreduce computes l_1 = f(v_1, v_2), l_2 = f(l_1, v_3), etc.,and returns l_{n-1} = f(l_{n-2}, v_n), and a right reduce doesr_{n-1} = f(v_{n-1}, v_n), r_{n-2} = f(v_{n-2}, r_{n-1})and returns r_1 = f(v_1, r_2).  (E.g., if v is thesequence (2, 3, 4) and f is division, left and right reduce give(2 / 3) / 4 = 1/6 and 2 / (3 / 4) = 8/3, respectively.)If v has only a single element, this is returned; if there areno elements, NULL is returned.  Thus, it is ensured thatf is always called with 2 arguments.
pretty ignores non-finite values in x.
pretty ignores non-finite values in x.
For numbers, formatC() calls prettyNum() when neededwhich itself calls .format.zeros(*, replace=replace.zero).(“when needed”: when zero.print is notNULL, drop0trailing is true, or one of big.mark,small.mark, or decimal.mark is not at default.)
The default method, print.default has its own help page.Use methods("print") to get all the methods for theprint generic.
Function I has two main uses.
A data frame is split by row into data framessubsetted by the values of one or more factors, and functionFUN is applied to each subset in turn.
The condition system provides a mechanism for signaling andhandling unusual conditions, including errors and warnings.Conditions are represented as objects that contain informationabout the condition that occurred, such as a message and the call inwhich the condition occurred.  Currently conditions are S3-styleobjects, though this may eventually change.
The first eleven functions create connections.  By default theconnection is not opened (except for a socket connection created bysocketConnection or socketAccept and for server socketconnection created by serverSocket), but maybe opened by setting a non-empty value of argument open.
This calls format which formats the data framecolumn-by-column, then converts to a character matrix and dispatchesto the print method for matrices.
Dates are represented as the number of days since 1970-01-01, withnegative values for earlier dates.  They are always printedfollowing the rules of the current Gregorian calendar, even thoughthat calendar was not in use long ago (it was adopted in 1752 inGreat Britain and its colonies).
The default for printing NAs is to print NA (withoutquotes) unless this is a character NA and quote =    FALSE, when <NA> is printed.
Function difftime calculates a difference of two date/timeobjects and returns an object of class "difftime" with anattribute indicating the units.  TheMath group method providesround, signif, floor,ceiling, trunc, abs, andsign methods for objects of this class, and there aremethods for the group-generic (seeOps) logical and arithmeticoperations.
The default method, print.default has its own help page.Use methods("print") to get all the methods for theprint generic.
This queries the internal table that manages the DLLs.
This queries the internal table that manages the DLLs.
This takes the registration information after it has been registeredand processed by the R internals.  In other words, it uses the extendedinformation.
If symmetric is unspecified, isSymmetric(x)determines if the matrix is symmetric up to plausible numericalinaccuracies.  It is surer and typically much faster to set the valueyourself.
The default method, print.default has its own help page.Use methods("print") to get all the methods for theprint generic.
The default method, print.default has its own help page.Use methods("print") to get all the methods for theprint generic.
Class "hexmode" consists of integer vectors with that classattribute, used merely to ensure that they are printed in hex.
library(package) and require(package) both load thenamespace of the package with name package and attach it on thesearch list.  require is designed for use inside otherfunctions; it returns FALSE and gives a warning (rather than anerror as library() does by default) if the package does notexist.  Both functions check and update the list of currently attachedpackages and do not reload a namespace which is already loaded.  (Ifyou want to reload such a package, call detach(unload =  TRUE) or unloadNamespace first.)  If you want to load apackage without attaching it on the search list, seerequireNamespace.
The default method, print.default has its own help page.Use methods("print") to get all the methods for theprint generic.
This takes the registration information after it has been registeredand processed by the R internals.  In other words, it uses the extendedinformation.
noquote returns its argument as an object of class"noquote".  There is a method for c() and subscriptmethod ("[.noquote") which ensures that the class is not lostby subsetting.  The print method (print.noquote) printscharacter strings without quotes ("...." is printed as ....).
Numeric versions are sequences of one or more non-negative integers,usually (e.g., in package ‘DESCRIPTION’ files) represented ascharacter strings with the elements of the sequence concatenated andseparated by single . or - characters.  R packageversions consist of at least two such integers, an R system versionof exactly three (major, minor and patchlevel).
Class "octmode" consists of integer vectors with that classattribute, used merely to ensure that they are printed in octalnotation, specifically for Unix-like file permissions such as755.  Subsetting ([) works too.
library(package) and require(package) both load thenamespace of the package with name package and attach it on thesearch list.  require is designed for use inside otherfunctions; it returns FALSE and gives a warning (rather than anerror as library() does by default) if the package does notexist.  Both functions check and update the list of currently attachedpackages and do not reload a namespace which is already loaded.  (Ifyou want to reload such a package, call detach(unload =  TRUE) or unloadNamespace first.)  If you want to load apackage without attaching it on the search list, seerequireNamespace.
There are two basic classes of date/times.  Class "POSIXct"represents the (signed) number of seconds since the beginning of 1970(in the UTC time zone) as a numeric vector.  Class "POSIXlt" isa named list of vectors representing
There are two basic classes of date/times.  Class "POSIXct"represents the (signed) number of seconds since the beginning of 1970(in the UTC time zone) as a numeric vector.  Class "POSIXlt" isa named list of vectors representing
proc.time returns five elements for backwards compatibility,but its print method prints a named vector oflength 3.  The first two entries are the total user and system CPUtimes of the current R process and any child processes on which ithas waited, and the third entry is the ‘real’ elapsed timesince the process was started.
The condition system provides a mechanism for signaling andhandling unusual conditions, including errors and warnings.Conditions are represented as objects that contain informationabout the condition that occurred, such as a message and the call inwhich the condition occurred.  Currently conditions are S3-styleobjects, though this may eventually change.
‘vector’ is used in the sense of is.vector.
The default method, print.default has its own help page.Use methods("print") to get all the methods for theprint generic.
These functions and classes handle source code references.
These functions and classes handle source code references.
If the argument dnn is not supplied, the internal functionlist.names is called to compute the ‘dimname names’.  If thearguments in ... are named, those names are used.  For theremaining arguments, deparse.level = 0 gives an empty name,deparse.level = 1 uses the supplied argument if it is a symbol,and deparse.level = 2 will deparse the argument.
See the description of options("warn") for thecircumstances under which there is a last.warning object andwarnings() is used.  In essence this is if options(warn =    0) and warning has been called at least once.
For factors, the frequency of the first maxsum - 1most frequent levels is shown, and the less frequent levels aresummarized in "(Others)" (resulting in at most maxsumfrequencies).
The default method, print.default has its own help page.Use methods("print") to get all the methods for theprint generic.
See the description of options("warn") for thecircumstances under which there is a last.warning object andwarnings() is used.  In essence this is if options(warn =    0) and warning has been called at least once.
prmatrix is an earlier form of print.matrix, andis very similar to the S function of the same name.
proc.time returns five elements for backwards compatibility,but its print method prints a named vector oflength 3.  The first two entries are the total user and system CPUtimes of the current R process and any child processes on which ithas waited, and the third entry is the ‘real’ elapsed timesince the process was started.
If na.rm is FALSE an NAvalue in any of the arguments will causea value of NA to be returned, otherwiseNA values are ignored.
NA
NA
The functions dimnames and dimnames<- are generic.
The functions beta and lbeta return the beta functionand the natural logarithm of the beta function,
Several character strings can be pushed back on one or more occasions.The occasions form a stack, so the first line to be retrieved will bethe first string from the last call to pushBack.  Lines whichare pushed back are read prior to the normal input from theconnection, by the normal text-reading functions such asreadLines and scan.
Several character strings can be pushed back on one or more occasions.The occasions form a stack, so the first line to be retrieved will bethe first string from the last call to pushBack.  Lines whichare pushed back are read prior to the normal input from theconnection, by the normal text-reading functions such asreadLines and scan.
save must be one of "no", "yes","ask" or "default".  In the first case the workspaceis not saved, in the second it is saved and in the third the user isprompted and can also decide not to quit.  The default is toask in interactive use but may be overridden by command-linearguments (which must be supplied in non-interactive use).
The QR decomposition plays an important role in manystatistical techniques.  In particular it can be used to solve theequation \bold{Ax} = \bold{b} for given matrix \bold{A},and vector \bold{b}.  It is useful for computing regressioncoefficients and in applying the Newton-Raphson algorithm.
The QR decomposition plays an important role in manystatistical techniques.  In particular it can be used to solve theequation \bold{Ax} = \bold{b} for given matrix \bold{A},and vector \bold{b}.  It is useful for computing regressioncoefficients and in applying the Newton-Raphson algorithm.
The QR decomposition plays an important role in manystatistical techniques.  In particular it can be used to solve theequation \bold{Ax} = \bold{b} for given matrix \bold{A},and vector \bold{b}.  It is useful for computing regressioncoefficients and in applying the Newton-Raphson algorithm.
The QR decomposition plays an important role in manystatistical techniques.  In particular it can be used to solve theequation \bold{Ax} = \bold{b} for given matrix \bold{A},and vector \bold{b}.  It is useful for computing regressioncoefficients and in applying the Newton-Raphson algorithm.
NA
The QR decomposition plays an important role in manystatistical techniques.  In particular it can be used to solve theequation \bold{Ax} = \bold{b} for given matrix \bold{A},and vector \bold{b}.  It is useful for computing regressioncoefficients and in applying the Newton-Raphson algorithm.
The QR decomposition plays an important role in manystatistical techniques.  In particular it can be used to solve theequation \bold{Ax} = \bold{b} for given matrix \bold{A},and vector \bold{b}.  It is useful for computing regressioncoefficients and in applying the Newton-Raphson algorithm.
NA
The QR decomposition plays an important role in manystatistical techniques.  In particular it can be used to solve theequation \bold{Ax} = \bold{b} for given matrix \bold{A},and vector \bold{b}.  It is useful for computing regressioncoefficients and in applying the Newton-Raphson algorithm.
The QR decomposition plays an important role in manystatistical techniques.  In particular it can be used to solve theequation \bold{Ax} = \bold{b} for given matrix \bold{A},and vector \bold{b}.  It is useful for computing regressioncoefficients and in applying the Newton-Raphson algorithm.
NA
NA
NA
NA
save must be one of "no", "yes","ask" or "default".  In the first case the workspaceis not saved, in the second it is saved and in the third the user isprompted and can also decide not to quit.  The default is toask in interactive use but may be overridden by command-linearguments (which must be supplied in non-interactive use).
The typical use of substitute is to create informative labelsfor data sets and plots.The myplot example below shows a simple use of this facility.It uses the functions deparse and substituteto create labels for a plot which are character string versionsof the actual arguments to the function myplot.
Numeric versions are sequences of one or more non-negative integers,usually (e.g., in package ‘DESCRIPTION’ files) represented ascharacter strings with the elements of the sequence concatenated andseparated by single . or - characters.  R packageversions consist of at least two such integers, an R system versionof exactly three (major, minor and patchlevel).
The R home directory is the top-level directory of the Rinstallation being run.
This gives details of the OS under which R was built, not the oneunder which it is currently running (for which seeSys.info).
This gives details of the OS under which R was built, not the oneunder which it is currently running (for which seeSys.info).
This gives details of the OS under which R was built, not the oneunder which it is currently running (for which seeSys.info).
range is a generic function: methods can be defined for itdirectly or via the Summary group generic.For this to work properly, the arguments ... should beunnamed, and dispatch is on the first argument.
range is a generic function: methods can be defined for itdirectly or via the Summary group generic.For this to work properly, the arguments ... should beunnamed, and dispatch is on the first argument.
If all components are different (and no NAs), the ranks arewell defined, with values in seq_along(x).  With some values equal(called ‘ties’), the argument ties.method determines theresult at the corresponding indices.  The "first" method resultsin a permutation with increasing values at each index set of ties, andanalogously "last" with decreasing values.  The"random" method puts these in random order whereas thedefault, "average", replaces them by their mean, and"max" and "min" replaces them by their maximum andminimum respectively, the latter being the typical sportsranking.
This function has two basic modes.  If how = "replace", eachelement of object which is not itself list-like and has a classincluded in classes is replaced by the result of applyingf to the element.
The raw type is intended to hold raw bytes.  It is possible to extractsubsequences of bytes, and to replace elements (but only by elementsof a raw vector).  The relational operators (see Comparison,using the numerical order of the byte representation) work, as do thelogical operators (see Logic) with a bitwise interpretation.
An input raw connection is opened and the raw vector is copiedat the time the connection object is created, and closedestroys the copy.
An input raw connection is opened and the raw vector is copiedat the time the connection object is created, and closedestroys the copy.
packBits accepts raw, integer or logical inputs, the last twowithout any NAs.
packBits accepts raw, integer or logical inputs, the last twowithout any NAs.
packBits accepts raw, integer or logical inputs, the last twowithout any NAs.
The functions cbind and rbind are S3 generic, withmethods for data frames.  The data frame method will be used if atleast one argument is a data frame and the rest are vectors ormatrices.  There can be other methods; in particular, there is one fortime series objects.  See the section on ‘Dispatch’ for howthe method to be used is selected.  If some of the arguments are of anS4 class, i.e., isS4(.) is true, S4 methods are soughtalso, and the hidden cbind / rbind functionsfrom package methods maybe called, which in turn build oncbind2 or rbind2, respectively.  In thatcase, deparse.level is obeyed, similarly to the default method.
The functions cbind and rbind are S3 generic, withmethods for data frames.  The data frame method will be used if atleast one argument is a data frame and the rest are vectors ormatrices.  There can be other methods; in particular, there is one fortime series objects.  See the section on ‘Dispatch’ for howthe method to be used is selected.  If some of the arguments are of anS4 class, i.e., isS4(.) is true, S4 methods are soughtalso, and the hidden cbind / rbind functionsfrom package methods maybe called, which in turn build oncbind2 or rbind2, respectively.  In thatcase, deparse.level is obeyed, similarly to the default method.
For kappa(), if exact = FALSE (the default) the 2-normcondition number is estimated by a cheap approximation.  However, theexact calculation (via svd) is also likely to be quickenough.
Complex vectors can be created with complex.  The vector can bespecified either by giving its length, its real and imaginary parts, ormodulus and argument.  (Giving just the length generates a vector ofcomplex zeroes.)
DCF is a simple format for storing databases in plain text files thatcan easily be directly read and written by humans.  DCF is used invarious places to store R system information, like descriptions andcontents of packages.
These functions can only be used with binary-mode connections.If con is a character string, the functions callfile to obtain a binary-mode file connection which isopened for the duration of the function call.
These functions complement readBin andwriteBin which read and write C-style zero-terminatedcharacter strings.  They are for strings of known length, andcan optionally write an end-of-string mark.  They are intended onlyfor character strings valid in the current locale.
The prompt string will be truncated to a maximum allowed length,normally 256 chars (but can be changed in the source code).
If the con is a character string, the function callsfile to obtain a file connection which is opened forthe duration of the function call.  This can be a compressed file.(tilde expansion of the file path is done by file.)
saveRDS and readRDS provide the means to save a single Robject to a connection (typically a file) and to restore the object, quitepossibly under a different name.  This differs from save andload, which save and restore one or more named objects intoan environment.  They are widely used by R itself, for example to storemetadata for a package and to store the help.searchdatabases: the ".rds" file extension is most often used.
NA
NA
If init is given, Reduce logically adds it to the start(when proceeding left to right) or the end of x, respectively.If this possibly augmented vector v has n > 1 elements,Reduce successively applies f to the elements of vfrom left to right or right to left, respectively.  I.e., a leftreduce computes l_1 = f(v_1, v_2), l_2 = f(l_1, v_3), etc.,and returns l_{n-1} = f(l_{n-2}, v_n), and a right reduce doesr_{n-1} = f(v_{n-1}, v_n), r_{n-2} = f(v_{n-2}, r_{n-1})and returns r_1 = f(v_1, r_2).  (E.g., if v is thesequence (2, 3, 4) and f is division, left and right reduce give(2 / 3) / 4 = 1/6 and 2 / (3 / 4) = 8/3, respectively.)If v has only a single element, this is returned; if there areno elements, NULL is returned.  Thus, it is ensured thatf is always called with 2 arguments.
The main purpose of this function is to allow objects that refer toexternal items (a temporary file, say) to perform cleanup actions whenthey are no longer referenced from within R.  This only makes sensefor objects that are never copied on assignment, hence the restrictionto environments and external pointers.
Arguments which should be character strings or character vectors arecoerced to character if possible.
Arguments which should be character strings or character vectors arecoerced to character if possible.
packageHasNamespace does not indicate if the package has anamespace (all now do), rather if it has a ‘NAMESPACE’ file,which base and some legacy packages do not.  But then you arenot intended to be using it ....
packageHasNamespace does not indicate if the package has anamespace (all now do), rather if it has a ‘NAMESPACE’ file,which base and some legacy packages do not.  But then you arenot intended to be using it ....
If invert is FALSE (default), regmatches extractsthe matched substrings as specified by the match data.  For vectormatch data (as obtained from regexpr), empty matches aredropped; for list match data, empty matches give empty components(zero-length character vectors).
If invert is FALSE (default), regmatches extractsthe matched substrings as specified by the match data.  For vectormatch data (as obtained from regexpr), empty matches aredropped; for list match data, empty matches give empty components(zero-length character vectors).
The pos argument can specify the  environment from which to removethe objects in any of several ways:as an integer (the position in the search list); asthe character string name of an element in the search list; or as anenvironment (including using sys.frame toaccess the currently active function calls).The envir argument is an alternative way to specify anenvironment, but is primarily there for back compatibility.
Top-level tasks are individual expressionsrather than entire lines of input.  Thus an inputline of the form expression1 ; expression2will give rise to 2 top-level tasks.
The default behaviour is as if the call was
The default behaviour is as if the call was
The default behaviour is as if the call was
Function difftime calculates a difference of two date/timeobjects and returns an object of class "difftime" with anattribute indicating the units.  TheMath group method providesround, signif, floor,ceiling, trunc, abs, andsign methods for objects of this class, and there aremethods for the group-generic (seeOps) logical and arithmeticoperations.
The default behaviour is as if the call was
The default behaviour is as if the call was
Numeric versions are sequences of one or more non-negative integers,usually (e.g., in package ‘DESCRIPTION’ files) represented ascharacter strings with the elements of the sequence concatenated andseparated by single . or - characters.  R packageversions consist of at least two such integers, an R system versionof exactly three (major, minor and patchlevel).
The default behaviour is as if the call was
The default behaviour is as if the call was
break breaks out of a for, while or repeatloop; control is transferred to the first statement outside theinner-most loop. next halts the processing of the currentiteration and advances the looping index.  Both break andnext apply only to the innermost of nested loops.
NA
FUN is found by a call to match.fun and typicallyis specified as a function or a symbol (e.g., a backquoted name) or acharacter string specifying a function to be searched for from theenvironment of the call to lapply.
library(package) and require(package) both load thenamespace of the package with name package and attach it on thesearch list.  require is designed for use inside otherfunctions; it returns FALSE and gives a warning (rather than anerror as library() does by default) if the package does notexist.  Both functions check and update the list of currently attachedpackages and do not reload a namespace which is already loaded.  (Ifyou want to reload such a package, call detach(unload =  TRUE) or unloadNamespace first.)  If you want to load apackage without attaching it on the search list, seerequireNamespace.
The functions loadNamespace and attachNamespace areusually called implicitly when library is used to load a namespace and any imports needed.  However it may be useful at times tocall these functions directly.
The condition system provides a mechanism for signaling andhandling unusual conditions, including errors and warnings.Conditions are represented as objects that contain informationabout the condition that occurred, such as a message and the call inwhich the condition occurred.  Currently conditions are S3-styleobjects, though this may eventually change.
The condition system provides a mechanism for signaling andhandling unusual conditions, including errors and warnings.Conditions are represented as objects that contain informationabout the condition that occurred, such as a message and the call inwhich the condition occurred.  Currently conditions are S3-styleobjects, though this may eventually change.
This functionality is optional, determined at compilation, because itmakes R run a little more slowly even when no objects are beingtraced.  tracemem and untracemem give errors when R is notcompiled with memory profiling; retracemem does not (so it can beleft in code during development).
The names in an argument list can be back-quoted non-standard names(see ‘backquote’).
The trace function operates by constructing a revised versionof the function (or of the method, if signature is supplied),and assigning the new object back where the original was found.If only the what argument is given, a line of trace printing isproduced for each call to the function (back compatible with theearlier version of trace).
NA
NA
‘vector’ is used in the sense of is.vector.
The pos argument can specify the  environment from which to removethe objects in any of several ways:as an integer (the position in the search list); asthe character string name of an element in the search list; or as anenvironment (including using sys.frame toaccess the currently active function calls).The envir argument is an alternative way to specify anenvironment, but is primarily there for back compatibility.
The currently available RNG kinds are given below.  kind ispartially matched to this list.  The default is"Mersenne-Twister".
The currently available RNG kinds are given below.  kind ispartially matched to this list.  The default is"Mersenne-Twister".
These are generic functions: methods can be defined for themindividually or via the Math groupgeneric.
The time is rounded or truncated to the second, minute, hour, day,month or year.  Time zones are only relevant to days or more, whenmidnight in the current time zone is used.
The time is rounded or truncated to the second, minute, hour, day,month or year.  Time zones are only relevant to days or more, whenmidnight in the current time zone is used.
NA
A data frame has (by definition) a vector of row names whichhas length the number of rows in the data frame, and contains neithermissing nor duplicated values.  Where a row names sequence has beenadded by the software to meet this requirement, they are regarded as‘automatic’.
A data frame has (by definition) a vector of row names whichhas length the number of rows in the data frame, and contains neithermissing nor duplicated values.  Where a row names sequence has beenadded by the software to meet this requirement, they are regarded as‘automatic’.
A data frame has (by definition) a vector of row names whichhas length the number of rows in the data frame, and contains neithermissing nor duplicated values.  Where a row names sequence has beenadded by the software to meet this requirement, they are regarded as‘automatic’.
A data frame has (by definition) a vector of row names whichhas length the number of rows in the data frame, and contains neithermissing nor duplicated values.  Where a row names sequence has beenadded by the software to meet this requirement, they are regarded as‘automatic’.
A data frame has (by definition) a vector of row names whichhas length the number of rows in the data frame, and contains neithermissing nor duplicated values.  Where a row names sequence has beenadded by the software to meet this requirement, they are regarded as‘automatic’.
A data frame has (by definition) a vector of row names whichhas length the number of rows in the data frame, and contains neithermissing nor duplicated values.  Where a row names sequence has beenadded by the software to meet this requirement, they are regarded as‘automatic’.
These functions are equivalent to use of apply withFUN = mean or FUN = sum with appropriate margins, butare a lot faster.  As they are written for speed, they blur over someof the subtleties of NaN and NA.  If na.rm =    FALSE and either NaN or NA appears in a sum, theresult will be one of NaN or NA, but which might beplatform-dependent.
The extractor functions try to do something sensible for anymatrix-like object x.  If the object has dimnamesthe first component is used as the row names, and the second component(if any) is used for the column names.  For a data frame, rownamesand colnames eventually call row.names andnames respectively, but the latter are preferred.
The extractor functions try to do something sensible for anymatrix-like object x.  If the object has dimnamesthe first component is used as the row names, and the second component(if any) is used for the column names.  For a data frame, rownamesand colnames eventually call row.names andnames respectively, but the latter are preferred.
The default is to reorder the rows to agree with tapply as inthe example below.  Reordering should not add noticeably to the timeexcept when there are very many distinct values of group andx has few columns.
The default is to reorder the rows to agree with tapply as inthe example below.  Reordering should not add noticeably to the timeexcept when there are very many distinct values of group andx has few columns.
The default is to reorder the rows to agree with tapply as inthe example below.  Reordering should not add noticeably to the timeexcept when there are very many distinct values of group andx has few columns.
These functions are equivalent to use of apply withFUN = mean or FUN = sum with appropriate margins, butare a lot faster.  As they are written for speed, they blur over someof the subtleties of NaN and NA.  If na.rm =    FALSE and either NaN or NA appears in a sum, theresult will be one of NaN or NA, but which might beplatform-dependent.
If x has length 1, is numeric (in the sense ofis.numeric) and x >= 1, sampling viasample takes place from 1:x.  Note that thisconvenience feature may lead to undesired behaviour when x isof varying length in calls such as sample(x).  See the examples.
If x has length 1, is numeric (in the sense ofis.numeric) and x >= 1, sampling viasample takes place from 1:x.  Note that thisconvenience feature may lead to undesired behaviour when x isof varying length in calls such as sample(x).  See the examples.
FUN is found by a call to match.fun and typicallyis specified as a function or a symbol (e.g., a backquoted name) or acharacter string specifying a function to be searched for from theenvironment of the call to lapply.
The names of the objects specified either as symbols (or characterstrings) in ... or as a character vector in list areused to look up the objects from environment envir.  By defaultpromises are evaluated, but if eval.promises = FALSEpromises are saved (together with their evaluation environments).(Promises embedded in objects are always saved unevaluated.)
The names of the objects specified either as symbols (or characterstrings) in ... or as a character vector in list areused to look up the objects from environment envir.  By defaultpromises are evaluated, but if eval.promises = FALSEpromises are saved (together with their evaluation environments).(Promises embedded in objects are always saved unevaluated.)
saveRDS and readRDS provide the means to save a single Robject to a connection (typically a file) and to restore the object, quitepossibly under a different name.  This differs from save andload, which save and restore one or more named objects intoan environment.  They are widely used by R itself, for example to storemetadata for a package and to store the help.searchdatabases: the ".rds" file extension is most often used.
The value of center determines how column centering isperformed.  If center is a numeric-alike vector with length equal tothe number of columns of x, then each column of x hasthe corresponding value from center subtracted from it.  Ifcenter is TRUE then centering is done by subtracting thecolumn means (omitting NAs) of x from theircorresponding columns, and if center is FALSE, nocentering is done.
The value of center determines how column centering isperformed.  If center is a numeric-alike vector with length equal tothe number of columns of x, then each column of x hasthe corresponding value from center subtracted from it.  Ifcenter is TRUE then centering is done by subtracting thecolumn means (omitting NAs) of x from theircorresponding columns, and if center is FALSE, nocentering is done.
The value of what can be a list of types, in which casescan returns a list of vectors with the types given by thetypes of the elements in what.  This provides a way of readingcolumnar data.  If any of the types is NULL, the correspondingfield is skipped (but a NULL component appears in the result).
NA
NA
seek with where = NA returns the current byte offsetof a connection (from the beginning), and with a non-missing whereargument the connection is re-positioned (if possible) to thespecified position.  isSeekable returns whether the connectionin principle supports seek: currently only (possiblygz-compressed) file connections do.
seek with where = NA returns the current byte offsetof a connection (from the beginning), and with a non-missing whereargument the connection is re-positioned (if possible) to thespecified position.  isSeekable returns whether the connectionin principle supports seek: currently only (possiblygz-compressed) file connections do.
Numerical inputs should all be finite (that is, not infinite,NaN or NA).
Numerical inputs should all be finite (that is, not infinite,NaN or NA).
Numerical inputs should all be finite (that is, not infinite,NaN or NA).
by can be specified in several ways.
Numerical inputs should all be finite (that is, not infinite,NaN or NA).
Numerical inputs should all be finite (that is, not infinite,NaN or NA).
by can be specified in several ways.
Negative values are supported for from andby. sequence(nvec, from, by=0L) is equivalent torep(from, each=nvec).
Negative values are supported for from andby. sequence(nvec, from, by=0L) is equivalent torep(from, each=nvec).
The function serialize serializes object to the specifiedconnection.  If connection is NULL then object isserialized to a raw vector, which is returned as the result ofserialize.
The first eleven functions create connections.  By default theconnection is not opened (except for a socket connection created bysocketConnection or socketAccept and for server socketconnection created by serverSocket), but maybe opened by setting a non-empty value of argument open.
The currently available RNG kinds are given below.  kind ispartially matched to this list.  The default is"Mersenne-Twister".
Each of union, intersect, setdiff andsetequal will discard any duplicated values in the arguments,and they apply as.vector to their arguments (and soin particular coerce factors to character vectors).
Each of union, intersect, setdiff andsetequal will discard any duplicated values in the arguments,and they apply as.vector to their arguments (and soin particular coerce factors to character vectors).
setHook provides a general mechanism for users to registerhooks, a list of functions to be called from system (or user)functions.  The initial set of hooks was associated with events onpackages/namespaces: these hooks are named via calls topackageEvent.
packageHasNamespace does not indicate if the package has anamespace (all now do), rather if it has a ‘NAMESPACE’ file,which base and some legacy packages do not.  But then you arenot intended to be using it ....
setTimeLimit sets limits which apply to each top-levelcomputation, that is a command line (including any continuation lines)entered at the console or from a file.  If it is called from within acomputation the limits apply to the rest of the computation and(unless transient = TRUE) to subsequent top-level computations.
setTimeLimit sets limits which apply to each top-levelcomputation, that is a command line (including any continuation lines)entered at the console or from a file.  If it is called from within acomputation the limits apply to the rest of the computation and(unless transient = TRUE) to subsequent top-level computations.
See files for how file paths with marked encodings are interpreted.
stdin(), stdout() and stderr() are standardconnections corresponding to input, output and error on the consolerespectively (and not necessarily to file streams).  They are text-modeconnections of class "terminal" which cannot be opened orclosed, and are read-only, write-only and write-only respectively.The stdout() and stderr() connections can bere-directed by sink (and in some circumstances theoutput from stdout() can be split: see the help page).
The default type of quoting supported under Unix-alikes is that forthe Bourne shell sh.  If the string does not contain singlequotes, we can just surround it with single quotes.  Otherwise, thestring is surrounded in double quotes, which suppresses all specialmeanings of metacharacters except dollar, backquote and backslash, sothese (and of course double quote) are preceded by backslash.  Thistype of quoting is also appropriate for bash, ksh andzsh.
This is an internal generic primitive function: methodscan be defined for it directly or via theMath group generic.
The condition system provides a mechanism for signaling andhandling unusual conditions, including errors and warnings.Conditions are represented as objects that contain informationabout the condition that occurred, such as a message and the call inwhich the condition occurred.  Currently conditions are S3-styleobjects, though this may eventually change.
These are generic functions: methods can be defined for themindividually or via the Math groupgeneric.
The condition system provides a mechanism for signaling andhandling unusual conditions, including errors and warnings.Conditions are represented as objects that contain informationabout the condition that occurred, such as a message and the call inwhich the condition occurred.  Currently conditions are S3-styleobjects, though this may eventually change.
The condition system provides a mechanism for signaling andhandling unusual conditions, including errors and warnings.Conditions are represented as objects that contain informationabout the condition that occurred, such as a message and the call inwhich the condition occurred.  Currently conditions are S3-styleobjects, though this may eventually change.
The condition system provides a mechanism for signaling andhandling unusual conditions, including errors and warnings.Conditions are represented as objects that contain informationabout the condition that occurred, such as a message and the call inwhich the condition occurred.  Currently conditions are S3-styleobjects, though this may eventually change.
The condition system provides a mechanism for signaling andhandling unusual conditions, including errors and warnings.Conditions are represented as objects that contain informationabout the condition that occurred, such as a message and the call inwhich the condition occurred.  Currently conditions are S3-styleobjects, though this may eventually change.
FUN is found by a call to match.fun and typicallyis specified as a function or a symbol (e.g., a backquoted name) or acharacter string specifying a function to be searched for from theenvironment of the call to lapply.
The arc-tangent of two arguments atan2(y, x) returns the anglebetween the x-axis and the vector from the origin to (x, y),i.e., for positive arguments atan2(y, x) == atan(y/x).
double creates a double-precision vector of the specifiedlength.  The elements of the vector are all equal to 0.It is identical to numeric.
These are internal generic primitive functions: methodscan be defined for them individually or via theMath group generic.
sink diverts R output to a connection (and must be used againto finish such a diversion, see below!).  If file is acharacter string, a file connection with that name will be establishedfor the duration of the diversion.
sink diverts R output to a connection (and must be used againto finish such a diversion, see below!).  If file is acharacter string, a file connection with that name will be establishedfor the duration of the diversion.
The arc-tangent of two arguments atan2(y, x) returns the anglebetween the x-axis and the vector from the origin to (x, y),i.e., for positive arguments atan2(y, x) == atan(y/x).
If MARGIN gives a single dimension, then all elements of slicenumber i with respect to this have value i.  In general,slice numbers are obtained by numbering all combinations of indices inthe dimensions given by MARGIN in column-major order.  I.e.,with m_1, ..., m_k the dimension numbers (elements ofMARGIN) sliced by and d_{m_1}, ..., d_{m_k} thecorresponding extents, and n_1 = 1, n_2 = d_{m_1}, ...,n_k = d_{m_1} … d_{m_{k-1}},the number of the slice where dimension m_1 has value i_1,..., dimension m_k has value i_k is 1 + n_1 (i_1 - 1) +    … + n_k (i_k - 1).
The first eleven functions create connections.  By default theconnection is not opened (except for a socket connection created bysocketConnection or socketAccept and for server socketconnection created by serverSocket), but maybe opened by setting a non-empty value of argument open.
The first eleven functions create connections.  By default theconnection is not opened (except for a socket connection created bysocketConnection or socketAccept and for server socketconnection created by serverSocket), but maybe opened by setting a non-empty value of argument open.
The values in write are recycled if necessary to make up alogical vector the same length as socklist. Socket connectionscan appear more than once in socklist; this can be useful ifyou want to determine whether a socket is available for reading orwriting.
The first eleven functions create connections.  By default theconnection is not opened (except for a socket connection created bysocketConnection or socketAccept and for server socketconnection created by serverSocket), but maybe opened by setting a non-empty value of argument open.
a or b can be complex, but this uses double complexarithmetic which might not be available on all platforms.
a or b can be complex, but this uses double complexarithmetic which might not be available on all platforms.
The QR decomposition plays an important role in manystatistical techniques.  In particular it can be used to solve theequation \bold{Ax} = \bold{b} for given matrix \bold{A},and vector \bold{b}.  It is useful for computing regressioncoefficients and in applying the Newton-Raphson algorithm.
sort is a generic function for which methods can be written,and sort.int is the internal method which is compatiblewith S if only the first three arguments are used.
sort is a generic function for which methods can be written,and sort.int is the internal method which is compatiblewith S if only the first three arguments are used.
sort is a generic function for which methods can be written,and sort.int is the internal method which is compatiblewith S if only the first three arguments are used.
In the case of ties in the first vector, values in the second are usedto break the ties.  If the values are still tied, values in the laterarguments are used to break the tie (see the first example).The sort used is stable (except for method = "quick"),so any unresolved ties will be left in their original ordering.
sort is a generic function for which methods can be written,and sort.int is the internal method which is compatiblewith S if only the first three arguments are used.
Note that running code via source differs in a few respectsfrom entering it at the R command line.  Since expressions are notexecuted at the top level, auto-printing is not done.  So you willneed to include explicit print calls for things you want to beprinted (and remember that this includes plotting by lattice,FAQ Q7.22).  Since the complete file is parsed before any of it isrun, syntax errors result in none of the code being run.  If an erroroccurs in running a syntactically correct script, anything assignedinto the workspace by code that has been run will be kept (just asfrom the command line), but diagnostic information such astraceback() will contain additional calls towithVisible.
split and split<- are generic functions with default anddata.frame methods.  The data frame method can also be used tosplit a matrix into a list of matrices, and the replacement formlikewise, provided they are invoked explicitly.
split and split<- are generic functions with default anddata.frame methods.  The data frame method can also be used tosplit a matrix into a list of matrices, and the replacement formlikewise, provided they are invoked explicitly.
Dates are represented as the number of days since 1970-01-01, withnegative values for earlier dates.  They are always printedfollowing the rules of the current Gregorian calendar, even thoughthat calendar was not in use long ago (it was adopted in 1752 inGreat Britain and its colonies).
split and split<- are generic functions with default anddata.frame methods.  The data frame method can also be used tosplit a matrix into a list of matrices, and the replacement formlikewise, provided they are invoked explicitly.
There are two basic classes of date/times.  Class "POSIXct"represents the (signed) number of seconds since the beginning of 1970(in the UTC time zone) as a numeric vector.  Class "POSIXlt" isa named list of vectors representing
split and split<- are generic functions with default anddata.frame methods.  The data frame method can also be used tosplit a matrix into a list of matrices, and the replacement formlikewise, provided they are invoked explicitly.
split and split<- are generic functions with default anddata.frame methods.  The data frame method can also be used tosplit a matrix into a list of matrices, and the replacement formlikewise, provided they are invoked explicitly.
split and split<- are generic functions with default anddata.frame methods.  The data frame method can also be used tosplit a matrix into a list of matrices, and the replacement formlikewise, provided they are invoked explicitly.
sprintf is a wrapper for the system sprintf C-libraryfunction.  Attempts are made to check that the mode of the valuespassed match the format supplied, and R's special values (NA,Inf, -Inf and NaN) are handled correctly.
These are internal generic primitive functions: methodscan be defined for them individually or via theMath group generic.  For complexarguments (and the default method), z, abs(z) ==  Mod(z) and sqrt(z) == z^0.5.
The purpose of the functions is to provide a simple means of markupfor quoting text to be used in the R output, e.g., in warnings orerror messages.
These functions and classes handle source code references.
These functions and classes handle source code references.
These functions and classes handle source code references.
These functions and classes handle source code references.
standardGeneric dispatches the method defined for a genericfunction named f, using the actual arguments in the frame from whichit is called.
startsWith() is equivalent to but much faster than
stdin(), stdout() and stderr() are standardconnections corresponding to input, output and error on the consolerespectively (and not necessarily to file streams).  They are text-modeconnections of class "terminal" which cannot be opened orclosed, and are read-only, write-only and write-only respectively.The stdout() and stderr() connections can bere-directed by sink (and in some circumstances theoutput from stdout() can be split: see the help page).
stdin(), stdout() and stderr() are standardconnections corresponding to input, output and error on the consolerespectively (and not necessarily to file streams).  They are text-modeconnections of class "terminal" which cannot be opened orclosed, and are read-only, write-only and write-only respectively.The stdout() and stderr() connections can bere-directed by sink (and in some circumstances theoutput from stdout() can be split: see the help page).
stdin(), stdout() and stderr() are standardconnections corresponding to input, output and error on the consolerespectively (and not necessarily to file streams).  They are text-modeconnections of class "terminal" which cannot be opened orclosed, and are read-only, write-only and write-only respectively.The stdout() and stderr() connections can bere-directed by sink (and in some circumstances theoutput from stdout() can be split: see the help page).
The error action is controlled by error handlers established withinthe executing code and by the current default error handler set byoptions(error=).  The error is first signaled as if usingsignalCondition().  If there are no handlers or if all handlersreturn, then the error message is printed (ifoptions("show.error.messages") is true) and the default errorhandler is used.  The default behaviour (the NULLerror-handler) in interactive use is to return to the top levelprompt or the top level browser, and in non-interactive use to(effectively) call q("no", status = 1, runLast = FALSE).The default handler stores the error message in a buffer; it can beretrieved by geterrmessage().  It also stores a trace ofthe call stack that can be retrieved by traceback().
This function is intended for use in regression tests or also argumentchecking of functions, in particular to make them easier to read.
Both mode and storage.mode return a character stringgiving the (storage) mode of the object — often the same — bothrelying on the output of typeof(x), see the examplebelow.
Both mode and storage.mode return a character stringgiving the (storage) mode of the object — often the same — bothrelying on the output of typeof(x), see the examplebelow.
If text has length greater than zero (after coercion) it is used inpreference to file.
If text has length greater than zero (after coercion) it is used inpreference to file.
The format and as.character methods and strftimeconvert objects from the classes "POSIXlt" and"POSIXct" to character vectors.
The format and as.character methods and strftimeconvert objects from the classes "POSIXlt" and"POSIXct" to character vectors.
The elements of x and times will be recycled asnecessary (if one has no elements, and empty character vector isreturned).  Missing elements in x or times result inmissing elements of the return value.
Argument split will be coerced to character, soyou will see uses with split = NULL to meansplit = character(0), including in the examples below.
Conversion is based on the C library function strtol.
‘Width’ is interpreted as the display width in a monospacedfont.  What happens with non-printable characters (such as backspace, tab)is implementation-dependent and may depend on the locale (e.g., theymay be included in the count or they may be omitted).
Adding a  class "factor" will ensure that numeric codes aregiven integer storage mode.
Whitespace (space, tab or newline characters) in the input isdestroyed.  Double spaces after periods, question and explanationmarks (thought as representing sentence ends) are preserved.Currently, possible sentence ends at line breaks are not consideredspecially.
Arguments which should be character strings or character vectors arecoerced to character if possible.
This is a generic function, with methods supplied for matrices, dataframes and vectors (including lists).  Packages and users can addfurther methods.
This is a generic function, with methods supplied for matrices, dataframes and vectors (including lists).  Packages and users can addfurther methods.
This is a generic function, with methods supplied for matrices, dataframes and vectors (including lists).  Packages and users can addfurther methods.
This is a generic function, with methods supplied for matrices, dataframes and vectors (including lists).  Packages and users can addfurther methods.
The typical use of substitute is to create informative labelsfor data sets and plots.The myplot example below shows a simple use of this facility.It uses the functions deparse and substituteto create labels for a plot which are character string versionsof the actual arguments to the function myplot.
substring is compatible with S, with first andlast instead of start and stop.For vector arguments, it expands the arguments cyclically to thelength of the longest provided none are of zero length.
substring is compatible with S, with first andlast instead of start and stop.For vector arguments, it expands the arguments cyclically to thelength of the longest provided none are of zero length.
substring is compatible with S, with first andlast instead of start and stop.For vector arguments, it expands the arguments cyclically to thelength of the longest provided none are of zero length.
substring is compatible with S, with first andlast instead of start and stop.For vector arguments, it expands the arguments cyclically to thelength of the longest provided none are of zero length.
This is a generic function: methods can be defined for itdirectly or via the Summary group generic.For this to work properly, the arguments ... should beunnamed, and dispatch is on the first argument.
For factors, the frequency of the first maxsum - 1most frequent levels is shown, and the less frequent levels aresummarized in "(Others)" (resulting in at most maxsumfrequencies).
The first eleven functions create connections.  By default theconnection is not opened (except for a socket connection created bysocketConnection or socketAccept and for server socketconnection created by serverSocket), but maybe opened by setting a non-empty value of argument open.
For factors, the frequency of the first maxsum - 1most frequent levels is shown, and the less frequent levels aresummarized in "(Others)" (resulting in at most maxsumfrequencies).
There are four groups for which S3 methods can be written,namely the "Math", "Ops", "Summary" and"Complex" groups.  These are not R objects in base R, butmethods can be supplied for them and base R containsfactor, data.frame anddifftime methods for the first three groups.  (There isalso a ordered method for Ops,POSIXt and Date methods for Mathand Ops, package_version methods for Opsand Summary, as well as a ts method forOps in package stats.)
Dates are represented as the number of days since 1970-01-01, withnegative values for earlier dates.  They are always printedfollowing the rules of the current Gregorian calendar, even thoughthat calendar was not in use long ago (it was adopted in 1752 inGreat Britain and its colonies).
Dates are represented as the number of days since 1970-01-01, withnegative values for earlier dates.  They are always printedfollowing the rules of the current Gregorian calendar, even thoughthat calendar was not in use long ago (it was adopted in 1752 inGreat Britain and its colonies).
For factors, the frequency of the first maxsum - 1most frequent levels is shown, and the less frequent levels aresummarized in "(Others)" (resulting in at most maxsumfrequencies).
Function difftime calculates a difference of two date/timeobjects and returns an object of class "difftime" with anattribute indicating the units.  TheMath group method providesround, signif, floor,ceiling, trunc, abs, andsign methods for objects of this class, and there aremethods for the group-generic (seeOps) logical and arithmeticoperations.
For factors, the frequency of the first maxsum - 1most frequent levels is shown, and the less frequent levels aresummarized in "(Others)" (resulting in at most maxsumfrequencies).
The type of the vector x is not restricted; it only must havean as.character method and be sortable (byorder).
For factors, the frequency of the first maxsum - 1most frequent levels is shown, and the less frequent levels aresummarized in "(Others)" (resulting in at most maxsumfrequencies).
Numeric versions are sequences of one or more non-negative integers,usually (e.g., in package ‘DESCRIPTION’ files) represented ascharacter strings with the elements of the sequence concatenated andseparated by single . or - characters.  R packageversions consist of at least two such integers, an R system versionof exactly three (major, minor and patchlevel).
The type of the vector x is not restricted; it only must havean as.character method and be sortable (byorder).
There are two basic classes of date/times.  Class "POSIXct"represents the (signed) number of seconds since the beginning of 1970(in the UTC time zone) as a numeric vector.  Class "POSIXlt" isa named list of vectors representing
There are two basic classes of date/times.  Class "POSIXct"represents the (signed) number of seconds since the beginning of 1970(in the UTC time zone) as a numeric vector.  Class "POSIXlt" isa named list of vectors representing
There are two basic classes of date/times.  Class "POSIXct"represents the (signed) number of seconds since the beginning of 1970(in the UTC time zone) as a numeric vector.  Class "POSIXlt" isa named list of vectors representing
There are two basic classes of date/times.  Class "POSIXct"represents the (signed) number of seconds since the beginning of 1970(in the UTC time zone) as a numeric vector.  Class "POSIXlt" isa named list of vectors representing
proc.time returns five elements for backwards compatibility,but its print method prints a named vector oflength 3.  The first two entries are the total user and system CPUtimes of the current R process and any child processes on which ithas waited, and the third entry is the ‘real’ elapsed timesince the process was started.
These functions and classes handle source code references.
These functions and classes handle source code references.
If the argument dnn is not supplied, the internal functionlist.names is called to compute the ‘dimname names’.  If thearguments in ... are named, those names are used.  For theremaining arguments, deparse.level = 0 gives an empty name,deparse.level = 1 uses the supplied argument if it is a symbol,and deparse.level = 2 will deparse the argument.
See the description of options("warn") for thecircumstances under which there is a last.warning object andwarnings() is used.  In essence this is if options(warn =    0) and warning has been called at least once.
message is used for generating ‘simple’ diagnosticmessages which are neither warnings nor errors, but neverthelessrepresented as conditions.  Unlike warnings and errors, a finalnewline is regarded as part of the message, and is optional.The default handler sends the message to thestderr() connection.
message is used for generating ‘simple’ diagnosticmessages which are neither warnings nor errors, but neverthelessrepresented as conditions.  Unlike warnings and errors, a finalnewline is regarded as part of the message, and is optional.The default handler sends the message to thestderr() connection.
The result depends on the value ofoptions("warn") and on handlers established in theexecuting code.
The condition system provides a mechanism for signaling andhandling unusual conditions, including errors and warnings.Conditions are represented as objects that contain informationabout the condition that occurred, such as a message and the call inwhich the condition occurred.  Currently conditions are S3-styleobjects, though this may eventually change.
The singular value decomposition plays an important role in manystatistical techniques.  svd and La.svd provide twointerfaces which differ in their return values.
FUN is found by a call to match.fun.  As in thedefault, binary operators can be supplied if quoted or backquoted.
switch works in two distinct ways depending whether the firstargument evaluates to a character string or a number.
.GlobalEnv is given number 0 in the list of frames.Each subsequent function evaluation increases the frame stack by 1.The call, function definition and the environment for evaluationof that function are returned by sys.call, sys.functionand sys.frame with the appropriate index.
.GlobalEnv is given number 0 in the list of frames.Each subsequent function evaluation increases the frame stack by 1.The call, function definition and the environment for evaluationof that function are returned by sys.call, sys.functionand sys.frame with the appropriate index.
dir.exists checks that the paths exist (in the same sense asfile.exists) and are directories.
Sys.time returns an absolute date-time value which can beconverted to various time zones and may return different days.
.GlobalEnv is given number 0 in the list of frames.Each subsequent function evaluation increases the frame stack by 1.The call, function definition and the environment for evaluationof that function are returned by sys.call, sys.functionand sys.frame with the appropriate index.
.GlobalEnv is given number 0 in the list of frames.Each subsequent function evaluation increases the frame stack by 1.The call, function definition and the environment for evaluationof that function are returned by sys.call, sys.functionand sys.frame with the appropriate index.
.GlobalEnv is given number 0 in the list of frames.Each subsequent function evaluation increases the frame stack by 1.The call, function definition and the environment for evaluationof that function are returned by sys.call, sys.functionand sys.frame with the appropriate index.
Both arguments will be coerced to character if necessary.
The locale describes aspects of the internationalization of a program.Initially most aspects of the locale of R are set to "C"(which is the default for the C language and reflects North-Americanusage – also known as "POSIX").  R sets "LC_CTYPE" and"LC_COLLATE", which allow the use of a different character setand alphabetic comparisons in that character set (including the use ofsort), "LC_MONETARY" (for use bySys.localeconv) and "LC_TIME" may affect thebehaviour of as.POSIXlt and strptime andfunctions which use them (but not date).
NA
This expands tilde (see tilde expansion) and wildcards in file paths. For precise details of wildcards expansion, see yoursystem's documentation on the glob system call.  There is aPOSIX 1003.2 standard (seehttps://pubs.opengroup.org/onlinepubs/9699919799/functions/glob.html)but some OSes will go beyond this.
This uses POSIX or Windows system calls.  Note that OS names (sysname) might notbe what you expect: for example macOS identifies itself asDarwin and Solaris as SunOS.
The functions .subset and .subset2 are essentiallyequivalent to the [ and [[ operators,except that methods dispatch does not take place.  This is to avoidexpensive unclassing when applying the default method to an object.  Theyshould not normally be invoked by end users.  Note that unlike theoperators they are builtins and not specials (all arguments areevaluated) and hence do not allow missing arguments.
Normally R is run without looking at the value of LC_NUMERIC,so the decimal point remains '.'.  So the first three of thesecomponents will only be useful if you have set the locale categoryLC_NUMERIC using Sys.setlocale in the current R session(when R may not work correctly).
.GlobalEnv is given number 0 in the list of frames.Each subsequent function evaluation increases the frame stack by 1.The call, function definition and the environment for evaluationof that function are returned by sys.call, sys.functionand sys.frame with the appropriate index.
.GlobalEnv is given number 0 in the list of frames.Each subsequent function evaluation increases the frame stack by 1.The call, function definition and the environment for evaluationof that function are returned by sys.call, sys.functionand sys.frame with the appropriate index.
.GlobalEnv is given number 0 in the list of frames.Each subsequent function evaluation increases the frame stack by 1.The call, function definition and the environment for evaluationof that function are returned by sys.call, sys.functionand sys.frame with the appropriate index.
.GlobalEnv is given number 0 in the list of frames.Each subsequent function evaluation increases the frame stack by 1.The call, function definition and the environment for evaluationof that function are returned by sys.call, sys.functionand sys.frame with the appropriate index.
NA
The functions .subset and .subset2 are essentiallyequivalent to the [ and [[ operators,except that methods dispatch does not take place.  This is to avoidexpensive unclassing when applying the default method to an object.  Theyshould not normally be invoked by end users.  Note that unlike theoperators they are builtins and not specials (all arguments areevaluated) and hence do not allow missing arguments.
Non-standard R names must be quoted in Sys.setenv: see theexamples.  Most platforms (and POSIX) do not allow names containing"=".  Windows does, but the facilities provided by R may nothandle these correctly so they should be avoided.  Most platformsallow setting an environment variable to "", but Windows doesnot and there Sys.setenv(FOO = "") unsets FOO.
This attempts sets the file time to the value specified.
The locale describes aspects of the internationalization of a program.Initially most aspects of the locale of R are set to "C"(which is the default for the C language and reflects North-Americanusage – also known as "POSIX").  R sets "LC_CTYPE" and"LC_COLLATE", which allow the use of a different character setand alphabetic comparisons in that character set (including the use ofsort), "LC_MONETARY" (for use bySys.localeconv) and "LC_TIME" may affect thebehaviour of as.POSIXlt and strptime andfunctions which use them (but not date).
Using this function allows R to temporarily be given very lowpriority and hence not to interfere with more important foregroundtasks.  A typical use is to allow a process launched from R to setitself up and read its input files before R execution is resumed.
For large files, keep.source = FALSE may save quite a bit ofmemory. Disabling only parse data via keep.parse.data = FALSEcan already save a lot.In order for the code being evaluated to use the correct environment(for example, in global assignments), source code in packages shouldcall topenv(), which will return the namespace, if any,the environment set up by sys.source, or the global environmentif a saved image is being used.
.GlobalEnv is given number 0 in the list of frames.Each subsequent function evaluation increases the frame stack by 1.The call, function definition and the environment for evaluationof that function are returned by sys.call, sys.functionand sys.frame with the appropriate index.
Sys.time returns an absolute date-time value which can beconverted to various time zones and may return different days.
Time zones are a system-specific topic, but these days almost all Rplatforms use similar underlying code, used by Linux, macOS, Solaris,AIX and FreeBSD, and installed with R on Windows.  (Unfortunatelythere are many system-specific errors in the implementations.)  It ispossible to use the R sources' version of the code on Unix-alikes aswell as on Windows: this is the default for macOS and recommended forSolaris.
dir.exists checks that the paths exist (in the same sense asfile.exists) and are directories.
Non-standard R names must be quoted in Sys.setenv: see theexamples.  Most platforms (and POSIX) do not allow names containing"=".  Windows does, but the facilities provided by R may nothandle these correctly so they should be avoided.  Most platformsallow setting an environment variable to "", but Windows doesnot and there Sys.setenv(FOO = "") unsets FOO.
The system command which reports on the full path names ofan executable (including an executable script) as would be executed bya shell, accepting either absolute paths or looking on the path.
This interface has become rather complicated over the years: seesystem2 for a more portable and flexible interfacewhich is recommended for new code.
This checks the existence of the specified files withfile.exists.  So file paths are only returned if thereare sufficient permissions to establish their existence.
system.time calls the function proc.time,evaluates expr, and then calls proc.time once more,returning the difference between the two proc.time calls.
Unlike system, command is always quoted byshQuote, so it must be a single command without arguments.
This is a generic function for which methods can be written.  Thedescription here applies to the default and "data.frame" methods.
TRUE and FALSE are reserved words denoting logicalconstants in the R language, whereas T and F are globalvariables whose initial values set to these.  All four arelogical(1) vectors.
This is a generic function for which methods can be written.  Thedescription here applies to the default and "data.frame" methods.
This is a generic function for which methods can be written.  Thedescription here applies to the default and "data.frame" methods.
If the argument dnn is not supplied, the internal functionlist.names is called to compute the ‘dimname names’.  If thearguments in ... are named, those names are used.  For theremaining arguments, deparse.level = 0 gives an empty name,deparse.level = 1 uses the supplied argument if it is a symbol,and deparse.level = 2 will deparse the argument.
tabulate is the workhorse for the table function.
The arc-tangent of two arguments atan2(y, x) returns the anglebetween the x-axis and the vector from the origin to (x, y),i.e., for positive arguments atan2(y, x) == atan(y/x).
These are internal generic primitive functions: methodscan be defined for them individually or via theMath group generic.
The arc-tangent of two arguments atan2(y, x) returns the anglebetween the x-axis and the vector from the origin to (x, y),i.e., for positive arguments atan2(y, x) == atan(y/x).
If FUN is not NULL, it is passed tomatch.fun, and hence it can be a function or a symbol orcharacter string naming a function.
NA
NA
The length of the result is the maximum of the lengths of the threearguments; values of shorter arguments are recycled.
The length of the result is the maximum of the lengths of the threearguments; values of shorter arguments are recycled.
An input text connection is opened and the character vector is copiedat time the connection object is created, and close destroysthe copy.  object should be the name of a character vector:however, short expressions will be accepted provided they deparse toless than 60 bytes.
An input text connection is opened and the character vector is copiedat time the connection object is created, and close destroysthe copy.  object should be the name of a character vector:however, short expressions will be accepted provided they deparse toless than 60 bytes.
chartr translates each character in x that is specifiedin old to the corresponding character specified in new.Ranges are supported in the specifications, but character classes andrepeated characters are not.  If old contains more charactersthan new, an error is signaled; if it contains fewer characters, theextra characters at the end of new are ignored.
topenv returns the first top level environmentfound when searching envir and its enclosing environments. If notop level environment is found, .GlobalEnv is returned.  Anenvironment is considered top level if it is the internal environmentof a namespace, a package environment in the searchpath, or .GlobalEnv .
This is a generic function for which methods can be written: only thedefault method is described here.  Most methods should honor thewidth argument to specify the maximum display width (as measuredby nchar(type = "width")) of the result.
This is a generic function for which methods can be written: only thedefault method is described here.  Most methods should honor thewidth argument to specify the maximum display width (as measuredby nchar(type = "width")) of the result.
chartr translates each character in x that is specifiedin old to the corresponding character specified in new.Ranges are supported in the specifications, but character classes andrepeated characters are not.  If old contains more charactersthan new, an error is signaled; if it contains fewer characters, theextra characters at the end of new are ignored.
The trace function operates by constructing a revised versionof the function (or of the method, if signature is supplied),and assigning the new object back where the original was found.If only the what argument is given, a line of trace printing isproduced for each call to the function (back compatible with theearlier version of trace).
The default display is of the stack of the last uncaught error asstored as a list of calls in .Traceback, whichtraceback prints in a user-friendly format.  The stack ofcalls always contains all function calls and all foreignfunction calls (such as .Call): if profiling is inprogress it will include calls to some primitive functions.  (Callsto builtins are included, but not to specials.)
This functionality is optional, determined at compilation, because itmakes R run a little more slowly even when no objects are beingtraced.  tracemem and untracemem give errors when R is notcompiled with memory profiling; retracemem does not (so it can beleft in code during development).
The trace function operates by constructing a revised versionof the function (or of the method, if signature is supplied),and assigning the new object back where the original was found.If only the what argument is given, a line of trace printing isproduced for each call to the function (back compatible with theearlier version of trace).
The ... arguments to transform.data.frame are taggedvector expressions, which are evaluated in the data frame_data.  The tags are matched against names(_data), and forthose that match, the value replace the corresponding variable in_data, and the others are appended to _data.
The ... arguments to transform.data.frame are taggedvector expressions, which are evaluated in the data frame_data.  The tags are matched against names(_data), and forthose that match, the value replace the corresponding variable in_data, and the others are appended to _data.
The ... arguments to transform.data.frame are taggedvector expressions, which are evaluated in the data frame_data.  The tags are matched against names(_data), and forthose that match, the value replace the corresponding variable in_data, and the others are appended to _data.
The functions beta and lbeta return the beta functionand the natural logarithm of the beta function,
Internally, sub(re, "", *, perl = TRUE), i.e., PCRElibrary regular expressions are used.For portability, the default ‘whitespace’ is the character class[ \t\r\n] (space, horizontal tab, carriage return,newline).  Alternatively, [\h\v] is a good (PCRE)generalization to match all Unicode horizontal and vertical whitespace characters, see also https://www.pcre.org.
These are generic functions: methods can be defined for themindividually or via the Math groupgeneric.
The time is rounded or truncated to the second, minute, hour, day,month or year.  Time zones are only relevant to days or more, whenmidnight in the current time zone is used.
The time is rounded or truncated to the second, minute, hour, day,month or year.  Time zones are only relevant to days or more, whenmidnight in the current time zone is used.
seek with where = NA returns the current byte offsetof a connection (from the beginning), and with a non-missing whereargument the connection is re-positioned (if possible) to thespecified position.  isSeekable returns whether the connectionin principle supports seek: currently only (possiblygz-compressed) file connections do.
seek with where = NA returns the current byte offsetof a connection (from the beginning), and with a non-missing whereargument the connection is re-positioned (if possible) to thespecified position.  isSeekable returns whether the connectionin principle supports seek: currently only (possiblygz-compressed) file connections do.
try evaluates an expression and traps any errors that occurduring the evaluation.  If an error occurs then the errormessage is printed to the stderr connection unlessoptions("show.error.messages") is false orthe call includes silent = TRUE.  The error message is alsostored in a buffer where it can be retrieved bygeterrmessage. (This should not be needed as the value returnedin case of an error contains the error message.)
The condition system provides a mechanism for signaling andhandling unusual conditions, including errors and warnings.Conditions are represented as objects that contain informationabout the condition that occurred, such as a message and the call inwhich the condition occurred.  Currently conditions are S3-styleobjects, though this may eventually change.
The condition system provides a mechanism for signaling andhandling unusual conditions, including errors and warnings.Conditions are represented as objects that contain informationabout the condition that occurred, such as a message and the call inwhich the condition occurred.  Currently conditions are S3-styleobjects, though this may eventually change.
NA
Here, we describe the so called “S3” classes (and methods). For“S4” classes (and methods), see ‘Formal classes’ below.
When a function flagged for debugging is entered, normal executionis suspended and the body of function is executed one statement at atime.  A new browser context is initiated for each step(and the previous one destroyed).
Each of union, intersect, setdiff andsetequal will discard any duplicated values in the arguments,and they apply as.vector to their arguments (and soin particular coerce factors to character vectors).
This is a generic function with methods for vectors, data frames andarrays (including matrices).
This is a generic function with methods for vectors, data frames andarrays (including matrices).
This is a generic function with methods for vectors, data frames andarrays (including matrices).
This is a generic function with methods for vectors, data frames andarrays (including matrices).
This is a generic function with methods for vectors, data frames andarrays (including matrices).
Numeric versions are sequences of one or more non-negative integers,usually (e.g., in package ‘DESCRIPTION’ files) represented ascharacter strings with the elements of the sequence concatenated andseparated by single . or - characters.  R packageversions consist of at least two such integers, an R system versionof exactly three (major, minor and patchlevel).
There are two basic classes of date/times.  Class "POSIXct"represents the (signed) number of seconds since the beginning of 1970(in the UTC time zone) as a numeric vector.  Class "POSIXlt" isa named list of vectors representing
See the description of options("warn") for thecircumstances under which there is a last.warning object andwarnings() is used.  In essence this is if options(warn =    0) and warning has been called at least once.
Function difftime calculates a difference of two date/timeobjects and returns an object of class "difftime" with anattribute indicating the units.  TheMath group method providesround, signif, floor,ceiling, trunc, abs, andsign methods for objects of this class, and there aremethods for the group-generic (seeOps) logical and arithmeticoperations.
Function difftime calculates a difference of two date/timeobjects and returns an object of class "difftime" with anattribute indicating the units.  TheMath group method providesround, signif, floor,ceiling, trunc, abs, andsign methods for objects of this class, and there aremethods for the group-generic (seeOps) logical and arithmeticoperations.
Function difftime calculates a difference of two date/timeobjects and returns an object of class "difftime" with anattribute indicating the units.  TheMath group method providesround, signif, floor,ceiling, trunc, abs, andsign methods for objects of this class, and there aremethods for the group-generic (seeOps) logical and arithmeticoperations.
Function difftime calculates a difference of two date/timeobjects and returns an object of class "difftime" with anattribute indicating the units.  TheMath group method providesround, signif, floor,ceiling, trunc, abs, andsign methods for objects of this class, and there aremethods for the group-generic (seeOps) logical and arithmeticoperations.
Functions in standard packages other than the base package are listed inhelp("pkg-deprecated"), where pkg is replaced by thename of the package.
If recursive = FALSE directories are not deleted,not even empty ones.
unlist is generic: you can write methods to handlespecific classes of objects, see InternalMethods,and note, e.g., relist with the unlist methodfor relistable objects.
The functions loadNamespace and attachNamespace areusually called implicitly when library is used to load a namespace and any imports needed.  However it may be useful at times tocall these functions directly.
The function lockEnvironment locks its environment argument.Locking theenvironment prevents adding or removing variable bindings from theenvironment.  Changing the value of a variable is still possible unlessthe binding has been locked.  The namespace environments of packageswith namespaces are locked when loaded.
NA
The function serialize serializes object to the specifiedconnection.  If connection is NULL then object isserialized to a raw vector, which is returned as the result ofserialize.
split and split<- are generic functions with default anddata.frame methods.  The data frame method can also be used tosplit a matrix into a list of matrices, and the replacement formlikewise, provided they are invoked explicitly.
The trace function operates by constructing a revised versionof the function (or of the method, if signature is supplied),and assigning the new object back where the original was found.If only the what argument is given, a line of trace printing isproduced for each call to the function (back compatible with theearlier version of trace).
This functionality is optional, determined at compilation, because itmakes R run a little more slowly even when no objects are beingtraced.  tracemem and untracemem give errors when R is notcompiled with memory profiling; retracemem does not (so it can beleft in code during development).
The first eleven functions create connections.  By default theconnection is not opened (except for a socket connection created bysocketConnection or socketAccept and for server socketconnection created by serverSocket), but maybe opened by setting a non-empty value of argument open.
NA
The first eleven functions create connections.  By default theconnection is not opened (except for a socket connection created bysocketConnection or socketAccept and for server socketconnection created by serverSocket), but maybe opened by setting a non-empty value of argument open.
An R object is a data object which has a classattribute (and this can be tested by is.object).A class attribute is a character vector giving the names ofthe classes from which the object inherits.If the object does not have a class attribute, it has an implicitclass.  Matrices and arrays have class "matrix"or"array" followed by the class of the underlying vector.Most vectors have class the result of mode(x), exceptthat integer vectors have class c("integer", "numeric") andreal vectors have class c("double", "numeric").
These will work in any locale, including on platforms that do nototherwise support multi-byte character sets.
These use similar checks to those used by functions such asgrep.
These use similar checks to those used by functions such asgrep.
FUN is found by a call to match.fun and typicallyis specified as a function or a symbol (e.g., a backquoted name) or acharacter string specifying a function to be searched for from theenvironment of the call to lapply.
The atomic modes are "logical", "integer","numeric" (synonym "double"), "complex","character" and "raw".
The arguments named in the vectorize.args argument toVectorize are the arguments passed in the ...  list tomapply.  Only those that are actually passed will bevectorized; default values will not.  See the examples.
This gives details of the OS under which R was built, not the oneunder which it is currently running (for which seeSys.info).
The result depends on the value ofoptions("warn") and on handlers established in theexecuting code.
The condition system provides a mechanism for signaling andhandling unusual conditions, including errors and warnings.Conditions are represented as objects that contain informationabout the condition that occurred, such as a message and the call inwhich the condition occurred.  Currently conditions are S3-styleobjects, though this may eventually change.
See the description of options("warn") for thecircumstances under which there is a last.warning object andwarnings() is used.  In essence this is if options(warn =    0) and warning has been called at least once.
NA
NA
NA
NA
NA
NA
break breaks out of a for, while or repeatloop; control is transferred to the first statement outside theinner-most loop. next halts the processing of the currentiteration and advances the looping index.  Both break andnext apply only to the innermost of nested loops.
with is a generic function that evaluates expr in alocal environment constructed from data.  The environment hasthe caller's environment as its parent.  This is useful forsimplifying calls to modeling functions.  (Note: if data isalready an environment then this is used with its existing parent.)
with is a generic function that evaluates expr in alocal environment constructed from data.  The environment hasthe caller's environment as its parent.  This is useful forsimplifying calls to modeling functions.  (Note: if data isalready an environment then this is used with its existing parent.)
Note that running code via source differs in a few respectsfrom entering it at the R command line.  Since expressions are notexecuted at the top level, auto-printing is not done.  So you willneed to include explicit print calls for things you want to beprinted (and remember that this includes plotting by lattice,FAQ Q7.22).  Since the complete file is parsed before any of it isrun, syntax errors result in none of the code being run.  If an erroroccurs in running a syntactically correct script, anything assignedinto the workspace by code that has been run will be kept (just asfrom the command line), but diagnostic information such astraceback() will contain additional calls towithVisible.
The condition system provides a mechanism for signaling andhandling unusual conditions, including errors and warnings.Conditions are represented as objects that contain informationabout the condition that occurred, such as a message and the call inwhich the condition occurred.  Currently conditions are S3-styleobjects, though this may eventually change.
with is a generic function that evaluates expr in alocal environment constructed from data.  The environment hasthe caller's environment as its parent.  This is useful forsimplifying calls to modeling functions.  (Note: if data isalready an environment then this is used with its existing parent.)
with is a generic function that evaluates expr in alocal environment constructed from data.  The environment hasthe caller's environment as its parent.  This is useful forsimplifying calls to modeling functions.  (Note: if data isalready an environment then this is used with its existing parent.)
with is a generic function that evaluates expr in alocal environment constructed from data.  The environment hasthe caller's environment as its parent.  This is useful forsimplifying calls to modeling functions.  (Note: if data isalready an environment then this is used with its existing parent.)
The condition system provides a mechanism for signaling andhandling unusual conditions, including errors and warnings.Conditions are represented as objects that contain informationabout the condition that occurred, such as a message and the call inwhich the condition occurred.  Currently conditions are S3-styleobjects, though this may eventually change.
The argument, not an expression object, ratheran (unevaluated function) call, is evaluated in thecaller's context.
NA
DCF is a simple format for storing databases in plain text files thatcan easily be directly read and written by humans.  DCF is used invarious places to store R system information, like descriptions andcontents of packages.
These functions can only be used with binary-mode connections.If con is a character string, the functions callfile to obtain a binary-mode file connection which isopened for the duration of the function call.
These functions complement readBin andwriteBin which read and write C-style zero-terminatedcharacter strings.  They are for strings of known length, andcan optionally write an end-of-string mark.  They are intended onlyfor character strings valid in the current locale.
If the con is a character string, the function callsfile to obtain a file connection which is opened forthe duration of the function call.(tilde expansion of the file path is done by file.)
! indicates logical negation (NOT).
xpdrows.data.frame is an auxiliary function which expands therows of a data frame.  It is used by the data frame methods of[<- and [[<- (which perform subscripted assignments on adata frame), and not intended to be called directly.
This is a special case of ranking, but as a less general function thanrank is more suitable to be made generic.  The defaultmethod is similar to rank(x, ties.method = "min",    na.last = "keep"), so NA values are given rank NA and alltied values are given equal integer rank.
This is a special case of ranking, but as a less general function thanrank is more suitable to be made generic.  The defaultmethod is similar to rank(x, ties.method = "min",    na.last = "keep"), so NA values are given rank NA and alltied values are given equal integer rank.
This is a special case of ranking, but as a less general function thanrank is more suitable to be made generic.  The defaultmethod is similar to rank(x, ties.method = "min",    na.last = "keep"), so NA values are given rank NA and alltied values are given equal integer rank.
This is a special case of ranking, but as a less general function thanrank is more suitable to be made generic.  The defaultmethod is similar to rank(x, ties.method = "min",    na.last = "keep"), so NA values are given rank NA and alltied values are given equal integer rank.
This is a special case of ranking, but as a less general function thanrank is more suitable to be made generic.  The defaultmethod is similar to rank(x, ties.method = "min",    na.last = "keep"), so NA values are given rank NA and alltied values are given equal integer rank.
This is a special case of ranking, but as a less general function thanrank is more suitable to be made generic.  The defaultmethod is similar to rank(x, ties.method = "min",    na.last = "keep"), so NA values are given rank NA and alltied values are given equal integer rank.
This is a special case of ranking, but as a less general function thanrank is more suitable to be made generic.  The defaultmethod is similar to rank(x, ties.method = "min",    na.last = "keep"), so NA values are given rank NA and alltied values are given equal integer rank.
Numeric versions are sequences of one or more non-negative integers,usually (e.g., in package ‘DESCRIPTION’ files) represented ascharacter strings with the elements of the sequence concatenated andseparated by single . or - characters.  R packageversions consist of at least two such integers, an R system versionof exactly three (major, minor and patchlevel).
This is a special case of ranking, but as a less general function thanrank is more suitable to be made generic.  The defaultmethod is similar to rank(x, ties.method = "min",    na.last = "keep"), so NA values are given rank NA and alltied values are given equal integer rank.
This is a special case of ranking, but as a less general function thanrank is more suitable to be made generic.  The defaultmethod is similar to rank(x, ties.method = "min",    na.last = "keep"), so NA values are given rank NA and alltied values are given equal integer rank.
The first eleven functions create connections.  By default theconnection is not opened (except for a socket connection created bysocketConnection or socketAccept and for server socketconnection created by serverSocket), but maybe opened by setting a non-empty value of argument open.
NA
Typical usages are
For each i, an arrow is drawn between the point (x0[i],    y0[i]) and the point (x1[i], y1[i]).  The coordinate vectorswill be recycled to the length of the longest.
For a two-way contingency table, the signed contribution to Pearson'schi^2 for cell i, j is d_{ij} = (f_{ij} - e_{ij}) / sqrt(e_{ij}),where f_{ij} and e_{ij} are the observed and expectedcounts corresponding to the cell.  In the Cohen-Friendly associationplot, each cell is represented by a rectangle that has (signed) heightproportional to d_{ij} and width proportional tosqrt(e_{ij}), so that the area of the box isproportional to the difference in observed and expected frequencies.The rectangles in each row are positioned relative to a baselineindicating independence (d_{ij} = 0).  If the observed frequencyof a cell is greater than the expected one, the box rises above thebaseline and is shaded in the color specified by the first element ofcol, which defaults to black; otherwise, the box falls belowthe baseline and is shaded in the color specified by the secondelement of col, which defaults to red.
The axis line is drawn from the lowest to the highest value ofat, but will be clipped at the plot region.  By default, onlyticks which are drawn from points within the plot region (up to atolerance for rounding error) are plotted, but the ticks and theirlabels may well extend outside the plot region.  Use xpd = TRUEor xpd = NA to allow axes to extend further.
This is a generic function.  It works in a slightly non-standard way:if x is supplied and non-NULL it dispatches on x,otherwise if at is supplied and non-NULL it dispatches on at,and the default action is to call axis, omitting argumentx.
axis.POSIXct and axis.Date work quite hard to choosesuitable time units (years, months, days, hours, minutes or seconds)and a sensible output format, but this can be overridden by supplyinga format specification.
axis.POSIXct and axis.Date work quite hard to choosesuitable time units (years, months, days, hours, minutes or seconds)and a sensible output format, but this can be overridden by supplyinga format specification.
The axp, usr, and log arguments must be consistentas their default values (the par(..) results) are.  If youspecify all three (as non-NULL), the graphics environment is not usedat all.  Note that the meaning of axp differs significantlywhen log is TRUE; see the documentation onpar(xaxp = .).
NA
NA
The choice of colour is complicated.  If col was suppliedand is not NA, it is used.  Otherwise, if fg was suppliedand is not NA, it is used.  The final default is par("col").
The generic function boxplot currently has a default method(boxplot.default) and a formula interface (boxplot.formula).
The generic function boxplot currently has a default method(boxplot.default) and a formula interface (boxplot.formula).
NA
NA
cdplot computes the conditional densities of x giventhe levels of y weighted by the marginal distribution of y.The densities are derived cumulatively over the levels of y.
How the clipping rectangle is set depends on the setting ofpar("xpd"): this function changes the current settinguntil the next high-level plotting command resets it.
The first call to split.screen places R into split-screenmode.  The other split-screen functions only work within this mode.While in this mode, certain other commands should be avoided (see theWarnings section below).  Split-screen mode is exited by the commandclose.screen(all = TRUE).
In the case of a single conditioning variable a, when bothrows and columns are unspecified, a ‘close tosquare’ layout is chosen with columns >= rows.
contour is a generic function with only a default method inbase R.
contour is a generic function with only a default method inbase R.
In the case of a single conditioning variable a, when bothrows and columns are unspecified, a ‘close tosquare’ layout is chosen with columns >= rows.
The function or expression expr (for curve) or functionx (for plot) is evaluated at n points equallyspaced over the range [from, to].  The points determined inthis way are then plotted.
NA
The first call to split.screen places R into split-screenmode.  The other split-screen functions only work within this mode.While in this mode, certain other commands should be avoided (see theWarnings section below).  Split-screen mode is exited by the commandclose.screen(all = TRUE).
The values to be plotted can contain NAs.  Rectangles with twoor more corner values are NA are omitted entirely: where thereis a single NA value the triangle opposite the NA isomitted.
The fourfold display is designed for the display of 2 by 2 by ktables.
The new page is painted with the background colour(par("bg")), which is often transparent.  For deviceswith a canvas colour (the on-screen devices X11,windows and quartz), the window is first painted with thecanvas colour and then the background colour.
The coordinate systems are
The coordinate systems are
NA
The definition of histogram differs by source (withcountry-specific biases).  R's default with equi-spaced breaks (alsothe default) is to plot the counts in the cells defined bybreaks.  Thus the height of a rectangle is proportional tothe number of points falling into the cell, as is the areaprovided the breaks are equally-spaced.
The definition of histogram differs by source (withcountry-specific biases).  R's default with equi-spaced breaks (alsothe default) is to plot the counts in the cells defined bybreaks.  Thus the height of a rectangle is proportional tothe number of points falling into the cell, as is the areaprovided the breaks are equally-spaced.
identify is a generic function, and only the default method isdescribed here.
The length of x should be equal to the nrow(z)+1 ornrow(z).  In the first case x specifies the boundariesbetween the cells: in the second case x specifies the midpointsof the cells.  Similar reasoning applies to y.  It probablyonly makes sense to specify the midpoints of an equally-spacedgrid.  If you specify just one row or column and a length-one xor y, the whole user area in the corresponding direction isfilled. For logarithmic x or y axes the boundaries betweencells must be specified.
The length of x should be equal to the nrow(z)+1 ornrow(z).  In the first case x specifies the boundariesbetween the cells: in the second case x specifies the midpointsof the cells.  Similar reasoning applies to y.  It probablyonly makes sense to specify the midpoints of an equally-spacedgrid.  If you specify just one row or column and a length-one xor y, the whole user area in the corresponding direction isfilled. For logarithmic x or y axes the boundaries betweencells must be specified.
Figure i is allocated a region composed from a subsetof these rows and columns, based on the rows and columnsin which i occurs in mat.
Figure i is allocated a region composed from a subsetof these rows and columns, based on the rows and columnsin which i occurs in mat.
Figure i is allocated a region composed from a subsetof these rows and columns, based on the rows and columnsin which i occurs in mat.
Arguments x, y, legend are interpreted in anon-standard way to allow the coordinates to be specified viaone or two arguments.  If legend is missing and y is notnumeric, it is assumed that the second argument is intended to belegend and that the first argument specifies the coordinates.
The coordinates can be passed in a plotting structure(a list with x and y components), a two-column matrix, atime series, ....  See xy.coords.  If suppliedseparately, they must be of the same length.
The coordinates can be passed in a plotting structure(a list with x and y components), a two-column matrix, atime series, ....  See xy.coords.  If suppliedseparately, they must be of the same length.
locator is only supported on screen devices such asX11, windows and quartz.  On other devices thecall will do nothing.
matplot(x,y, ..) is basically a wrapper for
matplot(x,y, ..) is basically a wrapper for
matplot(x,y, ..) is basically a wrapper for
This is a generic function.  It currently has a default method(mosaicplot.default) and a formula interface(mosaicplot.formula).
The user coordinates in the outer margins always range from zero toone, and are not affected by the user coordinates in the figureregion(s) — R differs here from other implementations of S.
The ijth scatterplot contains x[,i] plotted againstx[,j].  The scatterplot can be customised by setting panelfunctions to appear as something completely different. Theoff-diagonal panel functions are passed the appropriate columns ofx as x and y: the diagonal panel function (ifany) is passed a single column, and the text.panel function ispassed a single (x, y) location and the column name.Setting some of these panel functions to NULL isequivalent to not drawing anything there.
The ijth scatterplot contains x[,i] plotted againstx[,j].  The scatterplot can be customised by setting panelfunctions to appear as something completely different. Theoff-diagonal panel functions are passed the appropriate columns ofx as x and y: the diagonal panel function (ifany) is passed a single column, and the text.panel function ispassed a single (x, y) location and the column name.Setting some of these panel functions to NULL isequivalent to not drawing anything there.
NA
Each device has its own set of graphical parameters.  If the currentdevice is the null device, par will open a new device beforequerying/setting parameters.  (What device is controlled byoptions("device").)
The plots are produced by first transforming the (x,y,z)coordinates to the interval [0,1] using the limits supplied orcomputed from the range of the data.  The surface is then viewedby looking at the origin from a direction defined by thetaand phi.  If theta and phi are both zerothe viewing direction is directly down the negative y axis.Changing theta will vary the azimuth and changing phithe colatitude.
NA
Commonly used graphical parameters are:
Commonly used graphical parameters are:
The supplied function will be called once for each level of eachfactor in the design and the plot will show these summary values.  Thelevels of a particular factor are shown along a vertical line, and theoverall value of fun() for the response is drawn as ahorizontal line.
The function or expression expr (for curve) or functionx (for plot) is evaluated at n points equallyspaced over the range [from, to].  The points determined inthis way are then plotted.
The new page is painted with the background colour(par("bg")), which is often transparent.  For deviceswith a canvas colour (the on-screen devices X11,windows and quartz), the window is first painted with thecanvas colour and then the background colour.
If asp is a finite positive value then the window isset up so that one data unit in the y direction is equal in length toasp * one data unit in the x direction.
The arguments pch, col, bg, cex,lwd may be vectors and may be recycled, depending ontype: see points and lines forspecifics.  In particular note that lwd is treated as a vectorfor points and as a single (first) value for lines.
The coordinates can be passed in a plotting structure(a list with x and y components), a two-column matrix, atime series, ....  See xy.coords.  If suppliedseparately, they must be of the same length.
The coordinates can be passed in a plotting structure(a list with x and y components), a two-column matrix, atime series, ....  See xy.coords.  If suppliedseparately, they must be of the same length.
The coordinates can be passed in a plotting structure(a list with x and y components), a two-column matrix,....  See xy.coords.
The coordinates can be passed in a plotting structure(a list with x and y components), a two-column matrix,....  See xy.coords.
The positions supplied, i.e., xleft, ...,are relative to the current plotting region.  If the x-axis goes from100 to 200 then xleft should be larger than 100 and xrightshould be less than 200.  The position vectors will be recycled to thelength of the longest.
The positions supplied, i.e., xleft, ...,are relative to the current plotting region.  If the x-axis goes from100 to 200 then xleft must be larger than 100 and xrightmust be less than 200.  The position vectors will be recycled to thelength of the longest.
Because of the way rug is implemented, only values of xthat fall within the plot region are included.  There will be awarning if any finite values are omitted, but non-finite values areomitted silently.
The first call to split.screen places R into split-screenmode.  The other split-screen functions only work within this mode.While in this mode, certain other commands should be avoided (see theWarnings section below).  Split-screen mode is exited by the commandclose.screen(all = TRUE).
For each i, a line segment is drawn between the point(x0[i], y0[i]) and the point (x1[i], y1[i]).  Thecoordinate vectors will be recycled to the length of the longest.
smoothScatter produces a smoothed version of a scatter plot.Two dimensional (kernel density) smoothing is performed bybkde2D from package KernSmooth.See the examples for how to use this function together withpairs.
spineplot creates either a spinogram or a spine plot.  It canbe called via spineplot(x, y) or spineplot(y ~ x) wherey is interpreted to be the dependent variable (and has to becategorical) and x the explanatory variable.  x can beeither categorical (then a spine plot is created) or numerical (then aspinogram is plotted).  Additionally, spineplot can also becalled with only a single argument which then has to be a 2-way table,interpreted to correspond to table(x, y).
The first call to split.screen places R into split-screenmode.  The other split-screen functions only work within this mode.While in this mode, certain other commands should be avoided (see theWarnings section below).  Split-screen mode is exited by the commandclose.screen(all = TRUE).
Missing values are treated as 0.
Infinite and missing values in x are discarded.
Note that the ‘height’ of a string is determined only by thenumber of linefeeds ("\n") it contains: it is the (number oflinefeeds - 1) times the line spacing plus the height of "M" inthe selected font.  For an expression it is the height of thebounding box as computed by plotmath.  Thus in both cases it isan estimate of how far above the final baseline the typesetobject extends.  (It may also extend below the baseline.)  Theinter-line spacing is controlled by cex,par("lheight") and the ‘point size’ (but not theactual font in use).
Extensive examples of the use of this kind of plot can be found inBox, Hunter and Hunter or Seber and Wild.
Note that the ‘height’ of a string is determined only by thenumber of linefeeds ("\n") it contains: it is the (number oflinefeeds - 1) times the line spacing plus the height of "M" inthe selected font.  For an expression it is the height of thebounding box as computed by plotmath.  Thus in both cases it isan estimate of how far above the final baseline the typesetobject extends.  (It may also extend below the baseline.)  Theinter-line spacing is controlled by cex,par("lheight") and the ‘point size’ (but not theactual font in use).
This is a generic function with default and formula methods.
Observations which have missing coordinates or missing sizeparameters are not plotted.  The exception to this is stars.In that case, the length of any ray which is NA is resetto zero.
labels must be of type character orexpression (or be coercible to such a type).In the latter case, quite a bit ofmathematical notation is available such as sub- and superscripts,greek letters, fractions, etc.
labels must be of type character orexpression (or be coercible to such a type).In the latter case, quite a bit ofmathematical notation is available such as sub- and superscripts,greek letters, fractions, etc.
The labels passed to title can be character strings orlanguage objects (names, calls or expressions), or a listcontaining the string to be plotted, and a selection of the optionalmodifying graphical parameters cex=, col= andfont=.  Other objects will be coerced byas.graphicsAnnot.
NA
An X-spline is a line drawn relative to control points.  For eachcontrol point, the line may pass through (interpolate) the controlpoint or it may only approach (approximate) the control point;  thebehaviour is determined by a shape parameter for each control point.
NA
NA
Used in such problems as Thurstonian scaling.  Although not technically matrix addition, as pointed out by Krus, there are many applications where the sum or difference of two vectors or matrices is a useful operation.  An alternative operation for vectors is  outer(x ,y , FUN="+") but this does not work for matrices.  
lowerCor prints out the lower off diagonal matrix rounded to digits with column names abbreviated to digits + 3 characters, but also returns the full and unrounded matrix.  By default, it uses pairwise deletion of variables.  It in turn calls
Alpha is one of several estimates of the internal consistency reliability of a test.
Alpha is one of several estimates of the internal consistency reliability of a test.
setCor returns the SE.residual and degrees of freedom.  These are converted to SSR and then an analysis of variance is used to compare two (or more) models. For omega or fa the change in the ML chisquare statistic as a function of change in df is reported.
The problem of making binary decisions about the state of the world is ubiquitous.  We see this in Null Hypothesis Significance Testing (NHST), medical diagnoses, and selection for occupations.  Variously known as NHST, Signal Detection Theory, clinical Assessment, or college admissions, all of these domains share the same two x two decision task.
When examining multiple measures within subjects, it is sometimes useful to consider the variability of trial by trial observations in addition to the over all between trial variation.  The Mean Square of Successive Differences (mssd) and root mean square of successive differences (rmssd) is just 
This is essentially a wrapper to the fa and pca combined with the faCor functions.  They are called repeatedly and then the weights from the resulting solutions are used to find the factor/component correlations. 
This is essentially a wrapper to the fa and pca combined with the faCor functions.  They are called repeatedly and then the weights from the resulting solutions are used to find the factor/component correlations. 
Holzinger and Swineford (1937) introduced the bifactor model (one general factor and several group factors) for mental abilities.  This is a nice demonstration data set of a hierarchical factor structure that can be analyzed using the omega function or using sem. The bifactor model is typically used in measures of cognitive ability.
Holzinger and Swineford (1937) introduced the bifactor model (one general factor and several group factors) for mental abilities.  This is a nice demonstration data set of a hierarchical factor structure that can be analyzed using the omega function or using sem. The bifactor model is typically used in measures of cognitive ability.
Holzinger and Swineford (1937) introduced the bifactor model (one general factor and several group factors) for mental abilities.  This is a nice demonstration data set of a hierarchical factor structure that can be analyzed using the omega function or using sem. The bifactor model is typically used in measures of cognitive ability.
There are a number of procedures that can be used for predicting criteria from a set of predictors.  The generic term for this is "machine learning" or "statistical learning".  The basic logic of these procedures is to find a set of items that best predict a criteria according to some fit statistic and then cross validate these items numerous times.  "lasso" regression (least absolute shrinkage and selection) is one such example. bestScales differs from these procedures by unit weighting items chosen from their zero order correlations with the criteria rather than weighting the partial correlations ala regression.  This is an admittedly simple procedure that takes into account the well known finding (Wilks, 1938;  Wainer, 1976; Dawes, 1979; Waller, 2008) that although regression weights are optimal for any particular data set, unit weights are almost as good (fungible) and more robust across sample variation.  
There are a number of procedures that can be used for predicting criteria from a set of predictors.  The generic term for this is "machine learning" or "statistical learning".  The basic logic of these procedures is to find a set of items that best predict a criteria according to some fit statistic and then cross validate these items numerous times.  "lasso" regression (least absolute shrinkage and selection) is one such example. bestScales differs from these procedures by unit weighting items chosen from their zero order correlations with the criteria rather than weighting the partial correlations ala regression.  This is an admittedly simple procedure that takes into account the well known finding (Wilks, 1938;  Wainer, 1976; Dawes, 1979; Waller, 2008) that although regression weights are optimal for any particular data set, unit weights are almost as good (fungible) and more robust across sample variation.  
This data set is deprecated and users are encouraged to use bfi.It is kept here backward compatability for one more release.
This data set is deprecated and users are encouraged to use bfi.It is kept here backward compatability for one more release.
A trivial, if useful, function to draw back to back histograms/barplots. One for each group.
The two most useful of these  functions is probably biquartimin which implements the oblique bifactor rotation introduced by Jennrich and Bentler (2011). The second is TargetQ which allows for missing NA values in the target. Next best is the orthogonal case, bifactor.  None of these seem to be implemented in GPArotation (yet). 
The data are divided into subsets of size=size.  Correlations are then found for each subset and pairs of subsets. The basic loop loops over the subsets. When the size is a integer subset of the number of variables and is a muiltiple of the number of cores, the multiple cores will be used more.  Notice the benefit of 660/80 versus 660/100.  But this breaks down if we try 660/165.  Further notice the benefit when using a smaller subset (55) which led to the 4 cores being used more.  
Uses the generic biplot function to take the output of a factor analysis fa, fa.poly or principal components analysis principal and plot the factor/component scores along with the factor/component loadings.
The two most useful of these  functions is probably biquartimin which implements the oblique bifactor rotation introduced by Jennrich and Bentler (2011). The second is TargetQ which allows for missing NA values in the target. Next best is the orthogonal case, bifactor.  None of these seem to be implemented in GPArotation (yet). 
Tetrachoric correlations infer a latent Pearson correlation from a two x two table of frequencies with the assumption of bivariate normality.  The estimation procedure is two stage ML.  Cell frequencies for each pair of items are found. In the case of tetrachorics, cells with zero counts are replaced with .5 as a correction for continuity (correct=TRUE). 
NA
The lsat6 data set is analyzed in the ltm package as well as by McDonald (1999). lsat7 is another 1000 subjects on part 7 of the LSAT. Both sets are described by Bock and Lieberman (1970). Both sets are useful examples of testing out IRT procedures and showing the use of tetrachoric correlations and item factor analysis using the irt.fa function.
Cattell (1963) reported on 8 cognitive variables from Thurstone and four from the Institute for Personality Assessment Test (IPAT).  Rindskopf and Rose (1988) use this data set as an example of second order factor analysis. It is thus a nice set for examining alternative solutions such as bifactor rotation, omega hierarchical, as well as esem and interbattery factor analysis.
lowerCor prints out the lower off diagonal matrix rounded to digits with column names abbreviated to digits + 3 characters, but also returns the full and unrounded matrix.  By default, it uses pairwise deletion of variables.  It in turn calls
 Two artificial correlation matrices from Schmid and Leiman (1957). One real and one artificial covariance matrices from Chen et al. (2006). 
NA
This simulation was originally developed to compare the effect of skew on the measurement of affect (see Rafaeli and Revelle, 2005).  It has been extended to allow for a general simulation of affect or personality items with either a simple structure or a circumplex structure.  Items can be continuous normally distributed, or broken down into n categories (e.g, -2, -1, 0, 1, 2).  Items can be distorted by limiting them to these ranges, even though the items have a mean of (e.g., 1).  
“A common model for representing psychological data is simple structure (Thurstone, 1947). According to one common interpretation, data are simple structured when items or scales have non-zero factor loadings on one and only one factor (Revelle & Rocklin, 1979). Despite the commonplace application of simple structure, some psychological models are defined by a lack of simple structure. Circumplexes (Guttman, 1954) are one kind of model in which simple structure is lacking.
“A common model for representing psychological data is simple structure (Thurstone, 1947). According to one common interpretation, data are simple structured when items or scales have non-zero factor loadings on one and only one factor (Revelle & Rocklin, 1979). Despite the commonplace application of simple structure, some psychological models are defined by a lack of simple structure. Circumplexes (Guttman, 1954) are one kind of model in which simple structure is lacking.
“A common model for representing psychological data is simple structure (Thurstone, 1947). According to one common interpretation, data are simple structured when items or scales have non-zero factor loadings on one and only one factor (Revelle & Rocklin, 1979). Despite the commonplace application of simple structure, some psychological models are defined by a lack of simple structure. Circumplexes (Guttman, 1954) are one kind of model in which simple structure is lacking.
When data represent angles (such as the hours of peak alertness or peak tension during the day), we need to apply circular statistics rather than the more normal linear statistics (see Jammalamadaka (2006) for a very clear set of examples of circular statistics). The generalization of the mean to circular data is to convert each angle into a vector, average the x and y coordinates, and convert the result back to an angle. A statistic that represents the compactness of the observations is R which is the (normalized) vector length found by adding all of the observations together.  This will achieve a maximum value (1) when all the phase angles are the same and a minimum (0) if the phase angles are distributed uniformly around the clock.  
When data represent angles (such as the hours of peak alertness or peak tension during the day), we need to apply circular statistics rather than the more normal linear statistics (see Jammalamadaka (2006) for a very clear set of examples of circular statistics). The generalization of the mean to circular data is to convert each angle into a vector, average the x and y coordinates, and convert the result back to an angle. A statistic that represents the compactness of the observations is R which is the (normalized) vector length found by adding all of the observations together.  This will achieve a maximum value (1) when all the phase angles are the same and a minimum (0) if the phase angles are distributed uniformly around the clock.  
When data represent angles (such as the hours of peak alertness or peak tension during the day), we need to apply circular statistics rather than the more normal linear statistics (see Jammalamadaka (2006) for a very clear set of examples of circular statistics). The generalization of the mean to circular data is to convert each angle into a vector, average the x and y coordinates, and convert the result back to an angle. A statistic that represents the compactness of the observations is R which is the (normalized) vector length found by adding all of the observations together.  This will achieve a maximum value (1) when all the phase angles are the same and a minimum (0) if the phase angles are distributed uniformly around the clock.  
When data represent angles (such as the hours of peak alertness or peak tension during the day), we need to apply circular statistics rather than the more normal linear statistics (see Jammalamadaka (2006) for a very clear set of examples of circular statistics). The generalization of the mean to circular data is to convert each angle into a vector, average the x and y coordinates, and convert the result back to an angle. A statistic that represents the compactness of the observations is R which is the (normalized) vector length found by adding all of the observations together.  This will achieve a maximum value (1) when all the phase angles are the same and a minimum (0) if the phase angles are distributed uniformly around the clock.  
When data represent angles (such as the hours of peak alertness or peak tension during the day), we need to apply circular statistics rather than the more normal linear statistics (see Jammalamadaka (2006) for a very clear set of examples of circular statistics). The generalization of the mean to circular data is to convert each angle into a vector, average the x and y coordinates, and convert the result back to an angle. A statistic that represents the compactness of the observations is R which is the (normalized) vector length found by adding all of the observations together.  This will achieve a maximum value (1) when all the phase angles are the same and a minimum (0) if the phase angles are distributed uniformly around the clock.  
When data represent angles (such as the hours of peak alertness or peak tension during the day), we need to apply circular statistics rather than the more normal linear statistics (see Jammalamadaka (2006) for a very clear set of examples of circular statistics). The generalization of the mean to circular data is to convert each angle into a vector, average the x and y coordinates, and convert the result back to an angle. A statistic that represents the compactness of the observations is R which is the (normalized) vector length found by adding all of the observations together.  This will achieve a maximum value (1) when all the phase angles are the same and a minimum (0) if the phase angles are distributed uniformly around the clock.  
When data represent angles (such as the hours of peak alertness or peak tension during the day), we need to apply circular statistics rather than the more normal linear statistics (see Jammalamadaka (2006) for a very clear set of examples of circular statistics). The generalization of the mean to circular data is to convert each angle into a vector, average the x and y coordinates, and convert the result back to an angle. A statistic that represents the compactness of the observations is R which is the (normalized) vector length found by adding all of the observations together.  This will achieve a maximum value (1) when all the phase angles are the same and a minimum (0) if the phase angles are distributed uniformly around the clock.  
When data represent angles (such as the hours of peak alertness or peak tension during the day), we need to apply circular statistics rather than the more normal linear statistics (see Jammalamadaka (2006) for a very clear set of examples of circular statistics). The generalization of the mean to circular data is to convert each angle into a vector, average the x and y coordinates, and convert the result back to an angle. A statistic that represents the compactness of the observations is R which is the (normalized) vector length found by adding all of the observations together.  This will achieve a maximum value (1) when all the phase angles are the same and a minimum (0) if the phase angles are distributed uniformly around the clock.  
When data represent angles (such as the hours of peak alertness or peak tension during the day), we need to apply circular statistics rather than the more normal linear statistics (see Jammalamadaka (2006) for a very clear set of examples of circular statistics). The generalization of the mean to circular data is to convert each angle into a vector, average the x and y coordinates, and convert the result back to an angle. A statistic that represents the compactness of the observations is R which is the (normalized) vector length found by adding all of the observations together.  This will achieve a maximum value (1) when all the phase angles are the same and a minimum (0) if the phase angles are distributed uniformly around the clock.  
When data represent angles (such as the hours of peak alertness or peak tension during the day), we need to apply circular statistics rather than the more normal linear statistics (see Jammalamadaka (2006) for a very clear set of examples of circular statistics). The generalization of the mean to circular data is to convert each angle into a vector, average the x and y coordinates, and convert the result back to an angle. A statistic that represents the compactness of the observations is R which is the (normalized) vector length found by adding all of the observations together.  This will achieve a maximum value (1) when all the phase angles are the same and a minimum (0) if the phase angles are distributed uniformly around the clock.  
These  are three of the functions used in the SAPA (https://www.sapa-project.org/) procedures to form synthetic correlation matrices.  Given any correlation matrix of items, it is easy to find the correlation matrix of scales made up of those items. This can also be done from the original data matrix or from the correlation matrix using scoreItems which is probably preferred unless the keys are overlapping.  It is important to remember with SAPA data, that scale correlations should be found from the item correlations, not the raw data.
The cluster model is similar to the factor model: R is fitted by C'C. Where C <- Cluster definition matrix x the loading matrix.  How well does this model approximate the original correlation matrix and how does this compare to a factor model?
Given a set of items to be scored as (perhaps overlapping) clusters and the intercorrelation matrix of the items, find the clusters and then the correlations of each item with each cluster.  Correct for item overlap by replacing the item variance with its average within cluster inter-item correlation.  
Results of either a factor analysis or cluster analysis are plotted.  Each item is assigned to its highest loading factor, and then identified by variable name as well as cluster (by color). The cluster assignments can be specified to override the automatic clustering by loading.Both of these functions may be called directly or by calling the generic plot function.  (see example).
Note that because kmeans will not reverse score items, the clusters defined by kmeans will not necessarily match those of ICLUST with the same number of clusters extracted. 
There are many ways of reporting how two groups differ.  Cohen's d statistic is just the differences of means expressed in terms of the pooled within group standard deviation.  This is insensitive to sample size.  r is the a universal measure of effect size that is a simple function of d, but is bounded -1 to 1.  The t statistic is merely d * sqrt(n)/2 and thus reflects sample size.   
There are many ways of reporting how two groups differ.  Cohen's d statistic is just the differences of means expressed in terms of the pooled within group standard deviation.  This is insensitive to sample size.  r is the a universal measure of effect size that is a simple function of d, but is bounded -1 to 1.  The t statistic is merely d * sqrt(n)/2 and thus reflects sample size.   
There are many ways of reporting how two groups differ.  Cohen's d statistic is just the differences of means expressed in terms of the pooled within group standard deviation.  This is insensitive to sample size.  r is the a universal measure of effect size that is a simple function of d, but is bounded -1 to 1.  The t statistic is merely d * sqrt(n)/2 and thus reflects sample size.   
When cateogorical judgments are made with two cateories, a measure of relationship is the phi coefficient.  However, some categorical judgments are made using more than two outcomes.  For example, two diagnosticians might be asked to categorize patients three ways (e.g., Personality disorder, Neurosis, Psychosis) or to categorize the stages of a disease.  Just as base rates affect observed cell frequencies in a two by two table, they need to be considered in the n-way table (Cohen, 1960). 
Congruences are the cosines of pairs of vectors defined by a matrix and based at the origin.  Thus, for values that differ only by a scaler the congruence will be 1.
NA
This simulation was originally developed to compare the effect of skew on the measurement of affect (see Rafaeli and Revelle, 2005).  It has been extended to allow for a general simulation of affect or personality items with either a simple structure or a circumplex structure.  Items can be continuous normally distributed, or broken down into n categories (e.g, -2, -1, 0, 1, 2).  Items can be distorted by limiting them to these ranges, even though the items have a mean of (e.g., 1).  
When constructing examples for reliability analysis, it is convenient to simulate congeneric data structures.  These are the most simple of item structures, having just one factor. Mainly used for a discussion of reliability theory as well as factor score estimates. 
Congruences are the cosines of pairs of vectors defined by a matrix and based at the origin.  Thus, for values that differ only by a scaler the congruence will be 1.
If given a correlation matrix, then confidence intervals are found based upon the sample sizes using the conventional r2z fisher transformation (fisherz and the normal distribution.
When summarizing the correlations of large data bases or when teaching about factor analysis or cluster analysis, it is useful to graphically display the structure of correlation matrices.  This is a simple graphical display using the image function. 
When summarizing the correlations of large data bases or when teaching about factor analysis or cluster analysis, it is useful to graphically display the structure of correlation matrices.  This is a simple graphical display using the image function. 
The smoothing is done by eigen value decomposition.  eigen values < eig.tol are changed to 100  * eig.tol.  The positive eigen values are rescaled to sum to the number of items.  The matrix is recomputed (eigen.vectors %*% diag(eigen.values) %*% t(eigen.vectors) and forced to a correlation matrix using cov2cor. (See Bock, Gibbons and Muraki, 1988 and Wothke, 1993). 
The smoothing is done by eigen value decomposition.  eigen values < eig.tol are changed to 100  * eig.tol.  The positive eigen values are rescaled to sum to the number of items.  The matrix is recomputed (eigen.vectors %*% diag(eigen.values) %*% t(eigen.vectors) and forced to a correlation matrix using cov2cor. (See Bock, Gibbons and Muraki, 1988 and Wothke, 1993). 
A weighted correlation is just ∑ (wt_k * (x_ik - x_jk)) /sqrt[wt_k ∑(x^2_ik) wt_k ∑(x^2_jk)]  where x_ik is a deviation from the weighted mean.  
lowerCor prints out the lower off diagonal matrix rounded to digits with column names abbreviated to digits + 3 characters, but also returns the full and unrounded matrix.  By default, it uses pairwise deletion of variables.  It in turn calls
NA
NA
If given a correlation matrix, then confidence intervals are found based upon the sample sizes using the conventional r2z fisher transformation (fisherz and the normal distribution.
In the presence of missing data, Full Information Maximum Likelihood (FIML) is an alternative to simply using the pairwise correlations. The implementation in the lavaan package for structural equation modeling has been adapted for the simpler case of just finding the correlations or covariances.  
When summarizing the correlations of large data bases or when teaching about factor analysis or cluster analysis, it is useful to graphically display the structure of correlation matrices.  This is a simple graphical display using the image function. 
When summarizing the correlations of large data bases or when teaching about factor analysis or cluster analysis, it is useful to graphically display the structure of correlation matrices.  This is a simple graphical display using the image function. 
corr.test uses the cor function to find the correlations, and then applies a t-test to the individual correlations using the formula
corr.test uses the cor function to find the correlations, and then applies a t-test to the individual correlations using the formula
Disattenuated correlations may be thought of as  correlations between the latent variables measured by a set of observed variables. That is, what would the correlation be between two (unreliable) variables be if both variables were measured perfectly reliably.
There are several ways to test if a matrix is the identity matrix. The most well known is the chi square test  of Bartlett (1951) and Box (1949). A very straightforward test, discussed by Steiger (1980) is to find the sum of the squared correlations or the sum of the squared Fisher transformed correlations.  Under the null hypothesis that all the correlations are equal, this sum is distributed as chi square.  This is implemented in cortest and cortest.normal
More useful for pedagogical purposes than actual applications. The Bartlett test is asymptotically chi square distributed.
There are several ways to test if a matrix is the identity matrix. The most well known is the chi square test  of Bartlett (1951) and Box (1949). A very straightforward test, discussed by Steiger (1980) is to find the sum of the squared correlations or the sum of the squared Fisher transformed correlations.  Under the null hypothesis that all the correlations are equal, this sum is distributed as chi square.  This is implemented in cortest and cortest.normal
There are several ways to test if a matrix is the identity matrix. The most well known is the chi square test  of Bartlett (1951) and Box (1949). A very straightforward test, discussed by Steiger (1980) is to find the sum of the squared correlations or the sum of the squared Fisher transformed correlations.  Under the null hypothesis that all the correlations are equal, this sum is distributed as chi square.  This is implemented in cortest and cortest.normal
There are several ways to test if a matrix is the identity matrix. The most well known is the chi square test  of Bartlett (1951) and Box (1949). A very straightforward test, discussed by Steiger (1980) is to find the sum of the squared correlations or the sum of the squared Fisher transformed correlations.  Under the null hypothesis that all the correlations are equal, this sum is distributed as chi square.  This is implemented in cortest and cortest.normal
When data represent angles (such as the hours of peak alertness or peak tension during the day), we need to apply circular statistics rather than the more normal linear statistics (see Jammalamadaka (2006) for a very clear set of examples of circular statistics). The generalization of the mean to circular data is to convert each angle into a vector, average the x and y coordinates, and convert the result back to an angle. A statistic that represents the compactness of the observations is R which is the (normalized) vector length found by adding all of the observations together.  This will achieve a maximum value (1) when all the phase angles are the same and a minimum (0) if the phase angles are distributed uniformly around the clock.  
When data represent angles (such as the hours of peak alertness or peak tension during the day), we need to apply circular statistics rather than the more normal linear statistics (see Jammalamadaka (2006) for a very clear set of examples of circular statistics). The generalization of the mean to circular data is to convert each angle into a vector, average the x and y coordinates, and convert the result back to an angle. A statistic that represents the compactness of the observations is R which is the (normalized) vector length found by adding all of the observations together.  This will achieve a maximum value (1) when all the phase angles are the same and a minimum (0) if the phase angles are distributed uniformly around the clock.  
When data represent angles (such as the hours of peak alertness or peak tension during the day), we need to apply circular statistics rather than the more normal linear statistics (see Jammalamadaka (2006) for a very clear set of examples of circular statistics). The generalization of the mean to circular data is to convert each angle into a vector, average the x and y coordinates, and convert the result back to an angle. A statistic that represents the compactness of the observations is R which is the (normalized) vector length found by adding all of the observations together.  This will achieve a maximum value (1) when all the phase angles are the same and a minimum (0) if the phase angles are distributed uniformly around the clock.  
When using Massively Missing Completely at Random (MMCAR) designs used by the SAPA project, it is important to count the number of pairwise observations (pairwiseCount).  If there are pairs with 1 or fewer observations, these will produce NA values for correlations making subsequent factor analyses fa or reliability analsyes omega or scoreOverlap impossible.
Although it is more common to calculate multiple regression and canonical correlations from the raw data, it is,  of course, possible to do so from a matrix of correlations or covariances.  In this case, the input to the function is a square covariance or correlation matrix, as well as the column numbers (or names) of the x (predictor),  y (criterion) variables, and if desired z (covariates). The function will find the correlations if given raw data.
lowerCor prints out the lower off diagonal matrix rounded to digits with column names abbreviated to digits + 3 characters, but also returns the full and unrounded matrix.  By default, it uses pairwise deletion of variables.  It in turn calls
A very thorough discussion of the CTA model is available from Revelle (2008). An application of the model is discussed in Revelle and Condon (2015). 
A very thorough discussion of the CTA model is available from Revelle (2008). An application of the model is discussed in Revelle and Condon (2015). 
There are many ways of reporting how two groups differ.  Cohen's d statistic is just the differences of means expressed in terms of the pooled within group standard deviation.  This is insensitive to sample size.  r is the a universal measure of effect size that is a simple function of d, but is bounded -1 to 1.  The t statistic is merely d * sqrt(n)/2 and thus reflects sample size.   
There are many ways of reporting how two groups differ.  Cohen's d statistic is just the differences of means expressed in terms of the pooled within group standard deviation.  This is insensitive to sample size.  r is the a universal measure of effect size that is a simple function of d, but is bounded -1 to 1.  The t statistic is merely d * sqrt(n)/2 and thus reflects sample size.   
There are many ways of reporting how two groups differ.  Cohen's d statistic is just the differences of means expressed in terms of the pooled within group standard deviation.  This is insensitive to sample size.  r is the a universal measure of effect size that is a simple function of d, but is bounded -1 to 1.  The t statistic is merely d * sqrt(n)/2 and thus reflects sample size.   
There are many ways of reporting how two groups differ.  Cohen's d statistic is just the differences of means expressed in terms of the pooled within group standard deviation.  This is insensitive to sample size.  r is the a universal measure of effect size that is a simple function of d, but is bounded -1 to 1.  The t statistic is merely d * sqrt(n)/2 and thus reflects sample size.   
There are many ways of reporting how two groups differ.  Cohen's d statistic is just the differences of means expressed in terms of the pooled within group standard deviation.  This is insensitive to sample size.  r is the a universal measure of effect size that is a simple function of d, but is bounded -1 to 1.  The t statistic is merely d * sqrt(n)/2 and thus reflects sample size.   
There are many ways of reporting how two groups differ.  Cohen's d statistic is just the differences of means expressed in terms of the pooled within group standard deviation.  This is insensitive to sample size.  r is the a universal measure of effect size that is a simple function of d, but is bounded -1 to 1.  The t statistic is merely d * sqrt(n)/2 and thus reflects sample size.   
There are many ways of reporting how two groups differ.  Cohen's d statistic is just the differences of means expressed in terms of the pooled within group standard deviation.  This is insensitive to sample size.  r is the a universal measure of effect size that is a simple function of d, but is bounded -1 to 1.  The t statistic is merely d * sqrt(n)/2 and thus reflects sample size.   
There are many ways of reporting how two groups differ.  Cohen's d statistic is just the differences of means expressed in terms of the pooled within group standard deviation.  This is insensitive to sample size.  r is the a universal measure of effect size that is a simple function of d, but is bounded -1 to 1.  The t statistic is merely d * sqrt(n)/2 and thus reflects sample size.   
Describe the data using a violin plot. Change alpha to modify the shading.  The grp variable may be used to draw separate violin plots for each of multiple groups.
In basic data analysis it is vital to get basic descriptive statistics. Procedures such as summary and Hmisc::describe do so.  The describe function in the psych package is meant to produce the most frequently requested stats in psychometric and psychology studies, and to produce them in an easy to read data.frame. If a grouping variable is called for in formula mode, it will also call describeBy to the processing. The results from describe can be used in graphics functions (e.g., error.crosses).
To get descriptive statistics for several different grouping variables, make sure that group is a list.  In the case of matrix output with multiple grouping variables, the grouping variable values are added to the output.
To get descriptive statistics for several different grouping variables, make sure that group is a list.  In the case of matrix output with multiple grouping variables, the grouping variable values are added to the output.
In basic data analysis it is vital to get basic descriptive statistics. Procedures such as summary and Hmisc::describe do so.  The describe function in the psych package is meant to produce the most frequently requested stats in psychometric and psychology studies, and to produce them in an easy to read data.frame. If a grouping variable is called for in formula mode, it will also call describeBy to the processing. The results from describe can be used in graphics functions (e.g., error.crosses).
In basic data analysis it is vital to get basic descriptive statistics. Procedures such as summary and Hmisc::describe do so.  The describe function in the psych package is meant to produce the most frequently requested stats in psychometric and psychology studies, and to produce them in an easy to read data.frame. If a grouping variable is called for in formula mode, it will also call describeBy to the processing. The results from describe can be used in graphics functions (e.g., error.crosses).
The diagram function calls  fa.diagram, omega.diagram,  ICLUST.diagram, lavaan.diagram or bassAckward.diagram depending upon the class of the fit input.  See those functions for particular parameter values.
The diagram function calls  fa.diagram, omega.diagram,  ICLUST.diagram, lavaan.diagram or bassAckward.diagram depending upon the class of the fit input.  See those functions for particular parameter values.
The diagram function calls  fa.diagram, omega.diagram,  ICLUST.diagram, lavaan.diagram or bassAckward.diagram depending upon the class of the fit input.  See those functions for particular parameter values.
The diagram function calls  fa.diagram, omega.diagram,  ICLUST.diagram, lavaan.diagram or bassAckward.diagram depending upon the class of the fit input.  See those functions for particular parameter values.
The diagram function calls  fa.diagram, omega.diagram,  ICLUST.diagram, lavaan.diagram or bassAckward.diagram depending upon the class of the fit input.  See those functions for particular parameter values.
The diagram function calls  fa.diagram, omega.diagram,  ICLUST.diagram, lavaan.diagram or bassAckward.diagram depending upon the class of the fit input.  See those functions for particular parameter values.
The diagram function calls  fa.diagram, omega.diagram,  ICLUST.diagram, lavaan.diagram or bassAckward.diagram depending upon the class of the fit input.  See those functions for particular parameter values.
The diagram function calls  fa.diagram, omega.diagram,  ICLUST.diagram, lavaan.diagram or bassAckward.diagram depending upon the class of the fit input.  See those functions for particular parameter values.
The diagram function calls  fa.diagram, omega.diagram,  ICLUST.diagram, lavaan.diagram or bassAckward.diagram depending upon the class of the fit input.  See those functions for particular parameter values.
The diagram function calls  fa.diagram, omega.diagram,  ICLUST.diagram, lavaan.diagram or bassAckward.diagram depending upon the class of the fit input.  See those functions for particular parameter values.
The diagram function calls  fa.diagram, omega.diagram,  ICLUST.diagram, lavaan.diagram or bassAckward.diagram depending upon the class of the fit input.  See those functions for particular parameter values.
“Many scales are assumed by their developers and users to be primarily a measure of one latent variable. When it is also assumed that the scale conforms to the effect indicator model of measurement (as is almost always the case in psychological assessment), it is important to support such an interpretation with evidence regarding the internal structure of that scale. In particular, it is important to examine two related properties pertaining to the internal structure of such a scale. The first property relates to whether all the indicators forming the scale measure a latent variable in common. 
Congruences are the cosines of pairs of vectors defined by a matrix and based at the origin.  Thus, for values that differ only by a scaler the congruence will be 1.
A graphic demonstration of the tetrachoric correlation. Used for teaching purposes.  The default values are for a correlation of .5 with cuts at 1 and 1. Any other values are possible.  The code is also a demonstration of how to use the layout function for complex graphics using base graphics. 
A graphic demonstration of the tetrachoric correlation. Used for teaching purposes.  The default values are for a correlation of .5 with cuts at 1 and 1. Any other values are possible.  The code is also a demonstration of how to use the layout function for complex graphics using base graphics. 
When coding demographic information, it is typical to create one variable with multiple categorical values (e.g., ethnicity, college major, occupation). dummy.code will convert these categories into n distinct dummy coded variables.
NA
NA
Ellipse dimensions are calculated from the correlation between the x and y variables and are scaled as sqrt(1+r) and sqrt(1-r). They are then scaled as size[1] and size[2] standard deviation units.   To scale  for 95 and 99 percent confidence use c(1.64,2.32)
The two most useful of these  functions is probably biquartimin which implements the oblique bifactor rotation introduced by Jennrich and Bentler (2011). The second is TargetQ which allows for missing NA values in the target. Next best is the orthogonal case, bifactor.  None of these seem to be implemented in GPArotation (yet). 
Drawing the mean +/- a confidence interval is a frequently used function when reporting experimental results. By default, the confidence interval is 1.96 standard errors of the t-distribution.  
Drawing the mean +/- a confidence interval is a frequently used function when reporting experimental results. By default, the confidence interval is 1.96 standard errors (adjusted for the t-distribution). 
Drawing the mean +/- a confidence interval is a frequently used function when reporting experimental results. By default, the confidence interval is 1.96 standard errors of the t-distribution.  
For an example of two way error bars describing the effects of mood manipulations upon positive and negative affect, see https://personality-project.org/revelle/publications/happy-sad-appendix/FIG.A-6.pdf
Adapted from the dot.chart function to include error bars and to use the output of describe,  describeBy,   statsBy, fa, bestScales or cohen.d.   To speed up multiple plots, the function can work from the output of a previous run.  Thus describeBy will be done and the results can be show for multiple variables.
When visualizing the effect of an experimental manipulation or the relationship of multiple groups, it is convenient to plot their means as well as their confidence regions in a two dimensional space.  
Factor analysis as implemented in fa attempts to  summarize the covariance (correlational) structure of a set of variables with a small set of latent variables or “factors".  This solution may be ‘extended’ into a larger space with more variables without changing the original solution (see fa.extension.  Similarly,  the factors of a second set of variables  (the Y set) may be extended into the original (X ) set.  Doing so allows two independent measurement models, a measurement model for X and a measurement model for Y.  These two sets of latent variables may then be correlated  for an Exploratory Structural Equation Model.  (This is exploratory because it is based upon exploratory factor analysis (EFA) rather than a confirmatory factor model (CFA) using more traditional Structural Equation Modeling packages such as sem, lavaan, or Mx.)
Factor analysis as implemented in fa attempts to  summarize the covariance (correlational) structure of a set of variables with a small set of latent variables or “factors".  This solution may be ‘extended’ into a larger space with more variables without changing the original solution (see fa.extension.  Similarly,  the factors of a second set of variables  (the Y set) may be extended into the original (X ) set.  Doing so allows two independent measurement models, a measurement model for X and a measurement model for Y.  These two sets of latent variables may then be correlated  for an Exploratory Structural Equation Model.  (This is exploratory because it is based upon exploratory factor analysis (EFA) rather than a confirmatory factor model (CFA) using more traditional Structural Equation Modeling packages such as sem, lavaan, or Mx.)
Path diagram representations have become standard in confirmatory factor analysis, but are not yet common in exploratory factor analysis.  Representing factor structures graphically helps some people understand the structure. 
Factor analysis is an attempt to approximate a correlation or covariance matrix with one of lesser rank.  The basic model is that nRn = nFk kFn' + U2 where k is much less than n. There are many ways to do factor analysis, and maximum likelihood procedures are probably the most commonly preferred (see factanal ).  The existence of uniquenesses is what distinguishes factor analysis from principal components analysis (e.g., principal). If variables are thought to represent a “true" or latent part then factor analysis provides an estimate of the correlations with the latent factor(s) representing the data.  If variables are thought to be measured without error, then principal components provides the most parsimonious description of the data.  
Find the coefficient of factor congruence between two sets of factor loadings. 
Path diagram representations have become standard in confirmatory factor analysis, but are not yet common in exploratory factor analysis.  Representing factor structures graphically helps some people understand the structure. 
It is sometimes the case that factors are derived from a set of variables (the Fo factor loadings) and we want to see what the loadings of an extended set of variables (Fe) would be. Given the original correlation matrix Ro and the correlation of these original variables with the extension variables of Roe, it is a straight forward calculation to find the loadings Fe of the extended variables on the original factors.  This technique was developed by Dwyer (1937) for the case of adding new variables to a factor analysis without doing all the work over again. But, as discussed by Horn (1973) factor extension is also appropriate when one does not want to include the extension variables in the original factor analysis, but does want to see what the loadings would be anyway.
It is sometimes the case that factors are derived from a set of variables (the Fo factor loadings) and we want to see what the loadings of an extended set of variables (Fe) would be. Given the original correlation matrix Ro and the correlation of these original variables with the extension variables of Roe, it is a straight forward calculation to find the loadings Fe of the extended variables on the original factors.  This technique was developed by Dwyer (1937) for the case of adding new variables to a factor analysis without doing all the work over again. But, as discussed by Horn (1973) factor extension is also appropriate when one does not want to include the extension variables in the original factor analysis, but does want to see what the loadings would be anyway.
Path diagram representations have become standard in confirmatory factor analysis, but are not yet common in exploratory factor analysis.  Representing factor structures graphically helps some people understand the structure. 
fa.lookup and lookup are simple helper functions to summarize correlation matrices or factor loading matrices.  bestItems will sort the specified column (criteria) of x on the basis of the (absolute) value of the column.  The return as a default is just the rowname of the variable with those absolute values > cut.   If there is a dictionary of item content and item names, then include the contents as a two column (or more) matrix with rownames corresponding to the item name and then as many fields as desired for item content. (See the example dictionary bfi.dictionary).
See fa and omega for a discussion of factor analysis and of the case of one higher order factor.
See fa and omega for a discussion of factor analysis and of the case of one higher order factor.
The fa.results$loadings are replaced with sorted loadings.
Cattell's “scree" test is one of most simple tests for the number of factors problem.  Horn's (1965) “parallel" analysis is an equally compelling procedure.  Other procedures for determining the most optimal number of factors include finding the Very Simple Structure (VSS) criterion (VSS ) and Velicer's MAP procedure (included in VSS). Both the VSS and the MAP criteria are included in the nfactors function which also reports the  mean item complexity and the BIC for each of multiple solutions.   fa.parallel plots the eigen values for a principal components and the factor solution (minres by default) and does the same for random matrices of the same size as the original data matrix.  For raw data, the random matrices are 1) a matrix of univariate normal data and 2) random samples (randomized across rows) of the original data.
Cattell's “scree" test is one of most simple tests for the number of factors problem.  Horn's (1965) “parallel" analysis is an equally compelling procedure.  Other procedures for determining the most optimal number of factors include finding the Very Simple Structure (VSS) criterion (VSS ) and Velicer's MAP procedure (included in VSS). Both the VSS and the MAP criteria are included in the nfactors function which also reports the  mean item complexity and the BIC for each of multiple solutions.   fa.parallel plots the eigen values for a principal components and the factor solution (minres by default) and does the same for random matrices of the same size as the original data matrix.  For raw data, the random matrices are 1) a matrix of univariate normal data and 2) random samples (randomized across rows) of the original data.
Results of either a factor analysis or cluster analysis are plotted.  Each item is assigned to its highest loading factor, and then identified by variable name as well as cluster (by color). The cluster assignments can be specified to override the automatic clustering by loading.Both of these functions may be called directly or by calling the generic plot function.  (see example).
Please see the writeup for fa for all of the functionality in these older functions.
Factor analysis is an attempt to approximate a correlation or covariance matrix with one of lesser rank.  The basic model is that nRn = nFk kFn' + U2 where k is much less than n. There are many ways to do factor analysis, and maximum likelihood procedures are probably the most commonly preferred (see factanal ).  The existence of uniquenesses is what distinguishes factor analysis from principal components analysis (e.g., principal). If variables are thought to represent a “true" or latent part then factor analysis provides an estimate of the correlations with the latent factor(s) representing the data.  If variables are thought to be measured without error, then principal components provides the most parsimonious description of the data.  
This function is inspired by the wprifm function in the profileR package and the citation there to a paper by Davison, Kim and Close (2009).  The basic logic is to extract a means vector from each subject and then to analyze the resulting ipsatized data matrix.  This can be seen as removing acquiecence in the case of personality items, or the general factor, in the case of ability items.  Factors composed of items that are all keyed the same way (e.g., Neuroticism in the bfi data set) will be most affected by this technique. 
Path diagram representations have become standard in confirmatory factor analysis, but are not yet common in exploratory factor analysis.  Representing factor structures graphically helps some people understand the structure. 
Factor analysis is an attempt to approximate a correlation or covariance matrix with one of lesser rank.  The basic model is that nRn = nFk kFn' + U2 where k is much less than n. There are many ways to do factor analysis, and maximum likelihood procedures are probably the most commonly preferred (see factanal ).  The existence of uniquenesses is what distinguishes factor analysis from principal components analysis (e.g., principal). If variables are thought to represent a “true" or latent part then factor analysis provides an estimate of the correlations with the latent factor(s) representing the data.  If variables are thought to be measured without error, then principal components provides the most parsimonious description of the data.  
The fa.results$loadings are replaced with sorted loadings.
Combines the goodness of fit tests used in fa and principal into one function.  If the matrix is singular, will smooth the correlation matrix before finding the fit functions. Now will find the RMSEA (root mean square error of approximation) and the alpha confidence intervals similar to a SEM function.  Also reports the root mean square residual.
irt.fa combines several functions into one to make the process of item response analysis easier.  Correlations are found using either tetrachoric or polychoric.  Exploratory factor analyeses with all the normal options are then done using fa.  The results are then organized to be reported in terms of IRT parameters (difficulties and discriminations) as well as the more conventional factor analysis output. In addition, because the correlation step is somewhat slow, reanalyses may be done using the correlation matrix found in the first step.  In this case, if it is desired to use the fm="minchi" factoring method, the number of observations needs to be specified as the matrix resulting from pairwiseCount.
Multilevel data are endemic in psychological research. In multilevel data, observations are taken on subjects who are nested within some higher level grouping variable.  The data might be experimental (participants are nested within experimental conditions) or observational (students are nested within classrooms, students are nested within college majors.) To analyze this type of data, one uses random effects models or mixed effect models, or more generally, multilevel models.  There are at least two very powerful packages (nlme and multilevel) which allow for complex analysis of hierarchical (multilevel) data structures.  statsBy is a much simpler function to give some of the basic descriptive statistics for two level models.  It is meant to supplement true multilevel modeling.
Factor analysis is an attempt to approximate a correlation or covariance matrix with one of lesser rank.  The basic model is that nRn = nFk kFn' + U2 where k is much less than n. There are many ways to do factor analysis, and maximum likelihood procedures are probably the most commonly preferred (see factanal ).  The existence of uniquenesses is what distinguishes factor analysis from principal components analysis (e.g., principal). If variables are thought to represent a “true" or latent part then factor analysis provides an estimate of the correlations with the latent factor(s) representing the data.  If variables are thought to be measured without error, then principal components provides the most parsimonious description of the data.  
The factor correlations are found using the approach discussed by Gorsuch (1983) and uses the weights matrices found by w=S R^{-1} and r = w' R w where S is the structure matrix and is   s= F Φ.  The resulting correlations may be  adjusted for the factor score variances (the diagonal of r) (the default). 
Find the coefficient of factor congruence between two sets of factor loadings. 
There are probably as many fit indices as there are psychometricians.  This fit is a plausible estimate of the amount of reduction in a correlation matrix given a factor model.  Note that it is sensitive to the size of the original correlations.  That is, if the residuals are small but the original correlations are small, that is a bad fit. 
Please see the writeup for fa for all of the functionality in these older functions.
NA
Please see the writeup for fa for all of the functionality in these older functions.
Results of either a factor analysis or cluster analysis are plotted.  Each item is assigned to its highest loading factor, and then identified by variable name as well as cluster (by color). The cluster assignments can be specified to override the automatic clustering by loading.Both of these functions may be called directly or by calling the generic plot function.  (see example).
The basic factor equation is nRn = nFk kFn' + U2. Residuals are just  R* = R - F'F. The residuals should be (but in practice probably rarely are) examined to understand the adequacy of the factor analysis.  When doing Factor analysis or Principal Components analysis, one usually continues to extract factors/components until the residuals do not differ from those expected from a random matrix.
Partly meant as a demonstration of how rotation works, factor.rotate is useful for those cases that require specific rotations that are not available in more advanced packages such as GPArotation.  If the plot option is set to TRUE, then the original axes are shown as dashed lines.
Although the factor analysis model is defined at the structural level, it is undefined at the data level.  This is a well known but little discussed problem with factor analysis.  
Combines the goodness of fit tests used in fa and principal into one function.  If the matrix is singular, will smooth the correlation matrix before finding the fit functions. Now will find the RMSEA (root mean square error of approximation) and the alpha confidence intervals similar to a SEM function.  Also reports the root mean square residual.
Please see the writeup for fa for all of the functionality in these older functions.
A factor/principal components analysis loading matrix is converted to a cluster (-1,0,1) definition matrix where each item is assigned to one and only one cluster.  This is a fast way to extract items that will be unit weighted to form cluster composites.  Use this function in combination with cluster.cor to find the corrleations of these composite scores. 
The two most useful of these  functions is probably biquartimin which implements the oblique bifactor rotation introduced by Jennrich and Bentler (2011). The second is TargetQ which allows for missing NA values in the target. Next best is the orthogonal case, bifactor.  None of these seem to be implemented in GPArotation (yet). 
Nguyen and Waller review the problem of local minima in factor analysis.  This is a problem for all rotation algorithms, but is more so for some.  faRotate generates n.rotations different starting values and then applies the specified rotation to the original loadings using multiple start values.  Hyperplane counts and complexity indices are reported for each starting matrix, and the one with the highest hyoerplane count and the lowest complexity is returned.
NA
NA
The basic formula input given as DV1 + DV2 ~ IV1 + IV2 + (IV3) + I(IV4^2) - IV5 will be parsed to return 2 DVs (1 and 2), two normal IVs (1 and 2), a mediator (IV3) a quadratic (IV4) and a variable to be partialed (IV5). See the various examples in setCor and mediate.
lowerCor prints out the lower off diagonal matrix rounded to digits with column names abbreviated to digits + 3 characters, but also returns the full and unrounded matrix.  By default, it uses pairwise deletion of variables.  It in turn calls
NA
The reaction of women to women who protest discriminatory treatment was examined in an experiment reported by Garcia et al. (2010). 129 women  were given a description of sex discrimination in the workplace (a male lawyer was promoted over a clearly more qualified female lawyer).  Subjects then read that the target lawyer felt that the decision was unfair.  Subjects were then randomly assigned to three conditions: Control (no protest), Individual Protest (“They are treating me unfairly") , or Collective Protest (“The firm is is treating women unfairly"). 
Useful for teaching how to write functions, also useful for showing the different ways of estimating central tendency. 
Surprisingly, more than a century after Spearman (1904) introduced the concept of reliability to psychologists, there are still multiple approaches for measuring it. Although very popular, Cronbach's α  (1951) underestimates the reliability of a test and over estimates the first factor saturation. Using splitHalf for tests with 16 or fewer items, all possible splits may be found fairly easily.  For tests with 17 or more items, n.sample splits are randomly found. Thus, for 16 or fewer items, the upper and lower bounds are precise.  For 17 or more items, they are close but will probably slightly underestimate the highest and overestimate the lowest reliabilities.  
If C is a p * p-covariance matrix, v = diag(C) its diagonal (i. e. the vector of variances v_i = c_{ii}), C0 = C - Diag(v) is the covariance matrix with 0s substituted in the diagonal and x = the vector (x1, . . . , xp) the educational testing problem is (see e. g., Al-Homidan 2008)
Surprisingly, more than a century after Spearman (1904) introduced the concept of reliability to psychologists, there are still multiple approaches for measuring it. Although very popular, Cronbach's α  (1951) underestimates the reliability of a test and over estimates the first factor saturation. Using splitHalf for tests with 16 or fewer items, all possible splits may be found fairly easily.  For tests with 17 or more items, n.sample splits are randomly found. Thus, for 16 or fewer items, the upper and lower bounds are precise.  For 17 or more items, they are close but will probably slightly underestimate the highest and overestimate the lowest reliabilities.  
Generalizability theory is the application of a components of variance approach to the analysis of reliability.  Given a G study (generalizability) the components are estimated and then may be used in a D study (Decision).  Different ratios are formed as appropriate for the particular D study.
Gorsuc (1997) suggested an alternative model for factor extension.  His method is appropriate for the case of repeated variables.  This is handled in link{fa.extension} with correct=FALSE
Surprisingly, more than a century after Spearman (1904) introduced the concept of reliability to psychologists, there are still multiple approaches for measuring it. Although very popular, Cronbach's α  (1951) underestimates the reliability of a test and over estimates the first factor saturation. Using splitHalf for tests with 16 or fewer items, all possible splits may be found fairly easily.  For tests with 17 or more items, n.sample splits are randomly found. Thus, for 16 or fewer items, the upper and lower bounds are precise.  For 17 or more items, they are close but will probably slightly underestimate the highest and overestimate the lowest reliabilities.  
 Harman.Holzinger: 9 x 9 correlation matrix of ability tests, N = 696.
 Harman.Holzinger: 9 x 9 correlation matrix of ability tests, N = 696.
 Harman.Holzinger: 9 x 9 correlation matrix of ability tests, N = 696.
 Harman.Holzinger: 9 x 9 correlation matrix of ability tests, N = 696.
 Harman.Holzinger: 9 x 9 correlation matrix of ability tests, N = 696.
Included as an example for teaching about functions. As well as for a discussion of how to estimate central tendencies.Also used in statsBy to weight by the harmonic mean.
NA
NA
Path diagram representations have become standard in confirmatory factor analysis, but are not yet common in exploratory factor analysis.  Representing factor structures graphically helps some people understand the structure. 
This allows for quick summaries of multiple distributions.  Particularly useful when examining the results of multiple-split halves that come from the reliability function.  
Holzinger and Swineford (1937) introduced the bifactor model (one general factor and several group factors) for mental abilities.  This is a nice demonstration data set of a hierarchical factor structure that can be analyzed using the omega function or using sem. The bifactor model is typically used in measures of cognitive ability.
Holzinger and Swineford (1937) introduced the bifactor model (one general factor and several group factors) for mental abilities.  This is a nice demonstration data set of a hierarchical factor structure that can be analyzed using the omega function or using sem. The bifactor model is typically used in measures of cognitive ability.
Shrout and Fleiss (1979) consider six cases of reliability of ratings done by k raters on n targets. McGraw and Wong (1996) consider 10, 6 of which are identical to Shrout and Fleiss and  4 are conceptually different but use the same equations as the 6 in Shrout and Fleiss. 
 Extensive documentation and justification of the algorithm is available in the original MBR 1979 https://personality-project.org/revelle/publications/iclust.pdf paper.  Further discussion of the algorithm and sample output is available on the personality-project.org web page: https://personality-project.org/r/r.ICLUST.html 
 Extensive documentation and justification of the algorithm is available in the original MBR 1979 https://personality-project.org/revelle/publications/iclust.pdf paper.  Further discussion of the algorithm and sample output is available on the personality-project.org web page: https://personality-project.org/r/r.ICLUST.html 
See ICLUST
iclust.diagram provides most of the power of ICLUST.rgraph without the difficulties involved in installing Rgraphviz.  It is called automatically from ICLUST. 
Will create (or overwrite) an output file and print out the dot code to show a cluster structure. This dot file may be imported directly into a dot viewer (e.g.,  https://www.graphviz.org/).  The "dot" language is a powerful graphic description language that is particulary appropriate for viewing cluster output.  Commercial graphics programs (e.g., OmniGraffle) can also read (and clean up) dot files.  
Will create (or overwrite) an output file and print out the dot code to show a cluster structure. This dot file may be imported directly into a dot viewer (e.g.,  https://www.graphviz.org/).  The "dot" language is a powerful graphic description language that is particulary appropriate for viewing cluster output.  Commercial graphics programs (e.g., OmniGraffle) can also read (and clean up) dot files.  
When interpreting cluster or factor analysis outputs, is is useful to group the items in terms of which items have their biggest loading on each factor/cluster and then to sort the items by size of the absolute factor loading.
When interpreting cluster or factor analysis outputs, is is useful to group the items in terms of which items have their biggest loading on each factor/cluster and then to sort the items by size of the absolute factor loading.
Factor analysis as implemented in fa attempts to  summarize the covariance (correlational) structure of a set of variables with a small set of latent variables or “factors".  This solution may be ‘extended’ into a larger space with more variables without changing the original solution (see fa.extension.  Similarly,  the factors of a second set of variables  (the Y set) may be extended into the original (X ) set.  Doing so allows two independent measurement models, a measurement model for X and a measurement model for Y.  These two sets of latent variables may then be correlated  for an Exploratory Structural Equation Model.  (This is exploratory because it is based upon exploratory factor analysis (EFA) rather than a confirmatory factor model (CFA) using more traditional Structural Equation Modeling packages such as sem, lavaan, or Mx.)
If the total number of responses is N, with median, M, and the number of responses at the median value, Nm >1, and Nb= the number of responses less than the median,  then with the assumption that the responses are distributed uniformly within the category,  the interpolated median is M - .5w + w*(N/2 - Nb)/Nm. 
If the total number of responses is N, with median, M, and the number of responses at the median value, Nm >1, and Nb= the number of responses less than the median,  then with the assumption that the responses are distributed uniformly within the category,  the interpolated median is M - .5w + w*(N/2 - Nb)/Nm. 
If the total number of responses is N, with median, M, and the number of responses at the median value, Nm >1, and Nb= the number of responses less than the median,  then with the assumption that the responses are distributed uniformly within the category,  the interpolated median is M - .5w + w*(N/2 - Nb)/Nm. 
If the total number of responses is N, with median, M, and the number of responses at the median value, Nm >1, and Nb= the number of responses less than the median,  then with the assumption that the responses are distributed uniformly within the category,  the interpolated median is M - .5w + w*(N/2 - Nb)/Nm. 
If the total number of responses is N, with median, M, and the number of responses at the median value, Nm >1, and Nb= the number of responses less than the median,  then with the assumption that the responses are distributed uniformly within the category,  the interpolated median is M - .5w + w*(N/2 - Nb)/Nm. 
If the total number of responses is N, with median, M, and the number of responses at the median value, Nm >1, and Nb= the number of responses less than the median,  then with the assumption that the responses are distributed uniformly within the category,  the interpolated median is M - .5w + w*(N/2 - Nb)/Nm. 
If the total number of responses is N, with median, M, and the number of responses at the median value, Nm >1, and Nb= the number of responses less than the median,  then with the assumption that the responses are distributed uniformly within the category,  the interpolated median is M - .5w + w*(N/2 - Nb)/Nm. 
If the total number of responses is N, with median, M, and the number of responses at the median value, Nm >1, and Nb= the number of responses less than the median,  then with the assumption that the responses are distributed uniformly within the category,  the interpolated median is M - .5w + w*(N/2 - Nb)/Nm. 
A very preliminary IRT estimation procedure.Given scores xij for ith individual on jth item Classical Test Theory ignores item difficulty and defines ability as expected score : abilityi = theta(i) = x(i.)A zero parameter model rescales these mean scores from 0 to 1 to a quasi logistic scale ranging from - 4 to 4This is merely a non-linear transform of the raw data to reflect a logistic mapping.
A very preliminary IRT estimation procedure.Given scores xij for ith individual on jth item Classical Test Theory ignores item difficulty and defines ability as expected score : abilityi = theta(i) = x(i.)A zero parameter model rescales these mean scores from 0 to 1 to a quasi logistic scale ranging from - 4 to 4This is merely a non-linear transform of the raw data to reflect a logistic mapping.
A very preliminary IRT estimation procedure.Given scores xij for ith individual on jth item Classical Test Theory ignores item difficulty and defines ability as expected score : abilityi = theta(i) = x(i.)A zero parameter model rescales these mean scores from 0 to 1 to a quasi logistic scale ranging from - 4 to 4This is merely a non-linear transform of the raw data to reflect a logistic mapping.
Item Response Theory (aka "The new psychometrics") models individual responses to items with a logistic function and an individual (theta) and item difficulty (diff) parameter.
irt.fa combines several functions into one to make the process of item response analysis easier.  Correlations are found using either tetrachoric or polychoric.  Exploratory factor analyeses with all the normal options are then done using fa.  The results are then organized to be reported in terms of IRT parameters (difficulties and discriminations) as well as the more conventional factor analysis output. In addition, because the correlation step is somewhat slow, reanalyses may be done using the correlation matrix found in the first step.  In this case, if it is desired to use the fm="minchi" factoring method, the number of observations needs to be specified as the matrix resulting from pairwiseCount.
Item Response Theory (aka "The new psychometrics") models individual responses to items with a logistic function and an individual (theta) and item difficulty (diff) parameter.
A very preliminary IRT estimation procedure.Given scores xij for ith individual on jth item Classical Test Theory ignores item difficulty and defines ability as expected score : abilityi = theta(i) = x(i.)A zero parameter model rescales these mean scores from 0 to 1 to a quasi logistic scale ranging from - 4 to 4This is merely a non-linear transform of the raw data to reflect a logistic mapping.
This function is a convenient way to analyze the quality of item alternatives in a multiple choice ability test.  The typical use is to first score the test (using, e.g., score.multiple.choice according to some scoring key and to then find the score.irt based scores.  Response frequencies for each alternative are then plotted against total score.  An ideal item is one in which just one alternative (the correct one) has a monotonically increasing response probability.
Although there are more elegant ways of finding subject scores given a set of item locations (difficulties) and discriminations, simply finding that value of theta θ that best fits the equation P(x|θ) = 1/(1+exp(β(δ - θ) ) for a score vector X, and location δ and discrimination β provides more information than just total scores.  With complete data, total scores and irt estimates are almost perfectly correlated.  However, the irt estimates provide much more information in the case of missing data.
irt.fa combines several functions into one to make the process of item response analysis easier.  Correlations are found using either tetrachoric or polychoric.  Exploratory factor analyeses with all the normal options are then done using fa.  The results are then organized to be reported in terms of IRT parameters (difficulties and discriminations) as well as the more conventional factor analysis output. In addition, because the correlation step is somewhat slow, reanalyses may be done using the correlation matrix found in the first step.  In this case, if it is desired to use the fm="minchi" factoring method, the number of observations needs to be specified as the matrix resulting from pairwiseCount.
Although there are more elegant ways of finding subject scores given a set of item locations (difficulties) and discriminations, simply finding that value of theta θ that best fits the equation P(x|θ) = 1/(1+exp(β(δ - θ) ) for a score vector X, and location δ and discrimination β provides more information than just total scores.  With complete data, total scores and irt estimates are almost perfectly correlated.  However, the irt estimates provide much more information in the case of missing data.
Although there are more elegant ways of finding subject scores given a set of item locations (difficulties) and discriminations, simply finding that value of theta θ that best fits the equation P(x|θ) = 1/(1+exp(β(δ - θ) ) for a score vector X, and location δ and discrimination β provides more information than just total scores.  With complete data, total scores and irt estimates are almost perfectly correlated.  However, the irt estimates provide much more information in the case of missing data.
lowerCor prints out the lower off diagonal matrix rounded to digits with column names abbreviated to digits + 3 characters, but also returns the full and unrounded matrix.  By default, it uses pairwise deletion of variables.  It in turn calls
lowerCor prints out the lower off diagonal matrix rounded to digits with column names abbreviated to digits + 3 characters, but also returns the full and unrounded matrix.  By default, it uses pairwise deletion of variables.  It in turn calls
This simulation was originally developed to compare the effect of skew on the measurement of affect (see Rafaeli and Revelle, 2005).  It has been extended to allow for a general simulation of affect or personality items with either a simple structure or a circumplex structure.  Items can be continuous normally distributed, or broken down into n categories (e.g, -2, -1, 0, 1, 2).  Items can be distorted by limiting them to these ranges, even though the items have a mean of (e.g., 1).  
fa.lookup and lookup are simple helper functions to summarize correlation matrices or factor loading matrices.  bestItems will sort the specified column (criteria) of x on the basis of the (absolute) value of the column.  The return as a default is just the rowname of the variable with those absolute values > cut.   If there is a dictionary of item content and item names, then include the contents as a two column (or more) matrix with rownames corresponding to the item name and then as many fields as desired for item content. (See the example dictionary bfi.dictionary).
This simulation was originally developed to compare the effect of skew on the measurement of affect (see Rafaeli and Revelle, 2005).  It has been extended to allow for a general simulation of affect or personality items with either a simple structure or a circumplex structure.  Items can be continuous normally distributed, or broken down into n categories (e.g, -2, -1, 0, 1, 2).  Items can be distorted by limiting them to these ranges, even though the items have a mean of (e.g., 1).  
When predicting criteria from a set of items formed into scales, the validity of the scale (that is, the correlations of the scale with each criteria) is a function of the average item validity (r_y), the average intercorrelation of the items in the scale (r_x), and the number of items in the scale (n).  The limit of validity is r_y/sqrt(r_x).  
Best results if called from an unrotated solution.  Repeated calls using a rotated solution will produce incorrect estimates of the correlations between the factors.
fa.lookup and lookup are simple helper functions to summarize correlation matrices or factor loading matrices.  bestItems will sort the specified column (criteria) of x on the basis of the (absolute) value of the column.  The return as a default is just the rowname of the variable with those absolute values > cut.   If there is a dictionary of item content and item names, then include the contents as a two column (or more) matrix with rownames corresponding to the item name and then as many fields as desired for item content. (See the example dictionary bfi.dictionary).
The easiest way to prepare keys for scoreItems, scoreOverlap, scoreIrt.1pl, or scoreIrt.2pl  is to specify a keys.list.  This is just a list specifying the name of the scales to be scores and the direction of the items to be used.
Items used in measuring ability or other aspects of personality are typically not very reliable.  One suggestion has been to form items into homogeneous item composites (HICs), Factorially Homogeneous Item Dimensions (FHIDs) or mini scales (parcels).  Parcelling may be done rationally, factorially, or empirically based upon the structure of the correlation/covariance matrix.  link{parcels} facilitates the finding of parcels by forming a keys matrix suitable for using in score.items.  These keys represent the n/2 most similar pairs or the n/3 most similar triplets.
Let  S^2 = diag(R^{-1})^{-1}  and Q = SR^{-1}S.  Then Q is said to  be the anti-image intercorrelation matrix.  Let sumr2 = ∑{R^2} and sumq2 = ∑{Q^2} for all off diagonal elements of R and Q, then  SMA=sumr2/(sumr2 + sumq2).  Although originally MSA was 1 - sumq2/sumr2  (Kaiser, 1970), this was modified in Kaiser and Rice, (1974) to be   SMA=sumr2/(sumr2 + sumq2).  This is the formula used by Dziuban and Shirkey (1974) and by SPSS.
given a matrix or data.frame x, find the skew or kurtosis for each column (for skew and kurtosis) or the multivariate skew and kurtosis in the case of mardia.
The recommended function is structure.diagram which does not use Rgraphviz but which does not produce dot code either.  
lowerCor prints out the lower off diagonal matrix rounded to digits with column names abbreviated to digits + 3 characters, but also returns the full and unrounded matrix.  By default, it uses pairwise deletion of variables.  It in turn calls
These three functions are provided as simple helper functions for demonstrations of Item Response Theory. The one parameter logistic (1PL) model is also known as the Rasch model.  It assumes items differ only in difficulty.1PL, 2PL, 3PL and 4PL curves may be drawn by choosing the appropriate d (delta or item difficulty), a (discrimination or slope), c (gamma or  guessing) and z (zeta or upper asymptote).
These three functions are provided as simple helper functions for demonstrations of Item Response Theory. The one parameter logistic (1PL) model is also known as the Rasch model.  It assumes items differ only in difficulty.1PL, 2PL, 3PL and 4PL curves may be drawn by choosing the appropriate d (delta or item difficulty), a (discrimination or slope), c (gamma or  guessing) and z (zeta or upper asymptote).
These three functions are provided as simple helper functions for demonstrations of Item Response Theory. The one parameter logistic (1PL) model is also known as the Rasch model.  It assumes items differ only in difficulty.1PL, 2PL, 3PL and 4PL curves may be drawn by choosing the appropriate d (delta or item difficulty), a (discrimination or slope), c (gamma or  guessing) and z (zeta or upper asymptote).
fa.lookup and lookup are simple helper functions to summarize correlation matrices or factor loading matrices.  bestItems will sort the specified column (criteria) of x on the basis of the (absolute) value of the column.  The return as a default is just the rowname of the variable with those absolute values > cut.   If there is a dictionary of item content and item names, then include the contents as a two column (or more) matrix with rownames corresponding to the item name and then as many fields as desired for item content. (See the example dictionary bfi.dictionary).
fa.lookup and lookup are simple helper functions to summarize correlation matrices or factor loading matrices.  bestItems will sort the specified column (criteria) of x on the basis of the (absolute) value of the column.  The return as a default is just the rowname of the variable with those absolute values > cut.   If there is a dictionary of item content and item names, then include the contents as a two column (or more) matrix with rownames corresponding to the item name and then as many fields as desired for item content. (See the example dictionary bfi.dictionary).
fa.lookup and lookup are simple helper functions to summarize correlation matrices or factor loading matrices.  bestItems will sort the specified column (criteria) of x on the basis of the (absolute) value of the column.  The return as a default is just the rowname of the variable with those absolute values > cut.   If there is a dictionary of item content and item names, then include the contents as a two column (or more) matrix with rownames corresponding to the item name and then as many fields as desired for item content. (See the example dictionary bfi.dictionary).
lowerCor prints out the lower off diagonal matrix rounded to digits with column names abbreviated to digits + 3 characters, but also returns the full and unrounded matrix.  By default, it uses pairwise deletion of variables.  It in turn calls
lowerCor prints out the lower off diagonal matrix rounded to digits with column names abbreviated to digits + 3 characters, but also returns the full and unrounded matrix.  By default, it uses pairwise deletion of variables.  It in turn calls
If just one matrix is provided (i.e., upper is missing), it is decomposed into two square matrices, one equal to the lower off diagonal entries, the other to the upper off diagonal entries. In the normal case two symmetric matrices are provided and combined into one non-symmetric matrix with the lower off diagonals representing the lower matrix and the upper off diagonals representing the upper matrix.
The lsat6 data set is analyzed in the ltm package as well as by McDonald (1999). lsat7 is another 1000 subjects on part 7 of the LSAT. Both sets are described by Bock and Lieberman (1970). Both sets are useful examples of testing out IRT procedures and showing the use of tetrachoric correlations and item factor analysis using the irt.fa function.
The lsat6 data set is analyzed in the ltm package as well as by McDonald (1999). lsat7 is another 1000 subjects on part 7 of the LSAT. Both sets are described by Bock and Lieberman (1970). Both sets are useful examples of testing out IRT procedures and showing the use of tetrachoric correlations and item factor analysis using the irt.fa function.
There are many ways of reporting how two groups differ.  Cohen's d statistic is just the differences of means expressed in terms of the pooled within group standard deviation.  This is insensitive to sample size.  r is the a universal measure of effect size that is a simple function of d, but is bounded -1 to 1.  The t statistic is merely d * sqrt(n)/2 and thus reflects sample size.   
There are many ways of reporting how two groups differ.  Cohen's d statistic is just the differences of means expressed in terms of the pooled within group standard deviation.  This is insensitive to sample size.  r is the a universal measure of effect size that is a simple function of d, but is bounded -1 to 1.  The t statistic is merely d * sqrt(n)/2 and thus reflects sample size.   
When constructing examples for reliability analysis, it is convenient to simulate congeneric data structures.  These are the most simple of item structures, having just one factor. Mainly used for a discussion of reliability theory as well as factor score estimates. 
Many personality and cognitive tests have a hierarchical factor structure.  For demonstration purposes, it is useful to be able to create such matrices, either with population values, or sample values. 
Although there are more elegant ways of finding subject scores given a set of item locations (difficulties) and discriminations, simply finding that value of theta θ that best fits the equation P(x|θ) = 1/(1+exp(β(δ - θ) ) for a score vector X, and location δ and discrimination β provides more information than just total scores.  With complete data, total scores and irt estimates are almost perfectly correlated.  However, the irt estimates provide much more information in the case of missing data.
The easiest way to prepare keys for scoreItems, scoreOverlap, scoreIrt.1pl, or scoreIrt.2pl  is to specify a keys.list.  This is just a list specifying the name of the scales to be scores and the direction of the items to be used.
The easiest way to prepare keys for scoreItems, scoreOverlap, scoreIrt.1pl, or scoreIrt.2pl  is to specify a keys.list.  This is just a list specifying the name of the scales to be scores and the direction of the items to be used.
When exploring the correlations of many items with a few criteria, it is useful to form scales from the most correlated items (see bestScales.  To get a feeling of the distribution of items across various measures, we can display their correlations (or the log of the probabilities) grouped by some set of scale keys. May also be used to display and order correlations (rows) with a criteria (columns) if given a correlation as input (raw=FALSE).
given a matrix or data.frame x, find the skew or kurtosis for each column (for skew and kurtosis) or the multivariate skew and kurtosis in the case of mardia.
Although it is more common to calculate multiple regression and canonical correlations from the raw data, it is,  of course, possible to do so from a matrix of correlations or covariances.  In this case, the input to the function is a square covariance or correlation matrix, as well as the column numbers (or names) of the x (predictor),  y (criterion) variables, and if desired z (covariates). The function will find the correlations if given raw data.
The factor analysis output is sorted by size of the largest  factor loading for each variable  and then the matrix items are organized by those loadings.  The default is to sort by the loadings on the first factor.  Alternatives allow for ordering based upon any vector or matrix. 
Although it is more common to calculate multiple regression and canonical correlations from the raw data, it is,  of course, possible to do so from a matrix of correlations or covariances.  In this case, the input to the function is a square covariance or correlation matrix, as well as the column numbers (or names) of the x (predictor),  y (criterion) variables, and if desired z (covariates). The function will find the correlations if given raw data.
Although it is more common to calculate multiple regression and canonical correlations from the raw data, it is,  of course, possible to do so from a matrix of correlations or covariances.  In this case, the input to the function is a square covariance or correlation matrix, as well as the column numbers (or names) of the x (predictor),  y (criterion) variables, and if desired z (covariates). The function will find the correlations if given raw data.
The factor analysis output is sorted by size of the largest  factor loading for each variable  and then the matrix items are organized by those loadings.  The default is to sort by the loadings on the first factor.  Alternatives allow for ordering based upon any vector or matrix. 
When doing linear modeling, it is frequently convenient to estimate the direct effect of a predictor controlling for the indirect effect of a mediator.  See Preacher and Hayes (2004) for a very thorough discussion of mediation.  The mediate function will do some basic mediation and moderation models, with bootstrapped confidence intervals for the mediation/moderation effects. 
When doing linear modeling, it is frequently convenient to estimate the direct effect of a predictor controlling for the indirect effect of a mediator.  See Preacher and Hayes (2004) for a very thorough discussion of mediation.  The mediate function will do some basic mediation and moderation models, with bootstrapped confidence intervals for the mediation/moderation effects. 
Ellipse dimensions are calculated from the correlation between the x and y variables and are scaled as sqrt(1+r) and sqrt(1-r). They are then scaled as size[1] and size[2] standard deviation units.   To scale  for 95 and 99 percent confidence use c(1.64,2.32)
This function is particularly useful as part of the Synthetic Apeture Personality Assessment (SAPA) (https://www.sapa-project.org/) data sets where continuous variables (age, SAT V, SAT Q, etc) and mixed with polytomous personality items taken from the International Personality Item Pool (IPIP) and the dichotomous experimental IQ items that have been developed as part of SAPA (see, e.g., Revelle, Wilt and Rosenthal, 2010 or Revelle, Dworak and Condon, 2020.).  
This function is particularly useful as part of the Synthetic Apeture Personality Assessment (SAPA) (https://www.sapa-project.org/) data sets where continuous variables (age, SAT V, SAT Q, etc) and mixed with polytomous personality items taken from the International Personality Item Pool (IPIP) and the dichotomous experimental IQ items that have been developed as part of SAPA (see, e.g., Revelle, Wilt and Rosenthal, 2010 or Revelle, Dworak and Condon, 2020.).  
Classical reliabiiity theory estimates the amount of variance in a set of observations due to a true score that varies over subjects.  Generalizability theory extends this model to include other sources of variance, specifically, time.  The classic studies using this approach are people measured over multiple time points with multiple items.  Then the question is, how stable are various individual differences. Intraclass correlations (ICC) are found for each subject over items, and for each subject over time. Alpha reliabilities  are found for each subject for the items across time.   
Classical reliabiiity theory estimates the amount of variance in a set of observations due to a true score that varies over subjects.  Generalizability theory extends this model to include other sources of variance, specifically, time.  The classic studies using this approach are people measured over multiple time points with multiple items.  Then the question is, how stable are various individual differences. Intraclass correlations (ICC) are found for each subject over items, and for each subject over time. Alpha reliabilities  are found for each subject for the items across time.   
Classical reliabiiity theory estimates the amount of variance in a set of observations due to a true score that varies over subjects.  Generalizability theory extends this model to include other sources of variance, specifically, time.  The classic studies using this approach are people measured over multiple time points with multiple items.  Then the question is, how stable are various individual differences. Intraclass correlations (ICC) are found for each subject over items, and for each subject over time. Alpha reliabilities  are found for each subject for the items across time.   
When doing linear modeling, it is frequently convenient to estimate the direct effect of a predictor controlling for the indirect effect of a mediator.  See Preacher and Hayes (2004) for a very thorough discussion of mediation.  The mediate function will do some basic mediation and moderation models, with bootstrapped confidence intervals for the mediation/moderation effects. 
When examining multiple measures within subjects, it is sometimes useful to consider the variability of trial by trial observations in addition to the over all between trial variation.  The Mean Square of Successive Differences (mssd) and root mean square of successive differences (rmssd) is just 
The diagram function calls  fa.diagram, omega.diagram,  ICLUST.diagram, lavaan.diagram or bassAckward.diagram depending upon the class of the fit input.  See those functions for particular parameter values.
The diagram function calls  fa.diagram, omega.diagram,  ICLUST.diagram, lavaan.diagram or bassAckward.diagram depending upon the class of the fit input.  See those functions for particular parameter values.
This allows for quick summaries of multiple distributions.  Particularly useful when examining the results of multiple-split halves that come from the reliability function.  
The diagram function calls  fa.diagram, omega.diagram,  ICLUST.diagram, lavaan.diagram or bassAckward.diagram depending upon the class of the fit input.  See those functions for particular parameter values.
The diagram function calls  fa.diagram, omega.diagram,  ICLUST.diagram, lavaan.diagram or bassAckward.diagram depending upon the class of the fit input.  See those functions for particular parameter values.
Classical reliabiiity theory estimates the amount of variance in a set of observations due to a true score that varies over subjects.  Generalizability theory extends this model to include other sources of variance, specifically, time.  The classic studies using this approach are people measured over multiple time points with multiple items.  Then the question is, how stable are various individual differences. Intraclass correlations (ICC) are found for each subject over items, and for each subject over time. Alpha reliabilities  are found for each subject for the items across time.   
lowerCor prints out the lower off diagonal matrix rounded to digits with column names abbreviated to digits + 3 characters, but also returns the full and unrounded matrix.  By default, it uses pairwise deletion of variables.  It in turn calls
Determining the most interpretable number of factors from a factor analysis is perhaps one of the greatest challenges in factor analysis.  There are many solutions to this problem, none of which is uniformly the best.  "Solving the number of factors problem is easy, I do it everyday before breakfast."  But knowing the right solution is harder. (Horn and Engstrom, 1979) (Henry Kaiser in personal communication with J.L. Horn, as cited by Horn and Engstrom, 1979, MBR p 283).  
“Many scales are assumed by their developers and users to be primarily a measure of one latent variable. When it is also assumed that the scale conforms to the effect indicator model of measurement (as is almost always the case in psychological assessment), it is important to support such an interpretation with evidence regarding the internal structure of that scale. In particular, it is important to examine two related properties pertaining to the internal structure of such a scale. The first property relates to whether all the indicators forming the scale measure a latent variable in common. 
While omega.graph requires the Rgraphviz package, omega.diagram does not.  codeomega requires the GPArotation package.
While omega.graph requires the Rgraphviz package, omega.diagram does not.  codeomega requires the GPArotation package.
“Many scales are assumed by their developers and users to be primarily a measure of one latent variable. When it is also assumed that the scale conforms to the effect indicator model of measurement (as is almost always the case in psychological assessment), it is important to support such an interpretation with evidence regarding the internal structure of that scale. In particular, it is important to examine two related properties pertaining to the internal structure of such a scale. The first property relates to whether all the indicators forming the scale measure a latent variable in common. 
“Many scales are assumed by their developers and users to be primarily a measure of one latent variable. When it is also assumed that the scale conforms to the effect indicator model of measurement (as is almost always the case in psychological assessment), it is important to support such an interpretation with evidence regarding the internal structure of that scale. In particular, it is important to examine two related properties pertaining to the internal structure of such a scale. The first property relates to whether all the indicators forming the scale measure a latent variable in common. 
“Many scales are assumed by their developers and users to be primarily a measure of one latent variable. When it is also assumed that the scale conforms to the effect indicator model of measurement (as is almost always the case in psychological assessment), it is important to support such an interpretation with evidence regarding the internal structure of that scale. In particular, it is important to examine two related properties pertaining to the internal structure of such a scale. The first property relates to whether all the indicators forming the scale measure a latent variable in common. 
“Many scales are assumed by their developers and users to be primarily a measure of one latent variable. When it is also assumed that the scale conforms to the effect indicator model of measurement (as is almost always the case in psychological assessment), it is important to support such an interpretation with evidence regarding the internal structure of that scale. In particular, it is important to examine two related properties pertaining to the internal structure of such a scale. The first property relates to whether all the indicators forming the scale measure a latent variable in common. 
Adapted from the mahalanobis function and help page from stats.
The conventional Null Hypothesis Significance Test (NHST) is the likelihood of observing the data given the null hypothesis of no effect.  But this tells us nothing about the probability of the null hypothesis.  Peter Killeen (2005) introduced the probability of replication as a more useful measure.  The probability of replication is the probability that an exact replication study will find a result in the same direction as the original result.
The conventional Null Hypothesis Significance Test (NHST) is the likelihood of observing the data given the null hypothesis of no effect.  But this tells us nothing about the probability of the null hypothesis.  Peter Killeen (2005) introduced the probability of replication as a more useful measure.  The probability of replication is the probability that an exact replication study will find a result in the same direction as the original result.
The conventional Null Hypothesis Significance Test (NHST) is the likelihood of observing the data given the null hypothesis of no effect.  But this tells us nothing about the probability of the null hypothesis.  Peter Killeen (2005) introduced the probability of replication as a more useful measure.  The probability of replication is the probability that an exact replication study will find a result in the same direction as the original result.
The conventional Null Hypothesis Significance Test (NHST) is the likelihood of observing the data given the null hypothesis of no effect.  But this tells us nothing about the probability of the null hypothesis.  Peter Killeen (2005) introduced the probability of replication as a more useful measure.  The probability of replication is the probability that an exact replication study will find a result in the same direction as the original result.
To find the z of the difference between two independent correlations, first convert them to z scores using the Fisher r-z transform and then find the z of the difference between the two correlations.  The default assumption is that the group sizes are the same, but the test can be done for different size groups by specifying n2.
Shamelessly adapted from the pairs help page.  Uses panel.cor, panel.cor.scale, and panel.hist, all taken from the help pages for pairs. Also adapts the ellipse function from John Fox's car package. 
When using Massively Missing Completely at Random (MMCAR) designs used by the SAPA project, it is important to count the number of pairwise observations (pairwiseCount).  If there are pairs with 1 or fewer observations, these will produce NA values for correlations making subsequent factor analyses fa or reliability analsyes omega or scoreOverlap impossible.
When using Massively Missing Completely at Random (MMCAR) designs used by the SAPA project, it is important to count the number of pairwise observations (pairwiseCount).  If there are pairs with 1 or fewer observations, these will produce NA values for correlations making subsequent factor analyses fa or reliability analsyes omega or scoreOverlap impossible.
When using Massively Missing Completely at Random (MMCAR) designs used by the SAPA project, it is important to count the number of pairwise observations (pairwiseCount).  If there are pairs with 1 or fewer observations, these will produce NA values for correlations making subsequent factor analyses fa or reliability analsyes omega or scoreOverlap impossible.
When using Massively Missing Completely at Random (MMCAR) designs used by the SAPA project, it is important to count the number of pairwise observations (pairwiseCount).  If there are pairs with 1 or fewer observations, these will produce NA values for correlations making subsequent factor analyses fa or reliability analsyes omega or scoreOverlap impossible.
When using Massively Missing Completely at Random (MMCAR) designs used by the SAPA project, it is important to count the number of pairwise observations (pairwiseCount).  If there are pairs with 1 or fewer observations, these will produce NA values for correlations making subsequent factor analyses fa or reliability analsyes omega or scoreOverlap impossible.
When using Massively Missing Completely at Random (MMCAR) designs used by the SAPA project, it is important to count the number of pairwise observations (pairwiseCount).  If there are pairs with 1 or fewer observations, these will produce NA values for correlations making subsequent factor analyses fa or reliability analsyes omega or scoreOverlap impossible.
When using Massively Missing Completely at Random (MMCAR) designs used by the SAPA project, it is important to count the number of pairwise observations (pairwiseCount).  If there are pairs with 1 or fewer observations, these will produce NA values for correlations making subsequent factor analyses fa or reliability analsyes omega or scoreOverlap impossible.
When using Massively Missing Completely at Random (MMCAR) designs used by the SAPA project, it is important to count the number of pairwise observations (pairwiseCount).  If there are pairs with 1 or fewer observations, these will produce NA values for correlations making subsequent factor analyses fa or reliability analsyes omega or scoreOverlap impossible.
Items used in measuring ability or other aspects of personality are typically not very reliable.  One suggestion has been to form items into homogeneous item composites (HICs), Factorially Homogeneous Item Dimensions (FHIDs) or mini scales (parcels).  Parcelling may be done rationally, factorially, or empirically based upon the structure of the correlation/covariance matrix.  link{parcels} facilitates the finding of parcels by forming a keys matrix suitable for using in score.items.  These keys represent the n/2 most similar pairs or the n/3 most similar triplets.
There are two ways to use partial.r.  One is to find the complete partial correlation matrix (that is, partial all the other variables out of each variable).  This may be done by simply specifying the raw data or correlation matrix.  (In the case of raw data, correlations will be found according to use and method.)  In this case, just specify the data matrix. 
Useful for those cases where the correlation matrix is improper (perhaps because of SAPA techniques).
In many prediction situations, a dichotomous predictor (accept/reject) is validated against a dichotomous criterion (success/failure).  Although a polychoric correlation estimates the underlying Pearson correlation as if the predictor and criteria were continuous and bivariate normal variables, and the tetrachoric correlation if both x and y are assumed to dichotomized normal distributions,  the phi coefficient is the Pearson applied to a matrix of 0's and 1s. 
A demonstration of the problem of different base rates on the phi correlation, and how these are partially solved by using the polychoric correlation. Not one of my more interesting demonstrations.  See https://personality-project.org/r/simulating-personality.html and https://personality-project.org/r/r.datageneration.html for better demonstrations of data generation.
This is almost self explanatory.  See the examples.
used to require the mvtnorm package but this has been replaced with mnormt
These functions call Yule2poly,  Yule2phi or phi2poly for each cell of the matrix. See those functions for more details.  See phi.demo for an example.
used to require the mvtnorm package but this has been replaced with mnormt
 The singular value decomposition of a matrix X is UdV where for full rank matrices, d is the vector of eigen values and U and V are the matrices of eigen vectors. The inverse is just U/d.  If the matrix is less than full rank, many of the d values are effectively zero (at the limit of computational accuracy.) Thus, to solve matrix equations with matrices of less than full rank (e.g. the schmid Schmid-Leiman solution), we need to find the generalized inverse. 
Passes the appropriate values to plot.  For plotting the results of irt.fa, there are three options: type = "IIC" (default) will plot the item characteristic respone function.  type = "IIC" will plot the item information function, and type= "test" will plot the test information function.
Passes the appropriate values to plot.  For plotting the results of irt.fa, there are three options: type = "IIC" (default) will plot the item characteristic respone function.  type = "IIC" will plot the item information function, and type= "test" will plot the test information function.
Cattell's “scree" test is one of most simple tests for the number of factors problem.  Horn's (1965) “parallel" analysis is an equally compelling procedure.  Other procedures for determining the most optimal number of factors include finding the Very Simple Structure (VSS) criterion (VSS ) and Velicer's MAP procedure (included in VSS). Both the VSS and the MAP criteria are included in the nfactors function which also reports the  mean item complexity and the BIC for each of multiple solutions.   fa.parallel plots the eigen values for a principal components and the factor solution (minres by default) and does the same for random matrices of the same size as the original data matrix.  For raw data, the random matrices are 1) a matrix of univariate normal data and 2) random samples (randomized across rows) of the original data.
Passes the appropriate values to plot.  For plotting the results of irt.fa, there are three options: type = "IIC" (default) will plot the item characteristic respone function.  type = "IIC" will plot the item information function, and type= "test" will plot the test information function.
reliability is basically just a wrapper for omegah, unidim and splitHalf. Revelle and Condon (2019) recommended reporting at least three reliability statistics for any scale, here we make it easy to do. 
Passes the appropriate values to plot.  For plotting the results of irt.fa, there are three options: type = "IIC" (default) will plot the item characteristic respone function.  type = "IIC" will plot the item information function, and type= "test" will plot the test information function.
Although many uses of factor analysis/cluster analysis assume a simple structure where items have one and only one large loading, some domains such as personality or affect items have a more complex structure and some items have high loadings on two factors.  (These items are said to have complexity 2, see VSS).  By expressing the factor loadings in polar coordinates, this structure is more readily perceived.
Tetrachoric correlations infer a latent Pearson correlation from a two x two table of frequencies with the assumption of bivariate normality.  The estimation procedure is two stage ML.  Cell frequencies for each pair of items are found. In the case of tetrachorics, cells with zero counts are replaced with .5 as a correction for continuity (correct=TRUE). 
Tetrachoric correlations infer a latent Pearson correlation from a two x two table of frequencies with the assumption of bivariate normality.  The estimation procedure is two stage ML.  Cell frequencies for each pair of items are found. In the case of tetrachorics, cells with zero counts are replaced with .5 as a correction for continuity (correct=TRUE). 
Tetrachoric correlations infer a latent Pearson correlation from a two x two table of frequencies with the assumption of bivariate normality.  The estimation procedure is two stage ML.  Cell frequencies for each pair of items are found. In the case of tetrachorics, cells with zero counts are replaced with .5 as a correction for continuity (correct=TRUE). 
Tetrachoric correlations infer a latent Pearson correlation from a two x two table of frequencies with the assumption of bivariate normality.  The estimation procedure is two stage ML.  Cell frequencies for each pair of items are found. In the case of tetrachorics, cells with zero counts are replaced with .5 as a correction for continuity (correct=TRUE). 
NA
When predicting criteria from a set of items formed into scales, the validity of the scale (that is, the correlations of the scale with each criteria) is a function of the average item validity (r_y), the average intercorrelation of the items in the scale (r_x), and the number of items in the scale (n).  The limit of validity is r_y/sqrt(r_x).  
Useful for those cases where the correlation matrix is improper (perhaps because of SAPA techniques).
Most of the psych functions produce too much output.  print.psych and summary.psych use generic methods for printing just the highlights.  To see what else is available,  ask for the structure of the particular object: (str(theobject) ).
The two most useful of these  functions is probably biquartimin which implements the oblique bifactor rotation introduced by Jennrich and Bentler (2011). The second is TargetQ which allows for missing NA values in the target. Next best is the orthogonal case, bifactor.  None of these seem to be implemented in GPArotation (yet). 
lowerCor prints out the lower off diagonal matrix rounded to digits with column names abbreviated to digits + 3 characters, but also returns the full and unrounded matrix.  By default, it uses pairwise deletion of variables.  It in turn calls
The two most useful of these  functions is probably biquartimin which implements the oblique bifactor rotation introduced by Jennrich and Bentler (2011). The second is TargetQ which allows for missing NA values in the target. Next best is the orthogonal case, bifactor.  None of these seem to be implemented in GPArotation (yet). 
Three vignettes (overview.pdf and psych_for_sem.pdf) are useful introductions to the package. They may be found as vignettes in R or may be downloaded from https://personality-project.org/r/psych/intro.pdf https://personality-project.org/r/psych/overview.pdf and https://personality-project.org/r/psych/psych_for_sem.pdf.  In addition, there are a number of "HowTo"s available at https://personality-project.org/r/ 
lowerCor prints out the lower off diagonal matrix rounded to digits with column names abbreviated to digits + 3 characters, but also returns the full and unrounded matrix.  By default, it uses pairwise deletion of variables.  It in turn calls
NA
NA
Depending upon the input, one of four different tests of correlations is done.1) For a sample size n, find the t value for a single correlation where 
NA
NA
There are many ways of reporting how two groups differ.  Cohen's d statistic is just the differences of means expressed in terms of the pooled within group standard deviation.  This is insensitive to sample size.  r is the a universal measure of effect size that is a simple function of d, but is bounded -1 to 1.  The t statistic is merely d * sqrt(n)/2 and thus reflects sample size.   
NA
Displaying multivariate profiles may be done by a series of lines (see, e.g., matplot), by colors (see, e.g., corPlot, or by radar or spider plots. Spiders are particularly suitable for showing data thought to have circumplex structure. 
When participants in a study are selected on one variable, that will reduce the variance of that variable and the resulting correlation.  Thorndike (1949) considered four cases of range restriction.  Others have continued this discussion but have changed the case numbers.  
lowerCor prints out the lower off diagonal matrix rounded to digits with column names abbreviated to digits + 3 characters, but also returns the full and unrounded matrix.  By default, it uses pairwise deletion of variables.  It in turn calls
Holzinger and Swineford (1937) introduced the bifactor model (one general factor and several group factors) for mental abilities.  This is a nice demonstration data set of a hierarchical factor structure that can be analyzed using the omega function or using sem. The bifactor model is typically used in measures of cognitive ability.
reliability is basically just a wrapper for omegah, unidim and splitHalf. Revelle and Condon (2019) recommended reporting at least three reliability statistics for any scale, here we make it easy to do. 
NA
Currently implemented for fa, principal,   omega, irt.fa, and fa.extension. 
Currently implemented for fa, principal,   omega, irt.fa, and fa.extension. 
The process of finding sum or average scores for a set of scales given a larger set of items is a typical problem in applied psychometrics and in psychometric research.  Although the structure of scales can be determined from the item intercorrelations, to find scale means, variances, and do further analyses, it is typical to find scores based upon the sum or the average item score.  For some strange reason, personality scale scores are typically given as totals, but attitude scores as averages.  The default for scoreItems is the average as it would seem to make more sense to report scale scores in the metric of the item.  
The process of finding sum or average scores for a set of scales given a larger set of items is a typical problem in applied psychometrics and in psychometric research.  Although the structure of scales can be determined from the item intercorrelations, to find scale means, variances, and do further analyses, it is typical to find scores based upon the sum or the average item score.  For some strange reason, personality scale scores are typically given as totals, but attitude scores as averages.  The default for scoreItems is the average as it would seem to make more sense to report scale scores in the metric of the item.  
Not a very complicated function, but useful in the case that items need to be reversed prior to using IRT functions from the ltm or eRM packages. Most psych functions do not require reversing prior to analysis, but will do so within the function.
When examining multiple measures within subjects, it is sometimes useful to consider the variability of trial by trial observations in addition to the over all between trial variation.  The Mean Square of Successive Differences (mssd) and root mean square of successive differences (rmssd) is just 
hese items were collected as part of the  SAPA  project  (https://www.sapa-project.org/)to develop online measures of ability (Revelle, Wilt and Rosenthal, 2009).  The score means are higher than national norms suggesting both self selection for people taking on line personality and ability tests and a self reporting bias in scores.
How well does a model fit the data is the classic problem of all of statistics.  One fit statistic for scaling is the just the size of the residual matrix compared to the original estimates. 
Just a straightforward application of layout and barplot, with some tricks taken from pairs.panels.  The various options allow for correlation ellipses (1 and 2 sigma from the mean), lowess smooths, linear fits, density curves on the histograms, and the value of the correlation.  ellipse = TRUE implies smooth = TRUE.  The grid option provides a background grid to the scatterplot.
Just a straightforward application of layout and barplot, with some tricks taken from pairs.panels.  The various options allow for correlation ellipses (1 and 2 sigma from the mean), lowess smooths, linear fits, density curves on the histograms, and the value of the correlation.  ellipse = TRUE implies smooth = TRUE.  The grid option provides a background grid to the scatterplot.
Schmid Leiman orthogonalizations are typical in the ability domain, but are not seen as often in the non-cognitive personality domain.  S-L is one way of finding the loadings of items on the general factor for estimating omega. 
 Two artificial correlation matrices from Schmid and Leiman (1957). One real and one artificial covariance matrices from Chen et al. (2006). 
 Two artificial correlation matrices from Schmid and Leiman (1957). One real and one artificial covariance matrices from Chen et al. (2006). 
This function has been replaced with scoreItems (for multiple scales) and alpha for single scales.
Although there are more elegant ways of finding subject scores given a set of item locations (difficulties) and discriminations, simply finding that value of theta θ that best fits the equation P(x|θ) = 1/(1+exp(β(δ - θ) ) for a score vector X, and location δ and discrimination β provides more information than just total scores.  With complete data, total scores and irt estimates are almost perfectly correlated.  However, the irt estimates provide much more information in the case of missing data.
Although there are more elegant ways of finding subject scores given a set of item locations (difficulties) and discriminations, simply finding that value of theta θ that best fits the equation P(x|θ) = 1/(1+exp(β(δ - θ) ) for a score vector X, and location δ and discrimination β provides more information than just total scores.  With complete data, total scores and irt estimates are almost perfectly correlated.  However, the irt estimates provide much more information in the case of missing data.
Although there are more elegant ways of finding subject scores given a set of item locations (difficulties) and discriminations, simply finding that value of theta θ that best fits the equation P(x|θ) = 1/(1+exp(β(δ - θ) ) for a score vector X, and location δ and discrimination β provides more information than just total scores.  With complete data, total scores and irt estimates are almost perfectly correlated.  However, the irt estimates provide much more information in the case of missing data.
The process of finding sum or average scores for a set of scales given a larger set of items is a typical problem in applied psychometrics and in psychometric research.  Although the structure of scales can be determined from the item intercorrelations, to find scale means, variances, and do further analyses, it is typical to find scores based upon the sum or the average item score.  For some strange reason, personality scale scores are typically given as totals, but attitude scores as averages.  The default for scoreItems is the average as it would seem to make more sense to report scale scores in the metric of the item.  
Basically combines score.items with a conversion from multiple choice to right/wrong.
These  are three of the functions used in the SAPA (https://www.sapa-project.org/) procedures to form synthetic correlation matrices.  Given any correlation matrix of items, it is easy to find the correlation matrix of scales made up of those items. This can also be done from the original data matrix or from the correlation matrix using scoreItems which is probably preferred unless the keys are overlapping.  It is important to remember with SAPA data, that scale correlations should be found from the item correlations, not the raw data.
The process of finding sum or average scores for a set of scales given a larger set of items is a typical problem in applied psychometrics and in psychometric research.  Although the structure of scales can be determined from the item intercorrelations, to find scale means, variances, and do further analyses, it is typical to find scores based upon the sum or the average item score.  For some strange reason, personality scale scores are typically given as totals, but attitude scores as averages.  The default for scoreItems is the average as it would seem to make more sense to report scale scores in the metric of the item.  
Although there are more elegant ways of finding subject scores given a set of item locations (difficulties) and discriminations, simply finding that value of theta θ that best fits the equation P(x|θ) = 1/(1+exp(β(δ - θ) ) for a score vector X, and location δ and discrimination β provides more information than just total scores.  With complete data, total scores and irt estimates are almost perfectly correlated.  However, the irt estimates provide much more information in the case of missing data.
Although there are more elegant ways of finding subject scores given a set of item locations (difficulties) and discriminations, simply finding that value of theta θ that best fits the equation P(x|θ) = 1/(1+exp(β(δ - θ) ) for a score vector X, and location δ and discrimination β provides more information than just total scores.  With complete data, total scores and irt estimates are almost perfectly correlated.  However, the irt estimates provide much more information in the case of missing data.
Although there are more elegant ways of finding subject scores given a set of item locations (difficulties) and discriminations, simply finding that value of theta θ that best fits the equation P(x|θ) = 1/(1+exp(β(δ - θ) ) for a score vector X, and location δ and discrimination β provides more information than just total scores.  With complete data, total scores and irt estimates are almost perfectly correlated.  However, the irt estimates provide much more information in the case of missing data.
The process of finding sum or average scores for a set of scales given a larger set of items is a typical problem in applied psychometrics and in psychometric research.  Although the structure of scales can be determined from the item intercorrelations, to find scale means, variances, and do further analyses, it is typical to find scores based upon the sum or the average item score.  For some strange reason, personality scale scores are typically given as totals, but attitude scores as averages.  The default for scoreItems is the average as it would seem to make more sense to report scale scores in the metric of the item.  
These  are three of the functions used in the SAPA (https://www.sapa-project.org/) procedures to form synthetic correlation matrices.  Given any correlation matrix of items, it is easy to find the correlation matrix of scales made up of those items. This can also be done from the original data matrix or from the correlation matrix using scoreItems which is probably preferred unless the keys are overlapping.  It is important to remember with SAPA data, that scale correlations should be found from the item correlations, not the raw data.
The process of finding sum or average scores for a set of scales given a larger set of items is a typical problem in applied psychometrics and in psychometric research.  Although the structure of scales can be determined from the item intercorrelations, to find scale means, variances, and do further analyses, it is typical to find scores based upon the sum or the average item score.  For some strange reason, personality scale scores are typically given as totals, but attitude scores as averages.  The default for scoreItems is the average as it would seem to make more sense to report scale scores in the metric of the item.  
Although meant for finding correlation weighted scores using the weights from bestScales, it also possible to use alternative weight matrices, such as those returned by the coefficients in lm.   
Among the many ways to choose the optimal number of factors is the scree test.  A better function to show the scree as well as compare it to randomly parallel solutions is found found in fa.parallel
Solves a tedious problem that can be done directly but that is sometimes awkward.  Will either replace specified values with NA or will recode to values within a range.
Finds the standard deviation of a vector, matrix, or data.frame.  Returns NA if no cases.
The easiest way to prepare keys for scoreItems, scoreOverlap, scoreIrt.1pl, or scoreIrt.2pl  is to specify a keys.list.  This is just a list specifying the name of the scales to be scores and the direction of the items to be used.
The recommended function is structure.diagram which does not use Rgraphviz but which does not produce dot code either.  
The recommended function is structure.diagram which does not use Rgraphviz but which does not produce dot code either.  
Although it is more common to calculate multiple regression and canonical correlations from the raw data, it is,  of course, possible to do so from a matrix of correlations or covariances.  In this case, the input to the function is a square covariance or correlation matrix, as well as the column numbers (or names) of the x (predictor),  y (criterion) variables, and if desired z (covariates). The function will find the correlations if given raw data.
Although it is more common to calculate multiple regression and canonical correlations from the raw data, it is,  of course, possible to do so from a matrix of correlations or covariances.  In this case, the input to the function is a square covariance or correlation matrix, as well as the column numbers (or names) of the x (predictor),  y (criterion) variables, and if desired z (covariates). The function will find the correlations if given raw data.
Although it is more common to calculate multiple regression and canonical correlations from the raw data, it is,  of course, possible to do so from a matrix of correlations or covariances.  In this case, the input to the function is a square covariance or correlation matrix, as well as the column numbers (or names) of the x (predictor),  y (criterion) variables, and if desired z (covariates). The function will find the correlations if given raw data.
fa.lookup and lookup are simple helper functions to summarize correlation matrices or factor loading matrices.  bestItems will sort the specified column (criteria) of x on the basis of the (absolute) value of the column.  The return as a default is just the rowname of the variable with those absolute values > cut.   If there is a dictionary of item content and item names, then include the contents as a two column (or more) matrix with rownames corresponding to the item name and then as many fields as desired for item content. (See the example dictionary bfi.dictionary).
lowerCor prints out the lower off diagonal matrix rounded to digits with column names abbreviated to digits + 3 characters, but also returns the full and unrounded matrix.  By default, it uses pairwise deletion of variables.  It in turn calls
Simulation of data structures is a very useful tool in psychometric research and teaching.  By knowing “truth" it is possible to see how well various algorithms can capture it.  For a much longer discussion of the use of simulation in psychometrics, see the accompany vignettes.  
A simple simulation for teaching about ANOVA, regression and reliability.  A variety of demonstrations of the relation between anova and lm can be shown.
Many personality and cognitive tests have a hierarchical factor structure.  For demonstration purposes, it is useful to be able to create such matrices, either with population values, or sample values. 
This simulation was originally developed to compare the effect of skew on the measurement of affect (see Rafaeli and Revelle, 2005).  It has been extended to allow for a general simulation of affect or personality items with either a simple structure or a circumplex structure.  Items can be continuous normally distributed, or broken down into n categories (e.g, -2, -1, 0, 1, 2).  Items can be distorted by limiting them to these ranges, even though the items have a mean of (e.g., 1).  
When constructing examples for reliability analysis, it is convenient to simulate congeneric data structures.  These are the most simple of item structures, having just one factor. Mainly used for a discussion of reliability theory as well as factor score estimates. 
Given the measurement model, fx and the structure model Phi, the model is  f %*% Phi %*%  t(f).   Reliability is f %*% t(f). f φ f' and the reliability for each test is the items communality or just the diag of the model. 
This simulation was originally developed to compare the effect of skew on the measurement of affect (see Rafaeli and Revelle, 2005).  It has been extended to allow for a general simulation of affect or personality items with either a simple structure or a circumplex structure.  Items can be continuous normally distributed, or broken down into n categories (e.g, -2, -1, 0, 1, 2).  Items can be distorted by limiting them to these ranges, even though the items have a mean of (e.g., 1).  
Simulation of data structures is a very useful tool in psychometric research and teaching.  By knowing “truth" it is possible to see how well various algorithms can capture it.  For a much longer discussion of the use of simulation in psychometrics, see the accompany vignettes.  
Many personality and cognitive tests have a hierarchical factor structure.  For demonstration purposes, it is useful to be able to create such matrices, either with population values, or sample values. 
Simulation of data structures is a very useful tool in psychometric research and teaching.  By knowing “truth" it is possible to see how well various algorithms can capture it.  For a much longer discussion of the use of simulation in psychometrics, see the accompany vignettes.  
This simulation was originally developed to compare the effect of skew on the measurement of affect (see Rafaeli and Revelle, 2005).  It has been extended to allow for a general simulation of affect or personality items with either a simple structure or a circumplex structure.  Items can be continuous normally distributed, or broken down into n categories (e.g, -2, -1, 0, 1, 2).  Items can be distorted by limiting them to these ranges, even though the items have a mean of (e.g., 1).  
Simulation of data structures is a very useful tool in psychometric research and teaching.  By knowing “truth" it is possible to see how well various algorithms can capture it.  For a much longer discussion of the use of simulation in psychometrics, see the accompany vignettes.  
The basic concepts of the independence of within group and between group correlations is discussed very clearly by Pedhazur (1997) as well as by Bliese (2009).  sim.multi generates within subject data to model the traditional two level structure of multilevel data.
The basic concepts of the independence of within group and between group correlations is discussed very clearly by Pedhazur (1997) as well as by Bliese (2009).  sim.multi generates within subject data to model the traditional two level structure of multilevel data.
Simulation of data structures is a very useful tool in psychometric research and teaching.  By knowing “truth" it is possible to see how well various algorithms can capture it.  For a much longer discussion of the use of simulation in psychometrics, see the accompany vignettes.  
Simulation of data structures is a very useful tool in psychometric research and teaching.  By knowing “truth" it is possible to see how well various algorithms can capture it.  For a much longer discussion of the use of simulation in psychometrics, see the accompany vignettes.  
Simulation of data structures is a very useful tool in psychometric research and teaching.  By knowing “truth" it is possible to see how well various algorithms can capture it.  For a much longer discussion of the use of simulation in psychometrics, see the accompany vignettes.  
Simulation of data structures is a very useful tool in psychometric research and teaching.  By knowing “truth" it is possible to see how well various algorithms can capture it.  For a much longer discussion of the use of simulation in psychometrics, see the accompany vignettes.  
Simulation of data structures is a very useful tool in psychometric research and teaching.  By knowing “truth" it is possible to see how well various algorithms can capture it.  For a much longer discussion of the use of simulation in psychometrics, see the accompany vignettes.  
Simulation of data structures is a very useful tool in psychometric research and teaching.  By knowing “truth" it is possible to see how well various algorithms can capture it.  For a much longer discussion of the use of simulation in psychometrics, see the accompany vignettes.  
Simulation of data structures is a very useful tool in psychometric research and teaching.  By knowing “truth" it is possible to see how well various algorithms can capture it.  For a much longer discussion of the use of simulation in psychometrics, see the accompany vignettes.  
Simulation of data structures is a very useful tool in psychometric research and teaching.  By knowing “truth" it is possible to see how well various algorithms can capture it.  For a much longer discussion of the use of simulation in psychometrics, see the accompany vignettes.  
Simulation of data structures is a very useful tool in psychometric research and teaching.  By knowing “truth" it is possible to see how well various algorithms can capture it.  For a much longer discussion of the use of simulation in psychometrics, see the accompany vignettes.  
Simulation of data structures is a very useful tool in psychometric research and teaching.  By knowing “truth" it is possible to see how well various algorithms can capture it.  For a much longer discussion of the use of simulation in psychometrics, see the accompany vignettes.  
Simulation of data structures is a very useful tool in psychometric research and teaching.  By knowing “truth" it is possible to see how well various algorithms can capture it.  For a much longer discussion of the use of simulation in psychometrics, see the accompany vignettes.  
Simulation of data structures is a very useful tool in psychometric research and teaching.  By knowing “truth" it is possible to see how well various algorithms can capture it.  For a much longer discussion of the use of simulation in psychometrics, see the accompany vignettes.  
Simulation of data structures is a very useful tool in psychometric research and teaching.  By knowing “truth" it is possible to see how well various algorithms can capture it.  For a much longer discussion of the use of simulation in psychometrics, see the accompany vignettes.  
This simulation was originally developed to compare the effect of skew on the measurement of affect (see Rafaeli and Revelle, 2005).  It has been extended to allow for a general simulation of affect or personality items with either a simple structure or a circumplex structure.  Items can be continuous normally distributed, or broken down into n categories (e.g, -2, -1, 0, 1, 2).  Items can be distorted by limiting them to these ranges, even though the items have a mean of (e.g., 1).  
Given the measurement model, fx and the structure model Phi, the model is  f %*% Phi %*%  t(f).   Reliability is f %*% t(f). f φ f' and the reliability for each test is the items communality or just the diag of the model. 
Given the measurement model, fx and the structure model Phi, the model is  f %*% Phi %*%  t(f).   Reliability is f %*% t(f). f φ f' and the reliability for each test is the items communality or just the diag of the model. 
NA
Given the measurement model, fx and the structure model Phi, the model is  f %*% Phi %*%  t(f).   Reliability is f %*% t(f). f φ f' and the reliability for each test is the items communality or just the diag of the model. 
“A common model for representing psychological data is simple structure (Thurstone, 1947). According to one common interpretation, data are simple structured when items or scales have non-zero factor loadings on one and only one factor (Revelle & Rocklin, 1979). Despite the commonplace application of simple structure, some psychological models are defined by a lack of simple structure. Circumplexes (Guttman, 1954) are one kind of model in which simple structure is lacking.
given a matrix or data.frame x, find the skew or kurtosis for each column (for skew and kurtosis) or the multivariate skew and kurtosis in the case of mardia.
NA
Displaying multivariate profiles may be done by a series of lines (see, e.g., matplot), by colors (see, e.g., corPlot, or by radar or spider plots. Spiders are particularly suitable for showing data thought to have circumplex structure. 
Surprisingly, more than a century after Spearman (1904) introduced the concept of reliability to psychologists, there are still multiple approaches for measuring it. Although very popular, Cronbach's α  (1951) underestimates the reliability of a test and over estimates the first factor saturation. Using splitHalf for tests with 16 or fewer items, all possible splits may be found fairly easily.  For tests with 17 or more items, n.sample splits are randomly found. Thus, for 16 or fewer items, the upper and lower bounds are precise.  For 17 or more items, they are close but will probably slightly underestimate the highest and overestimate the lowest reliabilities.  
Multilevel data are endemic in psychological research. In multilevel data, observations are taken on subjects who are nested within some higher level grouping variable.  The data might be experimental (participants are nested within experimental conditions) or observational (students are nested within classrooms, students are nested within college majors.) To analyze this type of data, one uses random effects models or mixed effect models, or more generally, multilevel models.  There are at least two very powerful packages (nlme and multilevel) which allow for complex analysis of hierarchical (multilevel) data structures.  statsBy is a much simpler function to give some of the basic descriptive statistics for two level models.  It is meant to supplement true multilevel modeling.
Multilevel data are endemic in psychological research. In multilevel data, observations are taken on subjects who are nested within some higher level grouping variable.  The data might be experimental (participants are nested within experimental conditions) or observational (students are nested within classrooms, students are nested within college majors.) To analyze this type of data, one uses random effects models or mixed effect models, or more generally, multilevel models.  There are at least two very powerful packages (nlme and multilevel) which allow for complex analysis of hierarchical (multilevel) data structures.  statsBy is a much simpler function to give some of the basic descriptive statistics for two level models.  It is meant to supplement true multilevel modeling.
Multilevel data are endemic in psychological research. In multilevel data, observations are taken on subjects who are nested within some higher level grouping variable.  The data might be experimental (participants are nested within experimental conditions) or observational (students are nested within classrooms, students are nested within college majors.) To analyze this type of data, one uses random effects models or mixed effect models, or more generally, multilevel models.  There are at least two very powerful packages (nlme and multilevel) which allow for complex analysis of hierarchical (multilevel) data structures.  statsBy is a much simpler function to give some of the basic descriptive statistics for two level models.  It is meant to supplement true multilevel modeling.
The recommended function is structure.diagram which does not use Rgraphviz but which does not produce dot code either.  
The recommended function is structure.diagram which does not use Rgraphviz but which does not produce dot code either.  
This is almost self explanatory.  See the examples.
The recommended function is structure.diagram which does not use Rgraphviz but which does not produce dot code either.  
Most of the psych functions produce too much output.  print.psych and summary.psych use generic methods for printing just the highlights.  To see what else is available,  ask for the structure of the particular object: (str(theobject) ).
Several functions, e.g., sim.structural,structure.graph, make.keys use matrices that can be thought of as formed from a set of submatrices.  In particular, when using make.keys in order to score a set of items (scoreItems or scoreOverlap) or to form specified clusters (cluster.cor), it is convenient to define different sets of scoring keys for different sets of items and to combine these scoring keys into one super key.
Several functions, e.g., sim.structural,structure.graph, make.keys use matrices that can be thought of as formed from a set of submatrices.  In particular, when using make.keys in order to score a set of items (scoreItems or scoreOverlap) or to form specified clusters (cluster.cor), it is convenient to define different sets of scoring keys for different sets of items and to combine these scoring keys into one super key.
Several functions, e.g., sim.structural,structure.graph, make.keys use matrices that can be thought of as formed from a set of submatrices.  In particular, when using make.keys in order to score a set of items (scoreItems or scoreOverlap) or to form specified clusters (cluster.cor), it is convenient to define different sets of scoring keys for different sets of items and to combine these scoring keys into one super key.
There are many ways of reporting how two groups differ.  Cohen's d statistic is just the differences of means expressed in terms of the pooled within group standard deviation.  This is insensitive to sample size.  r is the a universal measure of effect size that is a simple function of d, but is bounded -1 to 1.  The t statistic is merely d * sqrt(n)/2 and thus reflects sample size.   
NA
The original Galton (1888) of heights by cubits (arm length) is in tabular form. To show this as a correlation or as a scatter plot, it is useful to convert the table to a matrix or data frame of two columns.  
The original Galton (1888) of heights by cubits (arm length) is in tabular form. To show this as a correlation or as a scatter plot, it is useful to convert the table to a matrix or data frame of two columns.  
lowerCor prints out the lower off diagonal matrix rounded to digits with column names abbreviated to digits + 3 characters, but also returns the full and unrounded matrix.  By default, it uses pairwise deletion of variables.  It in turn calls
Tal-Or et al. (2010) examined the presumed effect of the media in two experimental studies.  These data are from study 2. '... perceptions regarding the influence of a news story about an expected shortage in sugar were manipulated indirectly, by manipulating the perceived exposure to the news story, and behavioral intentions resulting from the story were consequently measured." (p 801). 
Tal-Or et al. (2010) examined the presumed effect of the media in two experimental studies.  These data are from study 2. '... perceptions regarding the influence of a news story about an expected shortage in sugar were manipulated indirectly, by manipulating the perceived exposure to the news story, and behavioral intentions resulting from the story were consequently measured." (p 801). 
The two most useful of these  functions is probably biquartimin which implements the oblique bifactor rotation introduced by Jennrich and Bentler (2011). The second is TargetQ which allows for missing NA values in the target. Next best is the orthogonal case, bifactor.  None of these seem to be implemented in GPArotation (yet). 
The two most useful of these  functions is probably biquartimin which implements the oblique bifactor rotation introduced by Jennrich and Bentler (2011). The second is TargetQ which allows for missing NA values in the target. Next best is the orthogonal case, bifactor.  None of these seem to be implemented in GPArotation (yet). 
The two most useful of these  functions is probably biquartimin which implements the oblique bifactor rotation introduced by Jennrich and Bentler (2011). The second is TargetQ which allows for missing NA values in the target. Next best is the orthogonal case, bifactor.  None of these seem to be implemented in GPArotation (yet). 
Surprisingly, more than a century after Spearman (1904) introduced the concept of reliability to psychologists, there are still multiple approaches for measuring it. Although very popular, Cronbach's α  (1951) underestimates the reliability of a test and over estimates the first factor saturation. Using splitHalf for tests with 16 or fewer items, all possible splits may be found fairly easily.  For tests with 17 or more items, n.sample splits are randomly found. Thus, for 16 or fewer items, the upper and lower bounds are precise.  For 17 or more items, they are close but will probably slightly underestimate the highest and overestimate the lowest reliabilities.  
lowerCor prints out the lower off diagonal matrix rounded to digits with column names abbreviated to digits + 3 characters, but also returns the full and unrounded matrix.  By default, it uses pairwise deletion of variables.  It in turn calls
n.obs observations (0/1)  on nvar variables are simulated using either a logistic or normal theory model.  Then, a number of different scoring algorithms are applied and shown graphically.  Requires the ltm package to be installed to compare ltm scores.
When modifying the psych package, it is useful to make sure that adding some code does not break something else.  The test.psych function tests the major functions on various standard data sets.  It  also shows off a number of the capabilities of the psych package.
There are many ways of measuring reliability. Test - Retest is one way.  If the time interval is very short (or immediate), this is known as a dependability correlation, if the time interval is longer, a stability coefficient.  In all cases, this is a correlation between two measures at different time points.  Given the multi-level nature of these data, it is possible to find variance components associated with individuals, time, item, and time by item, etc.  This leads to several different estimates of reliability (see multilevel.reliability for a discussion and references).
Tetrachoric correlations infer a latent Pearson correlation from a two x two table of frequencies with the assumption of bivariate normality.  The estimation procedure is two stage ML.  Cell frequencies for each pair of items are found. In the case of tetrachorics, cells with zero counts are replaced with .5 as a correction for continuity (correct=TRUE). 
Louis L. Thurstone was a pioneer in psychometric theory and measurement of attitudes, interests, and abilities.  Among his many contributions was a systematic analysis of the process of comparative judgment (thurstone, 1927).  He considered the case of asking subjects to successively compare pairs of objects. If the same subject does this repeatedly, or if  subjects act as random replicates of each other, their judgments can be thought of as sampled from a normal distribution of underlying (latent) scale  scores for each object, Thurstone  proposed that the comparison between the value of two objects could be represented as representing the differences of the average value for each object compared to the standard deviation of the differences between objects.  The basic model is that each item has a normal distribution of response strength and that choice represents the stronger of the two response strengths.  A justification for the normality assumption is that each decision represents the sum of many independent  inputs and thus, through the central limit theorem, is normally distributed. 
Holzinger and Swineford (1937) introduced the bifactor model (one general factor and several group factors) for mental abilities.  This is a nice demonstration data set of a hierarchical factor structure that can be analyzed using the omega function or using sem. The bifactor model is typically used in measures of cognitive ability.
Holzinger and Swineford (1937) introduced the bifactor model (one general factor and several group factors) for mental abilities.  This is a nice demonstration data set of a hierarchical factor structure that can be analyzed using the omega function or using sem. The bifactor model is typically used in measures of cognitive ability.
Holzinger and Swineford (1937) introduced the bifactor model (one general factor and several group factors) for mental abilities.  This is a nice demonstration data set of a hierarchical factor structure that can be analyzed using the omega function or using sem. The bifactor model is typically used in measures of cognitive ability.
NA
The tr function is used in various matrix operations and is the sum of the diagonal elements of a matrix.
The correlation matrix from Tucker (1958) was used in Tucker and Lewis (1973) for the Tucker-Lewis Index of factoring reliability.
This is set of exploratory indices that are still under development.  A number of test cases suggest that u provides high values when the data are in fact unidimensional, low values when they are not.
The two most useful of these  functions is probably biquartimin which implements the oblique bifactor rotation introduced by Jennrich and Bentler (2011). The second is TargetQ which allows for missing NA values in the target. Next best is the orthogonal case, bifactor.  None of these seem to be implemented in GPArotation (yet). 
The two most useful of these  functions is probably biquartimin which implements the oblique bifactor rotation introduced by Jennrich and Bentler (2011). The second is TargetQ which allows for missing NA values in the target. Next best is the orthogonal case, bifactor.  None of these seem to be implemented in GPArotation (yet). 
The two most useful of these  functions is probably biquartimin which implements the oblique bifactor rotation introduced by Jennrich and Bentler (2011). The second is TargetQ which allows for missing NA values in the target. Next best is the orthogonal case, bifactor.  None of these seem to be implemented in GPArotation (yet). 
The two most useful of these  functions is probably biquartimin which implements the oblique bifactor rotation introduced by Jennrich and Bentler (2011). The second is TargetQ which allows for missing NA values in the target. Next best is the orthogonal case, bifactor.  None of these seem to be implemented in GPArotation (yet). 
Describe the data using a violin plot. Change alpha to modify the shading.  The grp variable may be used to draw separate violin plots for each of multiple groups.
Describe the data using a violin plot. Change alpha to modify the shading.  The grp variable may be used to draw separate violin plots for each of multiple groups.
Determining the most interpretable number of factors from a factor analysis is perhaps one of the greatest challenges in factor analysis.  There are many solutions to this problem, none of which is uniformly the best.  "Solving the number of factors problem is easy, I do it everyday before breakfast."  But knowing the right solution is harder. (Horn and Engstrom, 1979) (Henry Kaiser in personal communication with J.L. Horn, as cited by Horn and Engstrom, 1979, MBR p 283).  
Determining the most interpretable number of factors from a factor analysis is perhaps one of the greatest challenges in factor analysis.  There are many solutions to this problem, none of which is uniformly the best.  "Solving the number of factors problem is easy, I do it everyday before breakfast."  But knowing the right solution is harder. (Horn and Engstrom, 1979) (Henry Kaiser in personal communication with J.L. Horn, as cited by Horn and Engstrom, 1979, MBR p 283).  
NA
Item-factor models differ in their "complexity".  Complexity 1 means that all except the greatest (absolute) loading for an item are ignored. Basically a cluster model (e.g., ICLUST). Complexity 2 implies all except the greatest two, etc.  
Among the many ways to choose the optimal number of factors is the scree test.  A better function to show the scree as well as compare it to randomly parallel solutions is found found in fa.parallel
NA
NA
 Two artificial correlation matrices from Schmid and Leiman (1957). One real and one artificial covariance matrices from Chen et al. (2006). 
Among the many robust estimates of central tendency, some recommend the Winsorized mean.  Rather than just dropping the top and bottom trim percent, these extreme values are replaced with values at the trim and 1- trim quantiles.
Among the many robust estimates of central tendency, some recommend the Winsorized mean.  Rather than just dropping the top and bottom trim percent, these extreme values are replaced with values at the trim and 1- trim quantiles.
Among the many robust estimates of central tendency, some recommend the Winsorized mean.  Rather than just dropping the top and bottom trim percent, these extreme values are replaced with values at the trim and 1- trim quantiles.
Among the many robust estimates of central tendency, some recommend the Winsorized mean.  Rather than just dropping the top and bottom trim percent, these extreme values are replaced with values at the trim and 1- trim quantiles.
Among the many robust estimates of central tendency, some recommend the Winsorized mean.  Rather than just dropping the top and bottom trim percent, these extreme values are replaced with values at the trim and 1- trim quantiles.
Correlations between individuals who belong to different natural groups (based upon e.g., ethnicity, age, gender, college major,or country) reflect an unknown mixture of the pooled correlation within each group as well as the correlation of the means of these groups. These two correlations are independent and do not allow inferences from one level (the group) to the other level (the individual).  This data set shows this independence.  The within group correlations between 9 variables are set to be 1, 0, and -1 while those between groups are also set to be 1, 0, -1.  These two sets of correlations are crossed such that V1, V4, and V7 have within group correlations of 1, as do V2, V5 and V8, and V3, V6 and V9.  V1 has a within group correlation of 0 with V2, V5, and V8, and a -1 within group correlation with V3, V6 and V9.  V1, V2, and V3 share a between group correlation of 1, as do V4, V5 and V6, and V7, V8 and V9.  The first group has a 0 between group correlation with the second and a -1 with the third group.  
When cateogorical judgments are made with two cateories, a measure of relationship is the phi coefficient.  However, some categorical judgments are made using more than two outcomes.  For example, two diagnosticians might be asked to categorize patients three ways (e.g., Personality disorder, Neurosis, Psychosis) or to categorize the stages of a disease.  Just as base rates affect observed cell frequencies in a two by two table, they need to be considered in the n-way table (Cohen, 1960). 
Yule developed two measures of association for two by two tables.  Both are functions of the odds ratio 
Yule developed two measures of association for two by two tables.  Both are functions of the odds ratio 
Yule developed two measures of association for two by two tables.  Both are functions of the odds ratio 
These functions call Yule2poly,  Yule2phi or phi2poly for each cell of the matrix. See those functions for more details.  See phi.demo for an example.
Yule developed two measures of association for two by two tables.  Both are functions of the odds ratio 
These functions call Yule2poly,  Yule2phi or phi2poly for each cell of the matrix. See those functions for more details.  See phi.demo for an example.
Yule developed two measures of association for two by two tables.  Both are functions of the odds ratio 
Yule developed two measures of association for two by two tables.  Both are functions of the odds ratio 
Yule developed two measures of association for two by two tables.  Both are functions of the odds ratio 
For type = "correlation" and "covariance", theestimates are based on the sample covariance. (The lag 0 autocorrelationis fixed at 1 by convention.)
NA
factor.scope is not intended to be called directly by users.
For drop1 methods, a missing scope is taken to be allterms in the model. The hierarchy is respected when considering termsto be added or dropped: all main effects contained in a second-orderinteraction must remain, and so on.
If the functions used to form margins are not commutative the resultdepends on the order in which margins are computed.  Annotationof margins is done via naming the FUN list.
aggregate is a generic function with methods for data framesand time series.
aggregate is a generic function with methods for data framesand time series.
aggregate is a generic function with methods for data framesand time series.
When comparing models fitted by maximum likelihood to the same data,the smaller the AIC or BIC, the better the fit.
Although the main method is for class "lm", alias ismost useful for experimental designs and so is used with fits fromaov.Complete aliasing refers to effects in linear models that cannot be estimatedindependently of the terms which occur earlier in the model and sohave their coefficients omitted from the fit. Partial aliasing refersto effects that can be estimated less precisely because ofcorrelations induced by the design.
NA
Suppose that x and y are independent samples fromdistributions with densities f((t-m)/s)/s and f(t-m),respectively, where m is an unknown nuisance parameter ands, the ratio of scales, is the parameter of interest.  TheAnsari-Bradley test is used for testing the null that s equals1, the two-sided alternative being that s != 1 (thedistributions differ only in variance), and the one-sided alternativesbeing s > 1 (the distribution underlying x has a largervariance, "greater") or s < 1 ("less").
This provides a wrapper to lm for fitting linear models tobalanced or unbalanced experimental designs.
The inputs can contain missing values which are deleted (if na.rmis true, i.e., by default), so at leasttwo complete (x, y) pairs are required (for method =  "linear", one otherwise).  If there are duplicated (tied) xvalues and ties contains a function it is applied to the yvalues for each distinct x value to produce (x,y) pairswith unique x.Useful functions in this context include mean,min, and max.
The inputs can contain missing values which are deleted (if na.rmis true, i.e., by default), so at leasttwo complete (x, y) pairs are required (for method =  "linear", one otherwise).  If there are duplicated (tied) xvalues and ties contains a function it is applied to the yvalues for each distinct x value to produce (x,y) pairswith unique x.Useful functions in this context include mean,min, and max.
For definiteness, note that the AR coefficients have the sign in
For definiteness, note that the AR coefficients have the sign in
For definiteness, note that the AR coefficients have the sign in
ar.ols fits the general AR model to a possibly non-stationaryand/or multivariate system of series x. The resultingunconstrained least squares estimates are consistent, even ifsome of the series are non-stationary and/or co-integrated.For definiteness, note that the AR coefficients have the sign in
For definiteness, note that the AR coefficients have the sign in
Different definitions of ARMA models have different signs for theAR and/or MA coefficients.  The definition used here has
See arima for the precise definition of an ARIMA model.
Different definitions of ARMA models have different signs for theAR and/or MA coefficients. The definition here has
The *chisq() functions now take an optional non-centralityargument, so the *nchisq() functions are no longer needed.
The methods used follow Brockwell & Davis (1991, section 3.3).  Theirequations (3.3.8) are solved for the autocovariances at lags0, …, max(p, q+1),and the remaining autocorrelations are given by a recursive filter.
NA
The dendrogram is directly represented as a nested list where eachcomponent corresponds to a branch of the tree.  Hence, the firstbranch of tree z is z[[1]], the second branch of thecorresponding subtree is z[[1]][[2]], or shorterz[[c(1,2)]], etc..  Each node of the treecarries some information needed for efficient plotting or cutting asattributes, of which only members, height andleaf for leaves are compulsory:
Available distance measures are (written for two vectors x andy):
The models fit by, e.g., the lm and glm functionsare specified in a compact symbolic form.The ~ operator is basic in the formation of such models.An expression of the form y ~ model is interpretedas a specification that the response y is modelledby a linear predictor specified symbolically by model.Such a model consists of a series of terms separatedby + operators.The terms themselves consist of variable and factornames separated by : operators.Such a term is interpreted as the interaction ofall the variables and factors appearing in the term.
Currently there is only support for converting objects ofclass "twins" as produced by the functions diana andagnes from the package cluster.  The default methodthrows an error unless passed an "hclust" object.
NA
The function ts is used to create time-series objects.  Theseare vectors or matrices with class of "ts" (and additionalattributes) which represent data which has been sampled at equispacedpoints in time.  In the matrix case, each column of the matrixdata is assumed to contain a single (univariate) time series.Time series must have at least one observation, and although they neednot be numeric there is very limited support for non-numeric series.
NA
NA
kernel is used to construct a general kernel or named specifickernels.  The modified Daniell kernel halves the end coefficients (asused by S-PLUS).
If x is a list, its elements are taken as the samples or fittedlinear models to be compared for homogeneity of variances.  In thiscase, the elements must either all be numeric data vectors or fittedlinear model objects, g is ignored, and one can simply usebartlett.test(x) to perform the test.  If the samples are notyet contained in a list, use bartlett.test(list(x, ...)).
When comparing models fitted by maximum likelihood to the same data,the smaller the AIC or BIC, the better the fit.
Confidence intervals are obtained by a procedure first given inClopper and Pearson (1934).  This guarantees that the confidence levelis at least conf.level, but in general does not give theshortest-length confidence intervals.
family is a generic function with methods for classes"glm" and "lm" (the latter returning gaussian()).
A biplot is plot which aims to represent both the observations andvariables of a matrix of multivariate data on the same plot. There aremany variations on biplots (see the references) and perhaps the mostwidely used one is implemented by biplot.princomp.The function biplot.default merely provides theunderlying code to plot two sets of variables on the same figure.
These tests are sometimes applied to the residuals from anARMA(p, q) fit, in which case the references suggest a betterapproximation to the null-hypothesis distribution is obtained bysetting fitdf = p+q, provided of course that lag > fitdf.
bw.nrd0 implements a rule-of-thumb forchoosing the bandwidth of a Gaussian kernel density estimator.It defaults to 0.9 times theminimum of the standard deviation and the interquartile range divided by1.34 times the sample size to the negative one-fifth power(= Silverman's ‘rule of thumb’, Silverman (1986, page 48, eqn (3.31)))unless the quartiles coincide when a positive resultwill be guaranteed.
bw.nrd0 implements a rule-of-thumb forchoosing the bandwidth of a Gaussian kernel density estimator.It defaults to 0.9 times theminimum of the standard deviation and the interquartile range divided by1.34 times the sample size to the negative one-fifth power(= Silverman's ‘rule of thumb’, Silverman (1986, page 48, eqn (3.31)))unless the quartiles coincide when a positive resultwill be guaranteed.
bw.nrd0 implements a rule-of-thumb forchoosing the bandwidth of a Gaussian kernel density estimator.It defaults to 0.9 times theminimum of the standard deviation and the interquartile range divided by1.34 times the sample size to the negative one-fifth power(= Silverman's ‘rule of thumb’, Silverman (1986, page 48, eqn (3.31)))unless the quartiles coincide when a positive resultwill be guaranteed.
bw.nrd0 implements a rule-of-thumb forchoosing the bandwidth of a Gaussian kernel density estimator.It defaults to 0.9 times theminimum of the standard deviation and the interquartile range divided by1.34 times the sample size to the negative one-fifth power(= Silverman's ‘rule of thumb’, Silverman (1986, page 48, eqn (3.31)))unless the quartiles coincide when a positive resultwill be guaranteed.
bw.nrd0 implements a rule-of-thumb forchoosing the bandwidth of a Gaussian kernel density estimator.It defaults to 0.9 times theminimum of the standard deviation and the interquartile range divided by1.34 times the sample size to the negative one-fifth power(= Silverman's ‘rule of thumb’, Silverman (1986, page 48, eqn (3.31)))unless the quartiles coincide when a positive resultwill be guaranteed.
For compatibility with S, contr can be treatment,helmert, sum or poly (without quotes) as shorthandfor contr.treatment and so on.
The canonical correlation analysis seeks linear combinations of they variables which are well explained by linear combinationsof the x variables. The relationship is symmetric as‘well explained’ is measured by correlations.
NA
For type = "correlation" and "covariance", theestimates are based on the sample covariance. (The lag 0 autocorrelationis fixed at 1 by convention.)
If x is a matrix with one row or column, or if x is avector and y is not given, then a goodness-of-fit testis performed (x is treated as a one-dimensionalcontingency table).  The entries of x must be non-negativeintegers.  In this case, the hypothesis tested is whether thepopulation probabilities equal those in p, or are all equal ifp is not given.
Multidimensional scaling takes a set of dissimilarities and returns aset of points such that the distances between the points areapproximately equal to the dissimilarities.  (It is a major part ofwhat ecologists call ‘ordination’.)
All object classes which are returned by model fitting functionsshould provide a coef method or use the default one.(Note that the method is for coef and not coefficients.)
All object classes which are returned by model fitting functionsshould provide a coef method or use the default one.(Note that the method is for coef and not coefficients.)
NA
confint is a generic function.  The default method assumesnormality, and needs suitable coef andvcov methods to be available.  The default method can becalled directly for comparison with other methods.
confint is a generic function.  The default method assumesnormality, and needs suitable coef andvcov methods to be available.  The default method can becalled directly for comparison with other methods.
confint is a generic function.  The default method assumesnormality, and needs suitable coef andvcov methods to be available.  The default method can becalled directly for comparison with other methods.
The feasible region is defined by ui %*% theta - ci >= 0. Thestarting value must be in the interior of the feasible region, but theminimum may be on the boundary.
These functions are used for creating contrast matrices for use infitting analysis of variance and regression models.  The columns ofthe resulting matrices contain contrasts which can be used for codinga factor with n levels.  The returned value contains thecomputed contrasts.  If the argument contrasts is FALSEa square indicator matrix (the dummy coding) is returned exceptfor contr.poly (which includes the 0-degree, i.e. constant,polynomial when contrasts = FALSE).
These functions are used for creating contrast matrices for use infitting analysis of variance and regression models.  The columns ofthe resulting matrices contain contrasts which can be used for codinga factor with n levels.  The returned value contains thecomputed contrasts.  If the argument contrasts is FALSEa square indicator matrix (the dummy coding) is returned exceptfor contr.poly (which includes the 0-degree, i.e. constant,polynomial when contrasts = FALSE).
These functions are used for creating contrast matrices for use infitting analysis of variance and regression models.  The columns ofthe resulting matrices contain contrasts which can be used for codinga factor with n levels.  The returned value contains thecomputed contrasts.  If the argument contrasts is FALSEa square indicator matrix (the dummy coding) is returned exceptfor contr.poly (which includes the 0-degree, i.e. constant,polynomial when contrasts = FALSE).
These functions are used for creating contrast matrices for use infitting analysis of variance and regression models.  The columns ofthe resulting matrices contain contrasts which can be used for codinga factor with n levels.  The returned value contains thecomputed contrasts.  If the argument contrasts is FALSEa square indicator matrix (the dummy coding) is returned exceptfor contr.poly (which includes the 0-degree, i.e. constant,polynomial when contrasts = FALSE).
These functions are used for creating contrast matrices for use infitting analysis of variance and regression models.  The columns ofthe resulting matrices contain contrasts which can be used for codinga factor with n levels.  The returned value contains thecomputed contrasts.  If the argument contrasts is FALSEa square indicator matrix (the dummy coding) is returned exceptfor contr.poly (which includes the 0-degree, i.e. constant,polynomial when contrasts = FALSE).
If contrasts are not set for a factor the default functions fromoptions("contrasts") are used.
If contrasts are not set for a factor the default functions fromoptions("contrasts") are used.
The Fast Fourier Transform, fft, is used for efficiency.
The primary high-level function is influence.measures which produces aclass "infl" object tabular display showing the DFBETAS foreach model variable, DFFITS, covariance ratios, Cook's distances andthe diagonal elements of the hat matrix.  Cases which are influentialwith respect to any of these measures are marked with an asterisk.
The cophenetic distance between two observations that have beenclustered is defined to be the intergroup dissimilarity at which thetwo observations are first combined into a single cluster.Note that this distance has many ties and restrictions.
For cov and cor one must either give a matrix ordata frame for x or give both x and y.
The three methods each estimate the association between paired samplesand compute a test of the value being zero.  They use differentmeasures of association, all in the range [-1, 1] with 0indicating no association.  These are sometimes referred to as testsof no correlation, but that term is often confined to thedefault method.
For cov and cor one must either give a matrix ordata frame for x or give both x and y.
By default, method = "unbiased",The covariance matrix is divided by one minus the sum of squares ofthe weights, so if the weights are the default (1/n) the conventionalunbiased estimate of the covariance matrix with divisor (n - 1)is obtained.  This differs from the behaviour in S-PLUS whichcorresponds to method = "ML" and does not divide.
For cov and cor one must either give a matrix ordata frame for x or give both x and y.
The primary high-level function is influence.measures which produces aclass "infl" object tabular display showing the DFBETAS foreach model variable, DFFITS, covariance ratios, Cook's distances andthe diagonal elements of the hat matrix.  Cases which are influentialwith respect to any of these measures are marked with an asterisk.
NA
Cutting trees at a given height is only possible for ultrametric trees(with monotone clustering heights).
These are all generic functions, which will use thetsp attribute of x if it exists. timeand cycle have methods for class ts that coercethe result to that class.
D is modelled after its S namesake for taking simple symbolicderivatives.
The Beta distribution with parameters shape1 = a andshape2 = b has density
The binomial distribution with size = n andprob = p has density
If location or scale are not specified, they assumethe default values of 0 and 1 respectively.
The chi-squared distribution with df= n ≥ 0degrees of freedom has density
The additive model used is:
NA
These are all generic functions, which will use thetsp attribute of x if it exists. timeand cycle have methods for class ts that coercethe result to that class.
NA
The algorithm used in density.default disperses the mass of theempirical distribution function over a regular grid of at least 512points and then uses the fast Fourier transform to convolve thisapproximation with a discretized version of the kernel and then useslinear approximation to evaluate the density at the specified points.
The algorithm used in density.default disperses the mass of theempirical distribution function over a regular grid of at least 512points and then uses the fast Fourier transform to convolve thisapproximation with a discretized version of the kernel and then useslinear approximation to evaluate the density at the specified points.
D is modelled after its S namesake for taking simple symbolicderivatives.
D is modelled after its S namesake for taking simple symbolicderivatives.
This is a generic function which can be used to extract deviances forfitted models.  Consult the individual modeling functions for detailson how to use this function.
If rate is not specified, it assumes the default value of1.
The F distribution with df1 = n1 and df2 =n2 degrees of freedom has density
kernel is used to construct a general kernel or named specifickernels.  The modified Daniell kernel halves the end coefficients (asused by S-PLUS).
This is a generic function which can be used to extract residualdegrees-of-freedom for fitted models.  Consult the individual modelingfunctions for details on how to use this function.
The models fit by, e.g., the lm and glm functionsare specified in a compact symbolic form.The ~ operator is basic in the formation of such models.An expression of the form y ~ model is interpretedas a specification that the response y is modelledby a linear predictor specified symbolically by model.Such a model consists of a series of terms separatedby + operators.The terms themselves consist of variable and factornames separated by : operators.Such a term is interpreted as the interaction ofall the variables and factors appearing in the term.
The primary high-level function is influence.measures which produces aclass "infl" object tabular display showing the DFBETAS foreach model variable, DFFITS, covariance ratios, Cook's distances andthe diagonal elements of the hat matrix.  Cases which are influentialwith respect to any of these measures are marked with an asterisk.
The primary high-level function is influence.measures which produces aclass "infl" object tabular display showing the DFBETAS foreach model variable, DFFITS, covariance ratios, Cook's distances andthe diagonal elements of the hat matrix.  Cases which are influentialwith respect to any of these measures are marked with an asterisk.
The primary high-level function is influence.measures which produces aclass "infl" object tabular display showing the DFBETAS foreach model variable, DFFITS, covariance ratios, Cook's distances andthe diagonal elements of the hat matrix.  Cases which are influentialwith respect to any of these measures are marked with an asterisk.
If scale is omitted, it assumes the default value of 1.
The geometric distribution with prob = p has density
The hypergeometric distribution is used for sampling withoutreplacement.  The density of this distribution with parametersm, n and k (named Np, N-Np, andn, respectively in the reference below, where N := m+n is also usedin other references) is given by
diffinv is a generic function with methods for class "ts"and default for vectors and matrices.
Available distance measures are (written for two vectors x andy):
The log normal distribution has density
If location or scale are omitted, they assume thedefault values of 0 and 1 respectively.
If x is a K-component vector, dmultinom(x, prob)is the probability
The negative binomial distribution with size = n andprob = p has density
If mean or sd are not specified they assume the defaultvalues of 0 and 1, respectively.
The Poisson distribution has density
factor.scope is not intended to be called directly by users.
NA
For drop1 methods, a missing scope is taken to be allterms in the model. The hierarchy is respected when considering termsto be added or dropped: all main effects contained in a second-orderinteraction must remain, and so on.
This distribution is obtained as follows.  Let x be a sample ofsize n from a continuous distribution symmetric about theorigin.  Then the Wilcoxon signed rank statistic is the sum of theranks of the absolute values x[i] for which x[i] ispositive.  This statistic takes values between 0 andn(n+1)/2, and its mean and variance are n(n+1)/4 andn(n+1)(2n+1)/24, respectively.
The t distribution with df = n degrees offreedom has density
A fitted linear model has coefficients for the contrasts of the factorterms, usually one less in number than the number of levels.  Thisfunction re-expresses the coefficients in the original coding; as thecoefficients will have been fitted in the reduced basis, any impliedconstraints (e.g., zero sum for contr.helmert or contr.sum)will be respected.  There will be little point in usingdummy.coef for contr.treatment contrasts, as the missingcoefficients are by definition zero.
A fitted linear model has coefficients for the contrasts of the factorterms, usually one less in number than the number of levels.  Thisfunction re-expresses the coefficients in the original coding; as thecoefficients will have been fitted in the reduced basis, any impliedconstraints (e.g., zero sum for contr.helmert or contr.sum)will be respected.  There will be little point in usingdummy.coef for contr.treatment contrasts, as the missingcoefficients are by definition zero.
If min or max are not specified they assume the defaultvalues of 0 and 1 respectively.
The Weibull distribution with shape parameter a andscale parameter b has density given by
This distribution is obtained as follows.  Let x and ybe two random, independent samples of size m and n.Then the Wilcoxon rank sum statistic is the number of all pairs(x[i], y[j]) for which y[j] is not greater thanx[i].  This statistic takes values between 0 andm * n, and its mean and variance are m * n / 2 andm * n * (m + n + 1) / 12, respectively.
The e.c.d.f. (empirical cumulative distribution function)Fn is a step function with jumps i/n atobservation values, where i is the number of tied observationsat that value.  Missing values are ignored.
Fixed-effect terms in an analysis of variance model with multiple stratamay be estimable in more than one stratum, in which case there is lessthan complete information in each.  The efficiency for a termis the fraction of the maximum possible precision (inverse variance)obtainable by estimating in just that stratum.  Under the assumptionof balance, this is the same for all contrasts involving that term.
For a linear model fitted by lm or aov,the effects are the uncorrelated single-degree-of-freedom valuesobtained by projecting the data onto the successive orthogonalsubspaces generated by the QR decomposition during the fittingprocess. The first r (the rank of the model) are associated withcoefficients and the remainder span the space of residuals (but arenot associated with particular residuals).
Each row of the resulting matrix consists of sequencesx[t], x[t-1], ..., x[t-dimension+1], wheret is the original index of x. If x is a matrix,i.e., x contains more than one variable, then x[t]consists of the tth observation on each variable.
These are generic functions, which will use thetsp attribute of x if it exists.Their default methods decode the start time from the original timeunits, so that for a monthly series 1995.5 is representedas c(1995, 7). For a series of frequency f, timen+i/f is presented as c(n, i+1) (even for i = 0and f = 1).
NA
If na.expand = FALSE then NA values in the extra variableswill be passed to the na.action function used inmodel.  This may result in a shorter data frame (withna.omit) or an error (with na.fail).  Ifna.expand = TRUE the returned data frame will have precisely thesame rows as model.frame(model), but the columns corresponding tothe extra variables may contain NA.
This is a generic function, with methods in base R for classes"aov", "glm" and "lm" as well as for"negbin" (package MASS) and "coxph" and"survreg" (package survival).
The factor analysis model is
factor.scope is not intended to be called directly by users.
family is a generic function with methods for classes"glm" and "lm" (the latter returning gaussian()).
NA
Missing values are allowed in x but not in filter(where they would lead to missing values everywhere in the output).
If x is a matrix, it is taken as a two-dimensional contingencytable, and hence its entries should be nonnegative integers.Otherwise, both x and y must be vectors of the samelength.  Incomplete cases are removed, the vectors are coerced intofactor objects, and the contingency table is computed from these.
NA
NA
NA
If x is a list, its elements are taken as the samples to becompared for homogeneity of variances, and hence have to be numericdata vectors.  In this case, g is ignored, and one can simplyuse fligner.test(x) to perform the test.  If the samples arenot yet contained in a list, use fligner.test(list(x, ...)).
The models fit by, e.g., the lm and glm functionsare specified in a compact symbolic form.The ~ operator is basic in the formation of such models.An expression of the form y ~ model is interpretedas a specification that the response y is modelledby a linear predictor specified symbolically by model.Such a model consists of a series of terms separatedby + operators.The terms themselves consist of variable and factornames separated by : operators.Such a term is interpreted as the interaction ofall the variables and factors appearing in the term.
These are all generic functions, which will use thetsp attribute of x if it exists. timeand cycle have methods for class ts that coercethe result to that class.
friedman.test can be used for analyzing unreplicated completeblock designs (i.e., there is exactly one observation in yfor each combination of levels of groups and blocks)where the normality assumption may be violated.
ftable creates ‘flat’ contingency tables.  Similar to theusual contingency tables, these contain the counts of each combinationof the levels of the variables (factors) involved.  This informationis then re-arranged as a matrix whose rows and columns correspond tounique combinations of the levels of the row and column variables (asspecified by row.vars and col.vars, respectively).  Thecombinations are created by looping over the variables in reverseorder (so that the levels of the left-most variable vary theslowest).  Displaying a contingency table in this flat matrix form(via print.ftable, the print method for objects of class"ftable") is often preferable to showing it as ahigher-dimensional array.
family is a generic function with methods for classes"glm" and "lm" (the latter returning gaussian()).
family is a generic function with methods for classes"glm" and "lm" (the latter returning gaussian()).
Exactly what happens depends on the class and attributes of the objectformula.  If this is an object of fitted-model class such as"lm", the method will either return the saved model frameused when fitting the model (if any, often selected by argumentmodel = TRUE) or pass the call used when fitting on to thedefault method.  The default method itself can cope with ratherstandard model objects such as those of class"lqs" from package MASS if no otherarguments are supplied.
NA
NA
A typical predictor has the form response ~ terms whereresponse is the (numeric) response vector and terms is aseries of terms which specifies a linear predictor forresponse.  For binomial and quasibinomialfamilies the response can also be specified as a factor(when the first level denotes failure and all others success) or as atwo-column matrix with the columns giving the numbers of successes andfailures.  A terms specification of the form first + secondindicates all the terms in first together with all the terms insecond with any duplicates removed.
The control argument of glm is by default passedto the control argument of glm.fit, which usesits elements as arguments to glm.control: the latter providesdefaults and sanity checking.
A typical predictor has the form response ~ terms whereresponse is the (numeric) response vector and terms is aseries of terms which specifies a linear predictor forresponse.  For binomial and quasibinomialfamilies the response can also be specified as a factor(when the first level denotes failure and all others success) or as atwo-column matrix with the columns giving the numbers of successes andfailures.  A terms specification of the form first + secondindicates all the terms in first together with all the terms insecond with any duplicates removed.
The tsp attribute gives the start time in time units,the end time and the frequency (the number of observations per unit oftime, e.g. 12 for a monthly series).
The primary high-level function is influence.measures which produces aclass "infl" object tabular display showing the DFBETAS foreach model variable, DFFITS, covariance ratios, Cook's distances andthe diagonal elements of the hat matrix.  Cases which are influentialwith respect to any of these measures are marked with an asterisk.
The primary high-level function is influence.measures which produces aclass "infl" object tabular display showing the DFBETAS foreach model variable, DFFITS, covariance ratios, Cook's distances andthe diagonal elements of the hat matrix.  Cases which are influentialwith respect to any of these measures are marked with an asterisk.
This function performs a hierarchical cluster analysisusing a set of dissimilarities for the n objects beingclustered.  Initially, each object is assigned to its owncluster and then the algorithm proceeds iteratively,at each stage joining the two most similar clusters,continuing until there is just a single cluster.At each stage distances between clusters are recomputedby the Lance–Williams dissimilarity update formulaaccording to the particular clustering method being used.
If either Rowv or Colv are dendrograms they are honored(and not reordered).  Otherwise, dendrograms are computed asdd <- as.dendrogram(hclustfun(distfun(X))) where X iseither x or t(x).
The additive Holt-Winters prediction function (for time series withperiod length p) is
The influence.measures() and other functions listed inSee Also provide a more user oriented way of computing avariety of regression diagnostics.  These all build onlm.influence.  Note that for GLMs (other than the Gaussianfamily with identity link) these are based on one-step approximationswhich may be inadequate if a case has high influence.
The primary high-level function is influence.measures which produces aclass "infl" object tabular display showing the DFBETAS foreach model variable, DFFITS, covariance ratios, Cook's distances andthe diagonal elements of the hat matrix.  Cases which are influentialwith respect to any of these measures are marked with an asterisk.
Note that arguments after ... must be matched exactly.
By default the levels of x.factor are plotted on the x axis intheir given order, with extra space left at the right for the legend(if specified). If x.factor is an ordered factor and the levelsare numeric, these numeric values are used for the x axis.
family is a generic function with methods for classes"glm" and "lm" (the latter returning gaussian()).
Note that this function computes the quartiles using thequantile function rather than followingTukey's recommendations,i.e., IQR(x) = quantile(x, 3/4) - quantile(x, 1/4).
NA
The dendrogram is directly represented as a nested list where eachcomponent corresponds to a branch of the tree.  Hence, the firstbranch of tree z is z[[1]], the second branch of thecorresponding subtree is z[[1]][[2]], or shorterz[[c(1,2)]], etc..  Each node of the treecarries some information needed for efficient plotting or cutting asattributes, of which only members, height andleaf for leaves are compulsory:
The function ts is used to create time-series objects.  Theseare vectors or matrices with class of "ts" (and additionalattributes) which represent data which has been sampled at equispacedpoints in time.  In the matrix case, each column of the matrixdata is assumed to contain a single (univariate) time series.Time series must have at least one observation, and although they neednot be numeric there is very limited support for non-numeric series.
NA
The function ts is used to create time-series objects.  Theseare vectors or matrices with class of "ts" (and additionalattributes) which represent data which has been sampled at equispacedpoints in time.  In the matrix case, each column of the matrixdata is assumed to contain a single (univariate) time series.Time series must have at least one observation, and although they neednot be numeric there is very limited support for non-numeric series.
kernel is used to construct a general kernel or named specifickernels.  The modified Daniell kernel halves the end coefficients (asused by S-PLUS).
The algorithm determines the convex minorant m(x) of thecumulative data (i.e., cumsum(y)) which is piecewiselinear and the result is m'(x), a step function with levelchanges at locations where the convex m(x) touches thecumulative data polygon and changes slope.as.stepfun() returns a stepfunobject which can be more parsimonious.
These functions work with a general univariate state-space modelwith state vector a, transitions a <- T a + R e,e ~ N(0, kappa Q) and observationequation y = Z'a + eta,eta ~ N(0, kappa h).The likelihood is a profile likelihood after estimation ofkappa.
These functions work with a general univariate state-space modelwith state vector a, transitions a <- T a + R e,e ~ N(0, kappa Q) and observationequation y = Z'a + eta,eta ~ N(0, kappa h).The likelihood is a profile likelihood after estimation ofkappa.
These functions work with a general univariate state-space modelwith state vector a, transitions a <- T a + R e,e ~ N(0, kappa Q) and observationequation y = Z'a + eta,eta ~ N(0, kappa h).The likelihood is a profile likelihood after estimation ofkappa.
These functions work with a general univariate state-space modelwith state vector a, transitions a <- T a + R e,e ~ N(0, kappa Q) and observationequation y = Z'a + eta,eta ~ N(0, kappa h).The likelihood is a profile likelihood after estimation ofkappa.
NA
kernel is used to construct a general kernel or named specifickernels.  The modified Daniell kernel halves the end coefficients (asused by S-PLUS).
The data given by x are clustered by the k-means method,which aims to partition the points into k groups such that thesum of squares from points to the assigned cluster centres is minimized.At the minimum, all cluster centres are at the mean of their Voronoisets (the set of data points which are nearest to the cluster centre).
NA
kruskal.test performs a Kruskal-Wallis rank sum test of thenull that the location parameters of the distribution of xare the same in each group (sample).  The alternative is that theydiffer in at least one.
If y is numeric, a two-sample test of the null hypothesisthat x and y were drawn from the same continuousdistribution is performed.
NA
Vector or matrix arguments x are given a tsp attributevia hasTsp.
If just one plot is produced, this is a conventional plot.  If morethan one plot is to be produced, par(mfrow) and several othergraphics parameters will be set, so it is not (easily) possible to mixsuch lag plots with other plots on the same page.
Cases with missing values are omitted.
Models for lm are specified symbolically.  A typical model hasthe form response ~ terms where response is the (numeric)response vector and terms is a series of terms which specifies alinear predictor for response.  A terms specification of the formfirst + second indicates all the terms in first togetherwith all the terms in second with duplicates removed.  Aspecification of the form first:second indicates the set ofterms obtained by taking the interactions of all terms in firstwith all terms in second.  The specification first*secondindicates the cross of first and second.  This isthe same as first + second + first:second.
NA
The influence.measures() and other functions listed inSee Also provide a more user oriented way of computing avariety of regression diagnostics.  These all build onlm.influence.  Note that for GLMs (other than the Gaussianfamily with identity link) these are based on one-step approximationswhich may be inadequate if a case has high influence.
NA
‘Loadings’ is a term from factor analysis, but becausefactor analysis and principal component analysis (PCA) are oftenconflated in the social science literature, it was used for PCA bySPSS and hence by princomp in S-PLUS to help SPSS users.
Fitting is done locally.  That is, for the fit at point x, thefit is made using points in a neighbourhood of x, weighted bytheir distance from x (with differences in ‘parametric’variables being ignored when computing the distance).  The size of theneighbourhood is controlled by α (set by span orenp.target).  For α < 1, theneighbourhood includes proportion α of the points,and these have tricubic weighting (proportional to (1 - (dist/maxdist)^3)^3).  Forα > 1, all points are used, with the‘maximum distance’ assumed to be α^(1/p)times the actual maximum distance for p explanatory variables.
NA
loess.smooth is an auxiliary function which evaluates theloess smooth at evaluation equally spaced pointscovering the range of x.
logLik is most commonly used for a model fitted by maximumlikelihood, and some uses, e.g. by AIC, assumethis.  So care is needed where other fit criteria have been used, forexample REML (the default for "lme").
The Iterative Proportional Fitting algorithm as presented inHaberman (1972) is used for fitting the model.  At most iteriterations are performed, convergence is taken to occur when themaximum deviation between observed and fitted margins is less thaneps.  All internal computations are done in double precision;there is no limit on the number of factors (the dimension of thetable) in the model.
lowess is defined by a complex algorithm, the Ratfor originalof which (by W. S. Cleveland) can be found in the R sources as file‘src/library/stats/src/lowess.doc’.  Normally a local linear polynomial fit isused, but under some circumstances (see the file) a local constant fitcan be used.  ‘Local’ is defined by the distance to thefloor(f*n)th nearest neighbour, and tricubic weighting is usedfor x which fall within the neighbourhood.
NA
NA
If weights are specified then a weighted least squares is performedwith the weight given to the jth case specified by the jthentry in wt.
The actual value calculated is constant * cMedian(abs(x - center))with the default value of center being median(x), andcMedian being the usual, the ‘low’ or ‘high’ median, seethe arguments description for low and high above.
NA
NA
These functions work with a general univariate state-space modelwith state vector a, transitions a <- T a + R e,e ~ N(0, kappa Q) and observationequation y = Z'a + eta,eta ~ N(0, kappa h).The likelihood is a profile likelihood after estimation ofkappa.
This is a generic function with methods for poly, bs andns: the default method handles scale.  Ifmodel.frame.default encounters such a term whencreating a model frame, it modifies the predvars attribute ofthe terms supplied by replacing the term with one which will work forpredicting new data.  For example makepredictcall.ns addsarguments for the knots and intercept.
Class "manova" differs from class "aov" in selecting adifferent summary method.  Function manova callsaov and then add class "manova" to the resultobject for each stratum.
If x is an array, each dimension must be at least 2, andthe entries should be nonnegative integers.  NA's are notallowed.  Otherwise, x, y and z must have thesame length.  Triples containing NA's are removed.  Allvariables must take at least two different values.
Mauchly's test test for whether a covariance matrix can be assumed tobe proportional to a given matrix.
The null is that the probabilities of being classified into cells[i,j] and [j,i] are the same.
This is a generic function for which methods can be written.  However,the default method makes use of is.na, sort andmean from package base all of which are generic, and sothe default method will work for most classes(e.g., "Date") for which a median is a reasonableconcept.
This is a generic function for which methods can be written.  However,the default method makes use of is.na, sort andmean from package base all of which are generic, and sothe default method will work for most classes(e.g., "Date") for which a median is a reasonableconcept.
The model fitted is additive (constant + rows + columns). Thealgorithm works by alternately removing the row and column medians,and continues until the proportional reduction in the sumof absolute residuals is less than epsor until there have been maxiter iterations.The sum of absolute residuals is printed ateach iteration of the fitting process, if trace.iter is TRUE.If na.rm is FALSE the presence of any NA value inx will cause an error, otherwise NA values are ignored.
model.extract is provided for compatibility with S, which doesnot have the more specific functions.  It is also useful to extracte.g. the etastart and mustart components of aglm fit.
Exactly what happens depends on the class and attributes of the objectformula.  If this is an object of fitted-model class such as"lm", the method will either return the saved model frameused when fitting the model (if any, often selected by argumentmodel = TRUE) or pass the call used when fitting on to thedefault method.  The default method itself can cope with ratherstandard model objects such as those of class"lqs" from package MASS if no otherarguments are supplied.
Exactly what happens depends on the class and attributes of the objectformula.  If this is an object of fitted-model class such as"lm", the method will either return the saved model frameused when fitting the model (if any, often selected by argumentmodel = TRUE) or pass the call used when fitting on to thedefault method.  The default method itself can cope with ratherstandard model objects such as those of class"lqs" from package MASS if no otherarguments are supplied.
model.matrix creates a design matrix from the descriptiongiven in terms(object), using the data in data whichmust supply variables with the same names as would be created by acall to model.frame(object) or, more precisely, by evaluatingattr(terms(object), "variables").  If data is a dataframe, there may be other columns and the order of columns is notimportant.  Any character variables are coerced to factors.  Aftercoercion, all the variables used on the right-hand side of theformula must be logical, integer, numeric or factor.
model.matrix creates a design matrix from the descriptiongiven in terms(object), using the data in data whichmust supply variables with the same names as would be created by acall to model.frame(object) or, more precisely, by evaluatingattr(terms(object), "variables").  If data is a dataframe, there may be other columns and the order of columns is notimportant.  Any character variables are coerced to factors.  Aftercoercion, all the variables used on the right-hand side of theformula must be logical, integer, numeric or factor.
model.matrix creates a design matrix from the descriptiongiven in terms(object), using the data in data whichmust supply variables with the same names as would be created by acall to model.frame(object) or, more precisely, by evaluatingattr(terms(object), "variables").  If data is a dataframe, there may be other columns and the order of columns is notimportant.  Any character variables are coerced to factors.  Aftercoercion, all the variables used on the right-hand side of theformula must be logical, integer, numeric or factor.
model.extract is provided for compatibility with S, which doesnot have the more specific functions.  It is also useful to extracte.g. the etastart and mustart components of aglm fit.
model.extract is provided for compatibility with S, which doesnot have the more specific functions.  It is also useful to extracte.g. the etastart and mustart components of aglm fit.
For type = "effects" give tables of the coefficients for eachterm, optionally with standard errors.
model.extract is provided for compatibility with S, which doesnot have the more specific functions.  It is also useful to extracte.g. the etastart and mustart components of aglm fit.
These functions extract subseries from a time series and plot themall in one frame.  The ts, stl, andStructTS methods use the internally recorded frequency andstart and finish times to set the scale and the seasons.  The defaultmethod assumes observations come in groups of 12 (though this can bechanged).
The underlying model is that the two samples are drawn fromf(x-l) and f((x-l)/s)/s, respectively, where l is acommon location parameter and s is a scale parameter.
NA
na.action is a generic function, and na.action.default itsdefault method.  The latter extracts the "na.action" componentof a list if present, otherwise the "na.action" attribute.
NA
At present these will handle vectors, matrices and data framescomprising vectors and matrices (only).
At present these will handle vectors, matrices and data framescomprising vectors and matrices (only).
At present these will handle vectors, matrices and data framescomprising vectors and matrices (only).
At present these will handle vectors, matrices and data framescomprising vectors and matrices (only).
These are utility functions used to allow predict,fitted and residuals methods for modellingfunctions to compensate for the removal of NAs in the fittingprocess.  They are used by the default, "lm", "glm" and"nls" methods, and by further methods in packages MASS,rpart and survival.  Also used for the scores returned byfactanal, prcomp and princomp.
This is a generic function, and the exact information differs bymethod. naprint.omit reports the number of rows omitted:naprint.default reports an empty string.
These are utility functions used to allow predict,fitted and residuals methods for modellingfunctions to compensate for the removal of NAs in the fittingprocess.  They are used by the default, "lm", "glm" and"nls" methods, and by further methods in packages MASS,rpart and survival.  Also used for the scores returned byfactanal, prcomp and princomp.
NA
Note that arguments after ... must be matched exactly.
Any names of start are passed on to objective and whereapplicable, gradient and hessian.  The parameter vectorwill be coerced to double.
An nls object is a type of fitted model object.  It has methodsfor the generic functions anova, coef,confint, deviance,df.residual, fitted,formula, logLik, predict,print, profile, residuals,summary, vcov and weights.
NA
NA
NA
NA
NA
This is a generic function, with an S4 generic in package stats4.There are methods in this package for objects of classes"lm", "glm", "nls" and"logLik", as well as a default method (which throws anerror, unless use.fallback = TRUE when it looks forweights and residuals components – use with care!).
This is a front end to the C function numeric_deriv, which isdescribed in Writing R Extensions.
There can be more than one offset in a model formula, but - isnot supported for offset terms (and is equivalent to +).
If the right-hand side of the formula contains more than one term,their interaction is taken to form the grouping.
Note that arguments after ... must be matched exactly.
Note that arguments after ... must be matched exactly.
Note that arguments after ... must be matched exactly.
Note that arguments after ... must be matched exactly.
The indices or labels for the leaves in left to right order are retrieved.
The adjustment methods include the Bonferroni correction("bonferroni") in which the p-values are multiplied by thenumber of comparisons.  Less conservative corrections are alsoincluded by Holm (1979) ("holm"), Hochberg (1988)("hochberg"), Hommel (1988) ("hommel"), Benjamini &Hochberg (1995) ("BH" or its alias "fdr"), and Benjamini &Yekutieli (2001) ("BY"), respectively.A pass-through option ("none") is also included.The set of methods are contained in the p.adjust.methods vectorfor the benefit of methods that need to have the method as an optionand pass it on to p.adjust.
The adjustment methods include the Bonferroni correction("bonferroni") in which the p-values are multiplied by thenumber of comparisons.  Less conservative corrections are alsoincluded by Holm (1979) ("holm"), Hochberg (1988)("hochberg"), Hommel (1988) ("hommel"), Benjamini &Hochberg (1995) ("BH" or its alias "fdr"), and Benjamini &Yekutieli (2001) ("BY"), respectively.A pass-through option ("none") is also included.The set of methods are contained in the p.adjust.methods vectorfor the benefit of methods that need to have the method as an optionand pass it on to p.adjust.
For type = "correlation" and "covariance", theestimates are based on the sample covariance. (The lag 0 autocorrelationis fixed at 1 by convention.)
NA
NA
 The pool.sd switch calculates a common SD for allgroups and uses that for all comparisons (this can be useful if somegroups are small). This method does not actually call t.test,so extra arguments are ignored. Pooling does not generalize to paired testsso pool.sd and paired cannot both be TRUE.
Functions that do multiple group comparisons create separatecompare.levels functions (assumed to be symmetrical in iand j) and passes them to this function.
Extra arguments that are passed on to wilcox.test may or maynot be sensible in this context. In particular,only the lower triangle of the matrix of possible comparisons is beingcalculated, so setting alternative to anything other than"two.sided" requires that the levels of g are orderedsensibly.
The Beta distribution with parameters shape1 = a andshape2 = b has density
The binomial distribution with size = n andprob = p has density
The birthday paradox is that a very small number of people, 23,suffices to have a 50–50 chance that two or more of them have the samebirthday.  This function generalises the calculation to probabilitiesother than 0.5, numbers of coincident events other than 2, and numbersof classes other than 365.
If location or scale are not specified, they assumethe default values of 0 and 1 respectively.
The chi-squared distribution with df= n ≥ 0degrees of freedom has density
If rate is not specified, it assumes the default value of1.
The F distribution with df1 = n1 and df2 =n2 degrees of freedom has density
If scale is omitted, it assumes the default value of 1.
The geometric distribution with prob = p has density
The hypergeometric distribution is used for sampling withoutreplacement.  The density of this distribution with parametersm, n and k (named Np, N-Np, andn, respectively in the reference below, where N := m+n is also usedin other references) is given by
The *chisq() functions now take an optional non-centralityargument, so the *nchisq() functions are no longer needed.
The log normal distribution has density
If location or scale are omitted, they assume thedefault values of 0 and 1 respectively.
The e.c.d.f. (empirical cumulative distribution function)Fn is a step function with jumps i/n atobservation values, where i is the number of tied observationsat that value.  Missing values are ignored.
NA
NA
NA
If y is missing, this function creates a time seriesplot, for multivariate series of one of two kinds depending onplot.type.
The negative binomial distribution with size = n andprob = p has density
If mean or sd are not specified they assume the defaultvalues of 0 and 1, respectively.
family is a generic function with methods for classes"glm" and "lm" (the latter returning gaussian()).
Confidence intervals are computed similarly to those ofbinom.test in the one-sample case, and usingbinom.test in the two sample case.
Although formally degree should be named (as it follows...), an unnamed second argument of length 1 will beinterpreted as the degree, such that poly(x, 3) can be used informulas.
Although formally degree should be named (as it follows...), an unnamed second argument of length 1 will beinterpreted as the degree, such that poly(x, 3) can be used informulas.
If lambda is non-positive, it is taken as zero, and the loglink is obtained.  The default lambda = 1 gives the identitylink.
Exactly one of the parameters groups, n, between.var,power, within.var, and sig.level must be passed as NULL,and that parameter is determined from the others. Notice thatsig.level has non-NULL default so NULL must be explicitlypassed if you want it computed.
Exactly one of the parameters n, p1, p2,power, and sig.level must be passed as NULL, and thatparameter is determined from the others.  Notice that sig.levelhas a non-NULL default so NULL must be explicitly passed if youwant it computed.
Exactly one of the parameters n, delta, power,sd, and sig.level must be passed as NULL, and thatparameter is determined from the others.  Notice that the last two havenon-NULL defaults, so NULL must be explicitly passed if you want tocompute them.
The general regression equation which incorporates a constant and alinear trend is used and the corrected t-statistic for a first orderautoregressive coefficient equals one is computed.  To estimatesigma^2 the Newey-West estimator is used.  If lshortis TRUE, then the truncation lag parameter is set totrunc(4*(n/100)^0.25), otherwisetrunc(12*(n/100)^0.25) is used.  The p-values areinterpolated from Table 4.2, page 103 of Banerjee et al(1993).
If 0 < a < 1, the resulting values are within (0,1)(excluding boundaries).In any case, the resulting sequence is symmetric in [0,1], i.e.,p + rev(p) == 1.
The Poisson distribution has density
The basic method is given by Friedman (1984), and is essentially thesame code used by S-PLUS's ppreg.  This code is extremelysensitive to the compiler used.
The calculation is done by a singular value decomposition of the(centered and possibly scaled) data matrix, not by usingeigen on the covariance matrix.  Thisis generally the preferred method for numerical accuracy.  Theprint method for these objects prints the results in a niceformat and the plot method produces a scree plot.
Most prediction methods which are similar to those for linear modelshave an argument newdata specifying the first place to look forexplanatory variables to be used for prediction.  Some considerableattempts are made to match up the columns in newdata to thoseused for fitting, for example that they are of comparable types andthat any factors have the same level set in the same order (or can betransformed to be so).
If newdata is omitted the predictions are based on the dataused for the fit.  In that case how cases with missing values in theoriginal fit is determined by the na.action argument of thatfit.  If na.action = na.omit omitted cases will not appear inthe residuals, whereas if na.action = na.exclude they willappear (in predictions and standard errors), with residual valueNA.  See also napredict.
predict.lm produces predicted values, obtained by evaluatingthe regression function in the frame newdata (which defaults tomodel.frame(object)).  If the logical se.fit isTRUE, standard errors of the predictions are calculated.  Ifthe numeric argument scale is set (with optional df), itis used as the residual standard deviation in the computation of thestandard errors, otherwise this is extracted from the model fit.Setting intervals specifies computation of confidence orprediction (tolerance) intervals at the specified level, sometimesreferred to as narrow vs. wide intervals.
Only the generic function is currently provided in base R, but someadd-on packages have methods. Principally here for S compatibility.
princomp is a generic function with "formula" and"default" methods.
NA
NA
A projection is given for each stratum of the object, so for aovmodels with an Error term the result is a list of projections.
These seek a ‘rotation’ of the factors x %*% T thataims to clarify the structure of the loadings matrix.  The matrixT is a rotation (possibly with reflection) for varimax,but a general linear transformation for promax, with thevariance of the factors being preserved.
Only groups with finite numbers of successes and failures are used.Counts of successes and failures must be nonnegative and hence notgreater than the corresponding numbers of trials which must bepositive.  All finite counts should be integers.
NA
This distribution is obtained as follows.  Let x be a sample ofsize n from a continuous distribution symmetric about theorigin.  Then the Wilcoxon signed rank statistic is the sum of theranks of the absolute values x[i] for which x[i] ispositive.  This statistic takes values between 0 andn(n+1)/2, and its mean and variance are n(n+1)/4 andn(n+1)(2n+1)/24, respectively.
The t distribution with df = n degrees offreedom has density
If ng =nranges is greater than one, R isthe maximum of ng groups of nmeansobservations each.
If min or max are not specified they assume the defaultvalues of 0 and 1 respectively.
The Weibull distribution with shape parameter a andscale parameter b has density given by
This distribution is obtained as follows.  Let x and ybe two random, independent samples of size m and n.Then the Wilcoxon rank sum statistic is the number of all pairs(x[i], y[j]) for which y[j] is not greater thanx[i].  This statistic takes values between 0 andm * n, and its mean and variance are m * n / 2 andm * n * (m + n + 1) / 12, respectively.
The Beta distribution with parameters shape1 = a andshape2 = b has density
The binomial distribution with size = n andprob = p has density
The birthday paradox is that a very small number of people, 23,suffices to have a 50–50 chance that two or more of them have the samebirthday.  This function generalises the calculation to probabilitiesother than 0.5, numbers of coincident events other than 2, and numbersof classes other than 365.
If location or scale are not specified, they assumethe default values of 0 and 1 respectively.
The chi-squared distribution with df= n ≥ 0degrees of freedom has density
If rate is not specified, it assumes the default value of1.
The F distribution with df1 = n1 and df2 =n2 degrees of freedom has density
If scale is omitted, it assumes the default value of 1.
The geometric distribution with prob = p has density
The hypergeometric distribution is used for sampling withoutreplacement.  The density of this distribution with parametersm, n and k (named Np, N-Np, andn, respectively in the reference below, where N := m+n is also usedin other references) is given by
The log normal distribution has density
If location or scale are omitted, they assume thedefault values of 0 and 1 respectively.
The negative binomial distribution with size = n andprob = p has density
If mean or sd are not specified they assume the defaultvalues of 0 and 1, respectively.
The Poisson distribution has density
NA
NA
NA
This distribution is obtained as follows.  Let x be a sample ofsize n from a continuous distribution symmetric about theorigin.  Then the Wilcoxon signed rank statistic is the sum of theranks of the absolute values x[i] for which x[i] ispositive.  This statistic takes values between 0 andn(n+1)/2, and its mean and variance are n(n+1)/4 andn(n+1)(2n+1)/24, respectively.
The t distribution with df = n degrees offreedom has density
If ng =nranges is greater than one, R isthe maximum of ng groups of nmeansobservations each.
quade.test can be used for analyzing unreplicated completeblock designs (i.e., there is exactly one observation in yfor each combination of levels of groups and blocks)where the normality assumption may be violated.
A vector of length length(probs) is returned;if names = TRUE, it has a names attribute.
family is a generic function with methods for classes"glm" and "lm" (the latter returning gaussian()).
family is a generic function with methods for classes"glm" and "lm" (the latter returning gaussian()).
family is a generic function with methods for classes"glm" and "lm" (the latter returning gaussian()).
If min or max are not specified they assume the defaultvalues of 0 and 1 respectively.
The Weibull distribution with shape parameter a andscale parameter b has density given by
This distribution is obtained as follows.  Let x and ybe two random, independent samples of size m and n.Then the Wilcoxon rank sum statistic is the number of all pairs(x[i], y[j]) for which y[j] is not greater thanx[i].  This statistic takes values between 0 andm * n, and its mean and variance are m * n / 2 andm * n * (m + n + 1) / 12, respectively.
NA
The Beta distribution with parameters shape1 = a andshape2 = b has density
The binomial distribution with size = n andprob = p has density
If location or scale are not specified, they assumethe default values of 0 and 1 respectively.
The chi-squared distribution with df= n ≥ 0degrees of freedom has density
read.ftable reads in a flat-like contingency table from afile.  If the file contains the written representation of a flattable (more precisely, a header with all information on names andlevels of column variables, followed by a line with the names of therow variables), no further arguments are needed.  Similarly, flattables with only one column variable the name of which is the onlyentry in the first line are handled automatically.  Other variants canbe dealt with by skipping all header information using skip,and providing the names of the row variables and the names and levelsof the column variable using row.var.names and col.vars,respectively.  See the examples below.
NA
NA
This, as reorder(), is a special case of simply callingfactor(x, levels = levels(x)[....]).
This, as relevel(), is a special case of simply callingfactor(x, levels = levels(x)[....]).
If formula is a data frame and data is missing,formula is used for data with the formula ~ ..
Although reshape() can be used in a variety of contexts, themotivating application is data from longitudinal studies, and thearguments of this function are named and described in those terms. Alongitudinal study is characterized by repeated measurements of thesame variable(s), e.g., height and weight, on each unit being studied(e.g., individual persons) at different time points (which are assumedto be the same for all units). These variables are called time-varyingvariables. The study may include other variables that are measuredonly once for each unit and do not vary with time (e.g., gender andrace); these are called time-constant variables.
NA
NA
The references define the types of residuals: Davison & Snell is agood reference for the usages of each.
The generic accessor functions coef, effects,fitted and residuals can be used to extractvarious useful features of the value returned by lm.
If rate is not specified, it assumes the default value of1.
The F distribution with df1 = n1 and df2 =n2 degrees of freedom has density
If scale is omitted, it assumes the default value of 1.
The geometric distribution with prob = p has density
The hypergeometric distribution is used for sampling withoutreplacement.  The density of this distribution with parametersm, n and k (named Np, N-Np, andn, respectively in the reference below, where N := m+n is also usedin other references) is given by
The log normal distribution has density
If location or scale are omitted, they assume thedefault values of 0 and 1 respectively.
If x is a K-component vector, dmultinom(x, prob)is the probability
The negative binomial distribution with size = n andprob = p has density
If mean or sd are not specified they assume the defaultvalues of 0 and 1, respectively.
The Poisson distribution has density
This distribution is obtained as follows.  Let x be a sample ofsize n from a continuous distribution symmetric about theorigin.  Then the Wilcoxon signed rank statistic is the sum of theranks of the absolute values x[i] for which x[i] ispositive.  This statistic takes values between 0 andn(n+1)/2, and its mean and variance are n(n+1)/4 andn(n+1)(2n+1)/24, respectively.
The primary high-level function is influence.measures which produces aclass "infl" object tabular display showing the DFBETAS foreach model variable, DFFITS, covariance ratios, Cook's distances andthe diagonal elements of the hat matrix.  Cases which are influentialwith respect to any of these measures are marked with an asterisk.
The primary high-level function is influence.measures which produces aclass "infl" object tabular display showing the DFBETAS foreach model variable, DFFITS, covariance ratios, Cook's distances andthe diagonal elements of the hat matrix.  Cases which are influentialwith respect to any of these measures are marked with an asterisk.
The t distribution with df = n degrees offreedom has density
If min or max are not specified they assume the defaultvalues of 0 and 1 respectively.
Apart from the end values, the result y = runmed(x, k) simply hasy[j] = median(x[(j-k2):(j+k2)]) (k = 2*k2+1), computed veryefficiently.
The Weibull distribution with shape parameter a andscale parameter b has density given by
This distribution is obtained as follows.  Let x and ybe two random, independent samples of size m and n.Then the Wilcoxon rank sum statistic is the number of all pairs(x[i], y[j]) for which y[j] is not greater thanx[i].  This statistic takes values between 0 andm * n, and its mean and variance are m * n / 2 andm * n * (m + n + 1) / 12, respectively.
If X1,...,Xm, Xi in R^p isa sample of m independent multivariate Gaussians with mean (vector) 0, andcovariance matrix Σ, the distribution ofM = X'X is W_p(Σ, m).
loess.smooth is an auxiliary function which evaluates theloess smooth at evaluation equally spaced pointscovering the range of x.
NA
Like var this uses denominator n - 1.
Contrasts are usually used to test if certain means aresignificantly different; it can be easier to use se.contrastthan compute them directly from the coefficients.
nls() calls getInitial and theinitial function for these self-starting models.
NA
NA
The stats package provides the S3 generic and a default method.The latter is correct typically for (asymptotically / approximately)generalized gaussian (“least squares”) problems, since it isdefined as
This is a generic function.  Consult the individual modeling functionsfor details on how to use this function.
3 is Tukey's short notation for running mediansof length 3,3R stands for Repeated 3 untilconvergence, andS for Splitting of horizontal stretches of length 2 or 3.
Neither x nor y are allowed to containing missing orinfinite values.
smoothEnds is used to only do the ‘end point smoothing’,i.e., change at most the observations closer to the beginning/endthan half the window k.  The first and last value are computed usingTukey's end point rule, i.e.,sm[1] = median(y[1], sm[2], 3*sm[2] - 2*sm[3], na.rm=TRUE).
NA
NA
The raw periodogram is not a consistent estimator of the spectral density,but adjacent values are asymptotically independent. Hence a consistentestimator can be derived by smoothing the raw periodogram, assuming thatthe spectral density is smooth.
The cosine-bell taper is applied to the first and last p[i]observations of time series x[, i].
spectrum is a wrapper function which calls the methodsspec.pgram and spec.ar.
The inputs can contain missing values which are deleted, so at leastone complete (x, y) pair is required.If method = "fmm", the spline used is that of Forsythe, Malcolmand Moler (an exact cubic is fitted through the four points at eachend of the data, and this is used to determine the end conditions).Natural splines are used when method = "natural", and periodicsplines when method = "periodic".
The inputs can contain missing values which are deleted, so at leastone complete (x, y) pair is required.If method = "fmm", the spline used is that of Forsythe, Malcolmand Moler (an exact cubic is fitted through the four points at eachend of the data, and this is used to determine the end conditions).Natural splines are used when method = "natural", and periodicsplines when method = "periodic".
The inputs can contain missing values which are deleted, so at leastone complete (x, y) pair is required.If method = "fmm", the spline used is that of Forsythe, Malcolmand Moler (an exact cubic is fitted through the four points at eachend of the data, and this is used to determine the end conditions).Natural splines are used when method = "natural", and periodicsplines when method = "periodic".
NA
NA
NA
NA
NA
NA
NA
NA
NA
NA
This model is a generalization of the SSasymp model inthat it reduces to SSasymp when pwr is unity.
These are generic functions, which will use thetsp attribute of x if it exists.Their default methods decode the start time from the original timeunits, so that for a monthly series 1995.5 is representedas c(1995, 7). For a series of frequency f, timen+i/f is presented as c(n, i+1) (even for i = 0and f = 1).
NA
step uses add1 and drop1repeatedly; it will work for any method for which they work, and thatis determined by having a valid method for extractAIC.When the additive constant can be chosen so that AIC is equal toMallows' Cp, this is done and the tables are labelledappropriately.
NA
The seasonal component is found by loess smoothing theseasonal sub-series (the series of all January values, ...); ifs.window = "periodic" smoothing is effectively replaced bytaking the mean. The seasonal values are removed, and the remaindersmoothed to find the trend. The overall level is removed from theseasonal component and added to the trend component. This process isiterated a few times.  The remainder component is theresiduals from the seasonal plus trend fit.
Structural time series models are (linear Gaussian) state-spacemodels for (univariate) time series based on a decomposition of theseries into a number of components. They are specified by a set oferror variances, some of which may be zero.
NA
print.summary.glm tries to be smart about formatting thecoefficients, standard errors, etc. and additionally gives‘significance stars’ if signif.stars is TRUE.The coefficients component of the result gives the estimatedcoefficients and their estimated standard errors, together with theirratio.  This third column is labelled t ratio if thedispersion is estimated, and z ratio if the dispersion is known(or fixed by the family).  A fourth column gives the two-tailedp-value corresponding to the t or z ratio based on a Student t orNormal reference distribution.  (It is possible that the dispersion isnot known and there are no residual degrees of freedom from which toestimate it.  In that case the estimate is NaN.)
print.summary.lm tries to be smart about formatting thecoefficients, standard errors, etc. and additionally gives‘significance stars’ if signif.stars is TRUE.
The summary.manova method uses a multivariate test statisticfor the summary table.  Wilks' statistic is most popular in theliterature, but the default Pillai–Bartlett statistic is recommendedby Hand and Taylor (1987).
NA
supsmu is a running lines smoother which chooses between threespans for the lines. The running lines smoothers are symmetric, withk/2 data points each side of the predicted point, and values ofk as 0.5 * n, 0.2 * n and 0.05 * n, wheren is the number of data points.  If span is specified,a single smoother with span span * n is used.
NA
alternative = "greater" is the alternative that x has alarger mean than y. For the one-sample case: that the mean is positive.
The model object must have a predict method that acceptstype = "terms", e.g., glm in the stats package,coxph and survreg inthe survival package.
There are methods for classes "aovlist", and "terms""formula" (see terms.formula):the default method just extracts the terms component of theobject, or failing that a "terms" attribute (as used bymodel.frame).
Not all of the options work in the same way that they do in S and notall are implemented.
These are all generic functions, which will use thetsp attribute of x if it exists. timeand cycle have methods for class ts that coercethe result to that class.
NA
The function ts is used to create time-series objects.  Theseare vectors or matrices with class of "ts" (and additionalattributes) which represent data which has been sampled at equispacedpoints in time.  In the matrix case, each column of the matrixdata is assumed to contain a single (univariate) time series.Time series must have at least one observation, and although they neednot be numeric there is very limited support for non-numeric series.
As a special case, ... can contain vectors or matrices of thesame length as the combined time series of the time series present, aswell as those of a single row.
NA
As a special case, ... can contain vectors or matrices of thesame length as the combined time series of the time series present, aswell as those of a single row.
This is a generic function. It will generally plot the residuals,often standardized, the autocorrelation function of the residuals, andthe p-values of a Portmanteau test for all lags up to gof.lag.
The tsp attribute gives the start time in time units,the end time and the frequency (the number of observations per unit oftime, e.g. 12 for a monthly series).
The tsp attribute gives the start time in time units,the end time and the frequency (the number of observations per unit oftime, e.g. 12 for a monthly series).
NA
This is a generic function: the description here applies to the methodfor fits of class "aov".
Note that arguments after ... must be matched exactly.
NA
NA
Either or both of old and new can be objects such aslength-one character vectors which can be coerced to a formula viaas.formula.
For cov and cor one must either give a matrix ordata frame for x or give both x and y.
The null hypothesis is that the ratio of the variances of thepopulations from which x and y were drawn, or in thedata to which the linear models x and y were fitted, isequal to ratio.
NA
These seek a ‘rotation’ of the factors x %*% T thataims to clarify the structure of the loadings matrix.  The matrixT is a rotation (possibly with reflection) for varimax,but a general linear transformation for promax, with thevariance of the factors being preserved.
vcov() is a generic function and functions with names beginningin vcov. will be methods for this function.Classes with methods for this function include:lm, mlm, glm, nls,summary.lm, summary.glm,negbin, polr, rlm (in package MASS),multinom (in package nnet)gls, lme (in package nlme),coxph and survreg (in package survival).
This is a generic function and methods can be defined for the firstargument x: apart from the default methods there are methodsfor the date-time classes "POSIXct", "POSIXlt","difftime" and "Date".  The default method will work forany numeric-like object for which [, multiplication, divisionand sum have suitable methods, including complex vectors.
Weighted residuals are based on the deviance residuals, which fora lm fit are the raw residuals Rimultiplied by wi^0.5, where wi are theweights as specified in lm's call.
NA
The formula interface is only applicable for the 2-sample tests.
The start and end times can be specified as for ts. Ifthere is no observation at the new start or end,the immediately following (start) or preceding (end)observation time is used.
The start and end times can be specified as for ts. Ifthere is no observation at the new start or end,the immediately following (start) or preceding (end)observation time is used.
read.ftable reads in a flat-like contingency table from afile.  If the file contains the written representation of a flattable (more precisely, a header with all information on names andlevels of column variables, followed by a line with the names of therow variables), no further arguments are needed.  Similarly, flattables with only one column variable the name of which is the onlyentry in the first line are handled automatically.  Other variants canbe dealt with by skipping all header information using skip,and providing the names of the row variables and the names and levelsof the column variable using row.var.names and col.vars,respectively.  See the examples below.
There is a summary method for contingency table objects createdby table or xtabs(*, sparse = FALSE), which gives basicinformation and performs a chi-squared test for independence offactors (note that the function chisq.test currentlyonly handles 2-d tables).
